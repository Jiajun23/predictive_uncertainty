{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRNN Model Selection\n",
    "\n",
    "This notebook performs a grid search for the best performing neural network configuration for\n",
    "quantile regression. As basic structure for the neural network a feed forward network is used and\n",
    "the following paramters are varied:\n",
    "\n",
    "- Network depth: 1 to 4 layers\n",
    "- Network width: 16, 32, 64, 128, 256, 512 neurons\n",
    "- Activation functions: linear, Sigmoid, ReLU, atan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ipyparallel Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "c     = ipp.Client(profile='mpi')\n",
    "lview = c.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:1] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:2] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:3] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:4] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:5] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:6] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:7] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:8] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:9] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:10] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:11] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:12] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:13] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:14] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:15] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:16] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:17] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:18] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:19] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:20] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:21] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:22] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n",
      "[stdout:23] \n",
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] Using TensorFlow backend.\n",
      "[stderr:1] Using TensorFlow backend.\n",
      "[stderr:2] Using TensorFlow backend.\n",
      "[stderr:3] Using TensorFlow backend.\n",
      "[stderr:4] Using TensorFlow backend.\n",
      "[stderr:5] Using TensorFlow backend.\n",
      "[stderr:6] Using TensorFlow backend.\n",
      "[stderr:7] Using TensorFlow backend.\n",
      "[stderr:8] Using TensorFlow backend.\n",
      "[stderr:9] Using TensorFlow backend.\n",
      "[stderr:10] Using TensorFlow backend.\n",
      "[stderr:11] Using TensorFlow backend.\n",
      "[stderr:12] Using TensorFlow backend.\n",
      "[stderr:13] Using TensorFlow backend.\n",
      "[stderr:14] Using TensorFlow backend.\n",
      "[stderr:15] Using TensorFlow backend.\n",
      "[stderr:16] Using TensorFlow backend.\n",
      "[stderr:17] Using TensorFlow backend.\n",
      "[stderr:18] Using TensorFlow backend.\n",
      "[stderr:19] Using TensorFlow backend.\n",
      "[stderr:20] Using TensorFlow backend.\n",
      "[stderr:21] Using TensorFlow backend.\n",
      "[stderr:22] Using TensorFlow backend.\n",
      "[stderr:23] Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "%env OMP_NUM_THREADS=1\n",
    "import matplotlib; matplotlib.use(\"agg\")\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/simonpf/src/typhon/\")\n",
    "from typhon.retrieval.qrnn import QRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "quantiles = np.array([0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95])\n",
    "def create_model(depth, width, act_fn):\n",
    "    qrnn = QRNN(5, quantiles, depth, width, act_fn)\n",
    "    return qrnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "Cross validation is used to determine the expected values of the quantile loss for each estimated quantile as well as the CRPS score of the estimated posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "from typhon.retrieval.scores import mean_quantile_score\n",
    "x_train = np.load(\"src/atms_simulations/data/x_train_5.npy\")\n",
    "y_train = np.load(\"src/atms_simulations/data/y_train_5.npy\")\n",
    "\n",
    "def score(y_pred, y_test):\n",
    "    quantile_scores = mean_quantile_score(y_pred, y_test, quantiles,\n",
    "                                          convergence_epochs = 1,\n",
    "                                          learning_rate_minimum = 1e-4,\n",
    "                                          maximum_epochs = 400)\n",
    "    crps = QRNN.crps(y_pred, y_test, quantiles)\n",
    "    return np.append(quantile_scores, crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(config):\n",
    "    depth, width, act_fn = config\n",
    "    qrnn = create_model(depth, width, act_fn)\n",
    "    return qrnn.cross_validation(x_train, y_train, 1.0, n_folds = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depths = [6, 8, 10]\n",
    "widths = [8, 16, 32, 64, 96, 128, 256, 512]\n",
    "act_funcs = [\"linear\", \"tanh\", \"sigmoid\", \"relu\"]\n",
    "act_funcs = [\"relu\"]\n",
    "configs = [(d, w, f) for d in depths for w in widths for f in act_funcs]\n",
    "async_results = lview.map_async(run_cross_validation, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 8, 'relu')\n",
      "Result: (0.98188435579109201, 0.015167518710878368)\n",
      "(6, 16, 'relu')\n",
      "Result: (0.91563199266052242, 0.0053207143314315912)\n",
      "(6, 32, 'relu')\n",
      "Result: (0.90462827638053889, 0.0078360805431844475)\n",
      "(6, 64, 'relu')\n",
      "Result: (0.89890136842918411, 0.0057325606718215448)\n",
      "(6, 96, 'relu')\n",
      "Result: (0.89850282076263421, 0.0077331700836060701)\n",
      "(6, 128, 'relu')\n",
      "Result: (0.89762011726379387, 0.0067965099447727063)\n",
      "(6, 256, 'relu')\n",
      "Result: (0.8965844658699037, 0.0066490351489058505)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i,r in enumerate(async_results):\n",
    "    print(configs[i])\n",
    "    print(\"Result: \" + str(r))\n",
    "    results += [(configs[i], r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.zeros((5, 7, 4, 2))\n",
    "act_indices = {\"linear\" : 0, \"tanh\" : 1, \"sigmoid\" : 2, \"relu\" : 3}\n",
    "for ((n_l, n_n, act), (m, s)) in results:\n",
    "    data[n_l, int(np.log2(n_n)) - 3, act_indices[act], :] = np.array([m, s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/model_selection_structure\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_settings\n",
    "f, axs = plt.subplots(1, 3, figsize = (15, 5))\n",
    "\n",
    "x = 2.0 ** np.arange(3, 10)\n",
    "\n",
    "ax = axs[0]\n",
    "for i in range(4):\n",
    "    m = data[i + 1, :, 1, 0]\n",
    "    s = data[i + 1, :, 1, 1]\n",
    "    ax.plot(x, m, lw = 2)\n",
    "    ax.fill_between(x, m + s, m - s, alpha = 0.2)\n",
    "    ax.set_ylim([0.88, 1.1])\n",
    "    ax.set_xscale(\"log\")\n",
    "    \n",
    "ax = axs[1]\n",
    "for i in range(4):\n",
    "    m = data[i + 1, :, 2, 0]\n",
    "    s = data[i + 1, :, 2, 1]\n",
    "    ax.plot(x, m, lw = 2)\n",
    "    ax.fill_between(x, m + s, m - s, alpha = 0.2)\n",
    "    ax.set_ylim([0.88, 1.1])\n",
    "    ax.set_xscale(\"log\")\n",
    "    \n",
    "ax = axs[2]\n",
    "for i in range(4):\n",
    "    m = data[i + 1, :, 3, 0]\n",
    "    s = data[i + 1, :, 3, 1]\n",
    "    ax.plot(x, m, lw = 2)\n",
    "    ax.fill_between(x, m + s, m - s, alpha = 0.2)\n",
    "    ax.set_ylim([0.88, 1.1])\n",
    "    ax.set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "res = {\"linear\"  : np.zeros((len(depths), len(widths), 2)),\n",
    "       \"relu\"    : np.zeros((len(depths), len(widths), 2)),\n",
    "       \"tanh\"    : np.zeros((len(depths), len(widths), 2)),\n",
    "       \"sigmoid\" : np.zeros((len(depths), len(widths), 2))}\n",
    "inds = dict(zip(widths, range(len(widths))))\n",
    "\n",
    "for ((n_layers, width, act), (mean, std)) in results:\n",
    "    res[act][int(n_layers), inds[width], 0] = mean\n",
    "    res[act][int(n_layers), inds[width], 1] = std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_table(res, fn = None):\n",
    "    s = r\"\"\n",
    "    for j in range(res.shape[1]):\n",
    "        s += r\" & $n_n = {0}$ \".format(widths[j])\n",
    "    s += r\"\\\\ \\hline\"\n",
    "    for i in range(res.shape[0]):\n",
    "        s += \"$n_h =  {0}$ & \".format(i)\n",
    "        for j in range(res.shape[1] - 1):\n",
    "            s += r\"${:.2} \\pm {:.2}$ & \".format(res[i, j, 0], res[i, j, 1])\n",
    "        s += r\"${:.2} \\pm {:.2}$ \\\\ \".format(res[i, j, 0], res[i, j, 1])\n",
    "    s+=\"\\hline\"\n",
    "        \n",
    "    if fn:\n",
    "        f = open(fn, \"w\")\n",
    "        f.write(s)\n",
    "        f.close()\n",
    "    else:\n",
    "        return s    \n",
    "    \n",
    "def print_table2(res1, res2, fn = None):\n",
    "    s = \"\"\n",
    "    for i in range(res1.shape[0]):\n",
    "        s += \"$n_h = i$ &\"\n",
    "        for j in range(res1.shape[1]):\n",
    "            s += r\"${:.2} \\pm {:.2}$ & \".format(res1[i, j, 0], res1[i, j, 1])\n",
    "        for j in range(res2.shape[1] - 1):\n",
    "            s += r\"${:.2} \\pm {:.2}$ & \".format(res2[i, j, 0], res2[i, j, 1])\n",
    "        s += r\"${:.2} \\pm {:.2}$ \\\\ \".format(res2[i, j, 0], res2[i, j, 1])\n",
    "        \n",
    "    if fn:\n",
    "        f = open(fn, \"w\")\n",
    "        f.write(s)\n",
    "        f.close()\n",
    "    else:\n",
    "        return s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_table(res[\"linear\"],  \"tables/linear.tbl\")\n",
    "print_table(res[\"sigmoid\"], \"tables/sigmoid.tbl\")\n",
    "print_table(res[\"tanh\"],    \"tables/tanh.tbl\")\n",
    "print_table(res[\"relu\"],    \"tables/relu.tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters\n",
    "\n",
    "Below the effect of training parameters on the QRNN performance is analyzed. This is again done by performing 10-fold cross-validation with varying training parameters. To save computation time the parameters are varied only independently. The following parameters are investigated:\n",
    "\n",
    "- batch size: 128, 256, 512, 1024\n",
    "- learning rate decay: 1.5, 2.0, 5.0, 10.0\n",
    "- learning rate minimum: $10^{-4},10^{-5}, 10^{-6}, 10^{-7}, 10^{-8}$\n",
    "- convergence epochs: 1, 2, 4, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cross_validation(config):\n",
    "    batch_size, lr_decay, lr_minimum, convergence_epochs = config\n",
    "    qrnn = create_model(3, 128, \"relu\")\n",
    "    return qrnn.cross_validation(x_train, y_train, 1.0, n_folds = 10,\n",
    "                                 batch_size = batch_size,\n",
    "                                 learning_rate_decay = lr_decay,\n",
    "                                 learning_rate_minimum = lr_minimum,\n",
    "                                 convergence_epochs = convergence_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "configs = []\n",
    "configs += [(bs, 2.0, 1e-6, 2) for bs in [128, 256, 512, 1024]]\n",
    "configs += [(256, lrd, 1e-6, 2) for lrd in [1.5, 2.0, 5.0, 10.0]]\n",
    "configs += [(256, 2.0, 10 ** -lrm, 2) for lrm in [4, 5, 6, 7, 8]]\n",
    "configs += [(256, 2.0, 1e-6, ce) for ce in [1, 2, 4, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "async_results = lview.map_async(run_cross_validation, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 2.0, 1e-06, 2)\n",
      "Result: (0.90578844951438897, 0.0081078108798440015)\n",
      "(256, 2.0, 1e-06, 2)\n",
      "Result: (0.91163818877601632, 0.0064749937914909033)\n",
      "(512, 2.0, 1e-06, 2)\n",
      "Result: (0.92271153948783868, 0.020830085622155849)\n",
      "(1024, 2.0, 1e-06, 2)\n",
      "Result: (0.93683845387268061, 0.020763810960643149)\n",
      "(256, 1.5, 1e-06, 2)\n",
      "Result: (0.91013961412239086, 0.0063265646771658041)\n",
      "(256, 2.0, 1e-06, 2)\n",
      "Result: (0.91320789633178712, 0.012580609311199118)\n",
      "(256, 5.0, 1e-06, 2)\n",
      "Result: (0.91662052987861631, 0.01052368406147664)\n",
      "(256, 10.0, 1e-06, 2)\n",
      "Result: (0.91795649431800841, 0.015360465991840955)\n",
      "(256, 2.0, 0.0001, 2)\n",
      "Result: (0.91043027124023435, 0.006420343418558328)\n",
      "(256, 2.0, 1e-05, 2)\n",
      "Result: (0.91255380694198607, 0.0070071830737801141)\n",
      "(256, 2.0, 1e-06, 2)\n",
      "Result: (0.91766805414772035, 0.010873377442336652)\n",
      "(256, 2.0, 1e-07, 2)\n",
      "Result: (0.91874591431236274, 0.014040805722100822)\n",
      "(256, 2.0, 1e-08, 2)\n",
      "Result: (0.91810450534629806, 0.021963042344801943)\n",
      "(256, 2.0, 1e-06, 1)\n",
      "Result: (0.91563019120407108, 0.017960504442175316)\n",
      "(256, 2.0, 1e-06, 2)\n",
      "Result: (0.91875616248893743, 0.019802076030250741)\n",
      "(256, 2.0, 1e-06, 4)\n",
      "Result: (0.90666980062294011, 0.0084810920075397006)\n",
      "(256, 2.0, 1e-06, 8)\n",
      "Result: (0.90356772063827528, 0.005805702090364951)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i,r in enumerate(async_results):\n",
    "    print(configs[i])\n",
    "    print(\"Result: \" + str(r))\n",
    "    results += [(configs[i], r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "configs = []\n",
    "configs += [(64, lrd, 1e-6, 2) for lrd in [1.2, 1.5, 2.0]]\n",
    "configs += [(64, 2.0, 10 ** -lrm, 2) for lrm in [3, 4, 5, 6]]\n",
    "configs += [(64, 2.0, 1e-6, ce) for ce in [1, 2, 4, 8]]\n",
    "async_results = lview.map_async(run_cross_validation, configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1.2, 1e-06, 2)\n",
      "Result: (0.89952332299423199, 0.0065377489453016082)\n",
      "(64, 1.5, 1e-06, 2)\n",
      "Result: (0.90161739125633233, 0.0086176645337436245)\n",
      "(64, 2.0, 1e-06, 2)\n",
      "Result: (0.90152903881454471, 0.00615886249641244)\n",
      "(64, 2.0, 0.001, 2)\n",
      "Result: (0.91008012251090997, 0.0050518619193384105)\n",
      "(64, 2.0, 0.0001, 2)\n",
      "Result: (0.90170960564231883, 0.0087728255696332968)\n",
      "(64, 2.0, 1e-05, 2)\n",
      "Result: (0.90167167879104626, 0.0068331846874113526)\n",
      "(64, 2.0, 1e-06, 2)\n",
      "Result: (0.900728275522232, 0.0093753006703030176)\n",
      "(64, 2.0, 1e-06, 1)\n",
      "Result: (0.90539736339759824, 0.0086392432600369915)\n",
      "(64, 2.0, 1e-06, 2)\n",
      "Result: (0.90346704487419127, 0.0066362010197610699)\n",
      "(64, 2.0, 1e-06, 4)\n",
      "Result: (0.90078221081542953, 0.0075512973896067958)\n",
      "(64, 2.0, 1e-06, 8)\n",
      "Result: (0.8986799619350434, 0.0041661199044197043)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i,r in enumerate(async_results):\n",
    "    print(configs[i])\n",
    "    print(\"Result: \" + str(r))\n",
    "    results += [(configs[i], r)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

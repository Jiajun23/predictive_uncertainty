#+TITLE: A neural network-based method to estimate uncertainty in remote sensing retrievals
#+AUTHOR: Simon Pfreundschuh
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage{macros}
#+LATEX_HEADER: \usepackage{siunitx}
#+LATEX_HEADER: \usepackage{adjustbox}
#+LATEX_HEADER: \usepackage{subcaption}
#+LATEX_HEADER: \usepackage{natbib}

* Abstract

   Quantile regression neural networks, a neural network-based regression
   method, is proposed as a method for the estimation of quantiles of the
   posterior distribution of scalar retrieval quantities. It is shown that
   the method is able to learn to predict quantiles of the posterior
   distribution from a training database consisting of simulated or
   observed brightness temperatures and corresponding values of
   the retrieval quantity. A synthetic validation case is presented
   where the method is compared to the true posterior distribution obtained from
   Markov Chain Monte Carlo simulations as well as another retrieval method
   based on monte carlo integration and importance sampling. Finally the
   method is applied to estimate cloud top height from MODIS
   observations. It is shown that quantile regression  yields
   statistically consistent uncertainty estimates on a per-retrieval basis
   and that the obtained uncertinty estimates are better calibrated than
   uncertainty estimates based on error statistics computed on an
   independent test set.

* Introduction

** Motivation

   The retrieval of atmospheric quantities from remote sensing measurements
   constitutes an inverse problem and thus generally is /ill posed/. This means
   that even in the absence of measurement errors, the problem may not allow a
   unique solution. The Bayesian formulation of the inverse problem
   \cite{tarantola, rodgers} provides a systematic and theoretically sound
   framework to handle the ill-posedness of remote sensing retrievals by
   replacing the search for a unique solution of the retrieval problem with that
   for a probability distribution describing the knowledge about the retrieval
   quantity after a measurement has been performed. The Bayesian solution of the
   retrieval problem is the a /posteriori distribution/ or /posterior/
   $\pcond{x}{\vec{y}}$, that is the conditional distribution of the retrieval
   quantity $x$ given a vector of measurement values $\vec{y}$.

   The forward problem underlying the inverse problem of retrieving an
   atmospheric quantity from a remote sensing measurement is given by the
   transmission of radiation through the atmosphere (and its detection). In
   cases that allow a sufficiently precise and efficient modeling of the
   measurement process, a numerical forward model can be used to guide to
   solution of the inverse problem. These so called /physical retrievals/ have
   the advantage of allowing an accurate analysis of uncertainties entering the
   retrieval calculations as well as conveying a certain sense of understanding
   of the atmsopheric and radiative processes involved. In general, however, an
   exact or even approximate computation of the true posterior distribution is
   computationally too demanding to be practical. In contrast to physical
   retrievals, /empirical retrievals/ are based solely on observations and
   corresponding measurements of the retrieval quantity obtained from other
   measurement techniques and thus do not involve any physical modeling.

   The optimal estimation method (OEM) as proposed by \cite{rodgers} simplifies
   the retrieval problem by assuming the prior knowledge and the measurement
   uncertainty to be described by Gaussian distributions and the forward model
   to be only slightly non-linear. In this case the posterior distribution is
   approximately Gaussian and the solution is obtained by computing its mean and
   covariance matrix. In cases where an efficient forward model for the
   computation of simulated measurements and corresponding Jacobians is available,
   the OEM has become the quasi standard method for Bayesian retrievals. However,
   even neglecting the validity of the assumptions of Gaussianity and linearity,
   the method is unsuitable for retrievals that involve complex radiative
   processes, such as for example scattering, that are too expensive to model
   online during the retrieval.

   Another Bayesian method \cite{kummerow_1, olson_1} to solve the inverse
   problem that avoids the limitations of assumed Gaussianity and computational
   complexity of the forward model is based on importance sampling of
   simulations from a retrieval database. In the following the method will be
   referred to as Bayesian Monte Carlo integration (BMCI). BMCI can be used for
   physical as well as empirical retrivals. When BMCI used within a physical
   retrieval, the foward model is needed only be to create the retrieval
   database and its evaluation is thus not critical for performance of the
   retrieval. Nevertheless, naive implementations of BMCI may require the
   traversal of large databases, which limit the computational performance of
   the retrieval.

   If the Bayesian inverse problem is cast into the more general problem of
   estimating a conditional distribution $\pcond{x}{\vec{y}}$, also general
   regression techniques can be used to solve the retieval inverse problem. In
   particular neural networks have become a popular method to build retrievals
   and offer the advantage of computational efficiency and high flexibility
   in incorporating ancillary data into the retrieval. Most of these retrievals,
   however, neglect the probabilistic character of the retrieval problem and
   provide only a scalar estimate of the retrieval quantity.

   In this article neural networks are used to estimate the posterior
   distribution of the Bayesian retrieval problem. It is argued that this
   approach provides a more complete treatment of the retrieval problem and
   a better way of dealing with its inherent uncertainties than the 
   non-probabilistic approach. It is shown that neural networks can
   successfully learn to represent the posterior distributions of Bayesian
   inverse problems and yield statistically consistent estimates of uncertainty.
   This modified application of neural networks thus aims to combine the
   theoretically sound Bayesian treatment of inverse problems with the
   flexibility and computational efficiency of neural network based
   retrivals.
   
** Related Work
   
   Bayesian remote sensing retrievals data back to at least the seminal
   work by Rodgers \cite{rodgers_1, rodgers_2, rodgers}.
   
   The use of the BMCI method was first proposed by Kummerow et al. in
   \cite{kummerow_1} and has since been applied in numerous retrieval algorithms
   mostly for the retrieval of hydrometeor profiles from passive or combined
   microwave observations 
   \cite{olson_1, bauer_1, tassa_1, di_michele_1, petty_1, viltard_1} but also
   cloud ice \cite{rydberg_1}. It is also used in the Goddard profiling
   algorithm (GPROF) \cite{gprof}.

   Also numerous applications of regression techniques, in particular neural
   networks, to remote sensing retrievals can be found in the literature.
   Jimenez \cite{jimenez} showed that neural networks can be used to retrieve
   ozone profiles from passive microwave limb-sounding observations and that
   they achieve similar performance on a test set of simulated measurements
   as OEM retrievals. Aires et al. \cite{aires_1, aires_2, aires_3} have shown
   that Bayesian neural networks allow a formal treatment of the retrieval
   problem and errors along the lines of the framework developed by Rodgers.
   Cerdeña e al. \cite{cerdena} use neural networks fitted to simulated
   measurements of the NOAA Advanced Very High Resolution Radiometer
   to retrieve effective droplet radius, cloud optical thickness and
   cloud temperature from water clouds.

   Just as BMCI, neural networks can be used to implement combined retrievals
   that exploit synergies between different types of sensors \cite{minnis, kox}.
   Holl et al. \cite{holl} use neural networks trained on cloud properties
   obtained from active sensors to retrieve ice water path from passive infrared
   and microwave measurements. Strandgren et al. \cite{strandgren} use several
   neural networks to perform cloud and opaqueness classification as well as
   retrieve ice water path and cloud optical depth. Håkansson et al. use collocated
   MODIS and CALIOP observations to retrieve cloud top pressure from MODIS
   observations.

   While far from being a novel technique, neural network have seen a renewed
   interest throughout the last decade due to their success on a number of
   machine learning problems \cite{goodfellow}. This success is to large extent
   driven by the increased availability of computational power that allows the
   training of deep models on large amounts of data. While deep learning
   techniques have been successfully applied to a range of scientific problems
   \cite{baldi, lecun, leung}, the quantification of uncertainty still remains an open
   question. While a Bayesian formalism can be applied to obtain probabilistic
   predictions, its use is hampered by increased computational cost during
   training and prediction as well as its rather involved implementation. In
   \cite{lakshminarayanan}, Lakshminarayanan propose the use of deep ensembles
   trained using proper scoring rules and adversarial examples to obtain
   well-calibrated probabilistic predictions. This is the approach on which the
   method proposed in this article builds. However, instead of the negative
   log-likelihood of a Gaussian distribution, a quantile loss function is
   used as training criterion. This technique, known as quantile regression,
   was introduced by Koenker \cite{koenker} and has been applied mainly
   in econometrics \cite{taylor} but also meteorology \cite{cannon}.

   
** Novelty and Significance
   
   To the best knowledge of the authors, this is the first application of
   quantile regression for the estimation of posterior distribution of
   Bayesian inverse problems. Furthermore, the implementation proposed in this
   article is the first to combine recent trends in neural network
   techniques, concretely deep networks and stochastic gradient descent
   training, that allow learning from very large training sets as they are
   typically encountered in remote sensing applications.
   
   In contrast to previous proposals to extend the application of neural networks
   to Bayesian retrievals, the method proposed here has the advantage of requiring
   only minimal modification to the standard neural network training and evaluation
   pipeline and conserving the performance benefits of hardware-optimized neural
   network implementations.
   
   The results presented in this article indicate that quantile regression neural
   networks are a viable alternative to comparable, inherently Bayesian methods
   to solve inverse problems while at the same time offering the flexibility
   and computational performance provided by neural networks. Similarly, it is
   demsontrated that with only slight modifications, neural network retrievals
   can be interpreted in a Bayesian way.

** Summary of Contributions
   
   Quantile regression neural networks are presented as method to solve
   Bayesian inverse problems arising from remote sensing retrievals.

   A synthetic retrieval case is presented and used to characterize the
   performance of BMCI and quantile regression. The predictions are compared
   to retrievals obtained form Markov Chain Monte Carlo simulations and it
   is shown that both methods are able to successfully estimate the posterior
   distribution of remote sensing retrievals.
   
   A real world application of quantile regression neural networks to the
   retrieval of cloud top height pressure from MODIS observations is presented.
   It is demsonstrated how the method can be used obtain statistically
   consistent estimates of uncertainty on a per-retrieval basis and that
   these are better calibrated than estimates based on error statistics
   computed over a test set.

   In conjuction with this article, implementations of all three retrieval 
   methods considered are released as part of the typhon package, with the
   main motivation of providing an efficient and easy to use implementation
   of quantile regression neural networks. Furthermore, all code used to
   produce the results presented in this article are released in the form
   of jupyter notebooks through a public repository.

* Theory
  
   This section briefly introduces the general problem formulation and
   notation as well as the retrieval methods on which the experiments
   in Section 3 and 4 are based.
 
   For the sake of simplicity, only the retrieval of a single scalar
   quantity is considered in this analysis. The general
   problem is thus to retrieve an atmospheric quantity $x \in \mathbb{R}$
   from an indirect measurement $\vec{y} \in \mathbb{R}^m$. Applying the
   Bayesian framework \cite{tarantola}, the problem may be formulated as
   finding  the posterior distribution $\pcond{x}{\vec{y}}$ of
   $x$ given the measurement $\vec{y}$. The formal solution of the
   Bayesian inverse problem is given by means of /Bayes theorem/:

   \begin{align}\label{eq:posterior}
       \pcond{x}{\mathbf{y}} \propto \pcond{\mathbf{y}}{x} \prop{x}
   \end{align}


   In most cases, however, this general solution is of little use since
   both the conditional probability of the observed measurement
   $\pcond{\vec{y}}{x}$ and the a priori distribution $\prop{x}$ cannot
   be expressed in closed form and hence only approximations
   of the posterior $\pcond{x}{\vec{y}}$ can be obtained as solutions
   of the inverse problem.

** Markov Chain Monte Carlo

    Markov Chain Monte Carlo (MCMC) or Markov Chain simulation is a method
    to generate samples from arbitrary posterior distributions. It
    is based on drawing samples from an approximate distribution and
    refining these in a way such that the resulting sample distribution
    converges to the true distribution \cite{bda}. The method thus allows
    direct sampling from the posterior distribution, at least in an
    asymptotic sense, which is why it is used in this article to validate
    the estimates of the posterior distribution obtained using the BMCI and
    QRNN methods.

    Since Markov Chain simulation is an iterative method that consecutively
    improves the approximation of the target distribution, it is imperative to
    assess the convergence of the simulation to ensure that the results are
    sufficiently close to target distribution. For values $x_{i,j}$ obtained
    from $i = 1,\ldots,m$ runs started from different initial states each
    yielding $j = 1,\ldots,n$ samples, this can be achieved by estimating the
    scale reduction factor $\hat{R}$ \cite{bda}
    
    \begin{align}
    \hat{\text{var}}^+(x | \vec{y}) &= \frac{1}{nm}
         \sum_{j = 1}^m \sum_{i = 1}^n (x_{i,j} - \bar{x}_{\cdot, j})^2
          + \frac{1}{(m - 1)n} \sum_{j = 1}^m(\bar{x}_{\cdot, j} - \bar{x}_{\cdot, \cdot})^2 \\
          \hat{R}^2 &= \frac{\hat{\text{var}}^+(x | \vec{y})}
                               {\frac{1}{m(n - 1)}\sum_{j = 1}^m \sum_{i = 1}^n (x_{i,j} - \bar{x}_{\cdot, j})^2},
    \end{align}

    where the subscript $\cdot$ denotes an average about the corresponding
    index.

    Moreover, attention has to be paid that consecutive samples are correlated
    and the effective number of independent samples from the target distribution
    is thus less than the simulations steps. The effective sample $\hat{n}_{eff}$
    size can be computed using:

    \begin{align}
    V_t &= \frac{1}{m(n - t)} \sum_{j = 1}^m \sum_{i = t + 1}^n (x_{i,j} - x_{i-t, j})^2 \\
    \hat{n}_{eff} &= \frac{mn}{1 + 2 \sum_{t = 1}^T 1 - \frac{V_t}{2\hat{\text{var}}^+}}
    \end{align}

** Neural Networks
    
    Neural networks are a general computing model that computes a vector of
    outputs $\mathbf{y}_{NN}$ from an input vector $\mathbf{x}_{NN}$ by
    propagating the input activations through a sequence of layers with
    learnable weights and biases:
    
    \begin{align}
        \mathbf{x}_{NN, i} &= f_{i}
        \left ( \mathbf{W}_{i} \mathbf{x}_{NN, i - 1} + \mathbf{b}_i \right )
    \end{align}

    where $f_i$ is the activation function of layer $i$.

    Neural networks can be used to solve regression problems by applying
    /supervised learning/ to find the weights and biases that provide the
    best fit of the function represented by the neural network and the
    set of values to fit. In this context, best is defined as minimizing
    the mean of a given loss function $\mathcal{L}(\hat{\vec{y}},\vec{y})$
    over the training set.

    Probabilistic predictions can be obtained from a neural network, by
    interpreting the outputs $\mathbf{y}_{NN}$ as values of a parametrization
    of a probability distribution \cite{mdn}. A neural network trained
    using squared error loss may be viewed as a maximum likelihood
    estimator of the mean of a conditional Gaussian distribution with
    fixed standard deviation.

    Recent developments in machine learning \cite{lecun, baldi} have shown
    that deep neural networks, that is networks with several hidden layers
    and a large number of neurons, can learn complex relations from data
    when trained on a sufficiently large training sets. Moreover, the large
    training sets and stochastic batch gradient descent training 
    reduce the risk of overfitting and the sensitivity to network
    design \cite{goodfellow}.
    
** Quantile Regression 

    While the most common form of regression, /least squares regression/, may be
    viewed as estimating the mean of a Gaussian distribution with fixed standard
    deviation conditional on the regressor, the concept can easily be extended
    to give a more complete estimate of the conditional distribution. By
    learning an inverse mapping from a measurement $\mathbf{y}$ to a conditional
    probability $\pcond{x}{\mathbf{y}}$, regression techniques can be used to
    solve the Bayesian inverse problem (\ref{eq:posterior}). Quantile regression
    \cite{koenker} is a method that can be used to estimate the /quantiles/ of
    the conditional distribution $\pcond{x}{\vec{y}}$. Given the cumulative density function $F(x)$ of a probability distribution
    $p$, its $\tauth$ quantile is defined as:

    \begin{align}
    F^{-1}(\tau) &= \inf \{x \: : \: F(x) \geq \tau \} \end{align}

    It can be shown \cite{koenker}, that the $\tau$ th quantile $x_\tau$ of $F$
    minimizes the expected value $\mathcal{E}_x(\mathcal{L}_\tau(x_\tau, x))$ of the
    loss function

    \begin{align}\label{eq:quantile_loss}
    \mathcal{L}_{\tau}(x_\tau, x) &= \begin{cases} (1 - \tau)|x - x_\tau| &, x_\tau < x
                           \\ \tau |x - x_\tau| & \text{otherwise} \end{cases}
                           \\ &= (x - x_\tau)(\tau - I_{x < x_\tau}).
                           \end{align}

    The reduction of the problem of finding the quantiles of a distribution
    function to an optimization problem makes it possible to apply this to any
    machine learning method that is trained using supervised learning. Moreover,
    Gneiting et al. \cite{gneiting} showed that the quantile loss function is a
    proper scoring rule and using it as a learning criterion iwll thus lead well
    calibrated predictions.

*** Bayesian Monte Carlo Integration

    The BMCI method is based on the use of importance sampling used to 
    approximate integrals over the posterior distribution. Consider an
    integral of the form

    
    \begin{align}\label{eq:bmci_int}
     \int f(x') \pcond{x'}{\mathbf{y}} \: dx'.
    \end{align}

    Applying Bayes' theorem, the integral can be written as

    \begin{align}
    \int f(x') \frac{\pcond{x'}{\mathbf{y}}\prop{x'}}{\prop{\vec{y}}} \: dx' &=
    \int f(x') \frac{\pcond{\mathbf{y}}{x'}\prop{x'}}
                    {\int \pcond{\mathbf{y}}{x''} \: dx''} \: dx'.
    \end{align}
    
    The last integral can be approximated by a sum over an observation
    database $\{(\mathbf{y}_i, x_i)\}_{i = 1}^n$ that is distributed according
    to the a priori distribution $\prop{x}$:

    \begin{align}
    \int f(x') \pcond{x'}{\mathbf{y}} \: dx' & \approx  \sum_{i = 1}^n \frac{w_i(\mathbf{y}) f(x_i)}
            {\sum_{j = 1}^n w_j(\mathbf{y})}.
    \end{align}

    The weights $w_i(\mathbf{y})$ are given by the conditional probability
    of the observed measurement $\mathbf{y}$ given the database measurement 
    $\mathbf{y_i}$, which is usually assumed to be Gaussian:

    \begin{align}
    w_i(\vec{y}) \propto \exp \left \{- \frac{(\vec{y} - \vec{y}_i)^T \mat{S}_o^{-1}
                                       (\vec{y} - \vec{y}_i)}{2} \right \}
    \end{align}

    The normalization factor is neglected here since it cancels out
    in the calculation. If the database is constructed from radiative
    transfer simulations, the covariance matrix $\mat{S}_o$ should take into
    account the observation noise as well as forward model uncertainties.

    By approximating integrals of the form (\ref{eq:bmci_int}), it is possible to estimate
    mean and variance of the posterior distribution by choosing $f(x) = x$
    and $f(x) = (x - \mathcal{E}(x | \mathbf{y}))^2$, respectively. Likewise
    is possible to approximate the cumulative density function of the
    posterior using

    \begin{align}
    F(x) &= \int_{-\infty}^x  p(x') \: dx \\
         &\approx \sum_{x_i < x}^n \frac{w_i(\mathbf{y})}
                                      {\sum_{j = 1}^n w_j(\mathbf{y})}
    \end{align}


*** Evaluating Uncertain Predictions
    
    Comparing two different probabilistic predictions against an observed value
    is difficult because the underlying true conditional distribution is
    generally not known. When comparing a probabilistic prediction to point
    data, the predicted conditional distribution should be sharp, i.e.
    concentrated in the vicinity of the observed value, while at the same time
    being well calibrated, i.e. predicting probabilities that truthfully reflect
    observed frequencies \cite{gneiting_2}. Summary measures for the evaluation
    of predicted conditional distributions are called scoring rules
    \cite{gneiting}. An important property of these scoring rules is propriety,
    which formalizes the concept of the scoring rule rewarding both sharpness
    and calibration of the prediction. Besides providing reliable measures
    for the comparison of probabilistic predictions, proper scoring rules
    can also be used as loss function in supervised learning incentivize
    statistically consistent predictions.

    As noted in \cite{gneiting}, the quantile loss function given in equation
    (\ref{eq:quantile_loss}) is a proper scoring rule for quantile estimation
    and can thus also be used to compare the skill of different methods for
    quantile estimation.

    Another proper scoring rule for the evaluation of estimations of a
    cumulative distribution function $F$ is the continuous ranked probability
    score (CRPS) defined as

    \begin{align}\label{eq:crps}
    \text{CRPS}(F, x) &= \int_{-\infty}^{\infty} 
                         \left ( F(y) - I_{x \geq y} \right )^2 \: dy
    \end{align}
    
    For the methods used in this article the integral in \ref{eq:crps} can only
    be evaluated approximately. The exact way in which this is done for each
    method is described in detail in Section \ref{sec:prob_test}.

    In addition to the scoring rules described above, which can be used to
    evaluate estimations of uncertainty against point data, the predictions
    obtained from quantile regression and BMCI are compared against posterior
    distributions obtained from Markov chain Monte Carlo simulations. These are
    generated from a simplified but realistic simulated retrieval setup, which
    guarantees that the true posterior distribution can be sampled from using
    MCMC. This distribution can then be used as a ground truth to assess the
    predictions obtained using the QRNN and BMCI.

* Implementation

  In this section the implementation of the retrieval methods in particular
  the quantile regression neural networks used in the following sections are
  described. The implementations of all methods are released as parts of the
  python package ~typhon~ \cite{typhon}. The code for all computations
  presented in this paper is made available in the form of jupyter notebook
  through a public repository \cite{github_repository}.

** Markov Chain Monte Carlo

   Our implementation of MCMC uses the Metropolis-Hastings algorithm to generate
   samples from the posterior distribution  given by equation
 (\ref{eq:posterior}). The retrieval is performed in the space of atmospheric
   states given by the profiles of temperature and water vapor concentrations
   used to model a plane parallel atmsophere. Proposal states are generated
   from a random walk using the a priori covariance matrix scaled by an
   adaptive factor that ensures to keep the acceptance rate near $20\%$.

   Each MCMC retrieval consists of 8 independent runs, that are started with
   different random states samples from the a priori distribution. Each run
   starts with a warm-up phase followed by am adaptive phase during which the
   scaling of the covariance matrix of the random walk used to generate
   proposal states is adapted. This is followed by a production phase during
   which 5000 samples are generated from which only 250 are kept in order to
   decrease the correlation between the samples. To ensure sufficient
   convergence of the simulations, the scale reduction factor $\hat{R}$ and
   the effective number of independent samples is computed an the retrieval
   discarded if they are not smaller than 1.1 and large than 100, respectively.
   
** Quantile Regression Neural Network

   A implementation of quantile regression neural networks has been developed
   based on the ~keras~ framework for deep learning. The main extension was the
   addition of a flexible loss function, that can be used to train neural
   networks on any set of quantiles. The approach chosen here is to train a
   single network to predict all quantiles. In addition to that training and
   validation data generators have been implemented that allow a more flexible
   incorporation of noise information into the training process. The general
   idea is to keep the training data noise-free and add noise according to
   sensor properties first when a batch of training data is presented to the
   network. This was found to be advantageous for the simulated retrieval case
   to be discussed in Section \ref{synthetic}. The QRNN implementation also
   provides an option to train an ensemble of networks and use them to
   predict quantiles. For an ensemble, the predicted quantiles are simply
   the means of the quantiles predicted from the networks.

   For the training of the neural network an adaptive form of stochastic batch
   gradient descent is used. During training, loss is monitored on an internal
   validation set consisting of $10\%$ of the data provided for training. When
   the loss on this internal validation set hasn't decreased for a given number
   of epochs, the training rate is reduced by a given reduction factor. The
   training is stopped when a certain minimum learning rate is reached.

   The reconstruction of the CDF from the estimated quantiles is obtained
   by using the quantiles as nodes of a piece-wise linear approximation and
   extending the first and last segements out to 0 and 1, respectively.
   This approximation is also used to compute the CRPS score on a test
   data.

** Bayesian Monte Carlo Integration

   The BMCI method has been implemented also in python. The implementation
   provides functionality to speed up calculations by excluding entries that are
   guaranteed to have a smaller weight then a given limit. For the experiments,
   however, this was not used, since computational performance was not
   considered critical. In addition to retrieving the first two moments of the
   posterior distribution the implementation also provides functionality to
   retrieve the posterior CDF using equation (\ref{eq:bmci_cdf}). This is done
   by ordering the weights according to their value and then interpolating the
   inverse CDF to the desired quantile(s). To compute the CRPS score for a given
   retrieval, the trapezoidal rule is used to integrate over the database
   values $x_i$ and corresponding weights $w_i(\vec{y})$.


* Application to a Synthetic Retrieval Case
  \label{sec:synthetic}

  In this section the simulated retrieval case that has been used to
  compare the performance of QRNNs and BMCI as retrieval methods is
  presented. The influence of different hyperparameters on the performance
  of the QRNN is investigated and finally the performance of the two
  methods is compared with respect to amount of training data.

** Retrieval Setup

   For this experiment, the retrieval of column water vapor (CWV) from passive
   microwave observations over the ocean is considered. The state of the
   atmosphere is represented by profiles of temperature and water vapor
   concentrations on 15 pressure levels between $10^3$ and $\SI{10}{\hecto
   \pascal}$. The variablility of these quantities has been estimated based on
   ECMWF ERA Interim data \cite{era_interim} from the year 2016 restricted to
   latitudes between $23^\circ$ and $66^\circ$ North. Parametrizations of the
   multivariate distributions of temperature and water vapor were obtained by
   fitting a joint multivariate normal distribution to the temperature and the
   logarithm of water vapor concentrations. The fitted distribution represents
   the a priori knowledge on which the simulations are based.

*** Radiative Transfer Simulations

   The /Atmospheric Radiative Transfer Simulator/ (ARTS) \cite{arts} is used to
   simulate satellite observations of the atmsopheric states sampled from the a
   priori distribution. The observations consist of simulated brightness
   temperatures from five channels at $23, 88, 165, \SI{183}{\giga \hertz}$
   (c.f. Table \ref{tab:channels}) of the ATMS sensor.

   #+NAME: tab:channels
   
\begin{table}[hbpt]
\centering
\begin{tabular}{|r|c|c|}
    \hline
    Channel & Center Frequency           & Bandwidth                \\ 
    \hline
                  1 & $\SI{23.8}{\giga \hertz}$  & $\SI{270 }{\mega \hertz}$ \\
                  2 & $\SI{88.2 }{\giga \hertz}$ & $\SI{500 }{\mega \hertz}$ \\
                  3 & $\SI{165.5}{\giga \hertz}$ & $\SI{300 }{\mega \hertz}$ \\
                  4 & $\SI{183.3}{\giga \hertz}$ & $\SI{3000}{\mega \hertz}$ \\
                  5 & $\SI{183.3}{\giga \hertz}$ & $\SI{1000}{\mega \hertz}$ \\
    \hline
\end{tabular}
\caption{Channels used for the raidative transfer simulations.}
\label{tab:channels}
\end{table}

#   | Channel Number | Center Frequency           | Bandwidth                 |
#   |----------------+----------------------------+---------------------------|
#   |              1 | $\SI{23.8}{\giga \hertz}$  | $\SI{270 }{\mega \hertz}$ |
#   |              2 | $\SI{88.2 }{\giga \hertz}$ | $\SI{500 }{\mega \hertz}$ |
#   |              3 | $\SI{165.5}{\giga \hertz}$ | $\SI{300 }{\mega \hertz}$ |
#   |              4 | $\SI{183.3}{\giga \hertz}$ | $\SI{3000}{\mega \hertz}$ |
#   |              5 | $\SI{183.3}{\giga \hertz}$ | $\SI{1000}{\mega \hertz}$ |

   The simulations take into acount only absorption and emission from water
   vapor. Ocean surface emissivities are computed using the Fastem \cite{fastem}
   model neglecting surface winds. The sea surface temperature is assumed equal
   to the temeperature at the highest pressure level but no lower than
   $\SI{270}{\kelvin}$. Sensor characteristics and absorption lines are taken
   from the ATMS sensor descriptions that are provided within the ARTS XML Data
   package. Simulations are performed assuming a plane-parallel atmsophere and
   neglecting polarization.

*** Training and Test Data

    The fitted distributions are used to generate a training ensemble of
    $10^6$ atmospheric states. For each of them, the integrated column water
    vapor is computed as well as the corresponding observed brightness 
    temperatures.
    
    In addition to that, two test sets are generated:
      1. A /point data/ test set consisting of scalar CWV values sampled from
         the a priori distribution of atmospheric states and corresponding
         simulated brightness temperatures
      2. A /probabilistic/ test set consisting of $5 \times 10^3$ simulated 
         observations and for each of those 2000 samples from the corresponding
         true posterior distribution obtained from MCMC simulations.


** QRNN Model Selection

   The QRNN implementation that has been developed for this work has the
   following hyperparameters that specify its structure: (1) the number of
   hidden layers, (2) the width of the hidden layers, (3) the activation
   functions of each layer. In addition to that, the following parameters
   can be used to influence the learning process: (4) the batch size,
   (5) the minimum learning rate, (6) the learning rate decay, and (7) the
   number of epochs without decrease of loss on the validation set before
   reducing the learning rate.

   To investigate the influence of these parameters on the performance of
   the QRNN, 10-fold cross validation has been used to estimate the
   performance impact of different hyperparameter configurations. Since the
   complete hyperparamter space is too large to be explored exhaustively,
   a joint grid search was performed to find the approximately optimal
   structural hyperparameters (1), (2), (3). This was  followed by an
   optimization of the training parameters (4), (5), (6) and (7) for the
   best performing configuration found in the first search.

   The full results for the grid search for optimal structural parameters are
   given in Table \ref{tab:model_selection} in the appendix. The results show a
   large difference between using linear activations as opposed to non-linear
   activations. This is expected since a linear network can only model linear
   relations and between the input variables. While the performance of the
   networks with non-linear activations is comparable, the results indicate a
   performance advantage for networks with ReLU activation functions.
   Performance is significantly increased when going from one to two hidden
   layers as well as to a width from 16 up to 64 neurons but saturates for
   higher values. Based on these results, a network with three hidden layers
   and 128 neurons each has been chosen for the comparison against BMCI.

   

** Results

   The performance of BMCI and QRNNs for differently sized training sets has
   been investigated on the two test sets.

*** Probabilistic Test Set
   \label{sec:prob_test}

   The probabilistic test set consists of samples from the true posterior
   distribution and thus allows for a more detailed assessment of the
   posterior distributions estimated using BMCI or a QRNN.

   Figure \ref{fig:posterior_100k} and \ref{fig:posteriors} display exemplaric
   results from the probabilistic test set in the form of the estimated
   cumulative distribution functions for training set sizes of $10^5$ and
   $10^6$, respectively. The choice of the cases plotted is based on their
   rank with respect to the true CWV value sorted in ascending order. 
   For both training set sizes, BMCI and the QRNN manage to reproduce the
   posterior distributions reasonably well. The result in the  first panel,
   however, shows that the QRNN struggles to reproduce the true shape of the
   CDF whereas BMCI performs well here. The reason for this is likely the
   underrepresentation of cases with equally small column water vapor in
   the training set. The results also indicate that using an ensemble of
   QRNNs improves the predictions from the QRNN.

   In order to assess how well predicted quantiles approximate those of the true
   posterior distribution, the fractions of MCMC samples that are less than the
   predicted quantiles are compute for both the BMCI and QRNN predictions. The
   distribution of these fractions for the $\tauth$ quantile should, in the
   ideal case, be a Dirac delta function centered at $\tau$. In general,
   however, the predicted quantile will will correspond to an /effective
   quantile/ that deviates from the true $\tau\text{th}$ quantile of the
   posterior distribution. The distributions of these effective quantiles are
   displayed in Figure \ref{fig:quantile_distributions}. The plots illustrate
   how well the two methods perform in estimating the quantilese of the
   posterior distribution on the probabilistic test set. The quality of the
   predictions from both methods is very similar. While the results obtained
   from a single QRNN are slightly inferior to the predictions from BMCI, using
   an ensemble of five QRNNs gives slightly better results than obtained from
   BMCI.


   \begin{figure}[hbpt]
   \centering
   \begin{subfigure}{0.49\textwidth}
   \includegraphics[width=\textwidth]{../plots/results_quantiles_100_k}
   \caption{$n_\text{train} = 10^5$}
   \label{fig:scorescrps}
   \end{subfigure}%
   \begin{subfigure}{0.49\textwidth}
   \includegraphics[width=\textwidth]{../plots/results_quantiles}
   \caption{$n_\text{train} = 10^6$}
   \label{fig:scoresmape}
   \end{subfigure}
   \caption{Distribution of predicted quantiles for training set size
   $n_\text{train} = 10^5$ and $n_\text{train} = 10^6$.}
   \label{fig:quantile_distributions}
   \end{figure}


*** Point Value Test Set
   
   On the point value test set, the quantile loss, the CRPS and the MAPE are
   used to characterize the performance of the two methods.

   The losses for the estimated quantiles with respect to differently sized
   training sets are displayed in Figure \ref{fig:quantile_loss}. As expected,
   the losses drop with increased training set size. For this specific example
   the performance increases only slightly for training set sizes larger than
   $10^5$. Both methods perform equally well, with a slight advantage for
   the QRNN at small values of $\tau$ and a slight advantage for BMCI at large
   values of $\tau$.

   Given in Figure \ref{fig:scorescrps} is the distribution of CRPS values achieved
   by both methods trained on the whole training set. Also here both methods
   perform equally well, at least no methods has a clear advantage over the
   other.


   Figure \ref{fig:scoresmape} displays the mean absolute error achieved by the
   two methods also in depence to the training set size. Again, both methods
   perform equally well but the decrease in error stagnates after for training
   set size larger than $10^5$. 
   
   \begin{figure}[hbpt]
   \centering
   \begin{subfigure}{0.49\textwidth}
   \includegraphics[width=\textwidth]{../plots/crps}
   \caption{CRPS}
   \label{fig:scorescrps}
   \end{subfigure}%
   \begin{subfigure}{0.49\textwidth}
   \includegraphics[width=\textwidth]{../plots/mape}
   \caption{MAPE}
   \label{fig:scoresmape}
   \end{subfigure}
   \end{figure}
   


   
* Appendix
  
  # Estimated Posterior CDFs

  \begin{figure}
  \includegraphics[width = \textwidth]{../plots/posterior_cdfs}
  \caption{Estimated cumulative posterior distributions obtained from MCMC (grey),
           BMCI (blue), QRNN (red). Selection is based on the rank of the true CWV
           value sorted in ascending order.}
  \label{fig:posteriors}
  \end{figure}
  
  # Quantile Losses

  \begin{figure}
  \includegraphics[width = \textwidth]{../plots/quantile_loss}
  \caption{The quantile losses over the point value test set obtained using
           BMCI and QRNN.}
  \label{fig:quantile_loss}
  \end{figure}
   

  \clearpage

** Model Selection Results

  \begin{table}[ht]
  \begin{center}

    \vspace{0.5cm}
    \begin{adjustbox}{max width = \textwidth}
     \begin{tabular}{|l|ccccccc|}
     \multicolumn{8}{c}{Linear}\\
     \hline
     \input{../tables/linear.tbl}
     \end{tabular}
    \end{adjustbox}

    \vspace{0.5cm}
    \begin{adjustbox}{max width = \textwidth}
     \begin{tabular}{|l|ccccccc|}
     \multicolumn{8}{c}{Sigmoid}\\
     \hline
     \input{../tables/sigmoid.tbl}
     \end{tabular}
    \end{adjustbox}

    \vspace{0.5cm}
    \begin{adjustbox}{max width = \textwidth}
     \begin{tabular}{|l|ccccccc|}
     \multicolumn{8}{c}{tanh}\\
     \hline
     \input{../tables/tanh.tbl}
     \end{tabular}
    \end{adjustbox}

    \vspace{0.5cm}
    \begin{adjustbox}{max width = \textwidth}
     \begin{tabular}{|l|ccccccc|}
     \multicolumn{8}{c}{ReLU}\\
     \hline
     \input{../tables/relu.tbl}
     \end{tabular}
    \end{adjustbox}

    \caption{Mean quantile loss and standard deviation for different activation functions, varying numbers
             $n_h$ of hidden layers and $n_n$ of neurons per layer. Results were obtained using 10-fold
             cross validation on the training set.}

 \label{tab:model_selection}

  \end{center}
 \end{table} 
\clearpage


\bibliographystyle{alpha}
\bibliography{literature}  

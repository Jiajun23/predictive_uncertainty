{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRNN Training\n",
    "\n",
    "This notebook trains several *quantile regression neural networks* (QRNNs) on differently sized training sets with different numbers of channels (5 and 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "%env OMP_NUM_THREADS=4\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib_settings\n",
    "from typhon.retrieval.qrnn import QRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/x_train_5.npy\")\n",
    "y_train = np.load(\"data/y_train_5.npy\")\n",
    "quantiles = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "70/70 [==============================] - 1s - loss: 64.1944 - val_loss: 11.9064\n",
      "Epoch 2/300\n",
      "70/70 [==============================] - 0s - loss: 7.3857 - val_loss: 4.5791\n",
      "Epoch 3/300\n",
      "70/70 [==============================] - 0s - loss: 5.0731 - val_loss: 3.8432\n",
      "Epoch 4/300\n",
      "70/70 [==============================] - 0s - loss: 3.8488 - val_loss: 3.3794\n",
      "Epoch 5/300\n",
      "70/70 [==============================] - 0s - loss: 4.2886 - val_loss: 3.5227\n",
      "Epoch 6/300\n",
      "70/70 [==============================] - 0s - loss: 4.0056 - val_loss: 2.9583\n",
      "Epoch 7/300\n",
      "70/70 [==============================] - 0s - loss: 3.9120 - val_loss: 3.3319\n",
      "Epoch 8/300\n",
      "70/70 [==============================] - 0s - loss: 3.8936 - val_loss: 3.4673\n",
      "Epoch 9/300\n",
      "70/70 [==============================] - 0s - loss: 3.4172 - val_loss: 5.3163\n",
      "Epoch 10/300\n",
      "70/70 [==============================] - 0s - loss: 3.9506 - val_loss: 3.0537\n",
      "Epoch 11/300\n",
      "70/70 [==============================] - 0s - loss: 3.3226 - val_loss: 3.2028\n",
      "Epoch 12/300\n",
      "70/70 [==============================] - 0s - loss: 3.4948 - val_loss: 2.7779\n",
      "Epoch 13/300\n",
      "70/70 [==============================] - 0s - loss: 3.7005 - val_loss: 3.4148\n",
      "Epoch 14/300\n",
      "70/70 [==============================] - 0s - loss: 3.4689 - val_loss: 3.0985\n",
      "Epoch 15/300\n",
      "70/70 [==============================] - 0s - loss: 3.5349 - val_loss: 2.9343\n",
      "Epoch 16/300\n",
      "70/70 [==============================] - 0s - loss: 3.6609 - val_loss: 2.3356\n",
      "Epoch 17/300\n",
      "70/70 [==============================] - 0s - loss: 3.1927 - val_loss: 2.5640\n",
      "Epoch 18/300\n",
      "70/70 [==============================] - 0s - loss: 3.3858 - val_loss: 2.2582\n",
      "Epoch 19/300\n",
      "70/70 [==============================] - 0s - loss: 3.2586 - val_loss: 1.9980\n",
      "Epoch 20/300\n",
      "70/70 [==============================] - 0s - loss: 3.6032 - val_loss: 3.0068\n",
      "Epoch 21/300\n",
      "70/70 [==============================] - 0s - loss: 3.3836 - val_loss: 3.2304\n",
      "Epoch 22/300\n",
      "70/70 [==============================] - 0s - loss: 3.2642 - val_loss: 3.0493\n",
      "Epoch 23/300\n",
      "70/70 [==============================] - 0s - loss: 3.3019 - val_loss: 3.8266\n",
      "Epoch 24/300\n",
      "70/70 [==============================] - 0s - loss: 3.3847 - val_loss: 2.9968\n",
      "Epoch 25/300\n",
      "70/70 [==============================] - 0s - loss: 3.1923 - val_loss: 2.4729\n",
      "Epoch 26/300\n",
      "70/70 [==============================] - 0s - loss: 3.1298 - val_loss: 2.6222\n",
      "Epoch 27/300\n",
      "70/70 [==============================] - 0s - loss: 3.0508 - val_loss: 2.8544\n",
      "Epoch 28/300\n",
      "70/70 [==============================] - 0s - loss: 3.2129 - val_loss: 3.3118\n",
      "Epoch 29/300\n",
      "70/70 [==============================] - 0s - loss: 3.1898 - val_loss: 3.6483\n",
      "Epoch 30/300\n",
      "63/70 [==========================>...] - ETA: 0s - loss: 3.3732\n",
      " Reduced learning rate to 0.01\n",
      "70/70 [==============================] - 0s - loss: 3.3798 - val_loss: 2.8469\n",
      "Epoch 31/300\n",
      "70/70 [==============================] - 0s - loss: 2.2754 - val_loss: 1.9682\n",
      "Epoch 32/300\n",
      "70/70 [==============================] - 0s - loss: 2.3125 - val_loss: 1.9160\n",
      "Epoch 33/300\n",
      "70/70 [==============================] - 0s - loss: 2.3324 - val_loss: 1.9828\n",
      "Epoch 34/300\n",
      "70/70 [==============================] - 0s - loss: 2.3153 - val_loss: 2.1752\n",
      "Epoch 35/300\n",
      "70/70 [==============================] - 0s - loss: 2.2974 - val_loss: 1.8322\n",
      "Epoch 36/300\n",
      "70/70 [==============================] - 0s - loss: 2.2876 - val_loss: 1.9605\n",
      "Epoch 37/300\n",
      "70/70 [==============================] - 0s - loss: 2.3528 - val_loss: 2.5725\n",
      "Epoch 38/300\n",
      "70/70 [==============================] - 0s - loss: 2.1748 - val_loss: 1.9252\n",
      "Epoch 39/300\n",
      "70/70 [==============================] - 0s - loss: 2.2185 - val_loss: 2.3190\n",
      "Epoch 40/300\n",
      "70/70 [==============================] - 0s - loss: 2.4970 - val_loss: 1.8656\n",
      "Epoch 41/300\n",
      "70/70 [==============================] - 0s - loss: 2.2562 - val_loss: 1.9554\n",
      "Epoch 42/300\n",
      "70/70 [==============================] - 0s - loss: 2.2266 - val_loss: 2.1581\n",
      "Epoch 43/300\n",
      "70/70 [==============================] - 0s - loss: 2.2727 - val_loss: 2.3926\n",
      "Epoch 44/300\n",
      "70/70 [==============================] - 0s - loss: 2.3631 - val_loss: 2.3191\n",
      "Epoch 45/300\n",
      "70/70 [==============================] - 0s - loss: 2.2513 - val_loss: 2.1421\n",
      "Epoch 46/300\n",
      "47/70 [===================>..........] - ETA: 0s - loss: 2.1995\n",
      " Reduced learning rate to 0.00666667\n",
      "70/70 [==============================] - 0s - loss: 2.1901 - val_loss: 2.0684\n",
      "Epoch 47/300\n",
      "70/70 [==============================] - 0s - loss: 1.9490 - val_loss: 1.6680\n",
      "Epoch 48/300\n",
      "70/70 [==============================] - 0s - loss: 1.8806 - val_loss: 1.8324\n",
      "Epoch 49/300\n",
      "70/70 [==============================] - 0s - loss: 1.8528 - val_loss: 1.7864\n",
      "Epoch 50/300\n",
      "70/70 [==============================] - 0s - loss: 2.0644 - val_loss: 1.8986\n",
      "Epoch 51/300\n",
      "70/70 [==============================] - 0s - loss: 2.0824 - val_loss: 1.8004\n",
      "Epoch 52/300\n",
      "70/70 [==============================] - 0s - loss: 1.9116 - val_loss: 1.7690\n",
      "Epoch 53/300\n",
      "70/70 [==============================] - 0s - loss: 1.9274 - val_loss: 1.7396\n",
      "Epoch 54/300\n",
      "70/70 [==============================] - 0s - loss: 2.0029 - val_loss: 1.8150\n",
      "Epoch 55/300\n",
      "70/70 [==============================] - 0s - loss: 1.9252 - val_loss: 1.9519\n",
      "Epoch 56/300\n",
      "70/70 [==============================] - 0s - loss: 1.9058 - val_loss: 1.8877\n",
      "Epoch 57/300\n",
      "70/70 [==============================] - 0s - loss: 1.9095 - val_loss: 1.9582\n",
      "Epoch 58/300\n",
      "56/70 [=======================>......] - ETA: 0s - loss: 1.9859\n",
      " Reduced learning rate to 0.00444444\n",
      "70/70 [==============================] - 0s - loss: 2.0117 - val_loss: 1.8009\n",
      "Epoch 59/300\n",
      "70/70 [==============================] - 0s - loss: 1.9609 - val_loss: 1.7716ss: 1.897\n",
      "Epoch 60/300\n",
      "70/70 [==============================] - 0s - loss: 1.8052 - val_loss: 1.7749\n",
      "Epoch 61/300\n",
      "70/70 [==============================] - 0s - loss: 1.9109 - val_loss: 1.7258\n",
      "Epoch 62/300\n",
      "70/70 [==============================] - 0s - loss: 1.8743 - val_loss: 1.7980\n",
      "Epoch 63/300\n",
      "70/70 [==============================] - 0s - loss: 1.9184 - val_loss: 1.8094\n",
      "Epoch 64/300\n",
      "70/70 [==============================] - 0s - loss: 1.8247 - val_loss: 1.7685\n",
      "Epoch 65/300\n",
      "70/70 [==============================] - 0s - loss: 1.9820 - val_loss: 1.8004\n",
      "Epoch 66/300\n",
      "70/70 [==============================] - 0s - loss: 1.9385 - val_loss: 1.7640\n",
      "Epoch 67/300\n",
      "70/70 [==============================] - 0s - loss: 1.9120 - val_loss: 1.7885\n",
      "Epoch 68/300\n",
      "70/70 [==============================] - 0s - loss: 1.9936 - val_loss: 1.7373\n",
      "Epoch 69/300\n",
      "56/70 [=======================>......] - ETA: 0s - loss: 1.9791\n",
      " Reduced learning rate to 0.00296296\n",
      "70/70 [==============================] - 0s - loss: 1.9583 - val_loss: 1.7658\n",
      "Epoch 70/300\n",
      "70/70 [==============================] - 0s - loss: 1.8326 - val_loss: 1.7615\n",
      "Epoch 71/300\n",
      "70/70 [==============================] - 0s - loss: 1.8453 - val_loss: 1.8224\n",
      "Epoch 72/300\n",
      "70/70 [==============================] - 0s - loss: 1.8963 - val_loss: 1.8957\n",
      "Epoch 73/300\n",
      "70/70 [==============================] - 0s - loss: 1.7834 - val_loss: 1.7280\n",
      "Epoch 74/300\n",
      "70/70 [==============================] - 0s - loss: 1.9279 - val_loss: 1.7036\n",
      "Epoch 75/300\n",
      "70/70 [==============================] - 0s - loss: 1.7920 - val_loss: 1.6587\n",
      "Epoch 76/300\n",
      "70/70 [==============================] - 0s - loss: 1.8160 - val_loss: 1.7811\n",
      "Epoch 77/300\n",
      "70/70 [==============================] - 0s - loss: 1.8398 - val_loss: 1.8048\n",
      "Epoch 78/300\n",
      "70/70 [==============================] - 0s - loss: 1.8587 - val_loss: 1.9045\n",
      "Epoch 79/300\n",
      "70/70 [==============================] - 0s - loss: 1.8173 - val_loss: 1.8557\n",
      "Epoch 80/300\n",
      "70/70 [==============================] - 0s - loss: 1.9244 - val_loss: 1.8868\n",
      "Epoch 81/300\n",
      "70/70 [==============================] - 0s - loss: 1.8677 - val_loss: 1.8080\n",
      "Epoch 82/300\n",
      "70/70 [==============================] - 0s - loss: 1.8843 - val_loss: 1.8400\n",
      "Epoch 83/300\n",
      "70/70 [==============================] - 0s - loss: 1.8615 - val_loss: 1.7724\n",
      "Epoch 84/300\n",
      "70/70 [==============================] - 0s - loss: 1.9078 - val_loss: 1.8989\n",
      "Epoch 85/300\n",
      "70/70 [==============================] - 0s - loss: 1.8959 - val_loss: 1.7201\n",
      "Epoch 86/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/70 [=====================>........] - ETA: 0s - loss: 1.8949\n",
      " Reduced learning rate to 0.00197531\n",
      "70/70 [==============================] - 0s - loss: 1.9149 - val_loss: 1.7764\n",
      "Epoch 87/300\n",
      "70/70 [==============================] - 0s - loss: 1.8524 - val_loss: 1.7329\n",
      "Epoch 88/300\n",
      "70/70 [==============================] - 0s - loss: 2.0515 - val_loss: 1.8123\n",
      "Epoch 89/300\n",
      "70/70 [==============================] - 0s - loss: 1.7788 - val_loss: 1.7823\n",
      "Epoch 90/300\n",
      "70/70 [==============================] - 0s - loss: 1.8594 - val_loss: 1.7130\n",
      "Epoch 91/300\n",
      "70/70 [==============================] - 0s - loss: 1.9136 - val_loss: 1.7767\n",
      "Epoch 92/300\n",
      "70/70 [==============================] - 0s - loss: 1.9648 - val_loss: 1.7132\n",
      "Epoch 93/300\n",
      "70/70 [==============================] - 0s - loss: 1.8768 - val_loss: 1.7644\n",
      "Epoch 94/300\n",
      "70/70 [==============================] - 0s - loss: 1.9657 - val_loss: 1.7843\n",
      "Epoch 95/300\n",
      "70/70 [==============================] - 0s - loss: 1.9611 - val_loss: 1.8714\n",
      "Epoch 96/300\n",
      "70/70 [==============================] - 0s - loss: 1.7801 - val_loss: 1.6650\n",
      "Epoch 97/300\n",
      "70/70 [==============================] - 0s - loss: 1.9266 - val_loss: 1.6510\n",
      "Epoch 98/300\n",
      "70/70 [==============================] - 0s - loss: 1.9013 - val_loss: 1.7829\n",
      "Epoch 99/300\n",
      "70/70 [==============================] - 0s - loss: 1.7883 - val_loss: 1.8916\n",
      "Epoch 100/300\n",
      "70/70 [==============================] - 0s - loss: 1.8203 - val_loss: 1.8420\n",
      "Epoch 101/300\n",
      "70/70 [==============================] - 0s - loss: 2.0084 - val_loss: 1.7890\n",
      "Epoch 102/300\n",
      "70/70 [==============================] - 0s - loss: 1.8442 - val_loss: 1.5791\n",
      "Epoch 103/300\n",
      "70/70 [==============================] - 0s - loss: 1.8323 - val_loss: 1.7573\n",
      "Epoch 104/300\n",
      "70/70 [==============================] - 0s - loss: 1.7916 - val_loss: 1.6748\n",
      "Epoch 105/300\n",
      "70/70 [==============================] - 0s - loss: 1.8661 - val_loss: 1.8381\n",
      "Epoch 106/300\n",
      "70/70 [==============================] - 0s - loss: 1.9173 - val_loss: 1.8230\n",
      "Epoch 107/300\n",
      "70/70 [==============================] - 0s - loss: 1.8307 - val_loss: 1.8783\n",
      "Epoch 108/300\n",
      "70/70 [==============================] - 0s - loss: 1.9793 - val_loss: 1.6898\n",
      "Epoch 109/300\n",
      "70/70 [==============================] - 0s - loss: 1.8522 - val_loss: 1.8511\n",
      "Epoch 110/300\n",
      "70/70 [==============================] - 0s - loss: 1.7609 - val_loss: 1.8916\n",
      "Epoch 111/300\n",
      "70/70 [==============================] - 0s - loss: 1.9827 - val_loss: 1.7295\n",
      "Epoch 112/300\n",
      "70/70 [==============================] - 0s - loss: 1.8604 - val_loss: 1.8172\n",
      "Epoch 113/300\n",
      "50/70 [====================>.........] - ETA: 0s - loss: 1.7434\n",
      " Reduced learning rate to 0.00131687\n",
      "70/70 [==============================] - 0s - loss: 1.7684 - val_loss: 1.7814\n",
      "Epoch 114/300\n",
      "70/70 [==============================] - 0s - loss: 1.8363 - val_loss: 1.7482\n",
      "Epoch 115/300\n",
      "70/70 [==============================] - 0s - loss: 1.8308 - val_loss: 1.7726\n",
      "Epoch 116/300\n",
      "70/70 [==============================] - 0s - loss: 1.7795 - val_loss: 1.7725\n",
      "Epoch 117/300\n",
      "70/70 [==============================] - 0s - loss: 1.6766 - val_loss: 1.7536\n",
      "Epoch 118/300\n",
      "70/70 [==============================] - 0s - loss: 1.9197 - val_loss: 1.7481\n",
      "Epoch 119/300\n",
      "70/70 [==============================] - 0s - loss: 1.7672 - val_loss: 1.7951\n",
      "Epoch 120/300\n",
      "70/70 [==============================] - 0s - loss: 1.9443 - val_loss: 1.7478\n",
      "Epoch 121/300\n",
      "70/70 [==============================] - 0s - loss: 1.8377 - val_loss: 1.7516\n",
      "Epoch 122/300\n",
      "70/70 [==============================] - 0s - loss: 1.8910 - val_loss: 1.7276\n",
      "Epoch 123/300\n",
      "70/70 [==============================] - 0s - loss: 1.7516 - val_loss: 1.9258\n",
      "Epoch 124/300\n",
      "45/70 [==================>...........] - ETA: 0s - loss: 1.7112\n",
      " Reduced learning rate to 0.000877915\n",
      "70/70 [==============================] - 0s - loss: 1.7150 - val_loss: 1.7947\n",
      "Epoch 125/300\n",
      "70/70 [==============================] - 0s - loss: 1.7731 - val_loss: 1.7316\n",
      "Epoch 126/300\n",
      "70/70 [==============================] - 0s - loss: 1.7750 - val_loss: 1.8239\n",
      "Epoch 127/300\n",
      "70/70 [==============================] - 0s - loss: 1.8627 - val_loss: 1.7836\n",
      "Epoch 128/300\n",
      "70/70 [==============================] - 0s - loss: 1.7763 - val_loss: 1.8012\n",
      "Epoch 129/300\n",
      "70/70 [==============================] - 0s - loss: 1.8672 - val_loss: 1.7327\n",
      "Epoch 130/300\n",
      "70/70 [==============================] - 0s - loss: 1.7878 - val_loss: 1.7584\n",
      "Epoch 131/300\n",
      "70/70 [==============================] - 0s - loss: 1.8752 - val_loss: 1.6501\n",
      "Epoch 132/300\n",
      "70/70 [==============================] - 0s - loss: 1.7828 - val_loss: 1.7656\n",
      "Epoch 133/300\n",
      "70/70 [==============================] - 0s - loss: 1.9150 - val_loss: 1.7680\n",
      "Epoch 134/300\n",
      "70/70 [==============================] - 0s - loss: 1.8126 - val_loss: 1.8730\n",
      "Epoch 135/300\n",
      "53/70 [=====================>........] - ETA: 0s - loss: 1.9324\n",
      " Reduced learning rate to 0.000585277\n",
      "70/70 [==============================] - 0s - loss: 1.8833 - val_loss: 1.8530\n",
      "Epoch 136/300\n",
      "70/70 [==============================] - 0s - loss: 1.9099 - val_loss: 1.6805\n",
      "Epoch 137/300\n",
      "70/70 [==============================] - 0s - loss: 1.8215 - val_loss: 1.6408\n",
      "Epoch 138/300\n",
      "70/70 [==============================] - 0s - loss: 1.8657 - val_loss: 1.6838\n",
      "Epoch 139/300\n",
      "70/70 [==============================] - 0s - loss: 1.8389 - val_loss: 1.7962\n",
      "Epoch 140/300\n",
      "70/70 [==============================] - 0s - loss: 1.8625 - val_loss: 1.7865\n",
      "Epoch 141/300\n",
      "70/70 [==============================] - 0s - loss: 1.8716 - val_loss: 1.6348\n",
      "Epoch 142/300\n",
      "70/70 [==============================] - 0s - loss: 1.8722 - val_loss: 1.6697\n",
      "Epoch 143/300\n",
      "70/70 [==============================] - 0s - loss: 1.8072 - val_loss: 1.6951\n",
      "Epoch 144/300\n",
      "70/70 [==============================] - 0s - loss: 1.8231 - val_loss: 1.7546\n",
      "Epoch 145/300\n",
      "70/70 [==============================] - 0s - loss: 1.7369 - val_loss: 1.7618\n",
      "Epoch 146/300\n",
      "51/70 [====================>.........] - ETA: 0s - loss: 1.8267\n",
      " Reduced learning rate to 0.000390184\n",
      "70/70 [==============================] - 0s - loss: 1.8296 - val_loss: 1.6930\n",
      "Epoch 147/300\n",
      "70/70 [==============================] - 0s - loss: 1.9010 - val_loss: 1.7283\n",
      "Epoch 148/300\n",
      "70/70 [==============================] - 0s - loss: 1.7569 - val_loss: 1.6795\n",
      "Epoch 149/300\n",
      "70/70 [==============================] - 0s - loss: 1.7846 - val_loss: 1.6744\n",
      "Epoch 150/300\n",
      "70/70 [==============================] - 0s - loss: 1.8356 - val_loss: 1.7412\n",
      "Epoch 151/300\n",
      "70/70 [==============================] - 0s - loss: 1.9008 - val_loss: 1.7494\n",
      "Epoch 152/300\n",
      "70/70 [==============================] - 0s - loss: 1.7706 - val_loss: 1.7793\n",
      "Epoch 153/300\n",
      "70/70 [==============================] - 0s - loss: 1.7887 - val_loss: 1.7279\n",
      "Epoch 154/300\n",
      "70/70 [==============================] - 0s - loss: 1.8383 - val_loss: 1.6647\n",
      "Epoch 155/300\n",
      "70/70 [==============================] - 0s - loss: 1.8467 - val_loss: 1.7916\n",
      "Epoch 156/300\n",
      "70/70 [==============================] - 0s - loss: 1.7663 - val_loss: 1.8167\n",
      "Epoch 157/300\n",
      "51/70 [====================>.........] - ETA: 0s - loss: 1.8488\n",
      " Reduced learning rate to 0.000260123\n",
      "70/70 [==============================] - 0s - loss: 1.8919 - val_loss: 1.7858\n",
      "Epoch 158/300\n",
      "70/70 [==============================] - 0s - loss: 1.7879 - val_loss: 1.7838\n",
      "Epoch 159/300\n",
      "70/70 [==============================] - 0s - loss: 1.9065 - val_loss: 1.7560\n",
      "Epoch 160/300\n",
      "70/70 [==============================] - 0s - loss: 1.8913 - val_loss: 1.6664\n",
      "Epoch 161/300\n",
      "70/70 [==============================] - 0s - loss: 1.8575 - val_loss: 1.7005\n",
      "Epoch 162/300\n",
      "70/70 [==============================] - 0s - loss: 1.7934 - val_loss: 1.8233\n",
      "Epoch 163/300\n",
      "70/70 [==============================] - 0s - loss: 1.7959 - val_loss: 1.7714\n",
      "Epoch 164/300\n",
      "70/70 [==============================] - 0s - loss: 1.8019 - val_loss: 1.7377\n",
      "Epoch 165/300\n",
      "70/70 [==============================] - 0s - loss: 1.7843 - val_loss: 1.8593\n",
      "Epoch 166/300\n",
      "70/70 [==============================] - 0s - loss: 1.7579 - val_loss: 1.6991\n",
      "Epoch 167/300\n",
      "70/70 [==============================] - 0s - loss: 2.0191 - val_loss: 1.6800\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/70 [====================>.........] - ETA: 0s - loss: 1.9891\n",
      " Reduced learning rate to 0.000173415\n",
      "70/70 [==============================] - 0s - loss: 1.9167 - val_loss: 1.7026\n",
      "Epoch 169/300\n",
      "70/70 [==============================] - 0s - loss: 1.8961 - val_loss: 1.7898\n",
      "Epoch 170/300\n",
      "70/70 [==============================] - 0s - loss: 1.8136 - val_loss: 1.7539\n",
      "Epoch 171/300\n",
      "70/70 [==============================] - 0s - loss: 1.7895 - val_loss: 1.6982\n",
      "Epoch 172/300\n",
      "70/70 [==============================] - 0s - loss: 1.8711 - val_loss: 1.7756\n",
      "Epoch 173/300\n",
      "70/70 [==============================] - 0s - loss: 1.7443 - val_loss: 1.7399\n",
      "Epoch 174/300\n",
      "70/70 [==============================] - 0s - loss: 1.9159 - val_loss: 1.7802\n",
      "Epoch 175/300\n",
      "70/70 [==============================] - 0s - loss: 1.7015 - val_loss: 1.7157\n",
      "Epoch 176/300\n",
      "70/70 [==============================] - 0s - loss: 1.8987 - val_loss: 1.8007\n",
      "Epoch 177/300\n",
      "70/70 [==============================] - 0s - loss: 1.7915 - val_loss: 1.7406\n",
      "Epoch 178/300\n",
      "70/70 [==============================] - 0s - loss: 1.8751 - val_loss: 1.6394\n",
      "Epoch 179/300\n",
      "59/70 [========================>.....] - ETA: 0s - loss: 1.8517\n",
      " Reduced learning rate to 0.00011561\n",
      "70/70 [==============================] - 0s - loss: 1.9142 - val_loss: 1.6534\n",
      "Epoch 180/300\n",
      "70/70 [==============================] - 0s - loss: 1.7211 - val_loss: 1.7490\n",
      "Epoch 181/300\n",
      "70/70 [==============================] - 0s - loss: 1.7736 - val_loss: 1.7278\n",
      "Epoch 182/300\n",
      "70/70 [==============================] - 0s - loss: 1.8250 - val_loss: 1.7964\n",
      "Epoch 183/300\n",
      "70/70 [==============================] - 0s - loss: 1.8099 - val_loss: 1.7277\n",
      "Epoch 184/300\n",
      "70/70 [==============================] - 0s - loss: 1.8898 - val_loss: 1.8362\n",
      "Epoch 185/300\n",
      "70/70 [==============================] - 0s - loss: 1.8145 - val_loss: 1.6823\n",
      "Epoch 186/300\n",
      "70/70 [==============================] - 0s - loss: 1.8474 - val_loss: 1.7261\n",
      "Epoch 187/300\n",
      "70/70 [==============================] - 0s - loss: 2.0165 - val_loss: 1.7885\n",
      "Epoch 188/300\n",
      "70/70 [==============================] - 0s - loss: 1.7942 - val_loss: 1.7003\n",
      "Epoch 189/300\n",
      "70/70 [==============================] - 0s - loss: 1.8279 - val_loss: 1.8009\n",
      "Epoch 190/300\n",
      "50/70 [====================>.........] - ETA: 0s - loss: 1.9771\n",
      " Reduced learning rate to 7.70735e-05\n",
      "70/70 [==============================] - 0s - loss: 1.9840 - val_loss: 1.7015\n",
      "Epoch 1/300\n",
      "70/70 [==============================] - 0s - loss: 68.8480 - val_loss: 14.1493\n",
      "Epoch 2/300\n",
      "70/70 [==============================] - 0s - loss: 8.5205 - val_loss: 4.8226\n",
      "Epoch 3/300\n",
      "70/70 [==============================] - 0s - loss: 5.5174 - val_loss: 4.0616\n",
      "Epoch 4/300\n",
      "70/70 [==============================] - 0s - loss: 4.3632 - val_loss: 3.8097\n",
      "Epoch 5/300\n",
      "70/70 [==============================] - 0s - loss: 4.3951 - val_loss: 3.8063\n",
      "Epoch 6/300\n",
      "70/70 [==============================] - 0s - loss: 3.5146 - val_loss: 3.1811\n",
      "Epoch 7/300\n",
      "70/70 [==============================] - 0s - loss: 3.3805 - val_loss: 2.8249\n",
      "Epoch 8/300\n",
      "70/70 [==============================] - 0s - loss: 3.7384 - val_loss: 3.9678\n",
      "Epoch 9/300\n",
      "70/70 [==============================] - 0s - loss: 3.5364 - val_loss: 2.9880\n",
      "Epoch 10/300\n",
      "70/70 [==============================] - 0s - loss: 3.8110 - val_loss: 2.3858\n",
      "Epoch 11/300\n",
      "70/70 [==============================] - 0s - loss: 3.4472 - val_loss: 3.5455\n",
      "Epoch 12/300\n",
      "70/70 [==============================] - 0s - loss: 3.6773 - val_loss: 2.3466\n",
      "Epoch 13/300\n",
      "70/70 [==============================] - 0s - loss: 3.3608 - val_loss: 2.8040\n",
      "Epoch 14/300\n",
      "70/70 [==============================] - 0s - loss: 3.4212 - val_loss: 3.0716\n",
      "Epoch 15/300\n",
      "70/70 [==============================] - 0s - loss: 3.4087 - val_loss: 2.6527\n",
      "Epoch 16/300\n",
      "70/70 [==============================] - 0s - loss: 3.4361 - val_loss: 3.4630\n",
      "Epoch 17/300\n",
      "70/70 [==============================] - 0s - loss: 3.4129 - val_loss: 3.2485\n",
      "Epoch 18/300\n",
      "70/70 [==============================] - 0s - loss: 3.1986 - val_loss: 4.3054\n",
      "Epoch 19/300\n",
      "70/70 [==============================] - 0s - loss: 3.6482 - val_loss: 3.1788\n",
      "Epoch 20/300\n",
      "70/70 [==============================] - 0s - loss: 3.4712 - val_loss: 3.4516\n",
      "Epoch 21/300\n",
      "70/70 [==============================] - 0s - loss: 3.1734 - val_loss: 2.2968\n",
      "Epoch 22/300\n",
      "70/70 [==============================] - 0s - loss: 3.0263 - val_loss: 2.2487\n",
      "Epoch 23/300\n",
      "70/70 [==============================] - 0s - loss: 3.5605 - val_loss: 2.7173\n",
      "Epoch 24/300\n",
      "70/70 [==============================] - 0s - loss: 3.4605 - val_loss: 2.5842\n",
      "Epoch 25/300\n",
      "70/70 [==============================] - 0s - loss: 3.2131 - val_loss: 3.2250\n",
      "Epoch 26/300\n",
      "70/70 [==============================] - 0s - loss: 3.0862 - val_loss: 2.6321\n",
      "Epoch 27/300\n",
      "70/70 [==============================] - 0s - loss: 3.3115 - val_loss: 2.2499\n",
      "Epoch 28/300\n",
      "70/70 [==============================] - 0s - loss: 3.3527 - val_loss: 1.8485\n",
      "Epoch 29/300\n",
      "70/70 [==============================] - 0s - loss: 3.1728 - val_loss: 3.1247\n",
      "Epoch 30/300\n",
      "70/70 [==============================] - 0s - loss: 3.3953 - val_loss: 3.7797\n",
      "Epoch 31/300\n",
      "70/70 [==============================] - 0s - loss: 3.2075 - val_loss: 3.2441\n",
      "Epoch 32/300\n",
      "70/70 [==============================] - 0s - loss: 3.4144 - val_loss: 3.3410\n",
      "Epoch 33/300\n",
      "70/70 [==============================] - 0s - loss: 2.9676 - val_loss: 2.5425\n",
      "Epoch 34/300\n",
      "70/70 [==============================] - 0s - loss: 3.0951 - val_loss: 2.8014\n",
      "Epoch 35/300\n",
      "70/70 [==============================] - 0s - loss: 3.0391 - val_loss: 3.8139\n",
      "Epoch 36/300\n",
      "70/70 [==============================] - 0s - loss: 3.1702 - val_loss: 3.1957\n",
      "Epoch 37/300\n",
      "70/70 [==============================] - 0s - loss: 3.0526 - val_loss: 2.0477\n",
      "Epoch 38/300\n",
      "70/70 [==============================] - 0s - loss: 3.0507 - val_loss: 1.9447\n",
      "Epoch 39/300\n",
      "56/70 [=======================>......] - ETA: 0s - loss: 3.0057\n",
      " Reduced learning rate to 0.01\n",
      "70/70 [==============================] - 0s - loss: 2.9909 - val_loss: 2.1316\n",
      "Epoch 40/300\n",
      "70/70 [==============================] - 0s - loss: 2.0565 - val_loss: 1.8442\n",
      "Epoch 41/300\n",
      "70/70 [==============================] - 0s - loss: 2.1347 - val_loss: 1.9835\n",
      "Epoch 42/300\n",
      "70/70 [==============================] - 0s - loss: 2.1706 - val_loss: 1.9308\n",
      "Epoch 43/300\n",
      "70/70 [==============================] - 0s - loss: 2.4183 - val_loss: 1.8458\n",
      "Epoch 44/300\n",
      "70/70 [==============================] - 0s - loss: 2.2731 - val_loss: 1.8242\n",
      "Epoch 45/300\n",
      "70/70 [==============================] - 0s - loss: 2.0583 - val_loss: 1.9290\n",
      "Epoch 46/300\n",
      "70/70 [==============================] - 0s - loss: 2.2142 - val_loss: 1.8497\n",
      "Epoch 47/300\n",
      "70/70 [==============================] - 0s - loss: 2.4651 - val_loss: 2.6495\n",
      "Epoch 48/300\n",
      "70/70 [==============================] - 0s - loss: 2.1671 - val_loss: 2.2066\n",
      "Epoch 49/300\n",
      "70/70 [==============================] - 0s - loss: 2.0848 - val_loss: 2.3042\n",
      "Epoch 50/300\n",
      "70/70 [==============================] - 0s - loss: 2.0508 - val_loss: 1.8520\n",
      "Epoch 51/300\n",
      "70/70 [==============================] - 0s - loss: 2.2364 - val_loss: 1.9231\n",
      "Epoch 52/300\n",
      "70/70 [==============================] - 0s - loss: 2.2143 - val_loss: 2.6205\n",
      "Epoch 53/300\n",
      "70/70 [==============================] - 0s - loss: 2.1660 - val_loss: 2.0882\n",
      "Epoch 54/300\n",
      "70/70 [==============================] - 0s - loss: 2.1414 - val_loss: 2.8390\n",
      "Epoch 55/300\n",
      "54/70 [======================>.......] - ETA: 0s - loss: 2.2447\n",
      " Reduced learning rate to 0.00666667\n",
      "70/70 [==============================] - 0s - loss: 2.2287 - val_loss: 1.9599\n",
      "Epoch 56/300\n",
      "70/70 [==============================] - 0s - loss: 1.8895 - val_loss: 1.6956\n",
      "Epoch 57/300\n",
      "70/70 [==============================] - 0s - loss: 2.1512 - val_loss: 1.8197\n",
      "Epoch 58/300\n",
      "70/70 [==============================] - 0s - loss: 1.9803 - val_loss: 1.8659\n",
      "Epoch 59/300\n",
      "70/70 [==============================] - 0s - loss: 1.9533 - val_loss: 1.8131\n",
      "Epoch 60/300\n",
      "70/70 [==============================] - 0s - loss: 1.8908 - val_loss: 1.8141\n",
      "Epoch 61/300\n",
      "70/70 [==============================] - 0s - loss: 1.8629 - val_loss: 1.7864\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 1.9774 - val_loss: 1.6497\n",
      "Epoch 63/300\n",
      "70/70 [==============================] - 0s - loss: 2.0175 - val_loss: 1.8552\n",
      "Epoch 64/300\n",
      "70/70 [==============================] - 0s - loss: 2.0996 - val_loss: 1.7916\n",
      "Epoch 65/300\n",
      "70/70 [==============================] - 0s - loss: 1.9601 - val_loss: 1.8101\n",
      "Epoch 66/300\n",
      "70/70 [==============================] - 0s - loss: 2.0223 - val_loss: 2.1446\n",
      "Epoch 67/300\n",
      "70/70 [==============================] - 0s - loss: 1.9650 - val_loss: 1.9050\n",
      "Epoch 68/300\n",
      "70/70 [==============================] - 0s - loss: 2.0162 - val_loss: 2.1767\n",
      "Epoch 69/300\n",
      "70/70 [==============================] - 0s - loss: 1.8958 - val_loss: 1.8280\n",
      "Epoch 70/300\n",
      "70/70 [==============================] - 0s - loss: 1.9024 - val_loss: 1.8075\n",
      "Epoch 71/300\n",
      "70/70 [==============================] - 0s - loss: 1.9645 - val_loss: 1.8747\n",
      "Epoch 72/300\n",
      "70/70 [==============================] - 0s - loss: 1.9049 - val_loss: 1.8313\n",
      "Epoch 73/300\n",
      "50/70 [====================>.........] - ETA: 0s - loss: 1.9418\n",
      " Reduced learning rate to 0.00444444\n",
      "70/70 [==============================] - 0s - loss: 1.9171 - val_loss: 1.7606\n",
      "Epoch 74/300\n",
      "70/70 [==============================] - 0s - loss: 2.0187 - val_loss: 1.6953\n",
      "Epoch 75/300\n",
      "70/70 [==============================] - 0s - loss: 2.0685 - val_loss: 1.7819\n",
      "Epoch 76/300\n",
      "70/70 [==============================] - 0s - loss: 1.9611 - val_loss: 1.6911\n",
      "Epoch 77/300\n",
      "70/70 [==============================] - 0s - loss: 1.8730 - val_loss: 1.7854\n",
      "Epoch 78/300\n",
      "70/70 [==============================] - 0s - loss: 1.9710 - val_loss: 1.7199\n",
      "Epoch 79/300\n",
      "70/70 [==============================] - 0s - loss: 1.8016 - val_loss: 1.8286\n",
      "Epoch 80/300\n",
      "70/70 [==============================] - 0s - loss: 1.8151 - val_loss: 1.8222\n",
      "Epoch 81/300\n",
      "70/70 [==============================] - 0s - loss: 2.0044 - val_loss: 1.9432\n",
      "Epoch 82/300\n",
      "70/70 [==============================] - 0s - loss: 1.9810 - val_loss: 1.8976\n",
      "Epoch 83/300\n",
      "70/70 [==============================] - 0s - loss: 1.9068 - val_loss: 1.7355\n",
      "Epoch 84/300\n",
      "53/70 [=====================>........] - ETA: 0s - loss: 1.7977\n",
      " Reduced learning rate to 0.00296296\n",
      "70/70 [==============================] - 0s - loss: 1.7854 - val_loss: 1.8382\n",
      "Epoch 85/300\n",
      "70/70 [==============================] - 0s - loss: 1.8992 - val_loss: 1.6459\n",
      "Epoch 86/300\n",
      "70/70 [==============================] - 0s - loss: 1.7483 - val_loss: 1.7770\n",
      "Epoch 87/300\n",
      "70/70 [==============================] - 0s - loss: 1.7949 - val_loss: 1.8511\n",
      "Epoch 88/300\n",
      "70/70 [==============================] - 0s - loss: 1.8470 - val_loss: 1.7746\n",
      "Epoch 89/300\n",
      "70/70 [==============================] - 0s - loss: 1.9227 - val_loss: 1.7492\n",
      "Epoch 90/300\n",
      "70/70 [==============================] - 0s - loss: 1.9251 - val_loss: 1.8383\n",
      "Epoch 91/300\n",
      "70/70 [==============================] - 0s - loss: 1.7253 - val_loss: 1.7306\n",
      "Epoch 92/300\n",
      "70/70 [==============================] - 0s - loss: 1.8340 - val_loss: 1.6957\n",
      "Epoch 93/300\n",
      "70/70 [==============================] - 0s - loss: 1.8699 - val_loss: 1.7050\n",
      "Epoch 94/300\n",
      "70/70 [==============================] - 0s - loss: 1.9073 - val_loss: 1.7545\n",
      "Epoch 95/300\n",
      "70/70 [==============================] - 0s - loss: 1.9092 - val_loss: 1.6603\n",
      "Epoch 96/300\n",
      "36/70 [==============>...............] - ETA: 0s - loss: 1.7766\n",
      " Reduced learning rate to 0.00197531\n",
      "70/70 [==============================] - 0s - loss: 1.9089 - val_loss: 1.8019\n",
      "Epoch 97/300\n",
      "70/70 [==============================] - 0s - loss: 1.8888 - val_loss: 1.8693\n",
      "Epoch 98/300\n",
      "70/70 [==============================] - 0s - loss: 1.7686 - val_loss: 1.7535\n",
      "Epoch 99/300\n",
      "70/70 [==============================] - 0s - loss: 1.9630 - val_loss: 1.8014\n",
      "Epoch 100/300\n",
      "70/70 [==============================] - 0s - loss: 1.8699 - val_loss: 1.7518\n",
      "Epoch 101/300\n",
      "70/70 [==============================] - 0s - loss: 1.8171 - val_loss: 1.6469\n",
      "Epoch 102/300\n",
      "70/70 [==============================] - 0s - loss: 1.7427 - val_loss: 1.7951\n",
      "Epoch 103/300\n",
      "70/70 [==============================] - 0s - loss: 1.8768 - val_loss: 1.7773\n",
      "Epoch 104/300\n",
      "70/70 [==============================] - 0s - loss: 1.7717 - val_loss: 1.8201\n",
      "Epoch 105/300\n",
      "70/70 [==============================] - 0s - loss: 1.7521 - val_loss: 1.6885\n",
      "Epoch 106/300\n",
      "70/70 [==============================] - 0s - loss: 1.8038 - val_loss: 1.6943\n",
      "Epoch 107/300\n",
      "70/70 [==============================] - 0s - loss: 1.7348 - val_loss: 1.6190\n",
      "Epoch 108/300\n",
      "70/70 [==============================] - 0s - loss: 1.7782 - val_loss: 1.7481\n",
      "Epoch 109/300\n",
      "70/70 [==============================] - 0s - loss: 1.9204 - val_loss: 1.8529\n",
      "Epoch 110/300\n",
      "70/70 [==============================] - 0s - loss: 1.8212 - val_loss: 1.7380\n",
      "Epoch 111/300\n",
      "70/70 [==============================] - 0s - loss: 1.7921 - val_loss: 1.8058\n",
      "Epoch 112/300\n",
      "70/70 [==============================] - 0s - loss: 1.8367 - val_loss: 1.7818\n",
      "Epoch 113/300\n",
      "70/70 [==============================] - 0s - loss: 1.8555 - val_loss: 1.7036\n",
      "Epoch 114/300\n",
      "70/70 [==============================] - 0s - loss: 1.7955 - val_loss: 1.6994\n",
      "Epoch 115/300\n",
      "70/70 [==============================] - 0s - loss: 1.7560 - val_loss: 1.8059\n",
      "Epoch 116/300\n",
      "70/70 [==============================] - 0s - loss: 1.7742 - val_loss: 1.6877\n",
      "Epoch 117/300\n",
      "70/70 [==============================] - 0s - loss: 1.8752 - val_loss: 1.7488\n",
      "Epoch 118/300\n",
      "49/70 [====================>.........] - ETA: 0s - loss: 2.0414\n",
      " Reduced learning rate to 0.00131687\n",
      "70/70 [==============================] - 0s - loss: 1.9815 - val_loss: 1.6677\n",
      "Epoch 119/300\n",
      "70/70 [==============================] - 0s - loss: 1.8222 - val_loss: 1.7228\n",
      "Epoch 120/300\n",
      "70/70 [==============================] - 0s - loss: 1.8172 - val_loss: 1.8927\n",
      "Epoch 121/300\n",
      "70/70 [==============================] - 0s - loss: 1.8943 - val_loss: 1.6959\n",
      "Epoch 122/300\n",
      "70/70 [==============================] - 0s - loss: 1.8657 - val_loss: 1.6798\n",
      "Epoch 123/300\n",
      "70/70 [==============================] - 0s - loss: 1.8864 - val_loss: 1.7484\n",
      "Epoch 124/300\n",
      "70/70 [==============================] - 0s - loss: 2.0021 - val_loss: 1.7462\n",
      "Epoch 125/300\n",
      "70/70 [==============================] - 0s - loss: 1.8415 - val_loss: 1.7735\n",
      "Epoch 126/300\n",
      "70/70 [==============================] - 0s - loss: 1.7413 - val_loss: 1.7708\n",
      "Epoch 127/300\n",
      "70/70 [==============================] - 0s - loss: 1.8238 - val_loss: 1.7476\n",
      "Epoch 128/300\n",
      "70/70 [==============================] - 0s - loss: 1.7642 - val_loss: 1.7063\n",
      "Epoch 129/300\n",
      "50/70 [====================>.........] - ETA: 0s - loss: 1.8327\n",
      " Reduced learning rate to 0.000877915\n",
      "70/70 [==============================] - 0s - loss: 1.8194 - val_loss: 1.6484\n",
      "Epoch 130/300\n",
      "70/70 [==============================] - 0s - loss: 1.8911 - val_loss: 1.6523\n",
      "Epoch 131/300\n",
      "70/70 [==============================] - 0s - loss: 1.7963 - val_loss: 1.6211\n",
      "Epoch 132/300\n",
      "70/70 [==============================] - 0s - loss: 1.9882 - val_loss: 1.7892\n",
      "Epoch 133/300\n",
      "70/70 [==============================] - 0s - loss: 1.8836 - val_loss: 1.7205\n",
      "Epoch 134/300\n",
      "70/70 [==============================] - 0s - loss: 1.9163 - val_loss: 1.6804\n",
      "Epoch 135/300\n",
      "70/70 [==============================] - 0s - loss: 1.8800 - val_loss: 1.5977\n",
      "Epoch 136/300\n",
      "70/70 [==============================] - 0s - loss: 1.8639 - val_loss: 1.6842\n",
      "Epoch 137/300\n",
      "70/70 [==============================] - 0s - loss: 1.9496 - val_loss: 1.7108\n",
      "Epoch 138/300\n",
      "70/70 [==============================] - 0s - loss: 1.9116 - val_loss: 1.8136\n",
      "Epoch 139/300\n",
      "70/70 [==============================] - 0s - loss: 1.9277 - val_loss: 1.7868\n",
      "Epoch 140/300\n",
      "70/70 [==============================] - 0s - loss: 1.8093 - val_loss: 1.6972\n",
      "Epoch 141/300\n",
      "70/70 [==============================] - 0s - loss: 1.8238 - val_loss: 1.7748\n",
      "Epoch 142/300\n",
      "70/70 [==============================] - 0s - loss: 1.8056 - val_loss: 1.7189\n",
      "Epoch 143/300\n",
      "70/70 [==============================] - 0s - loss: 1.8295 - val_loss: 1.7850\n",
      "Epoch 144/300\n",
      "70/70 [==============================] - 0s - loss: 1.7771 - val_loss: 1.7385\n",
      "Epoch 145/300\n",
      "70/70 [==============================] - 0s - loss: 1.7948 - val_loss: 1.8034\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/70 [========================>.....] - ETA: 0s - loss: 1.8313\n",
      " Reduced learning rate to 0.000585277\n",
      "70/70 [==============================] - 0s - loss: 1.8126 - val_loss: 1.7176\n",
      "Epoch 147/300\n",
      "70/70 [==============================] - 0s - loss: 1.7489 - val_loss: 1.6617\n",
      "Epoch 148/300\n",
      "70/70 [==============================] - 0s - loss: 1.7729 - val_loss: 1.6837\n",
      "Epoch 149/300\n",
      "70/70 [==============================] - 0s - loss: 1.7484 - val_loss: 1.6269\n",
      "Epoch 150/300\n",
      "70/70 [==============================] - 0s - loss: 1.8411 - val_loss: 1.8164\n",
      "Epoch 151/300\n",
      "70/70 [==============================] - 0s - loss: 1.8636 - val_loss: 1.7736\n",
      "Epoch 152/300\n",
      "70/70 [==============================] - 0s - loss: 1.8428 - val_loss: 1.6554\n",
      "Epoch 153/300\n",
      "70/70 [==============================] - 0s - loss: 1.7626 - val_loss: 1.7601\n",
      "Epoch 154/300\n",
      "70/70 [==============================] - 0s - loss: 1.8447 - val_loss: 1.7288\n",
      "Epoch 155/300\n",
      "70/70 [==============================] - 0s - loss: 1.8618 - val_loss: 1.6081\n",
      "Epoch 156/300\n",
      "70/70 [==============================] - 0s - loss: 1.7530 - val_loss: 1.7639\n",
      "Epoch 157/300\n",
      "65/70 [==========================>...] - ETA: 0s - loss: 1.8396\n",
      " Reduced learning rate to 0.000390184\n",
      "70/70 [==============================] - 0s - loss: 1.8373 - val_loss: 1.7308\n",
      "Epoch 158/300\n",
      "70/70 [==============================] - 0s - loss: 1.8912 - val_loss: 1.7683\n",
      "Epoch 159/300\n",
      "70/70 [==============================] - 0s - loss: 1.8488 - val_loss: 1.6218\n",
      "Epoch 160/300\n",
      "70/70 [==============================] - 0s - loss: 1.9340 - val_loss: 1.7547\n",
      "Epoch 161/300\n",
      "70/70 [==============================] - 0s - loss: 1.8508 - val_loss: 1.7582\n",
      "Epoch 162/300\n",
      "70/70 [==============================] - 0s - loss: 2.0633 - val_loss: 1.9528\n",
      "Epoch 163/300\n",
      "70/70 [==============================] - 0s - loss: 1.7693 - val_loss: 1.7281\n",
      "Epoch 164/300\n",
      "70/70 [==============================] - 0s - loss: 1.8793 - val_loss: 1.8259\n",
      "Epoch 165/300\n",
      "70/70 [==============================] - 0s - loss: 1.8817 - val_loss: 1.7941\n",
      "Epoch 166/300\n",
      "70/70 [==============================] - 0s - loss: 1.7218 - val_loss: 1.6011\n",
      "Epoch 167/300\n",
      "70/70 [==============================] - 0s - loss: 1.7287 - val_loss: 1.7430\n",
      "Epoch 168/300\n",
      "53/70 [=====================>........] - ETA: 0s - loss: 1.8033\n",
      " Reduced learning rate to 0.000260123\n",
      "70/70 [==============================] - 0s - loss: 1.8190 - val_loss: 1.7467\n",
      "Epoch 169/300\n",
      "70/70 [==============================] - 0s - loss: 1.6980 - val_loss: 1.7170\n",
      "Epoch 170/300\n",
      "70/70 [==============================] - 0s - loss: 1.8028 - val_loss: 1.7944\n",
      "Epoch 171/300\n",
      "70/70 [==============================] - 0s - loss: 1.8780 - val_loss: 1.6793\n",
      "Epoch 172/300\n",
      "70/70 [==============================] - 0s - loss: 1.9250 - val_loss: 1.6518\n",
      "Epoch 173/300\n",
      "70/70 [==============================] - 0s - loss: 1.7842 - val_loss: 1.6601\n",
      "Epoch 174/300\n",
      "70/70 [==============================] - 0s - loss: 1.8138 - val_loss: 1.7312\n",
      "Epoch 175/300\n",
      "70/70 [==============================] - 0s - loss: 1.7370 - val_loss: 1.6880\n",
      "Epoch 176/300\n",
      "70/70 [==============================] - 0s - loss: 1.9040 - val_loss: 1.7606\n",
      "Epoch 177/300\n",
      "70/70 [==============================] - 0s - loss: 1.8535 - val_loss: 1.8578\n",
      "Epoch 178/300\n",
      "70/70 [==============================] - 0s - loss: 1.9474 - val_loss: 1.7006\n",
      "Epoch 179/300\n",
      "51/70 [====================>.........] - ETA: 0s - loss: 1.8227\n",
      " Reduced learning rate to 0.000173415\n",
      "70/70 [==============================] - 0s - loss: 1.8919 - val_loss: 1.7398\n",
      "Epoch 180/300\n",
      "70/70 [==============================] - 0s - loss: 1.7555 - val_loss: 1.8179\n",
      "Epoch 181/300\n",
      "70/70 [==============================] - 0s - loss: 1.7748 - val_loss: 1.7261\n",
      "Epoch 182/300\n",
      "70/70 [==============================] - 0s - loss: 1.8042 - val_loss: 1.7717\n",
      "Epoch 183/300\n",
      "70/70 [==============================] - 0s - loss: 1.8196 - val_loss: 1.6295\n",
      "Epoch 184/300\n",
      "70/70 [==============================] - 0s - loss: 1.7991 - val_loss: 1.6902\n",
      "Epoch 185/300\n",
      "70/70 [==============================] - 0s - loss: 1.8486 - val_loss: 1.7148\n",
      "Epoch 186/300\n",
      "70/70 [==============================] - 0s - loss: 1.8030 - val_loss: 1.7349\n",
      "Epoch 187/300\n",
      "70/70 [==============================] - 0s - loss: 1.8403 - val_loss: 1.8286\n",
      "Epoch 188/300\n",
      "70/70 [==============================] - 0s - loss: 1.7237 - val_loss: 1.8151\n",
      "Epoch 189/300\n",
      "70/70 [==============================] - 0s - loss: 1.7719 - val_loss: 1.7484\n",
      "Epoch 190/300\n",
      "64/70 [==========================>...] - ETA: 0s - loss: 1.8649\n",
      " Reduced learning rate to 0.00011561\n",
      "70/70 [==============================] - 0s - loss: 1.8450 - val_loss: 1.7618\n",
      "Epoch 191/300\n",
      "70/70 [==============================] - 0s - loss: 1.9465 - val_loss: 1.8568\n",
      "Epoch 192/300\n",
      "70/70 [==============================] - 0s - loss: 1.8015 - val_loss: 1.7432\n",
      "Epoch 193/300\n",
      "70/70 [==============================] - 0s - loss: 1.6570 - val_loss: 1.7876\n",
      "Epoch 194/300\n",
      "70/70 [==============================] - 0s - loss: 1.7118 - val_loss: 1.7903\n",
      "Epoch 195/300\n",
      "70/70 [==============================] - 0s - loss: 1.8374 - val_loss: 1.7176\n",
      "Epoch 196/300\n",
      "70/70 [==============================] - 0s - loss: 1.9565 - val_loss: 1.6477\n",
      "Epoch 197/300\n",
      "70/70 [==============================] - 0s - loss: 1.9899 - val_loss: 1.8012\n",
      "Epoch 198/300\n",
      "70/70 [==============================] - 0s - loss: 1.9868 - val_loss: 1.7591\n",
      "Epoch 199/300\n",
      "70/70 [==============================] - 0s - loss: 1.7550 - val_loss: 1.7928\n",
      "Epoch 200/300\n",
      "70/70 [==============================] - 0s - loss: 2.0628 - val_loss: 1.7225\n",
      "Epoch 201/300\n",
      "70/70 [==============================] - 0s - loss: 1.7759 - val_loss: 1.5631\n",
      "Epoch 202/300\n",
      "70/70 [==============================] - 0s - loss: 1.8148 - val_loss: 1.7613\n",
      "Epoch 203/300\n",
      "70/70 [==============================] - 0s - loss: 1.7931 - val_loss: 1.6246\n",
      "Epoch 204/300\n",
      "70/70 [==============================] - 0s - loss: 1.7979 - val_loss: 1.7064\n",
      "Epoch 205/300\n",
      "70/70 [==============================] - 0s - loss: 1.9291 - val_loss: 1.7590\n",
      "Epoch 206/300\n",
      "70/70 [==============================] - 0s - loss: 1.8522 - val_loss: 1.7114\n",
      "Epoch 207/300\n",
      "70/70 [==============================] - 0s - loss: 1.8776 - val_loss: 1.6804\n",
      "Epoch 208/300\n",
      "70/70 [==============================] - 0s - loss: 1.7791 - val_loss: 1.7650\n",
      "Epoch 209/300\n",
      "70/70 [==============================] - 0s - loss: 1.9124 - val_loss: 1.6617\n",
      "Epoch 210/300\n",
      "70/70 [==============================] - 0s - loss: 1.9195 - val_loss: 1.7332\n",
      "Epoch 211/300\n",
      "70/70 [==============================] - 0s - loss: 1.8199 - val_loss: 1.7225\n",
      "Epoch 212/300\n",
      "46/70 [==================>...........] - ETA: 0s - loss: 1.7854\n",
      " Reduced learning rate to 7.70735e-05\n",
      "70/70 [==============================] - 0s - loss: 1.8440 - val_loss: 1.8672\n",
      "Epoch 1/300\n",
      "70/70 [==============================] - 0s - loss: 79.4876 - val_loss: 17.8087\n",
      "Epoch 2/300\n",
      "70/70 [==============================] - 0s - loss: 10.1999 - val_loss: 5.0173\n",
      "Epoch 3/300\n",
      "70/70 [==============================] - 0s - loss: 5.4785 - val_loss: 4.1075\n",
      "Epoch 4/300\n",
      "70/70 [==============================] - 0s - loss: 4.2191 - val_loss: 3.4563\n",
      "Epoch 5/300\n",
      "70/70 [==============================] - 0s - loss: 3.7968 - val_loss: 3.2699\n",
      "Epoch 6/300\n",
      "70/70 [==============================] - 0s - loss: 4.1936 - val_loss: 3.4910\n",
      "Epoch 7/300\n",
      "70/70 [==============================] - 0s - loss: 3.8014 - val_loss: 3.9455\n",
      "Epoch 8/300\n",
      "70/70 [==============================] - 0s - loss: 3.6971 - val_loss: 2.8648\n",
      "Epoch 9/300\n",
      "70/70 [==============================] - 0s - loss: 3.4849 - val_loss: 2.5493\n",
      "Epoch 10/300\n",
      "70/70 [==============================] - 0s - loss: 3.5446 - val_loss: 3.6260\n",
      "Epoch 11/300\n",
      "70/70 [==============================] - 0s - loss: 3.6274 - val_loss: 4.4763ss: 3.5\n",
      "Epoch 12/300\n",
      "70/70 [==============================] - 0s - loss: 3.3731 - val_loss: 3.4442\n",
      "Epoch 13/300\n",
      "70/70 [==============================] - 0s - loss: 3.4636 - val_loss: 3.3831\n",
      "Epoch 14/300\n",
      "70/70 [==============================] - 0s - loss: 3.2869 - val_loss: 2.5556\n",
      "Epoch 15/300\n",
      "70/70 [==============================] - 0s - loss: 3.5747 - val_loss: 3.1745\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 3.5270 - val_loss: 2.3918\n",
      "Epoch 17/300\n",
      "70/70 [==============================] - 0s - loss: 3.1889 - val_loss: 2.2737\n",
      "Epoch 18/300\n",
      "70/70 [==============================] - 0s - loss: 3.3956 - val_loss: 4.1791\n",
      "Epoch 19/300\n",
      "70/70 [==============================] - 0s - loss: 3.2351 - val_loss: 3.5535\n",
      "Epoch 20/300\n",
      "70/70 [==============================] - 0s - loss: 3.2969 - val_loss: 3.4498\n",
      "Epoch 21/300\n",
      "70/70 [==============================] - 0s - loss: 3.2276 - val_loss: 3.0050\n",
      "Epoch 22/300\n",
      "70/70 [==============================] - 0s - loss: 3.2285 - val_loss: 2.2623\n",
      "Epoch 23/300\n",
      "70/70 [==============================] - 0s - loss: 3.3204 - val_loss: 3.7910\n",
      "Epoch 24/300\n",
      "70/70 [==============================] - 0s - loss: 3.4471 - val_loss: 2.4685\n",
      "Epoch 25/300\n",
      "70/70 [==============================] - 0s - loss: 3.4024 - val_loss: 3.0585\n",
      "Epoch 26/300\n",
      "70/70 [==============================] - 0s - loss: 3.2176 - val_loss: 2.0648\n",
      "Epoch 27/300\n",
      "70/70 [==============================] - 0s - loss: 3.0877 - val_loss: 2.9597\n",
      "Epoch 28/300\n",
      "70/70 [==============================] - 0s - loss: 3.3153 - val_loss: 3.3002\n",
      "Epoch 29/300\n",
      "70/70 [==============================] - 0s - loss: 3.3619 - val_loss: 2.8486\n",
      "Epoch 30/300\n",
      "70/70 [==============================] - 0s - loss: 3.1979 - val_loss: 2.7625\n",
      "Epoch 31/300\n",
      "70/70 [==============================] - 0s - loss: 3.3212 - val_loss: 2.7505\n",
      "Epoch 32/300\n",
      "70/70 [==============================] - 0s - loss: 3.2464 - val_loss: 3.4054\n",
      "Epoch 33/300\n",
      "70/70 [==============================] - 0s - loss: 3.4571 - val_loss: 3.3343\n",
      "Epoch 34/300\n",
      "70/70 [==============================] - 0s - loss: 3.1897 - val_loss: 2.6826\n",
      "Epoch 35/300\n",
      "70/70 [==============================] - 0s - loss: 3.0337 - val_loss: 3.3002\n",
      "Epoch 36/300\n",
      "70/70 [==============================] - 0s - loss: 3.2492 - val_loss: 3.3453\n",
      "Epoch 37/300\n",
      "53/70 [=====================>........] - ETA: 0s - loss: 3.1106\n",
      " Reduced learning rate to 0.01\n",
      "70/70 [==============================] - 0s - loss: 3.0607 - val_loss: 3.4562\n",
      "Epoch 38/300\n",
      "70/70 [==============================] - 0s - loss: 2.0609 - val_loss: 2.0684\n",
      "Epoch 39/300\n",
      "70/70 [==============================] - 0s - loss: 2.5743 - val_loss: 1.8865\n",
      "Epoch 40/300\n",
      "70/70 [==============================] - 0s - loss: 2.3025 - val_loss: 1.9964\n",
      "Epoch 41/300\n",
      "70/70 [==============================] - 0s - loss: 2.2527 - val_loss: 1.8385\n",
      "Epoch 42/300\n",
      "70/70 [==============================] - 0s - loss: 2.2703 - val_loss: 1.9606\n",
      "Epoch 43/300\n",
      "70/70 [==============================] - 0s - loss: 2.2188 - val_loss: 2.2100\n",
      "Epoch 44/300\n",
      "70/70 [==============================] - 0s - loss: 2.0231 - val_loss: 1.7216\n",
      "Epoch 45/300\n",
      "70/70 [==============================] - 0s - loss: 2.3029 - val_loss: 2.1198\n",
      "Epoch 46/300\n",
      "70/70 [==============================] - 0s - loss: 2.3227 - val_loss: 1.8830\n",
      "Epoch 47/300\n",
      "70/70 [==============================] - 0s - loss: 2.3954 - val_loss: 1.8762\n",
      "Epoch 48/300\n",
      "70/70 [==============================] - 0s - loss: 2.3402 - val_loss: 1.8837\n",
      "Epoch 49/300\n",
      "70/70 [==============================] - 0s - loss: 2.1591 - val_loss: 2.1541\n",
      "Epoch 50/300\n",
      "70/70 [==============================] - 0s - loss: 2.1416 - val_loss: 2.0193\n",
      "Epoch 51/300\n",
      "70/70 [==============================] - 0s - loss: 2.2715 - val_loss: 1.8792\n",
      "Epoch 52/300\n",
      "70/70 [==============================] - 0s - loss: 2.1590 - val_loss: 1.7957\n",
      "Epoch 53/300\n",
      "70/70 [==============================] - 0s - loss: 2.2028 - val_loss: 2.0975\n",
      "Epoch 54/300\n",
      "70/70 [==============================] - 0s - loss: 2.1915 - val_loss: 2.0874\n",
      "Epoch 55/300\n",
      "49/70 [====================>.........] - ETA: 0s - loss: 2.3490\n",
      " Reduced learning rate to 0.00666667\n",
      "70/70 [==============================] - 0s - loss: 2.2926 - val_loss: 1.9314\n",
      "Epoch 56/300\n",
      "70/70 [==============================] - 0s - loss: 2.0795 - val_loss: 1.7246\n",
      "Epoch 57/300\n",
      "70/70 [==============================] - 0s - loss: 2.0233 - val_loss: 1.8206\n",
      "Epoch 58/300\n",
      "70/70 [==============================] - 0s - loss: 1.9417 - val_loss: 1.8026\n",
      "Epoch 59/300\n",
      "70/70 [==============================] - 0s - loss: 1.9180 - val_loss: 1.7892\n",
      "Epoch 60/300\n",
      "70/70 [==============================] - 0s - loss: 2.0228 - val_loss: 2.1096\n",
      "Epoch 61/300\n",
      "70/70 [==============================] - 0s - loss: 2.1244 - val_loss: 1.7314\n",
      "Epoch 62/300\n",
      "70/70 [==============================] - 0s - loss: 1.9962 - val_loss: 1.8832\n",
      "Epoch 63/300\n",
      "70/70 [==============================] - 0s - loss: 1.9844 - val_loss: 1.8582\n",
      "Epoch 64/300\n",
      "70/70 [==============================] - 0s - loss: 1.8790 - val_loss: 1.9570\n",
      "Epoch 65/300\n",
      "70/70 [==============================] - 0s - loss: 1.9443 - val_loss: 1.7338\n",
      "Epoch 66/300\n",
      "48/70 [===================>..........] - ETA: 0s - loss: 2.0666\n",
      " Reduced learning rate to 0.00444444\n",
      "70/70 [==============================] - 0s - loss: 1.9861 - val_loss: 1.7261\n",
      "Epoch 67/300\n",
      "70/70 [==============================] - 0s - loss: 1.7566 - val_loss: 1.7750\n",
      "Epoch 68/300\n",
      "70/70 [==============================] - 0s - loss: 1.9389 - val_loss: 1.8707\n",
      "Epoch 69/300\n",
      "70/70 [==============================] - 0s - loss: 1.7566 - val_loss: 1.9056\n",
      "Epoch 70/300\n",
      "70/70 [==============================] - 0s - loss: 1.9615 - val_loss: 1.7398\n",
      "Epoch 71/300\n",
      "70/70 [==============================] - 0s - loss: 1.8667 - val_loss: 1.6926\n",
      "Epoch 72/300\n",
      "70/70 [==============================] - 0s - loss: 1.9040 - val_loss: 1.8489\n",
      "Epoch 73/300\n",
      "70/70 [==============================] - 0s - loss: 1.9705 - val_loss: 2.0034\n",
      "Epoch 74/300\n",
      "70/70 [==============================] - 0s - loss: 1.8422 - val_loss: 1.7732\n",
      "Epoch 75/300\n",
      "70/70 [==============================] - 0s - loss: 1.8302 - val_loss: 1.8217\n",
      "Epoch 76/300\n",
      "70/70 [==============================] - 0s - loss: 2.0328 - val_loss: 1.7627ss: 2.01\n",
      "Epoch 77/300\n",
      "70/70 [==============================] - 0s - loss: 1.7910 - val_loss: 1.8992\n",
      "Epoch 78/300\n",
      "70/70 [==============================] - 0s - loss: 1.7990 - val_loss: 1.8243\n",
      "Epoch 79/300\n",
      "70/70 [==============================] - 0s - loss: 1.9098 - val_loss: 1.7630\n",
      "Epoch 80/300\n",
      "70/70 [==============================] - 0s - loss: 1.9107 - val_loss: 1.8046\n",
      "Epoch 81/300\n",
      "70/70 [==============================] - 0s - loss: 1.9278 - val_loss: 1.8374\n",
      "Epoch 82/300\n",
      "52/70 [=====================>........] - ETA: 0s - loss: 2.1563\n",
      " Reduced learning rate to 0.00296296\n",
      "70/70 [==============================] - 0s - loss: 2.1215 - val_loss: 1.9184\n",
      "Epoch 83/300\n",
      "70/70 [==============================] - 0s - loss: 1.7991 - val_loss: 1.7156\n",
      "Epoch 84/300\n",
      "70/70 [==============================] - 0s - loss: 1.8037 - val_loss: 1.8228\n",
      "Epoch 85/300\n",
      "70/70 [==============================] - 0s - loss: 1.8760 - val_loss: 1.8195\n",
      "Epoch 86/300\n",
      "70/70 [==============================] - 0s - loss: 1.8354 - val_loss: 1.8015\n",
      "Epoch 87/300\n",
      "70/70 [==============================] - 0s - loss: 1.8332 - val_loss: 1.7266\n",
      "Epoch 88/300\n",
      "70/70 [==============================] - 0s - loss: 1.7914 - val_loss: 1.8206\n",
      "Epoch 89/300\n",
      "70/70 [==============================] - 0s - loss: 1.8861 - val_loss: 1.7256\n",
      "Epoch 90/300\n",
      "70/70 [==============================] - 0s - loss: 1.9223 - val_loss: 1.9393\n",
      "Epoch 91/300\n",
      "70/70 [==============================] - 0s - loss: 1.7939 - val_loss: 1.7298\n",
      "Epoch 92/300\n",
      "70/70 [==============================] - 0s - loss: 1.9494 - val_loss: 1.7599\n",
      "Epoch 93/300\n",
      "70/70 [==============================] - 0s - loss: 1.7772 - val_loss: 1.6502\n",
      "Epoch 94/300\n",
      "70/70 [==============================] - 0s - loss: 1.7837 - val_loss: 1.7165\n",
      "Epoch 95/300\n",
      "70/70 [==============================] - 0s - loss: 1.7874 - val_loss: 1.7568\n",
      "Epoch 96/300\n",
      "70/70 [==============================] - 0s - loss: 1.7601 - val_loss: 1.8262\n",
      "Epoch 97/300\n",
      "70/70 [==============================] - 0s - loss: 1.8955 - val_loss: 1.7823\n",
      "Epoch 98/300\n",
      "70/70 [==============================] - 0s - loss: 1.9319 - val_loss: 1.6722\n",
      "Epoch 99/300\n",
      "70/70 [==============================] - 0s - loss: 1.9052 - val_loss: 1.7923\n",
      "Epoch 100/300\n",
      "70/70 [==============================] - 0s - loss: 1.7538 - val_loss: 1.6981\n",
      "Epoch 101/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 1.8020 - val_loss: 1.7934\n",
      "Epoch 102/300\n",
      "70/70 [==============================] - 0s - loss: 1.8907 - val_loss: 1.7863\n",
      "Epoch 103/300\n",
      "70/70 [==============================] - 0s - loss: 1.9990 - val_loss: 1.7822\n",
      "Epoch 104/300\n",
      "53/70 [=====================>........] - ETA: 0s - loss: 1.8540\n",
      " Reduced learning rate to 0.00197531\n",
      "70/70 [==============================] - 0s - loss: 1.8444 - val_loss: 1.7348\n",
      "Epoch 105/300\n",
      "70/70 [==============================] - 0s - loss: 1.7348 - val_loss: 1.7386\n",
      "Epoch 106/300\n",
      "70/70 [==============================] - 0s - loss: 1.8825 - val_loss: 1.8268\n",
      "Epoch 107/300\n",
      "70/70 [==============================] - 0s - loss: 1.8272 - val_loss: 1.7340\n",
      "Epoch 108/300\n",
      "70/70 [==============================] - 0s - loss: 1.8711 - val_loss: 1.7604\n",
      "Epoch 109/300\n",
      "70/70 [==============================] - 0s - loss: 1.7713 - val_loss: 1.7199\n",
      "Epoch 110/300\n",
      "70/70 [==============================] - 0s - loss: 1.7736 - val_loss: 1.7779\n",
      "Epoch 111/300\n",
      "70/70 [==============================] - 0s - loss: 1.8407 - val_loss: 1.8000\n",
      "Epoch 112/300\n",
      "70/70 [==============================] - 0s - loss: 1.8549 - val_loss: 1.6845\n",
      "Epoch 113/300\n",
      "70/70 [==============================] - 0s - loss: 1.8036 - val_loss: 1.8065\n",
      "Epoch 114/300\n",
      "70/70 [==============================] - 0s - loss: 1.8266 - val_loss: 1.7741\n",
      "Epoch 115/300\n",
      "60/70 [========================>.....] - ETA: 0s - loss: 1.7682\n",
      " Reduced learning rate to 0.00131687\n",
      "70/70 [==============================] - 0s - loss: 1.7923 - val_loss: 1.7763\n",
      "Epoch 116/300\n",
      "70/70 [==============================] - 0s - loss: 1.8256 - val_loss: 1.6766\n",
      "Epoch 117/300\n",
      "70/70 [==============================] - 0s - loss: 1.8641 - val_loss: 1.7640\n",
      "Epoch 118/300\n",
      "70/70 [==============================] - 0s - loss: 1.8915 - val_loss: 1.7415\n",
      "Epoch 119/300\n",
      "70/70 [==============================] - 0s - loss: 1.8488 - val_loss: 1.6644\n",
      "Epoch 120/300\n",
      "70/70 [==============================] - 0s - loss: 1.8460 - val_loss: 1.7274\n",
      "Epoch 121/300\n",
      "70/70 [==============================] - 0s - loss: 1.8546 - val_loss: 1.6895\n",
      "Epoch 122/300\n",
      "70/70 [==============================] - 0s - loss: 1.9937 - val_loss: 1.7325\n",
      "Epoch 123/300\n",
      "70/70 [==============================] - 0s - loss: 1.8636 - val_loss: 1.6984\n",
      "Epoch 124/300\n",
      "70/70 [==============================] - 0s - loss: 1.7166 - val_loss: 1.7531\n",
      "Epoch 125/300\n",
      "70/70 [==============================] - 0s - loss: 1.7306 - val_loss: 1.8171\n",
      "Epoch 126/300\n",
      "46/70 [==================>...........] - ETA: 0s - loss: 1.8083\n",
      " Reduced learning rate to 0.000877915\n",
      "70/70 [==============================] - 0s - loss: 1.7997 - val_loss: 1.7883\n",
      "Epoch 127/300\n",
      "70/70 [==============================] - 0s - loss: 1.8185 - val_loss: 1.7608\n",
      "Epoch 128/300\n",
      "70/70 [==============================] - 0s - loss: 1.8026 - val_loss: 1.6809\n",
      "Epoch 129/300\n",
      "70/70 [==============================] - 0s - loss: 1.9383 - val_loss: 1.8095\n",
      "Epoch 130/300\n",
      "70/70 [==============================] - 0s - loss: 1.8966 - val_loss: 1.7141\n",
      "Epoch 131/300\n",
      "70/70 [==============================] - 0s - loss: 1.8136 - val_loss: 1.7906\n",
      "Epoch 132/300\n",
      "70/70 [==============================] - 0s - loss: 1.8358 - val_loss: 1.7229\n",
      "Epoch 133/300\n",
      "70/70 [==============================] - 0s - loss: 1.8279 - val_loss: 1.7947\n",
      "Epoch 134/300\n",
      "70/70 [==============================] - 0s - loss: 1.9152 - val_loss: 1.6444\n",
      "Epoch 135/300\n",
      "70/70 [==============================] - 0s - loss: 1.9321 - val_loss: 1.8994\n",
      "Epoch 136/300\n",
      "70/70 [==============================] - 0s - loss: 1.8346 - val_loss: 1.7522\n",
      "Epoch 137/300\n",
      "70/70 [==============================] - 0s - loss: 1.7925 - val_loss: 1.7585\n",
      "Epoch 138/300\n",
      "70/70 [==============================] - 0s - loss: 1.7616 - val_loss: 1.6755\n",
      "Epoch 139/300\n",
      "70/70 [==============================] - 0s - loss: 1.8809 - val_loss: 1.6932\n",
      "Epoch 140/300\n",
      "70/70 [==============================] - 0s - loss: 1.7852 - val_loss: 1.7346\n",
      "Epoch 141/300\n",
      "70/70 [==============================] - 0s - loss: 1.8067 - val_loss: 1.6879\n",
      "Epoch 142/300\n",
      "70/70 [==============================] - 0s - loss: 1.9569 - val_loss: 1.7737\n",
      "Epoch 143/300\n",
      "70/70 [==============================] - 0s - loss: 1.8880 - val_loss: 1.7665\n",
      "Epoch 144/300\n",
      "70/70 [==============================] - 0s - loss: 1.9594 - val_loss: 1.6065\n",
      "Epoch 145/300\n",
      "70/70 [==============================] - 0s - loss: 1.8136 - val_loss: 1.7029\n",
      "Epoch 146/300\n",
      "70/70 [==============================] - 0s - loss: 1.7923 - val_loss: 1.7426\n",
      "Epoch 147/300\n",
      "70/70 [==============================] - 0s - loss: 1.8440 - val_loss: 1.7510\n",
      "Epoch 148/300\n",
      "70/70 [==============================] - 0s - loss: 1.9560 - val_loss: 1.6585\n",
      "Epoch 149/300\n",
      "70/70 [==============================] - 0s - loss: 1.8184 - val_loss: 1.5749\n",
      "Epoch 150/300\n",
      "70/70 [==============================] - 0s - loss: 1.7992 - val_loss: 1.6896\n",
      "Epoch 151/300\n",
      "70/70 [==============================] - 0s - loss: 1.7858 - val_loss: 1.7187\n",
      "Epoch 152/300\n",
      "70/70 [==============================] - 0s - loss: 1.8838 - val_loss: 1.7967\n",
      "Epoch 153/300\n",
      "70/70 [==============================] - 0s - loss: 1.8639 - val_loss: 1.7368\n",
      "Epoch 154/300\n",
      "70/70 [==============================] - 0s - loss: 1.8502 - val_loss: 1.6512\n",
      "Epoch 155/300\n",
      "70/70 [==============================] - 0s - loss: 1.8779 - val_loss: 1.8042\n",
      "Epoch 156/300\n",
      "70/70 [==============================] - 0s - loss: 1.7656 - val_loss: 1.8270\n",
      "Epoch 157/300\n",
      "70/70 [==============================] - 0s - loss: 1.8725 - val_loss: 1.6809\n",
      "Epoch 158/300\n",
      "70/70 [==============================] - 0s - loss: 1.7379 - val_loss: 1.9349\n",
      "Epoch 159/300\n",
      "70/70 [==============================] - 0s - loss: 1.7843 - val_loss: 1.7398\n",
      "Epoch 160/300\n",
      "68/70 [============================>.] - ETA: 0s - loss: 1.9629\n",
      " Reduced learning rate to 0.000585277\n",
      "70/70 [==============================] - 0s - loss: 1.9627 - val_loss: 1.7213\n",
      "Epoch 161/300\n",
      "70/70 [==============================] - 0s - loss: 1.7584 - val_loss: 1.7789\n",
      "Epoch 162/300\n",
      "70/70 [==============================] - 0s - loss: 1.7857 - val_loss: 1.7320\n",
      "Epoch 163/300\n",
      "70/70 [==============================] - 0s - loss: 1.7813 - val_loss: 1.7604\n",
      "Epoch 164/300\n",
      "70/70 [==============================] - 0s - loss: 1.8515 - val_loss: 1.6741\n",
      "Epoch 165/300\n",
      "70/70 [==============================] - 0s - loss: 1.8554 - val_loss: 1.7475\n",
      "Epoch 166/300\n",
      "70/70 [==============================] - 0s - loss: 1.9237 - val_loss: 1.8023\n",
      "Epoch 167/300\n",
      "70/70 [==============================] - 0s - loss: 1.9143 - val_loss: 1.8157\n",
      "Epoch 168/300\n",
      "70/70 [==============================] - 0s - loss: 1.7718 - val_loss: 1.8060\n",
      "Epoch 169/300\n",
      "70/70 [==============================] - 0s - loss: 1.8710 - val_loss: 1.7178\n",
      "Epoch 170/300\n",
      "70/70 [==============================] - 0s - loss: 1.8142 - val_loss: 1.7982\n",
      "Epoch 171/300\n",
      "65/70 [==========================>...] - ETA: 0s - loss: 1.7560\n",
      " Reduced learning rate to 0.000390184\n",
      "70/70 [==============================] - 0s - loss: 1.7520 - val_loss: 1.7762\n",
      "Epoch 172/300\n",
      "70/70 [==============================] - 0s - loss: 1.8509 - val_loss: 1.7967\n",
      "Epoch 173/300\n",
      "70/70 [==============================] - 0s - loss: 1.7969 - val_loss: 1.7150\n",
      "Epoch 174/300\n",
      "70/70 [==============================] - 0s - loss: 1.7952 - val_loss: 1.7114\n",
      "Epoch 175/300\n",
      "70/70 [==============================] - 0s - loss: 1.8374 - val_loss: 1.8178\n",
      "Epoch 176/300\n",
      "70/70 [==============================] - 0s - loss: 1.8037 - val_loss: 1.8682\n",
      "Epoch 177/300\n",
      "70/70 [==============================] - 0s - loss: 1.7316 - val_loss: 1.7695\n",
      "Epoch 178/300\n",
      "70/70 [==============================] - 0s - loss: 1.7405 - val_loss: 1.6541\n",
      "Epoch 179/300\n",
      "70/70 [==============================] - 0s - loss: 1.7522 - val_loss: 1.7840\n",
      "Epoch 180/300\n",
      "70/70 [==============================] - 0s - loss: 1.8026 - val_loss: 1.6983\n",
      "Epoch 181/300\n",
      "70/70 [==============================] - 0s - loss: 1.9667 - val_loss: 1.7194\n",
      "Epoch 182/300\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 1.8643\n",
      " Reduced learning rate to 0.000260123\n",
      "70/70 [==============================] - 0s - loss: 1.8593 - val_loss: 1.6720\n",
      "Epoch 183/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 1.7478 - val_loss: 1.6787\n",
      "Epoch 184/300\n",
      "70/70 [==============================] - 0s - loss: 1.7546 - val_loss: 1.6933\n",
      "Epoch 185/300\n",
      "70/70 [==============================] - 0s - loss: 1.8159 - val_loss: 1.8498\n",
      "Epoch 186/300\n",
      "70/70 [==============================] - 0s - loss: 1.8079 - val_loss: 1.6485\n",
      "Epoch 187/300\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.823 - 0s - loss: 1.8253 - val_loss: 1.7832\n",
      "Epoch 188/300\n",
      "70/70 [==============================] - 0s - loss: 2.0805 - val_loss: 1.6648\n",
      "Epoch 189/300\n",
      "70/70 [==============================] - 0s - loss: 1.7966 - val_loss: 1.7447\n",
      "Epoch 190/300\n",
      "70/70 [==============================] - 0s - loss: 1.7978 - val_loss: 1.8576\n",
      "Epoch 191/300\n",
      "70/70 [==============================] - 0s - loss: 1.8660 - val_loss: 1.7617\n",
      "Epoch 192/300\n",
      "70/70 [==============================] - 0s - loss: 1.7913 - val_loss: 1.6708\n",
      "Epoch 193/300\n",
      "55/70 [======================>.......] - ETA: 0s - loss: 1.8168\n",
      " Reduced learning rate to 0.000173415\n",
      "70/70 [==============================] - 0s - loss: 1.8084 - val_loss: 1.8147\n",
      "Epoch 194/300\n",
      "70/70 [==============================] - 0s - loss: 1.9538 - val_loss: 1.6998\n",
      "Epoch 195/300\n",
      "70/70 [==============================] - 0s - loss: 1.7756 - val_loss: 1.7123\n",
      "Epoch 196/300\n",
      "70/70 [==============================] - 0s - loss: 1.7872 - val_loss: 1.7096\n",
      "Epoch 197/300\n",
      "70/70 [==============================] - 0s - loss: 1.9722 - val_loss: 1.7749\n",
      "Epoch 198/300\n",
      "70/70 [==============================] - 0s - loss: 1.7964 - val_loss: 1.7372\n",
      "Epoch 199/300\n",
      "70/70 [==============================] - 0s - loss: 1.8931 - val_loss: 1.7793\n",
      "Epoch 200/300\n",
      "70/70 [==============================] - 0s - loss: 1.6857 - val_loss: 1.8677\n",
      "Epoch 201/300\n",
      "70/70 [==============================] - 0s - loss: 1.8295 - val_loss: 1.7301\n",
      "Epoch 202/300\n",
      "70/70 [==============================] - 0s - loss: 1.8022 - val_loss: 1.6216\n",
      "Epoch 203/300\n",
      "70/70 [==============================] - 0s - loss: 1.8767 - val_loss: 1.7025\n",
      "Epoch 204/300\n",
      "60/70 [========================>.....] - ETA: 0s - loss: 1.8859\n",
      " Reduced learning rate to 0.00011561\n",
      "70/70 [==============================] - 0s - loss: 1.8586 - val_loss: 1.7040\n",
      "Epoch 205/300\n",
      "70/70 [==============================] - 0s - loss: 1.7582 - val_loss: 1.8088\n",
      "Epoch 206/300\n",
      "70/70 [==============================] - 0s - loss: 1.8094 - val_loss: 1.7539\n",
      "Epoch 207/300\n",
      "70/70 [==============================] - 0s - loss: 1.7669 - val_loss: 1.6796\n",
      "Epoch 208/300\n",
      "70/70 [==============================] - 0s - loss: 1.9973 - val_loss: 1.6653\n",
      "Epoch 209/300\n",
      "70/70 [==============================] - 0s - loss: 1.7482 - val_loss: 1.8293\n",
      "Epoch 210/300\n",
      "70/70 [==============================] - 0s - loss: 1.7443 - val_loss: 1.7364\n",
      "Epoch 211/300\n",
      "70/70 [==============================] - 0s - loss: 1.7084 - val_loss: 1.7363\n",
      "Epoch 212/300\n",
      "70/70 [==============================] - 0s - loss: 1.8141 - val_loss: 1.6816\n",
      "Epoch 213/300\n",
      "70/70 [==============================] - 0s - loss: 1.8402 - val_loss: 1.8380\n",
      "Epoch 214/300\n",
      "70/70 [==============================] - 0s - loss: 1.9125 - val_loss: 1.7774\n",
      "Epoch 215/300\n",
      "61/70 [=========================>....] - ETA: 0s - loss: 1.9510\n",
      " Reduced learning rate to 7.70735e-05\n",
      "70/70 [==============================] - 0s - loss: 1.9221 - val_loss: 1.7515\n",
      "Epoch 1/300\n",
      "70/70 [==============================] - 1s - loss: 72.4995 - val_loss: 14.5725\n",
      "Epoch 2/300\n",
      "70/70 [==============================] - 0s - loss: 9.4187 - val_loss: 4.9861\n",
      "Epoch 3/300\n",
      "70/70 [==============================] - 0s - loss: 5.1336 - val_loss: 3.8223\n",
      "Epoch 4/300\n",
      "70/70 [==============================] - 0s - loss: 4.3952 - val_loss: 3.1429\n",
      "Epoch 5/300\n",
      "70/70 [==============================] - 0s - loss: 3.6619 - val_loss: 3.3219\n",
      "Epoch 6/300\n",
      "70/70 [==============================] - 0s - loss: 3.4777 - val_loss: 3.4542\n",
      "Epoch 7/300\n",
      "70/70 [==============================] - 0s - loss: 3.4622 - val_loss: 3.1883\n",
      "Epoch 8/300\n",
      "70/70 [==============================] - 0s - loss: 3.6347 - val_loss: 3.0924\n",
      "Epoch 9/300\n",
      "70/70 [==============================] - 0s - loss: 3.2568 - val_loss: 4.0524\n",
      "Epoch 10/300\n",
      "70/70 [==============================] - 0s - loss: 3.9479 - val_loss: 3.1884\n",
      "Epoch 11/300\n",
      "70/70 [==============================] - 0s - loss: 3.3594 - val_loss: 2.9821\n",
      "Epoch 12/300\n",
      "70/70 [==============================] - 0s - loss: 3.4322 - val_loss: 2.6038\n",
      "Epoch 13/300\n",
      "70/70 [==============================] - 0s - loss: 4.0020 - val_loss: 2.8569\n",
      "Epoch 14/300\n",
      "70/70 [==============================] - 0s - loss: 3.3006 - val_loss: 2.9595\n",
      "Epoch 15/300\n",
      "70/70 [==============================] - 0s - loss: 3.4168 - val_loss: 3.3938\n",
      "Epoch 16/300\n",
      "70/70 [==============================] - 0s - loss: 3.3301 - val_loss: 2.9293\n",
      "Epoch 17/300\n",
      "70/70 [==============================] - 0s - loss: 3.2320 - val_loss: 3.0492\n",
      "Epoch 18/300\n",
      "70/70 [==============================] - 0s - loss: 3.5968 - val_loss: 3.0659\n",
      "Epoch 19/300\n",
      "70/70 [==============================] - 0s - loss: 3.4932 - val_loss: 2.7684\n",
      "Epoch 20/300\n",
      "70/70 [==============================] - 0s - loss: 3.1487 - val_loss: 2.2610\n",
      "Epoch 21/300\n",
      "70/70 [==============================] - 0s - loss: 3.1807 - val_loss: 2.2880\n",
      "Epoch 22/300\n",
      "70/70 [==============================] - 0s - loss: 3.4101 - val_loss: 2.2667\n",
      "Epoch 23/300\n",
      "70/70 [==============================] - 0s - loss: 3.1666 - val_loss: 3.0027\n",
      "Epoch 24/300\n",
      "70/70 [==============================] - 0s - loss: 3.4359 - val_loss: 3.6918\n",
      "Epoch 25/300\n",
      "70/70 [==============================] - 0s - loss: 3.3531 - val_loss: 2.5401\n",
      "Epoch 26/300\n",
      "70/70 [==============================] - 0s - loss: 3.2944 - val_loss: 2.9075ss: \n",
      "Epoch 27/300\n",
      "70/70 [==============================] - 0s - loss: 3.2838 - val_loss: 2.8405\n",
      "Epoch 28/300\n",
      "70/70 [==============================] - 0s - loss: 3.1405 - val_loss: 2.2819\n",
      "Epoch 29/300\n",
      "70/70 [==============================] - 0s - loss: 3.1042 - val_loss: 3.4473\n",
      "Epoch 30/300\n",
      "70/70 [==============================] - 0s - loss: 3.1693 - val_loss: 2.7801\n",
      "Epoch 31/300\n",
      "59/70 [========================>.....] - ETA: 0s - loss: 3.2166\n",
      " Reduced learning rate to 0.01\n",
      "70/70 [==============================] - 0s - loss: 3.2862 - val_loss: 3.6253\n",
      "Epoch 32/300\n",
      "70/70 [==============================] - 0s - loss: 2.3098 - val_loss: 1.8021\n",
      "Epoch 33/300\n",
      "70/70 [==============================] - 0s - loss: 2.3063 - val_loss: 2.1654\n",
      "Epoch 34/300\n",
      "70/70 [==============================] - 0s - loss: 2.2622 - val_loss: 1.9503\n",
      "Epoch 35/300\n",
      "70/70 [==============================] - 0s - loss: 2.3716 - val_loss: 2.0324\n",
      "Epoch 36/300\n",
      "70/70 [==============================] - 0s - loss: 2.1810 - val_loss: 1.8772\n",
      "Epoch 37/300\n",
      "70/70 [==============================] - 0s - loss: 2.1726 - val_loss: 2.2760\n",
      "Epoch 38/300\n",
      "70/70 [==============================] - 0s - loss: 2.1010 - val_loss: 1.7985\n",
      "Epoch 39/300\n",
      "70/70 [==============================] - 0s - loss: 2.2650 - val_loss: 1.9044\n",
      "Epoch 40/300\n",
      "70/70 [==============================] - 0s - loss: 2.1553 - val_loss: 1.8817\n",
      "Epoch 41/300\n",
      "70/70 [==============================] - 0s - loss: 2.2056 - val_loss: 1.8608\n",
      "Epoch 42/300\n",
      "70/70 [==============================] - 0s - loss: 2.1282 - val_loss: 1.9025\n",
      "Epoch 43/300\n",
      "70/70 [==============================] - 0s - loss: 2.3568 - val_loss: 1.6831\n",
      "Epoch 44/300\n",
      "70/70 [==============================] - 0s - loss: 2.1977 - val_loss: 2.2238\n",
      "Epoch 45/300\n",
      "70/70 [==============================] - 0s - loss: 2.2339 - val_loss: 1.9829\n",
      "Epoch 46/300\n",
      "70/70 [==============================] - 0s - loss: 2.2047 - val_loss: 2.1033\n",
      "Epoch 47/300\n",
      "70/70 [==============================] - 0s - loss: 2.3280 - val_loss: 1.8647\n",
      "Epoch 48/300\n",
      "70/70 [==============================] - 0s - loss: 2.3535 - val_loss: 2.3773\n",
      "Epoch 49/300\n",
      "70/70 [==============================] - 0s - loss: 2.3056 - val_loss: 1.9194\n",
      "Epoch 50/300\n",
      "70/70 [==============================] - 0s - loss: 2.3937 - val_loss: 2.9333\n",
      "Epoch 51/300\n",
      "70/70 [==============================] - 0s - loss: 2.2860 - val_loss: 2.2544\n",
      "Epoch 52/300\n",
      "70/70 [==============================] - 0s - loss: 2.2732 - val_loss: 1.7959\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 2.2413 - val_loss: 2.1913\n",
      "Epoch 54/300\n",
      "64/70 [==========================>...] - ETA: 0s - loss: 2.3605\n",
      " Reduced learning rate to 0.00666667\n",
      "70/70 [==============================] - 0s - loss: 2.3422 - val_loss: 1.8332\n",
      "Epoch 55/300\n",
      "70/70 [==============================] - 0s - loss: 1.8798 - val_loss: 1.8496\n",
      "Epoch 56/300\n",
      "70/70 [==============================] - 0s - loss: 1.9540 - val_loss: 1.8697\n",
      "Epoch 57/300\n",
      "70/70 [==============================] - 0s - loss: 2.0090 - val_loss: 1.8770\n",
      "Epoch 58/300\n",
      "70/70 [==============================] - 0s - loss: 2.1633 - val_loss: 1.7673\n",
      "Epoch 59/300\n",
      "70/70 [==============================] - 0s - loss: 1.8356 - val_loss: 1.8256\n",
      "Epoch 60/300\n",
      "70/70 [==============================] - 0s - loss: 1.8903 - val_loss: 1.8974\n",
      "Epoch 61/300\n",
      "70/70 [==============================] - 0s - loss: 1.9209 - val_loss: 1.7213\n",
      "Epoch 62/300\n",
      "70/70 [==============================] - 0s - loss: 1.9602 - val_loss: 1.8058\n",
      "Epoch 63/300\n",
      "70/70 [==============================] - 0s - loss: 1.9189 - val_loss: 1.8284\n",
      "Epoch 64/300\n",
      "70/70 [==============================] - 0s - loss: 2.0309 - val_loss: 1.7828\n",
      "Epoch 65/300\n",
      "58/70 [=======================>......] - ETA: 0s - loss: 1.9651\n",
      " Reduced learning rate to 0.00444444\n",
      "70/70 [==============================] - 0s - loss: 1.9616 - val_loss: 2.0036\n",
      "Epoch 66/300\n",
      "70/70 [==============================] - 0s - loss: 2.0207 - val_loss: 1.8298\n",
      "Epoch 67/300\n",
      "70/70 [==============================] - 0s - loss: 1.9539 - val_loss: 1.7485\n",
      "Epoch 68/300\n",
      "70/70 [==============================] - 0s - loss: 2.1960 - val_loss: 1.7616\n",
      "Epoch 69/300\n",
      "70/70 [==============================] - 0s - loss: 1.8175 - val_loss: 1.7535\n",
      "Epoch 70/300\n",
      "70/70 [==============================] - 0s - loss: 1.9051 - val_loss: 1.8056\n",
      "Epoch 71/300\n",
      "70/70 [==============================] - 0s - loss: 1.7648 - val_loss: 1.7377\n",
      "Epoch 72/300\n",
      "70/70 [==============================] - 0s - loss: 1.8835 - val_loss: 1.8745\n",
      "Epoch 73/300\n",
      "70/70 [==============================] - 0s - loss: 1.8570 - val_loss: 1.8820\n",
      "Epoch 74/300\n",
      "70/70 [==============================] - 0s - loss: 1.9474 - val_loss: 1.8390\n",
      "Epoch 75/300\n",
      "70/70 [==============================] - 0s - loss: 1.8592 - val_loss: 1.8112\n",
      "Epoch 76/300\n",
      "68/70 [============================>.] - ETA: 0s - loss: 1.9599\n",
      " Reduced learning rate to 0.00296296\n",
      "70/70 [==============================] - 0s - loss: 1.9498 - val_loss: 1.7331\n",
      "Epoch 77/300\n",
      "70/70 [==============================] - 0s - loss: 1.8698 - val_loss: 1.8304\n",
      "Epoch 78/300\n",
      "70/70 [==============================] - 0s - loss: 1.9072 - val_loss: 1.8458\n",
      "Epoch 79/300\n",
      "70/70 [==============================] - 0s - loss: 1.9294 - val_loss: 1.7538\n",
      "Epoch 80/300\n",
      "70/70 [==============================] - 0s - loss: 1.8287 - val_loss: 1.6649\n",
      "Epoch 81/300\n",
      "70/70 [==============================] - 0s - loss: 1.8525 - val_loss: 1.7812\n",
      "Epoch 82/300\n",
      "70/70 [==============================] - 0s - loss: 1.8320 - val_loss: 1.7820\n",
      "Epoch 83/300\n",
      "70/70 [==============================] - 0s - loss: 1.8934 - val_loss: 1.7901\n",
      "Epoch 84/300\n",
      "70/70 [==============================] - 0s - loss: 1.8397 - val_loss: 1.6784\n",
      "Epoch 85/300\n",
      "70/70 [==============================] - 0s - loss: 1.8683 - val_loss: 1.8572\n",
      "Epoch 86/300\n",
      "70/70 [==============================] - 0s - loss: 1.7620 - val_loss: 1.8201\n",
      "Epoch 87/300\n",
      "70/70 [==============================] - 0s - loss: 1.7995 - val_loss: 1.7517\n",
      "Epoch 88/300\n",
      "70/70 [==============================] - 0s - loss: 1.9441 - val_loss: 1.5939\n",
      "Epoch 89/300\n",
      "70/70 [==============================] - 0s - loss: 1.7924 - val_loss: 1.7533\n",
      "Epoch 90/300\n",
      "70/70 [==============================] - 0s - loss: 1.8076 - val_loss: 1.7740\n",
      "Epoch 91/300\n",
      "70/70 [==============================] - 0s - loss: 1.8320 - val_loss: 1.7703\n",
      "Epoch 92/300\n",
      "70/70 [==============================] - 0s - loss: 1.9241 - val_loss: 1.7089\n",
      "Epoch 93/300\n",
      "70/70 [==============================] - 0s - loss: 2.0268 - val_loss: 1.7375\n",
      "Epoch 94/300\n",
      "70/70 [==============================] - 0s - loss: 1.7826 - val_loss: 1.7951\n",
      "Epoch 95/300\n",
      "70/70 [==============================] - 0s - loss: 1.8016 - val_loss: 1.7943\n",
      "Epoch 96/300\n",
      "70/70 [==============================] - 0s - loss: 1.7857 - val_loss: 1.6957\n",
      "Epoch 97/300\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.793 - 0s - loss: 1.7892 - val_loss: 1.8017\n",
      "Epoch 98/300\n",
      "70/70 [==============================] - 0s - loss: 1.8262 - val_loss: 1.7855\n",
      "Epoch 99/300\n",
      "61/70 [=========================>....] - ETA: 0s - loss: 1.9433\n",
      " Reduced learning rate to 0.00197531\n",
      "70/70 [==============================] - 0s - loss: 1.9234 - val_loss: 1.7099\n",
      "Epoch 100/300\n",
      "70/70 [==============================] - 0s - loss: 1.8404 - val_loss: 1.6813\n",
      "Epoch 101/300\n",
      "70/70 [==============================] - 0s - loss: 1.9254 - val_loss: 1.7452\n",
      "Epoch 102/300\n",
      "70/70 [==============================] - 0s - loss: 1.7997 - val_loss: 1.8177\n",
      "Epoch 103/300\n",
      "70/70 [==============================] - 0s - loss: 1.8707 - val_loss: 1.7214\n",
      "Epoch 104/300\n",
      "70/70 [==============================] - 0s - loss: 1.8645 - val_loss: 1.7247\n",
      "Epoch 105/300\n",
      "70/70 [==============================] - 0s - loss: 1.9962 - val_loss: 1.6372\n",
      "Epoch 106/300\n",
      "70/70 [==============================] - 0s - loss: 1.8268 - val_loss: 1.6558\n",
      "Epoch 107/300\n",
      "70/70 [==============================] - 0s - loss: 1.7817 - val_loss: 1.8228\n",
      "Epoch 108/300\n",
      "70/70 [==============================] - 0s - loss: 2.0338 - val_loss: 1.7062\n",
      "Epoch 109/300\n",
      "70/70 [==============================] - 0s - loss: 1.8181 - val_loss: 1.7365\n",
      "Epoch 110/300\n",
      "62/70 [=========================>....] - ETA: 0s - loss: 1.7274\n",
      " Reduced learning rate to 0.00131687\n",
      "70/70 [==============================] - 0s - loss: 1.7494 - val_loss: 1.6014\n",
      "Epoch 111/300\n",
      "70/70 [==============================] - 0s - loss: 1.7966 - val_loss: 1.7454\n",
      "Epoch 112/300\n",
      "70/70 [==============================] - 0s - loss: 1.8574 - val_loss: 1.7989\n",
      "Epoch 113/300\n",
      "70/70 [==============================] - 0s - loss: 1.8937 - val_loss: 1.7507\n",
      "Epoch 114/300\n",
      "70/70 [==============================] - 0s - loss: 1.7326 - val_loss: 1.7771\n",
      "Epoch 115/300\n",
      "70/70 [==============================] - 0s - loss: 1.8026 - val_loss: 1.8809\n",
      "Epoch 116/300\n",
      "70/70 [==============================] - 0s - loss: 1.9023 - val_loss: 1.6760\n",
      "Epoch 117/300\n",
      "70/70 [==============================] - 0s - loss: 1.9515 - val_loss: 1.7218\n",
      "Epoch 118/300\n",
      "70/70 [==============================] - 0s - loss: 1.9349 - val_loss: 1.8441\n",
      "Epoch 119/300\n",
      "70/70 [==============================] - 0s - loss: 1.7685 - val_loss: 1.7683\n",
      "Epoch 120/300\n",
      "70/70 [==============================] - 0s - loss: 1.7676 - val_loss: 1.6741\n",
      "Epoch 121/300\n",
      "65/70 [==========================>...] - ETA: 0s - loss: 1.8798\n",
      " Reduced learning rate to 0.000877915\n",
      "70/70 [==============================] - 0s - loss: 1.8636 - val_loss: 1.6895\n",
      "Epoch 122/300\n",
      "70/70 [==============================] - 0s - loss: 1.9543 - val_loss: 1.7704\n",
      "Epoch 123/300\n",
      "70/70 [==============================] - 0s - loss: 1.9627 - val_loss: 1.7732\n",
      "Epoch 124/300\n",
      "70/70 [==============================] - 0s - loss: 1.9543 - val_loss: 1.7773\n",
      "Epoch 125/300\n",
      "70/70 [==============================] - 0s - loss: 1.9753 - val_loss: 1.7362\n",
      "Epoch 126/300\n",
      "70/70 [==============================] - 0s - loss: 1.9336 - val_loss: 1.6519\n",
      "Epoch 127/300\n",
      "70/70 [==============================] - 0s - loss: 1.8287 - val_loss: 1.7358\n",
      "Epoch 128/300\n",
      "70/70 [==============================] - 0s - loss: 1.8726 - val_loss: 1.7443\n",
      "Epoch 129/300\n",
      "70/70 [==============================] - 0s - loss: 1.8901 - val_loss: 1.6357\n",
      "Epoch 130/300\n",
      "70/70 [==============================] - 0s - loss: 1.7547 - val_loss: 1.6389\n",
      "Epoch 131/300\n",
      "70/70 [==============================] - 0s - loss: 1.7793 - val_loss: 1.7981\n",
      "Epoch 132/300\n",
      "65/70 [==========================>...] - ETA: 0s - loss: 1.9157\n",
      " Reduced learning rate to 0.000585277\n",
      "70/70 [==============================] - 0s - loss: 1.9106 - val_loss: 1.7486\n",
      "Epoch 133/300\n",
      "70/70 [==============================] - 0s - loss: 1.9072 - val_loss: 1.7343\n",
      "Epoch 134/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 1.9447 - val_loss: 1.8856\n",
      "Epoch 135/300\n",
      "70/70 [==============================] - 0s - loss: 1.8151 - val_loss: 1.7302\n",
      "Epoch 136/300\n",
      "70/70 [==============================] - 0s - loss: 1.8861 - val_loss: 1.6861\n",
      "Epoch 137/300\n",
      "70/70 [==============================] - 0s - loss: 1.9032 - val_loss: 1.7361\n",
      "Epoch 138/300\n",
      "70/70 [==============================] - 0s - loss: 1.8793 - val_loss: 1.7152\n",
      "Epoch 139/300\n",
      "70/70 [==============================] - 0s - loss: 1.8269 - val_loss: 1.7881\n",
      "Epoch 140/300\n",
      "70/70 [==============================] - 0s - loss: 1.7580 - val_loss: 1.7180\n",
      "Epoch 141/300\n",
      "70/70 [==============================] - 0s - loss: 1.8955 - val_loss: 1.7246\n",
      "Epoch 142/300\n",
      "70/70 [==============================] - 0s - loss: 1.7317 - val_loss: 1.6577\n",
      "Epoch 143/300\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 1.7764\n",
      " Reduced learning rate to 0.000390184\n",
      "70/70 [==============================] - 0s - loss: 1.7607 - val_loss: 1.7014\n",
      "Epoch 144/300\n",
      "70/70 [==============================] - 0s - loss: 1.7823 - val_loss: 1.8465\n",
      "Epoch 145/300\n",
      "70/70 [==============================] - 0s - loss: 1.8007 - val_loss: 1.7704\n",
      "Epoch 146/300\n",
      "70/70 [==============================] - 0s - loss: 1.9868 - val_loss: 1.7471ss: 2.\n",
      "Epoch 147/300\n",
      "70/70 [==============================] - 0s - loss: 1.8642 - val_loss: 1.7451\n",
      "Epoch 148/300\n",
      "70/70 [==============================] - 0s - loss: 1.7375 - val_loss: 1.8510\n",
      "Epoch 149/300\n",
      "70/70 [==============================] - 0s - loss: 1.7538 - val_loss: 1.7151\n",
      "Epoch 150/300\n",
      "70/70 [==============================] - 0s - loss: 1.7787 - val_loss: 1.6674\n",
      "Epoch 151/300\n",
      "70/70 [==============================] - 0s - loss: 1.7932 - val_loss: 1.7973\n",
      "Epoch 152/300\n",
      "70/70 [==============================] - 0s - loss: 1.8948 - val_loss: 1.7597\n",
      "Epoch 153/300\n",
      "70/70 [==============================] - 0s - loss: 1.7871 - val_loss: 1.6528\n",
      "Epoch 154/300\n",
      "62/70 [=========================>....] - ETA: 0s - loss: 1.7589\n",
      " Reduced learning rate to 0.000260123\n",
      "70/70 [==============================] - 0s - loss: 1.7648 - val_loss: 1.6567\n",
      "Epoch 155/300\n",
      "70/70 [==============================] - 0s - loss: 1.7856 - val_loss: 1.7495\n",
      "Epoch 156/300\n",
      "70/70 [==============================] - 0s - loss: 1.8087 - val_loss: 1.7387\n",
      "Epoch 157/300\n",
      "70/70 [==============================] - 0s - loss: 1.9547 - val_loss: 1.7792ss: 1\n",
      "Epoch 158/300\n",
      "70/70 [==============================] - 0s - loss: 1.9203 - val_loss: 1.7688\n",
      "Epoch 159/300\n",
      "70/70 [==============================] - 0s - loss: 1.8455 - val_loss: 1.8232\n",
      "Epoch 160/300\n",
      "70/70 [==============================] - 0s - loss: 1.7918 - val_loss: 1.7580\n",
      "Epoch 161/300\n",
      "70/70 [==============================] - 0s - loss: 1.8303 - val_loss: 1.7027\n",
      "Epoch 162/300\n",
      "70/70 [==============================] - 0s - loss: 1.9288 - val_loss: 1.7220\n",
      "Epoch 163/300\n",
      "70/70 [==============================] - 0s - loss: 1.8218 - val_loss: 1.6845\n",
      "Epoch 164/300\n",
      "70/70 [==============================] - 0s - loss: 1.7417 - val_loss: 1.8080\n",
      "Epoch 165/300\n",
      "60/70 [========================>.....] - ETA: 0s - loss: 1.9242\n",
      " Reduced learning rate to 0.000173415\n",
      "70/70 [==============================] - 0s - loss: 1.9699 - val_loss: 1.8032\n",
      "Epoch 166/300\n",
      "70/70 [==============================] - 0s - loss: 1.7548 - val_loss: 1.6459\n",
      "Epoch 167/300\n",
      "70/70 [==============================] - 0s - loss: 1.8466 - val_loss: 1.7458\n",
      "Epoch 168/300\n",
      "70/70 [==============================] - 0s - loss: 1.7437 - val_loss: 1.7252\n",
      "Epoch 169/300\n",
      "70/70 [==============================] - 0s - loss: 1.8609 - val_loss: 1.7785\n",
      "Epoch 170/300\n",
      "70/70 [==============================] - 0s - loss: 1.8987 - val_loss: 1.7414\n",
      "Epoch 171/300\n",
      "70/70 [==============================] - 0s - loss: 1.8204 - val_loss: 1.7814\n",
      "Epoch 172/300\n",
      "70/70 [==============================] - 0s - loss: 1.8874 - val_loss: 1.7552\n",
      "Epoch 173/300\n",
      "70/70 [==============================] - 0s - loss: 1.8404 - val_loss: 1.8039\n",
      "Epoch 174/300\n",
      "70/70 [==============================] - 0s - loss: 1.8833 - val_loss: 1.7576\n",
      "Epoch 175/300\n",
      "70/70 [==============================] - 0s - loss: 1.8855 - val_loss: 1.6504\n",
      "Epoch 176/300\n",
      "69/70 [============================>.] - ETA: 0s - loss: 1.8293\n",
      " Reduced learning rate to 0.00011561\n",
      "70/70 [==============================] - 0s - loss: 1.8306 - val_loss: 1.7827\n",
      "Epoch 177/300\n",
      "70/70 [==============================] - 0s - loss: 1.7609 - val_loss: 1.7454\n",
      "Epoch 178/300\n",
      "70/70 [==============================] - 0s - loss: 1.8265 - val_loss: 1.8581\n",
      "Epoch 179/300\n",
      "70/70 [==============================] - 0s - loss: 1.8377 - val_loss: 1.6994\n",
      "Epoch 180/300\n",
      "70/70 [==============================] - 0s - loss: 1.7828 - val_loss: 1.7074\n",
      "Epoch 181/300\n",
      "70/70 [==============================] - 0s - loss: 1.8374 - val_loss: 1.7320\n",
      "Epoch 182/300\n",
      "70/70 [==============================] - 0s - loss: 1.8049 - val_loss: 1.8092\n",
      "Epoch 183/300\n",
      "70/70 [==============================] - 0s - loss: 1.8357 - val_loss: 1.9205\n",
      "Epoch 184/300\n",
      "70/70 [==============================] - 0s - loss: 1.8453 - val_loss: 1.7460\n",
      "Epoch 185/300\n",
      "70/70 [==============================] - 0s - loss: 1.7991 - val_loss: 1.7080\n",
      "Epoch 186/300\n",
      "70/70 [==============================] - 0s - loss: 1.8161 - val_loss: 1.9121\n",
      "Epoch 187/300\n",
      "68/70 [============================>.] - ETA: 0s - loss: 1.7656\n",
      " Reduced learning rate to 7.70735e-05\n",
      "70/70 [==============================] - 0s - loss: 1.7622 - val_loss: 1.6414\n",
      "Epoch 1/300\n",
      "70/70 [==============================] - 1s - loss: 70.2004 - val_loss: 14.0701\n",
      "Epoch 2/300\n",
      "70/70 [==============================] - 0s - loss: 8.6756 - val_loss: 5.2069\n",
      "Epoch 3/300\n",
      "70/70 [==============================] - 0s - loss: 5.4662 - val_loss: 3.7791\n",
      "Epoch 4/300\n",
      "70/70 [==============================] - 0s - loss: 4.1823 - val_loss: 3.0962\n",
      "Epoch 5/300\n",
      "70/70 [==============================] - 0s - loss: 4.1909 - val_loss: 3.1930\n",
      "Epoch 6/300\n",
      "70/70 [==============================] - 0s - loss: 3.7441 - val_loss: 3.6794\n",
      "Epoch 7/300\n",
      "70/70 [==============================] - 0s - loss: 3.8647 - val_loss: 3.1266\n",
      "Epoch 8/300\n",
      "70/70 [==============================] - 0s - loss: 3.7300 - val_loss: 2.8218\n",
      "Epoch 9/300\n",
      "70/70 [==============================] - 0s - loss: 3.4974 - val_loss: 2.6493\n",
      "Epoch 10/300\n",
      "70/70 [==============================] - 0s - loss: 3.5000 - val_loss: 3.1441\n",
      "Epoch 11/300\n",
      "70/70 [==============================] - 0s - loss: 3.7695 - val_loss: 2.9257\n",
      "Epoch 12/300\n",
      "70/70 [==============================] - 0s - loss: 3.4245 - val_loss: 2.4785\n",
      "Epoch 13/300\n",
      "70/70 [==============================] - 0s - loss: 3.2096 - val_loss: 3.0346\n",
      "Epoch 14/300\n",
      "70/70 [==============================] - 0s - loss: 3.2664 - val_loss: 2.1954\n",
      "Epoch 15/300\n",
      "70/70 [==============================] - 0s - loss: 3.4151 - val_loss: 2.8917\n",
      "Epoch 16/300\n",
      "70/70 [==============================] - 0s - loss: 3.4038 - val_loss: 2.4945\n",
      "Epoch 17/300\n",
      "70/70 [==============================] - 0s - loss: 3.2175 - val_loss: 2.4018\n",
      "Epoch 18/300\n",
      "70/70 [==============================] - 0s - loss: 3.4045 - val_loss: 2.5335\n",
      "Epoch 19/300\n",
      "70/70 [==============================] - 0s - loss: 3.1659 - val_loss: 2.2792\n",
      "Epoch 20/300\n",
      "70/70 [==============================] - 0s - loss: 3.2907 - val_loss: 3.0493\n",
      "Epoch 21/300\n",
      "70/70 [==============================] - 0s - loss: 3.3067 - val_loss: 2.7925\n",
      "Epoch 22/300\n",
      "70/70 [==============================] - 0s - loss: 3.2726 - val_loss: 3.1376\n",
      "Epoch 23/300\n",
      "70/70 [==============================] - 0s - loss: 3.3639 - val_loss: 3.5055\n",
      "Epoch 24/300\n",
      "70/70 [==============================] - 0s - loss: 3.1765 - val_loss: 2.8836\n",
      "Epoch 25/300\n",
      "69/70 [============================>.] - ETA: 0s - loss: 3.2257\n",
      " Reduced learning rate to 0.01\n",
      "70/70 [==============================] - 0s - loss: 3.2348 - val_loss: 4.3762\n",
      "Epoch 26/300\n",
      "70/70 [==============================] - 0s - loss: 2.3893 - val_loss: 2.1355\n",
      "Epoch 27/300\n",
      "70/70 [==============================] - 0s - loss: 2.2629 - val_loss: 2.6655\n",
      "Epoch 28/300\n",
      "70/70 [==============================] - 0s - loss: 2.2625 - val_loss: 1.8768\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 2.3661 - val_loss: 1.9693\n",
      "Epoch 30/300\n",
      "70/70 [==============================] - 0s - loss: 2.7710 - val_loss: 2.0257\n",
      "Epoch 31/300\n",
      "70/70 [==============================] - 0s - loss: 2.2601 - val_loss: 2.3023\n",
      "Epoch 32/300\n",
      "70/70 [==============================] - 0s - loss: 2.6249 - val_loss: 2.0560\n",
      "Epoch 33/300\n",
      "70/70 [==============================] - 0s - loss: 2.3492 - val_loss: 2.0394\n",
      "Epoch 34/300\n",
      "70/70 [==============================] - 0s - loss: 2.3741 - val_loss: 2.3268\n",
      "Epoch 35/300\n",
      "70/70 [==============================] - 0s - loss: 2.3919 - val_loss: 2.0357\n",
      "Epoch 36/300\n",
      "70/70 [==============================] - 0s - loss: 2.4127 - val_loss: 1.9081\n",
      "Epoch 37/300\n",
      "70/70 [==============================] - 0s - loss: 2.2237 - val_loss: 1.8020\n",
      "Epoch 38/300\n",
      "70/70 [==============================] - 0s - loss: 2.5208 - val_loss: 2.0895\n",
      "Epoch 39/300\n",
      "70/70 [==============================] - 0s - loss: 2.4728 - val_loss: 2.0674\n",
      "Epoch 40/300\n",
      "70/70 [==============================] - 0s - loss: 2.3095 - val_loss: 1.8498\n",
      "Epoch 41/300\n",
      "70/70 [==============================] - 0s - loss: 2.4307 - val_loss: 3.4410\n",
      "Epoch 42/300\n",
      "70/70 [==============================] - 0s - loss: 2.3184 - val_loss: 2.0729\n",
      "Epoch 43/300\n",
      "70/70 [==============================] - 0s - loss: 2.2741 - val_loss: 2.1984\n",
      "Epoch 44/300\n",
      "70/70 [==============================] - 0s - loss: 2.2633 - val_loss: 2.1870\n",
      "Epoch 45/300\n",
      "70/70 [==============================] - 0s - loss: 2.4767 - val_loss: 2.4871\n",
      "Epoch 46/300\n",
      "70/70 [==============================] - 0s - loss: 2.4202 - val_loss: 2.3642\n",
      "Epoch 47/300\n",
      "70/70 [==============================] - 0s - loss: 2.5374 - val_loss: 2.2354\n",
      "Epoch 48/300\n",
      "67/70 [===========================>..] - ETA: 0s - loss: 2.5295\n",
      " Reduced learning rate to 0.00666667\n",
      "70/70 [==============================] - 0s - loss: 2.5319 - val_loss: 2.1094\n",
      "Epoch 49/300\n",
      "70/70 [==============================] - 0s - loss: 2.1886 - val_loss: 1.9422\n",
      "Epoch 50/300\n",
      "70/70 [==============================] - 0s - loss: 2.0131 - val_loss: 1.9711\n",
      "Epoch 51/300\n",
      "70/70 [==============================] - 0s - loss: 1.9485 - val_loss: 1.7465\n",
      "Epoch 52/300\n",
      "70/70 [==============================] - 0s - loss: 2.0407 - val_loss: 1.8704\n",
      "Epoch 53/300\n",
      "70/70 [==============================] - 0s - loss: 2.0341 - val_loss: 1.8836\n",
      "Epoch 54/300\n",
      "70/70 [==============================] - 0s - loss: 1.9813 - val_loss: 1.8542\n",
      "Epoch 55/300\n",
      "70/70 [==============================] - 0s - loss: 1.9906 - val_loss: 1.7899\n",
      "Epoch 56/300\n",
      "70/70 [==============================] - 0s - loss: 1.9188 - val_loss: 1.7761\n",
      "Epoch 57/300\n",
      "70/70 [==============================] - 0s - loss: 2.0014 - val_loss: 1.9440\n",
      "Epoch 58/300\n",
      "70/70 [==============================] - 0s - loss: 1.9821 - val_loss: 1.8735\n",
      "Epoch 59/300\n",
      "70/70 [==============================] - 0s - loss: 1.9260 - val_loss: 1.9236\n",
      "Epoch 60/300\n",
      "70/70 [==============================] - 0s - loss: 1.9946 - val_loss: 2.0720\n",
      "Epoch 61/300\n",
      "70/70 [==============================] - 0s - loss: 2.0014 - val_loss: 1.9244\n",
      "Epoch 62/300\n",
      "69/70 [============================>.] - ETA: 0s - loss: 2.0671\n",
      " Reduced learning rate to 0.00444444\n",
      "70/70 [==============================] - 0s - loss: 2.0695 - val_loss: 1.9309\n",
      "Epoch 63/300\n",
      "70/70 [==============================] - 0s - loss: 1.8924 - val_loss: 1.8346\n",
      "Epoch 64/300\n",
      "70/70 [==============================] - 0s - loss: 1.8236 - val_loss: 1.8418\n",
      "Epoch 65/300\n",
      "70/70 [==============================] - 0s - loss: 1.9866 - val_loss: 1.8008\n",
      "Epoch 66/300\n",
      "70/70 [==============================] - 0s - loss: 1.8027 - val_loss: 1.6861\n",
      "Epoch 67/300\n",
      "70/70 [==============================] - 0s - loss: 1.9356 - val_loss: 1.8695\n",
      "Epoch 68/300\n",
      "70/70 [==============================] - 0s - loss: 1.9820 - val_loss: 1.7969\n",
      "Epoch 69/300\n",
      "70/70 [==============================] - 0s - loss: 1.8707 - val_loss: 1.8612\n",
      "Epoch 70/300\n",
      "70/70 [==============================] - 0s - loss: 1.8483 - val_loss: 1.8074\n",
      "Epoch 71/300\n",
      "70/70 [==============================] - 0s - loss: 1.9473 - val_loss: 1.7371\n",
      "Epoch 72/300\n",
      "70/70 [==============================] - 0s - loss: 1.8448 - val_loss: 1.8457\n",
      "Epoch 73/300\n",
      "70/70 [==============================] - 0s - loss: 1.8728 - val_loss: 1.6166\n",
      "Epoch 74/300\n",
      "70/70 [==============================] - 0s - loss: 1.8056 - val_loss: 1.7960\n",
      "Epoch 75/300\n",
      "70/70 [==============================] - 0s - loss: 1.8688 - val_loss: 1.7946\n",
      "Epoch 76/300\n",
      "70/70 [==============================] - 0s - loss: 1.8666 - val_loss: 1.7450\n",
      "Epoch 77/300\n",
      "70/70 [==============================] - 0s - loss: 1.9111 - val_loss: 1.7878\n",
      "Epoch 78/300\n",
      "70/70 [==============================] - 0s - loss: 1.8850 - val_loss: 1.8160\n",
      "Epoch 79/300\n",
      "70/70 [==============================] - 0s - loss: 1.8478 - val_loss: 1.8674\n",
      "Epoch 80/300\n",
      "70/70 [==============================] - 0s - loss: 1.9183 - val_loss: 1.8306\n",
      "Epoch 81/300\n",
      "70/70 [==============================] - 0s - loss: 1.8822 - val_loss: 1.8067\n",
      "Epoch 82/300\n",
      "70/70 [==============================] - 0s - loss: 1.8722 - val_loss: 1.7099\n",
      "Epoch 83/300\n",
      "70/70 [==============================] - 0s - loss: 1.9395 - val_loss: 1.8169\n",
      "Epoch 84/300\n",
      "62/70 [=========================>....] - ETA: 0s - loss: 1.9123\n",
      " Reduced learning rate to 0.00296296\n",
      "70/70 [==============================] - 0s - loss: 1.8992 - val_loss: 1.9167\n",
      "Epoch 85/300\n",
      "70/70 [==============================] - 0s - loss: 2.2646 - val_loss: 1.8908\n",
      "Epoch 86/300\n",
      "70/70 [==============================] - 0s - loss: 1.7795 - val_loss: 1.7956\n",
      "Epoch 87/300\n",
      "70/70 [==============================] - 0s - loss: 1.7886 - val_loss: 1.8502\n",
      "Epoch 88/300\n",
      "70/70 [==============================] - 0s - loss: 1.9314 - val_loss: 1.8222\n",
      "Epoch 89/300\n",
      "70/70 [==============================] - 0s - loss: 1.8524 - val_loss: 1.9233\n",
      "Epoch 90/300\n",
      "70/70 [==============================] - 0s - loss: 1.8916 - val_loss: 1.6599\n",
      "Epoch 91/300\n",
      "70/70 [==============================] - 0s - loss: 1.8958 - val_loss: 1.6166\n",
      "Epoch 92/300\n",
      "70/70 [==============================] - 0s - loss: 2.0944 - val_loss: 1.7422\n",
      "Epoch 93/300\n",
      "70/70 [==============================] - 0s - loss: 1.8011 - val_loss: 1.7755\n",
      "Epoch 94/300\n",
      "70/70 [==============================] - 0s - loss: 1.9326 - val_loss: 1.6947\n",
      "Epoch 95/300\n",
      "70/70 [==============================] - 0s - loss: 2.0045 - val_loss: 1.7298\n",
      "Epoch 96/300\n",
      "70/70 [==============================] - 0s - loss: 1.8085 - val_loss: 1.7121\n",
      "Epoch 97/300\n",
      "70/70 [==============================] - 0s - loss: 2.0059 - val_loss: 1.8032\n",
      "Epoch 98/300\n",
      "70/70 [==============================] - 0s - loss: 1.9394 - val_loss: 1.7752\n",
      "Epoch 99/300\n",
      "70/70 [==============================] - 0s - loss: 1.8903 - val_loss: 1.7819\n",
      "Epoch 100/300\n",
      "70/70 [==============================] - 0s - loss: 1.8980 - val_loss: 1.7576\n",
      "Epoch 101/300\n",
      "70/70 [==============================] - 0s - loss: 1.9189 - val_loss: 1.6626\n",
      "Epoch 102/300\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 1.7749\n",
      " Reduced learning rate to 0.00197531\n",
      "70/70 [==============================] - 0s - loss: 1.7685 - val_loss: 1.7722\n",
      "Epoch 103/300\n",
      "70/70 [==============================] - 0s - loss: 1.9004 - val_loss: 1.8289\n",
      "Epoch 104/300\n",
      "70/70 [==============================] - 0s - loss: 1.8277 - val_loss: 1.6372\n",
      "Epoch 105/300\n",
      "70/70 [==============================] - 0s - loss: 1.8813 - val_loss: 1.7417\n",
      "Epoch 106/300\n",
      "70/70 [==============================] - 0s - loss: 1.7648 - val_loss: 1.8098\n",
      "Epoch 107/300\n",
      "70/70 [==============================] - 0s - loss: 1.8335 - val_loss: 1.6983\n",
      "Epoch 108/300\n",
      "70/70 [==============================] - 0s - loss: 1.8629 - val_loss: 1.7351\n",
      "Epoch 109/300\n",
      "70/70 [==============================] - 0s - loss: 1.8459 - val_loss: 1.7741\n",
      "Epoch 110/300\n",
      "70/70 [==============================] - 0s - loss: 2.0346 - val_loss: 1.6881\n",
      "Epoch 111/300\n",
      "70/70 [==============================] - 0s - loss: 1.8807 - val_loss: 1.7071\n",
      "Epoch 112/300\n",
      "70/70 [==============================] - 0s - loss: 2.0321 - val_loss: 1.7428\n",
      "Epoch 113/300\n",
      "64/70 [==========================>...] - ETA: 0s - loss: 1.8645\n",
      " Reduced learning rate to 0.00131687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s - loss: 1.8621 - val_loss: 1.8092\n",
      "Epoch 114/300\n",
      "70/70 [==============================] - 0s - loss: 1.9800 - val_loss: 1.8351\n",
      "Epoch 115/300\n",
      "70/70 [==============================] - 0s - loss: 1.7783 - val_loss: 1.8386\n",
      "Epoch 116/300\n",
      "70/70 [==============================] - 0s - loss: 1.7745 - val_loss: 1.8211\n",
      "Epoch 117/300\n",
      "70/70 [==============================] - 0s - loss: 1.8764 - val_loss: 1.7807\n",
      "Epoch 118/300\n",
      "70/70 [==============================] - 0s - loss: 1.8558 - val_loss: 1.7903\n",
      "Epoch 119/300\n",
      "70/70 [==============================] - 0s - loss: 1.8037 - val_loss: 1.8020\n",
      "Epoch 120/300\n",
      "70/70 [==============================] - 0s - loss: 1.8710 - val_loss: 1.7148\n",
      "Epoch 121/300\n",
      "70/70 [==============================] - 0s - loss: 1.7879 - val_loss: 1.7008\n",
      "Epoch 122/300\n",
      "70/70 [==============================] - 0s - loss: 1.9406 - val_loss: 1.7649\n",
      "Epoch 123/300\n",
      "70/70 [==============================] - 0s - loss: 1.8896 - val_loss: 1.7387\n",
      "Epoch 124/300\n",
      "55/70 [======================>.......] - ETA: 0s - loss: 1.8679\n",
      " Reduced learning rate to 0.000877915\n",
      "70/70 [==============================] - 0s - loss: 1.8397 - val_loss: 1.7820\n",
      "Epoch 125/300\n",
      "70/70 [==============================] - 0s - loss: 1.7873 - val_loss: 1.6459\n",
      "Epoch 126/300\n",
      "70/70 [==============================] - 0s - loss: 1.8214 - val_loss: 1.6556\n",
      "Epoch 127/300\n",
      "70/70 [==============================] - 0s - loss: 1.8198 - val_loss: 1.7821\n",
      "Epoch 128/300\n",
      "70/70 [==============================] - 0s - loss: 1.8975 - val_loss: 1.6292\n",
      "Epoch 129/300\n",
      "70/70 [==============================] - 0s - loss: 1.9774 - val_loss: 1.7973\n",
      "Epoch 130/300\n",
      "70/70 [==============================] - 0s - loss: 1.7984 - val_loss: 1.7169\n",
      "Epoch 131/300\n",
      "70/70 [==============================] - 0s - loss: 1.9314 - val_loss: 1.7278\n",
      "Epoch 132/300\n",
      "70/70 [==============================] - 0s - loss: 1.8587 - val_loss: 1.7884\n",
      "Epoch 133/300\n",
      "70/70 [==============================] - 0s - loss: 1.7878 - val_loss: 1.7777\n",
      "Epoch 134/300\n",
      "70/70 [==============================] - 0s - loss: 1.8783 - val_loss: 1.8173\n",
      "Epoch 135/300\n",
      "60/70 [========================>.....] - ETA: 0s - loss: 1.7468\n",
      " Reduced learning rate to 0.000585277\n",
      "70/70 [==============================] - 0s - loss: 1.7442 - val_loss: 1.7689\n",
      "Epoch 136/300\n",
      "70/70 [==============================] - 0s - loss: 2.0266 - val_loss: 1.7168\n",
      "Epoch 137/300\n",
      "70/70 [==============================] - 0s - loss: 1.7726 - val_loss: 1.7996\n",
      "Epoch 138/300\n",
      "70/70 [==============================] - 0s - loss: 2.0705 - val_loss: 1.6971\n",
      "Epoch 139/300\n",
      "70/70 [==============================] - 0s - loss: 1.8288 - val_loss: 1.7464\n",
      "Epoch 140/300\n",
      "70/70 [==============================] - 0s - loss: 1.8119 - val_loss: 1.7419\n",
      "Epoch 141/300\n",
      "70/70 [==============================] - 0s - loss: 1.8847 - val_loss: 1.8659\n",
      "Epoch 142/300\n",
      "70/70 [==============================] - 0s - loss: 1.8160 - val_loss: 1.7822\n",
      "Epoch 143/300\n",
      "70/70 [==============================] - 0s - loss: 1.9807 - val_loss: 1.6799\n",
      "Epoch 144/300\n",
      "70/70 [==============================] - 0s - loss: 1.7573 - val_loss: 1.7093\n",
      "Epoch 145/300\n",
      "70/70 [==============================] - 0s - loss: 1.8353 - val_loss: 1.7974\n",
      "Epoch 146/300\n",
      "60/70 [========================>.....] - ETA: 0s - loss: 1.8758\n",
      " Reduced learning rate to 0.000390184\n",
      "70/70 [==============================] - 0s - loss: 1.8790 - val_loss: 1.8402\n",
      "Epoch 147/300\n",
      "70/70 [==============================] - 0s - loss: 1.7789 - val_loss: 1.7952\n",
      "Epoch 148/300\n",
      "70/70 [==============================] - 0s - loss: 1.9305 - val_loss: 1.7821\n",
      "Epoch 149/300\n",
      "70/70 [==============================] - 0s - loss: 1.8794 - val_loss: 1.7538\n",
      "Epoch 150/300\n",
      "70/70 [==============================] - 0s - loss: 1.8082 - val_loss: 1.8130\n",
      "Epoch 151/300\n",
      "70/70 [==============================] - 0s - loss: 1.8371 - val_loss: 1.7788\n",
      "Epoch 152/300\n",
      "70/70 [==============================] - 0s - loss: 1.7740 - val_loss: 1.7760\n",
      "Epoch 153/300\n",
      "70/70 [==============================] - 0s - loss: 1.7930 - val_loss: 1.6611\n",
      "Epoch 154/300\n",
      "70/70 [==============================] - 0s - loss: 1.8040 - val_loss: 1.5832\n",
      "Epoch 155/300\n",
      "70/70 [==============================] - 0s - loss: 1.8265 - val_loss: 1.8448\n",
      "Epoch 156/300\n",
      "70/70 [==============================] - 0s - loss: 1.7962 - val_loss: 1.6328\n",
      "Epoch 157/300\n",
      "70/70 [==============================] - 0s - loss: 1.8509 - val_loss: 1.6267\n",
      "Epoch 158/300\n",
      "70/70 [==============================] - 0s - loss: 1.8415 - val_loss: 1.7518\n",
      "Epoch 159/300\n",
      "70/70 [==============================] - 0s - loss: 2.0247 - val_loss: 1.7958\n",
      "Epoch 160/300\n",
      "70/70 [==============================] - 0s - loss: 1.7375 - val_loss: 1.8059\n",
      "Epoch 161/300\n",
      "70/70 [==============================] - 0s - loss: 1.7462 - val_loss: 1.6620\n",
      "Epoch 162/300\n",
      "70/70 [==============================] - 0s - loss: 1.7828 - val_loss: 1.7028\n",
      "Epoch 163/300\n",
      "70/70 [==============================] - 0s - loss: 1.8092 - val_loss: 1.8229\n",
      "Epoch 164/300\n",
      "70/70 [==============================] - 0s - loss: 1.8622 - val_loss: 1.6895\n",
      "Epoch 165/300\n",
      "60/70 [========================>.....] - ETA: 0s - loss: 1.8963\n",
      " Reduced learning rate to 0.000260123\n",
      "70/70 [==============================] - 0s - loss: 1.8852 - val_loss: 1.6875\n",
      "Epoch 166/300\n",
      "70/70 [==============================] - 0s - loss: 1.7592 - val_loss: 1.8157\n",
      "Epoch 167/300\n",
      "70/70 [==============================] - 0s - loss: 1.9214 - val_loss: 1.7335\n",
      "Epoch 168/300\n",
      "70/70 [==============================] - 0s - loss: 1.8519 - val_loss: 1.6058\n",
      "Epoch 169/300\n",
      "70/70 [==============================] - 0s - loss: 1.7746 - val_loss: 1.5840\n",
      "Epoch 170/300\n",
      "70/70 [==============================] - 0s - loss: 1.8352 - val_loss: 1.7816\n",
      "Epoch 171/300\n",
      "70/70 [==============================] - 0s - loss: 1.8125 - val_loss: 1.7038\n",
      "Epoch 172/300\n",
      "70/70 [==============================] - 0s - loss: 1.7784 - val_loss: 1.6636\n",
      "Epoch 173/300\n",
      "70/70 [==============================] - 0s - loss: 1.8998 - val_loss: 1.6982\n",
      "Epoch 174/300\n",
      "70/70 [==============================] - 0s - loss: 1.9870 - val_loss: 1.7878\n",
      "Epoch 175/300\n",
      "70/70 [==============================] - 0s - loss: 1.8625 - val_loss: 1.8046\n",
      "Epoch 176/300\n",
      "66/70 [===========================>..] - ETA: 0s - loss: 1.7739\n",
      " Reduced learning rate to 0.000173415\n",
      "70/70 [==============================] - 0s - loss: 1.7798 - val_loss: 1.7701\n",
      "Epoch 177/300\n",
      "70/70 [==============================] - 0s - loss: 1.8532 - val_loss: 1.6752\n",
      "Epoch 178/300\n",
      "70/70 [==============================] - 0s - loss: 1.8072 - val_loss: 1.8009\n",
      "Epoch 179/300\n",
      "70/70 [==============================] - 0s - loss: 1.8515 - val_loss: 1.7201\n",
      "Epoch 180/300\n",
      "70/70 [==============================] - 0s - loss: 1.9259 - val_loss: 1.8275\n",
      "Epoch 181/300\n",
      "70/70 [==============================] - 0s - loss: 1.9234 - val_loss: 1.7464\n",
      "Epoch 182/300\n",
      "70/70 [==============================] - 0s - loss: 1.9343 - val_loss: 1.7489\n",
      "Epoch 183/300\n",
      "70/70 [==============================] - 0s - loss: 1.9571 - val_loss: 1.8188ss: 1\n",
      "Epoch 184/300\n",
      "70/70 [==============================] - 0s - loss: 1.8331 - val_loss: 1.6803\n",
      "Epoch 185/300\n",
      "70/70 [==============================] - 0s - loss: 1.7445 - val_loss: 1.7306\n",
      "Epoch 186/300\n",
      "70/70 [==============================] - 0s - loss: 1.7954 - val_loss: 1.6861\n",
      "Epoch 187/300\n",
      "65/70 [==========================>...] - ETA: 0s - loss: 1.8161\n",
      " Reduced learning rate to 0.00011561\n",
      "70/70 [==============================] - 0s - loss: 1.8162 - val_loss: 1.8419\n",
      "Epoch 188/300\n",
      "70/70 [==============================] - 0s - loss: 1.7996 - val_loss: 1.7068\n",
      "Epoch 189/300\n",
      "70/70 [==============================] - 0s - loss: 1.7332 - val_loss: 1.7236\n",
      "Epoch 190/300\n",
      "70/70 [==============================] - 0s - loss: 1.7442 - val_loss: 1.7988\n",
      "Epoch 191/300\n",
      "70/70 [==============================] - 0s - loss: 1.7885 - val_loss: 1.6461\n",
      "Epoch 192/300\n",
      "70/70 [==============================] - 0s - loss: 1.8882 - val_loss: 1.7594\n",
      "Epoch 193/300\n",
      "70/70 [==============================] - 0s - loss: 2.0694 - val_loss: 1.6749\n",
      "Epoch 194/300\n",
      "70/70 [==============================] - 0s - loss: 1.7903 - val_loss: 1.6864\n",
      "Epoch 195/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA: 0s - loss: 1.828 - 0s - loss: 1.8337 - val_loss: 1.6763\n",
      "Epoch 196/300\n",
      "70/70 [==============================] - 0s - loss: 1.7919 - val_loss: 1.6067\n",
      "Epoch 197/300\n",
      "70/70 [==============================] - 0s - loss: 1.9340 - val_loss: 1.6449\n",
      "Epoch 198/300\n",
      "55/70 [======================>.......] - ETA: 0s - loss: 1.8000\n",
      " Reduced learning rate to 7.70735e-05\n",
      "70/70 [==============================] - 0s - loss: 1.7735 - val_loss: 1.7551\n",
      "Epoch 1/300\n",
      "140/140 [==============================] - 1s - loss: 39.0076 - val_loss: 5.7338\n",
      "Epoch 2/300\n",
      "140/140 [==============================] - 0s - loss: 4.6371 - val_loss: 3.9464\n",
      "Epoch 3/300\n",
      "140/140 [==============================] - 0s - loss: 3.7297 - val_loss: 3.1627\n",
      "Epoch 4/300\n",
      "140/140 [==============================] - 0s - loss: 3.5274 - val_loss: 3.2067\n",
      "Epoch 5/300\n",
      "140/140 [==============================] - 0s - loss: 3.5865 - val_loss: 3.3476\n",
      "Epoch 6/300\n",
      "140/140 [==============================] - 0s - loss: 3.3567 - val_loss: 2.8460\n",
      "Epoch 7/300\n",
      "140/140 [==============================] - 0s - loss: 3.3372 - val_loss: 4.1474\n",
      "Epoch 8/300\n",
      "140/140 [==============================] - 0s - loss: 3.4203 - val_loss: 3.5416\n",
      "Epoch 9/300\n",
      "140/140 [==============================] - 0s - loss: 3.2409 - val_loss: 3.3673\n",
      "Epoch 10/300\n",
      "140/140 [==============================] - 0s - loss: 3.4912 - val_loss: 3.7180\n",
      "Epoch 11/300\n",
      "140/140 [==============================] - 0s - loss: 3.2773 - val_loss: 2.9809\n",
      "Epoch 12/300\n",
      "140/140 [==============================] - 0s - loss: 3.2819 - val_loss: 3.0219\n",
      "Epoch 13/300\n",
      "140/140 [==============================] - 0s - loss: 3.4214 - val_loss: 3.1608\n",
      "Epoch 14/300\n",
      "140/140 [==============================] - 0s - loss: 3.1891 - val_loss: 2.8547\n",
      "Epoch 15/300\n",
      "140/140 [==============================] - 0s - loss: 3.0917 - val_loss: 2.3484\n",
      "Epoch 16/300\n",
      "140/140 [==============================] - 0s - loss: 3.1543 - val_loss: 4.1406\n",
      "Epoch 17/300\n",
      "140/140 [==============================] - 0s - loss: 3.1958 - val_loss: 4.0305\n",
      "Epoch 18/300\n",
      "140/140 [==============================] - 0s - loss: 3.0007 - val_loss: 2.9911\n",
      "Epoch 19/300\n",
      "140/140 [==============================] - 0s - loss: 3.1188 - val_loss: 2.1668\n",
      "Epoch 20/300\n",
      "140/140 [==============================] - 0s - loss: 3.0480 - val_loss: 2.9294\n",
      "Epoch 21/300\n",
      "140/140 [==============================] - 0s - loss: 2.9200 - val_loss: 3.5431\n",
      "Epoch 22/300\n",
      "140/140 [==============================] - 0s - loss: 3.0432 - val_loss: 3.2680\n",
      "Epoch 23/300\n",
      "140/140 [==============================] - 0s - loss: 2.9923 - val_loss: 4.9081\n",
      "Epoch 24/300\n",
      "140/140 [==============================] - 0s - loss: 2.9854 - val_loss: 1.9197\n",
      "Epoch 25/300\n",
      "140/140 [==============================] - 0s - loss: 2.8367 - val_loss: 4.0453\n",
      "Epoch 26/300\n",
      "140/140 [==============================] - 0s - loss: 2.7960 - val_loss: 2.7532\n",
      "Epoch 27/300\n",
      "140/140 [==============================] - 0s - loss: 2.9421 - val_loss: 3.2144\n",
      "Epoch 28/300\n",
      "140/140 [==============================] - 0s - loss: 2.8193 - val_loss: 3.3312s\n",
      "Epoch 29/300\n",
      "140/140 [==============================] - 0s - loss: 2.9646 - val_loss: 3.2522\n",
      "Epoch 30/300\n",
      "140/140 [==============================] - 0s - loss: 2.9594 - val_loss: 3.3893\n",
      "Epoch 31/300\n",
      "140/140 [==============================] - 0s - loss: 2.8426 - val_loss: 2.2040\n",
      "Epoch 32/300\n",
      "140/140 [==============================] - 0s - loss: 2.8332 - val_loss: 2.5317\n",
      "Epoch 33/300\n",
      "140/140 [==============================] - 0s - loss: 2.8362 - val_loss: 2.4933\n",
      "Epoch 34/300\n",
      "140/140 [==============================] - 0s - loss: 2.6262 - val_loss: 2.3846\n",
      "Epoch 35/300\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 2.9405\n",
      " Reduced learning rate to 0.01\n",
      "140/140 [==============================] - 1s - loss: 2.8927 - val_loss: 3.6192\n",
      "Epoch 36/300\n",
      "140/140 [==============================] - 0s - loss: 1.9951 - val_loss: 1.9113\n",
      "Epoch 37/300\n",
      "140/140 [==============================] - 0s - loss: 1.9712 - val_loss: 2.2398\n",
      "Epoch 38/300\n",
      "140/140 [==============================] - 0s - loss: 2.1319 - val_loss: 1.8347\n",
      "Epoch 39/300\n",
      "140/140 [==============================] - 0s - loss: 2.0514 - val_loss: 2.2411\n",
      "Epoch 40/300\n",
      "140/140 [==============================] - 0s - loss: 2.0037 - val_loss: 2.1881\n",
      "Epoch 41/300\n",
      "140/140 [==============================] - 0s - loss: 1.9829 - val_loss: 1.8582\n",
      "Epoch 42/300\n",
      "140/140 [==============================] - 0s - loss: 1.9633 - val_loss: 1.9443\n",
      "Epoch 43/300\n",
      "140/140 [==============================] - 0s - loss: 1.9815 - val_loss: 1.9773\n",
      "Epoch 44/300\n",
      "140/140 [==============================] - 0s - loss: 1.9829 - val_loss: 1.7711\n",
      "Epoch 45/300\n",
      "140/140 [==============================] - 0s - loss: 2.0561 - val_loss: 1.7761\n",
      "Epoch 46/300\n",
      "140/140 [==============================] - 0s - loss: 2.0346 - val_loss: 1.9877\n",
      "Epoch 47/300\n",
      "140/140 [==============================] - 0s - loss: 2.0178 - val_loss: 2.1282\n",
      "Epoch 48/300\n",
      "140/140 [==============================] - 0s - loss: 1.9756 - val_loss: 1.9920\n",
      "Epoch 49/300\n",
      "140/140 [==============================] - 0s - loss: 1.9206 - val_loss: 1.8179\n",
      "Epoch 50/300\n",
      "140/140 [==============================] - 0s - loss: 2.0024 - val_loss: 2.0898\n",
      "Epoch 51/300\n",
      "140/140 [==============================] - 0s - loss: 1.9997 - val_loss: 1.8392\n",
      "Epoch 52/300\n",
      "140/140 [==============================] - 0s - loss: 2.0098 - val_loss: 2.0917\n",
      "Epoch 53/300\n",
      "140/140 [==============================] - 0s - loss: 2.0310 - val_loss: 1.9346\n",
      "Epoch 54/300\n",
      "140/140 [==============================] - 0s - loss: 1.9711 - val_loss: 1.7597\n",
      "Epoch 55/300\n",
      "140/140 [==============================] - 0s - loss: 1.9872 - val_loss: 2.0109\n",
      "Epoch 56/300\n",
      "140/140 [==============================] - 0s - loss: 2.0361 - val_loss: 1.9072\n",
      "Epoch 57/300\n",
      "140/140 [==============================] - 1s - loss: 2.0504 - val_loss: 2.6789\n",
      "Epoch 58/300\n",
      "140/140 [==============================] - 1s - loss: 2.0291 - val_loss: 2.2963\n",
      "Epoch 59/300\n",
      "140/140 [==============================] - 1s - loss: 2.0110 - val_loss: 1.7531\n",
      "Epoch 60/300\n",
      "140/140 [==============================] - 1s - loss: 2.0874 - val_loss: 1.9143\n",
      "Epoch 61/300\n",
      "140/140 [==============================] - 1s - loss: 2.0360 - val_loss: 1.7816\n",
      "Epoch 62/300\n",
      "140/140 [==============================] - 1s - loss: 1.9994 - val_loss: 1.7782\n",
      "Epoch 63/300\n",
      "140/140 [==============================] - 1s - loss: 2.0425 - val_loss: 1.9330\n",
      "Epoch 64/300\n",
      "140/140 [==============================] - 0s - loss: 2.1293 - val_loss: 2.3618\n",
      "Epoch 65/300\n",
      "140/140 [==============================] - 0s - loss: 1.9871 - val_loss: 1.8938\n",
      "Epoch 66/300\n",
      "140/140 [==============================] - 0s - loss: 2.0218 - val_loss: 1.7957\n",
      "Epoch 67/300\n",
      "140/140 [==============================] - 0s - loss: 1.9505 - val_loss: 1.8296\n",
      "Epoch 68/300\n",
      "140/140 [==============================] - 0s - loss: 1.9609 - val_loss: 1.9829\n",
      "Epoch 69/300\n",
      "140/140 [==============================] - 0s - loss: 1.9593 - val_loss: 2.0271\n",
      "Epoch 70/300\n",
      "137/140 [============================>.] - ETA: 0s - loss: 2.0019\n",
      " Reduced learning rate to 0.00666667\n",
      "140/140 [==============================] - 0s - loss: 2.0038 - val_loss: 1.8297\n",
      "Epoch 71/300\n",
      "140/140 [==============================] - 0s - loss: 1.8415 - val_loss: 1.7701\n",
      "Epoch 72/300\n",
      "140/140 [==============================] - 0s - loss: 1.8088 - val_loss: 1.7030\n",
      "Epoch 73/300\n",
      "140/140 [==============================] - 0s - loss: 1.9204 - val_loss: 1.7725\n",
      "Epoch 74/300\n",
      "140/140 [==============================] - 0s - loss: 1.8661 - val_loss: 1.7529\n",
      "Epoch 75/300\n",
      "140/140 [==============================] - 0s - loss: 1.7351 - val_loss: 1.6880\n",
      "Epoch 76/300\n",
      "140/140 [==============================] - 0s - loss: 1.8253 - val_loss: 1.8197\n",
      "Epoch 77/300\n",
      "140/140 [==============================] - 0s - loss: 1.8241 - val_loss: 1.8362\n",
      "Epoch 78/300\n",
      "140/140 [==============================] - 0s - loss: 1.7874 - val_loss: 1.7182\n",
      "Epoch 79/300\n",
      "140/140 [==============================] - 0s - loss: 1.7949 - val_loss: 1.7236\n",
      "Epoch 80/300\n",
      "140/140 [==============================] - 0s - loss: 1.8505 - val_loss: 1.7051\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.8564 - val_loss: 1.7226\n",
      "Epoch 82/300\n",
      "140/140 [==============================] - 0s - loss: 1.8097 - val_loss: 1.8393\n",
      "Epoch 83/300\n",
      "140/140 [==============================] - 0s - loss: 1.7790 - val_loss: 2.0510\n",
      "Epoch 84/300\n",
      "140/140 [==============================] - 0s - loss: 1.8327 - val_loss: 1.8054\n",
      "Epoch 85/300\n",
      "140/140 [==============================] - 0s - loss: 1.7909 - val_loss: 1.8925\n",
      "Epoch 86/300\n",
      "122/140 [=========================>....] - ETA: 0s - loss: 1.8139\n",
      " Reduced learning rate to 0.00444444\n",
      "140/140 [==============================] - 0s - loss: 1.8139 - val_loss: 1.7502\n",
      "Epoch 87/300\n",
      "140/140 [==============================] - 0s - loss: 1.7444 - val_loss: 1.7233\n",
      "Epoch 88/300\n",
      "140/140 [==============================] - 0s - loss: 1.7629 - val_loss: 1.7466\n",
      "Epoch 89/300\n",
      "140/140 [==============================] - 0s - loss: 1.7901 - val_loss: 1.7344\n",
      "Epoch 90/300\n",
      "140/140 [==============================] - 0s - loss: 1.8380 - val_loss: 1.8325\n",
      "Epoch 91/300\n",
      "140/140 [==============================] - 0s - loss: 1.7031 - val_loss: 1.7392\n",
      "Epoch 92/300\n",
      "140/140 [==============================] - 0s - loss: 1.7936 - val_loss: 1.7327\n",
      "Epoch 93/300\n",
      "140/140 [==============================] - 0s - loss: 1.8148 - val_loss: 1.8062\n",
      "Epoch 94/300\n",
      "140/140 [==============================] - 0s - loss: 1.8007 - val_loss: 1.7260\n",
      "Epoch 95/300\n",
      "140/140 [==============================] - 0s - loss: 1.7496 - val_loss: 1.7298\n",
      "Epoch 96/300\n",
      "140/140 [==============================] - 0s - loss: 1.7909 - val_loss: 1.7546\n",
      "Epoch 97/300\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1.8144\n",
      " Reduced learning rate to 0.00296296\n",
      "140/140 [==============================] - 0s - loss: 1.8173 - val_loss: 1.8936\n",
      "Epoch 98/300\n",
      "140/140 [==============================] - 0s - loss: 1.7953 - val_loss: 1.7279\n",
      "Epoch 99/300\n",
      "140/140 [==============================] - 0s - loss: 1.7732 - val_loss: 1.7380\n",
      "Epoch 100/300\n",
      "140/140 [==============================] - 0s - loss: 1.7329 - val_loss: 1.7197\n",
      "Epoch 101/300\n",
      "140/140 [==============================] - 0s - loss: 1.7973 - val_loss: 1.7291\n",
      "Epoch 102/300\n",
      "140/140 [==============================] - 0s - loss: 1.7395 - val_loss: 1.6672\n",
      "Epoch 103/300\n",
      "140/140 [==============================] - 0s - loss: 1.7399 - val_loss: 1.8243\n",
      "Epoch 104/300\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.776 - 0s - loss: 1.7989 - val_loss: 1.7331\n",
      "Epoch 105/300\n",
      "140/140 [==============================] - 0s - loss: 1.7946 - val_loss: 1.6753\n",
      "Epoch 106/300\n",
      "140/140 [==============================] - 0s - loss: 1.8208 - val_loss: 1.7325\n",
      "Epoch 107/300\n",
      "140/140 [==============================] - 0s - loss: 1.7394 - val_loss: 1.6916\n",
      "Epoch 108/300\n",
      "140/140 [==============================] - 0s - loss: 1.7783 - val_loss: 1.7079\n",
      "Epoch 109/300\n",
      "140/140 [==============================] - 0s - loss: 1.7354 - val_loss: 1.7787\n",
      "Epoch 110/300\n",
      "140/140 [==============================] - 0s - loss: 1.7648 - val_loss: 1.6752\n",
      "Epoch 111/300\n",
      "140/140 [==============================] - 0s - loss: 1.7272 - val_loss: 1.6989\n",
      "Epoch 112/300\n",
      "140/140 [==============================] - 0s - loss: 1.8531 - val_loss: 1.7224\n",
      "Epoch 113/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 1.7921\n",
      " Reduced learning rate to 0.00197531\n",
      "140/140 [==============================] - 0s - loss: 1.7893 - val_loss: 1.6927\n",
      "Epoch 114/300\n",
      "140/140 [==============================] - 0s - loss: 1.7311 - val_loss: 1.7902\n",
      "Epoch 115/300\n",
      "140/140 [==============================] - 0s - loss: 1.7636 - val_loss: 1.7081\n",
      "Epoch 116/300\n",
      "140/140 [==============================] - 0s - loss: 1.7843 - val_loss: 1.6840\n",
      "Epoch 117/300\n",
      "140/140 [==============================] - 0s - loss: 1.7204 - val_loss: 1.6843\n",
      "Epoch 118/300\n",
      "140/140 [==============================] - 0s - loss: 1.8064 - val_loss: 1.6868\n",
      "Epoch 119/300\n",
      "140/140 [==============================] - 0s - loss: 1.7838 - val_loss: 1.7674\n",
      "Epoch 120/300\n",
      "140/140 [==============================] - 0s - loss: 1.7232 - val_loss: 1.6541s\n",
      "Epoch 121/300\n",
      "140/140 [==============================] - 0s - loss: 1.7605 - val_loss: 1.7409\n",
      "Epoch 122/300\n",
      "140/140 [==============================] - 0s - loss: 1.7774 - val_loss: 1.6953\n",
      "Epoch 123/300\n",
      "140/140 [==============================] - 0s - loss: 1.7316 - val_loss: 1.6389\n",
      "Epoch 124/300\n",
      "140/140 [==============================] - 0s - loss: 1.6973 - val_loss: 1.7535\n",
      "Epoch 125/300\n",
      "140/140 [==============================] - 0s - loss: 1.7575 - val_loss: 1.7235\n",
      "Epoch 126/300\n",
      "140/140 [==============================] - 0s - loss: 1.8494 - val_loss: 1.7714\n",
      "Epoch 127/300\n",
      "140/140 [==============================] - 0s - loss: 1.7442 - val_loss: 1.7208\n",
      "Epoch 128/300\n",
      "140/140 [==============================] - 0s - loss: 1.7676 - val_loss: 1.7044\n",
      "Epoch 129/300\n",
      "140/140 [==============================] - 0s - loss: 1.7927 - val_loss: 1.7603\n",
      "Epoch 130/300\n",
      "140/140 [==============================] - 0s - loss: 1.8252 - val_loss: 1.7915\n",
      "Epoch 131/300\n",
      "140/140 [==============================] - 0s - loss: 1.8435 - val_loss: 1.6793\n",
      "Epoch 132/300\n",
      "140/140 [==============================] - 0s - loss: 1.8599 - val_loss: 1.7791\n",
      "Epoch 133/300\n",
      "140/140 [==============================] - 0s - loss: 1.8043 - val_loss: 1.6796\n",
      "Epoch 134/300\n",
      "134/140 [===========================>..] - ETA: 0s - loss: 1.7372\n",
      " Reduced learning rate to 0.00131687\n",
      "140/140 [==============================] - 0s - loss: 1.7396 - val_loss: 1.7111\n",
      "Epoch 135/300\n",
      "140/140 [==============================] - 0s - loss: 1.7081 - val_loss: 1.6681\n",
      "Epoch 136/300\n",
      "140/140 [==============================] - 0s - loss: 1.7042 - val_loss: 1.7212\n",
      "Epoch 137/300\n",
      "140/140 [==============================] - 0s - loss: 1.7949 - val_loss: 1.6360\n",
      "Epoch 138/300\n",
      "140/140 [==============================] - 0s - loss: 1.7630 - val_loss: 1.6876\n",
      "Epoch 139/300\n",
      "140/140 [==============================] - 0s - loss: 1.7414 - val_loss: 1.7858\n",
      "Epoch 140/300\n",
      "140/140 [==============================] - 0s - loss: 1.6934 - val_loss: 1.7168\n",
      "Epoch 141/300\n",
      "140/140 [==============================] - 0s - loss: 1.7711 - val_loss: 1.7141\n",
      "Epoch 142/300\n",
      "140/140 [==============================] - 0s - loss: 1.8188 - val_loss: 1.6017\n",
      "Epoch 143/300\n",
      "140/140 [==============================] - 0s - loss: 1.7361 - val_loss: 1.7453\n",
      "Epoch 144/300\n",
      "140/140 [==============================] - 0s - loss: 1.7434 - val_loss: 1.7070\n",
      "Epoch 145/300\n",
      "140/140 [==============================] - 0s - loss: 1.7765 - val_loss: 1.7444\n",
      "Epoch 146/300\n",
      "140/140 [==============================] - 0s - loss: 1.7665 - val_loss: 1.7061\n",
      "Epoch 147/300\n",
      "140/140 [==============================] - 0s - loss: 1.7933 - val_loss: 1.7379\n",
      "Epoch 148/300\n",
      "140/140 [==============================] - 0s - loss: 1.7232 - val_loss: 1.7645\n",
      "Epoch 149/300\n",
      "140/140 [==============================] - 0s - loss: 1.7848 - val_loss: 1.6851\n",
      "Epoch 150/300\n",
      "140/140 [==============================] - 0s - loss: 1.7371 - val_loss: 1.6989\n",
      "Epoch 151/300\n",
      "140/140 [==============================] - 0s - loss: 1.7582 - val_loss: 1.6699\n",
      "Epoch 152/300\n",
      "140/140 [==============================] - 0s - loss: 1.7824 - val_loss: 1.7127\n",
      "Epoch 153/300\n",
      "134/140 [===========================>..] - ETA: 0s - loss: 1.7639\n",
      " Reduced learning rate to 0.000877915\n",
      "140/140 [==============================] - 0s - loss: 1.7604 - val_loss: 1.7214\n",
      "Epoch 154/300\n",
      "140/140 [==============================] - 0s - loss: 1.8036 - val_loss: 1.7280\n",
      "Epoch 155/300\n",
      "140/140 [==============================] - 0s - loss: 1.7319 - val_loss: 1.6491\n",
      "Epoch 156/300\n",
      "140/140 [==============================] - 0s - loss: 1.7082 - val_loss: 1.6988\n",
      "Epoch 157/300\n",
      "140/140 [==============================] - 0s - loss: 1.7126 - val_loss: 1.6969\n",
      "Epoch 158/300\n",
      "140/140 [==============================] - 0s - loss: 1.7604 - val_loss: 1.8073\n",
      "Epoch 159/300\n",
      "140/140 [==============================] - 0s - loss: 1.8110 - val_loss: 1.7026\n",
      "Epoch 160/300\n",
      "140/140 [==============================] - 0s - loss: 1.7768 - val_loss: 1.6820\n",
      "Epoch 161/300\n",
      "140/140 [==============================] - 0s - loss: 1.7373 - val_loss: 1.7776\n",
      "Epoch 162/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.7495 - val_loss: 1.7655\n",
      "Epoch 163/300\n",
      "140/140 [==============================] - 0s - loss: 1.7122 - val_loss: 1.7595\n",
      "Epoch 164/300\n",
      "134/140 [===========================>..] - ETA: 0s - loss: 1.7433\n",
      " Reduced learning rate to 0.000585277\n",
      "140/140 [==============================] - 0s - loss: 1.7438 - val_loss: 1.6504\n",
      "Epoch 165/300\n",
      "140/140 [==============================] - 0s - loss: 1.7267 - val_loss: 1.6336\n",
      "Epoch 166/300\n",
      "140/140 [==============================] - 0s - loss: 1.7211 - val_loss: 1.6634\n",
      "Epoch 167/300\n",
      "140/140 [==============================] - 0s - loss: 1.7666 - val_loss: 1.7404\n",
      "Epoch 168/300\n",
      "140/140 [==============================] - 0s - loss: 1.7262 - val_loss: 1.6959\n",
      "Epoch 169/300\n",
      "140/140 [==============================] - 0s - loss: 1.7573 - val_loss: 1.6987\n",
      "Epoch 170/300\n",
      "140/140 [==============================] - 0s - loss: 1.7980 - val_loss: 1.6922\n",
      "Epoch 171/300\n",
      "140/140 [==============================] - 0s - loss: 1.7248 - val_loss: 1.7268\n",
      "Epoch 172/300\n",
      "140/140 [==============================] - 0s - loss: 1.6838 - val_loss: 1.7056\n",
      "Epoch 173/300\n",
      "140/140 [==============================] - 0s - loss: 1.7341 - val_loss: 1.6749\n",
      "Epoch 174/300\n",
      "140/140 [==============================] - 0s - loss: 1.7972 - val_loss: 1.8487\n",
      "Epoch 175/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 1.7556\n",
      " Reduced learning rate to 0.000390184\n",
      "140/140 [==============================] - 0s - loss: 1.7514 - val_loss: 1.7407\n",
      "Epoch 176/300\n",
      "140/140 [==============================] - 0s - loss: 1.7177 - val_loss: 1.7560\n",
      "Epoch 177/300\n",
      "140/140 [==============================] - 0s - loss: 1.6985 - val_loss: 1.7549\n",
      "Epoch 178/300\n",
      "140/140 [==============================] - 0s - loss: 1.6724 - val_loss: 1.7753\n",
      "Epoch 179/300\n",
      "140/140 [==============================] - 0s - loss: 1.7792 - val_loss: 1.6722\n",
      "Epoch 180/300\n",
      "140/140 [==============================] - 0s - loss: 1.7321 - val_loss: 1.7494\n",
      "Epoch 181/300\n",
      "140/140 [==============================] - 0s - loss: 1.7732 - val_loss: 1.7850\n",
      "Epoch 182/300\n",
      "140/140 [==============================] - 0s - loss: 1.7102 - val_loss: 1.6681\n",
      "Epoch 183/300\n",
      "140/140 [==============================] - 0s - loss: 1.7461 - val_loss: 1.6919\n",
      "Epoch 184/300\n",
      "140/140 [==============================] - 0s - loss: 1.6983 - val_loss: 1.6978\n",
      "Epoch 185/300\n",
      "140/140 [==============================] - 0s - loss: 1.6787 - val_loss: 1.7219\n",
      "Epoch 186/300\n",
      "138/140 [============================>.] - ETA: 0s - loss: 1.7342\n",
      " Reduced learning rate to 0.000260123\n",
      "140/140 [==============================] - 0s - loss: 1.7326 - val_loss: 1.6573\n",
      "Epoch 187/300\n",
      "140/140 [==============================] - 0s - loss: 1.7957 - val_loss: 1.7473\n",
      "Epoch 188/300\n",
      "140/140 [==============================] - 0s - loss: 1.6783 - val_loss: 1.6297\n",
      "Epoch 189/300\n",
      "140/140 [==============================] - 0s - loss: 1.6917 - val_loss: 1.7010\n",
      "Epoch 190/300\n",
      "140/140 [==============================] - 0s - loss: 1.7248 - val_loss: 1.7126\n",
      "Epoch 191/300\n",
      "140/140 [==============================] - 0s - loss: 1.7426 - val_loss: 1.7116\n",
      "Epoch 192/300\n",
      "140/140 [==============================] - 0s - loss: 1.7623 - val_loss: 1.7270\n",
      "Epoch 193/300\n",
      "140/140 [==============================] - 0s - loss: 1.7962 - val_loss: 1.6451\n",
      "Epoch 194/300\n",
      "140/140 [==============================] - 0s - loss: 1.7434 - val_loss: 1.7352\n",
      "Epoch 195/300\n",
      "140/140 [==============================] - 0s - loss: 1.7979 - val_loss: 1.6839\n",
      "Epoch 196/300\n",
      "140/140 [==============================] - 0s - loss: 1.6653 - val_loss: 1.6077\n",
      "Epoch 197/300\n",
      "128/140 [==========================>...] - ETA: 0s - loss: 1.7557\n",
      " Reduced learning rate to 0.000173415\n",
      "140/140 [==============================] - 0s - loss: 1.7592 - val_loss: 1.6587\n",
      "Epoch 198/300\n",
      "140/140 [==============================] - 0s - loss: 1.7539 - val_loss: 1.6885\n",
      "Epoch 199/300\n",
      "140/140 [==============================] - 0s - loss: 1.7916 - val_loss: 1.6467\n",
      "Epoch 200/300\n",
      "140/140 [==============================] - 0s - loss: 1.7156 - val_loss: 1.6884\n",
      "Epoch 201/300\n",
      "140/140 [==============================] - 0s - loss: 1.7069 - val_loss: 1.6757\n",
      "Epoch 202/300\n",
      "140/140 [==============================] - 0s - loss: 1.6893 - val_loss: 1.7528\n",
      "Epoch 203/300\n",
      "140/140 [==============================] - 0s - loss: 1.7338 - val_loss: 1.6944\n",
      "Epoch 204/300\n",
      "140/140 [==============================] - 0s - loss: 1.7480 - val_loss: 1.6754\n",
      "Epoch 205/300\n",
      "140/140 [==============================] - 0s - loss: 1.7330 - val_loss: 1.7383\n",
      "Epoch 206/300\n",
      "140/140 [==============================] - 0s - loss: 1.7592 - val_loss: 1.7556\n",
      "Epoch 207/300\n",
      "140/140 [==============================] - 0s - loss: 1.8026 - val_loss: 1.7319\n",
      "Epoch 208/300\n",
      "136/140 [============================>.] - ETA: 0s - loss: 1.7429\n",
      " Reduced learning rate to 0.00011561\n",
      "140/140 [==============================] - 0s - loss: 1.7539 - val_loss: 1.6914\n",
      "Epoch 209/300\n",
      "140/140 [==============================] - 0s - loss: 1.6845 - val_loss: 1.7605\n",
      "Epoch 210/300\n",
      "140/140 [==============================] - 0s - loss: 1.6954 - val_loss: 1.7178\n",
      "Epoch 211/300\n",
      "140/140 [==============================] - 0s - loss: 1.7088 - val_loss: 1.6908\n",
      "Epoch 212/300\n",
      "140/140 [==============================] - 0s - loss: 1.7665 - val_loss: 1.7306\n",
      "Epoch 213/300\n",
      "140/140 [==============================] - 0s - loss: 1.7091 - val_loss: 1.7386\n",
      "Epoch 214/300\n",
      "140/140 [==============================] - 0s - loss: 1.8143 - val_loss: 1.7533\n",
      "Epoch 215/300\n",
      "140/140 [==============================] - 0s - loss: 1.7053 - val_loss: 1.7729\n",
      "Epoch 216/300\n",
      "140/140 [==============================] - 0s - loss: 1.7187 - val_loss: 1.6571\n",
      "Epoch 217/300\n",
      "140/140 [==============================] - 0s - loss: 1.6352 - val_loss: 1.7122\n",
      "Epoch 218/300\n",
      "140/140 [==============================] - 0s - loss: 1.7159 - val_loss: 1.6673\n",
      "Epoch 219/300\n",
      "130/140 [==========================>...] - ETA: 0s - loss: 1.7215\n",
      " Reduced learning rate to 7.70735e-05\n",
      "140/140 [==============================] - 0s - loss: 1.7129 - val_loss: 1.7085\n",
      "Epoch 1/300\n",
      "140/140 [==============================] - 2s - loss: 41.4892 - val_loss: 5.6071\n",
      "Epoch 2/300\n",
      "140/140 [==============================] - 0s - loss: 4.4209 - val_loss: 4.0970\n",
      "Epoch 3/300\n",
      "140/140 [==============================] - 0s - loss: 3.6088 - val_loss: 3.6763\n",
      "Epoch 4/300\n",
      "140/140 [==============================] - 0s - loss: 3.5836 - val_loss: 3.8151\n",
      "Epoch 5/300\n",
      "140/140 [==============================] - 0s - loss: 3.2353 - val_loss: 2.8135\n",
      "Epoch 6/300\n",
      "140/140 [==============================] - 0s - loss: 3.4341 - val_loss: 2.8713\n",
      "Epoch 7/300\n",
      "140/140 [==============================] - 0s - loss: 3.3806 - val_loss: 2.6618\n",
      "Epoch 8/300\n",
      "140/140 [==============================] - 0s - loss: 3.2381 - val_loss: 3.8478\n",
      "Epoch 9/300\n",
      "140/140 [==============================] - 0s - loss: 3.2777 - val_loss: 3.8472\n",
      "Epoch 10/300\n",
      "140/140 [==============================] - 0s - loss: 3.2077 - val_loss: 4.6619\n",
      "Epoch 11/300\n",
      "140/140 [==============================] - 0s - loss: 3.1571 - val_loss: 2.5084\n",
      "Epoch 12/300\n",
      "140/140 [==============================] - 0s - loss: 3.2537 - val_loss: 2.7113\n",
      "Epoch 13/300\n",
      "140/140 [==============================] - 0s - loss: 3.2903 - val_loss: 2.3397\n",
      "Epoch 14/300\n",
      "140/140 [==============================] - 0s - loss: 3.3779 - val_loss: 2.3563\n",
      "Epoch 15/300\n",
      "140/140 [==============================] - 0s - loss: 3.1443 - val_loss: 2.8927\n",
      "Epoch 16/300\n",
      "140/140 [==============================] - 0s - loss: 3.0512 - val_loss: 2.3152\n",
      "Epoch 17/300\n",
      "140/140 [==============================] - 0s - loss: 2.9493 - val_loss: 3.0202\n",
      "Epoch 18/300\n",
      "140/140 [==============================] - 0s - loss: 3.0384 - val_loss: 3.3776\n",
      "Epoch 19/300\n",
      "140/140 [==============================] - 0s - loss: 2.9832 - val_loss: 3.8361\n",
      "Epoch 20/300\n",
      "140/140 [==============================] - 0s - loss: 2.9556 - val_loss: 3.0535\n",
      "Epoch 21/300\n",
      "140/140 [==============================] - 0s - loss: 3.1294 - val_loss: 3.0419\n",
      "Epoch 22/300\n",
      "140/140 [==============================] - 0s - loss: 3.0650 - val_loss: 2.1261\n",
      "Epoch 23/300\n",
      "140/140 [==============================] - 0s - loss: 3.0013 - val_loss: 2.7625\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 2.8877 - val_loss: 2.7185\n",
      "Epoch 25/300\n",
      "140/140 [==============================] - 0s - loss: 2.9310 - val_loss: 3.3809\n",
      "Epoch 26/300\n",
      "140/140 [==============================] - 0s - loss: 3.0613 - val_loss: 2.7401\n",
      "Epoch 27/300\n",
      "140/140 [==============================] - 0s - loss: 2.8817 - val_loss: 2.8529\n",
      "Epoch 28/300\n",
      "140/140 [==============================] - 0s - loss: 2.9727 - val_loss: 2.6274\n",
      "Epoch 29/300\n",
      "140/140 [==============================] - 0s - loss: 2.8500 - val_loss: 2.1908\n",
      "Epoch 30/300\n",
      "140/140 [==============================] - 0s - loss: 2.8675 - val_loss: 3.1347\n",
      "Epoch 31/300\n",
      "140/140 [==============================] - 0s - loss: 2.7451 - val_loss: 2.9825\n",
      "Epoch 32/300\n",
      "140/140 [==============================] - 0s - loss: 2.8682 - val_loss: 2.3318\n",
      "Epoch 33/300\n",
      "121/140 [========================>.....] - ETA: 0s - loss: 2.7793\n",
      " Reduced learning rate to 0.01\n",
      "140/140 [==============================] - 1s - loss: 2.7628 - val_loss: 4.5509\n",
      "Epoch 34/300\n",
      "140/140 [==============================] - 0s - loss: 2.0221 - val_loss: 1.9130\n",
      "Epoch 35/300\n",
      "140/140 [==============================] - 0s - loss: 2.1063 - val_loss: 1.8809\n",
      "Epoch 36/300\n",
      "140/140 [==============================] - 0s - loss: 2.0252 - val_loss: 1.9231\n",
      "Epoch 37/300\n",
      "140/140 [==============================] - 0s - loss: 2.0762 - val_loss: 2.3218\n",
      "Epoch 38/300\n",
      "140/140 [==============================] - 0s - loss: 2.1042 - val_loss: 2.0406\n",
      "Epoch 39/300\n",
      "140/140 [==============================] - 0s - loss: 2.0217 - val_loss: 1.9503\n",
      "Epoch 40/300\n",
      "140/140 [==============================] - 0s - loss: 2.0990 - val_loss: 2.1638\n",
      "Epoch 41/300\n",
      "140/140 [==============================] - 0s - loss: 2.0330 - val_loss: 1.9952\n",
      "Epoch 42/300\n",
      "140/140 [==============================] - 0s - loss: 1.9102 - val_loss: 1.9867\n",
      "Epoch 43/300\n",
      "140/140 [==============================] - 0s - loss: 2.1088 - val_loss: 1.9683\n",
      "Epoch 44/300\n",
      "140/140 [==============================] - 0s - loss: 2.0573 - val_loss: 2.5217\n",
      "Epoch 45/300\n",
      "140/140 [==============================] - 0s - loss: 2.1078 - val_loss: 2.0195\n",
      "Epoch 46/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 2.0909\n",
      " Reduced learning rate to 0.00666667\n",
      "140/140 [==============================] - 0s - loss: 2.0995 - val_loss: 2.3069\n",
      "Epoch 47/300\n",
      "140/140 [==============================] - 0s - loss: 1.8565 - val_loss: 1.8431\n",
      "Epoch 48/300\n",
      "140/140 [==============================] - 0s - loss: 1.8910 - val_loss: 1.8084\n",
      "Epoch 49/300\n",
      "140/140 [==============================] - 0s - loss: 1.8181 - val_loss: 1.8093\n",
      "Epoch 50/300\n",
      "140/140 [==============================] - 0s - loss: 1.7884 - val_loss: 1.8001\n",
      "Epoch 51/300\n",
      "140/140 [==============================] - 0s - loss: 1.8980 - val_loss: 1.7680\n",
      "Epoch 52/300\n",
      "140/140 [==============================] - 0s - loss: 1.8322 - val_loss: 1.8132\n",
      "Epoch 53/300\n",
      "140/140 [==============================] - 0s - loss: 1.7950 - val_loss: 1.8027\n",
      "Epoch 54/300\n",
      "140/140 [==============================] - 0s - loss: 1.8183 - val_loss: 1.8596\n",
      "Epoch 55/300\n",
      "140/140 [==============================] - 0s - loss: 1.8484 - val_loss: 1.8816\n",
      "Epoch 56/300\n",
      "140/140 [==============================] - 0s - loss: 1.8777 - val_loss: 1.8082\n",
      "Epoch 57/300\n",
      "140/140 [==============================] - 0s - loss: 1.8466 - val_loss: 1.8403\n",
      "Epoch 58/300\n",
      "140/140 [==============================] - 0s - loss: 1.9080 - val_loss: 1.9148\n",
      "Epoch 59/300\n",
      "140/140 [==============================] - 0s - loss: 1.8349 - val_loss: 1.8338\n",
      "Epoch 60/300\n",
      "140/140 [==============================] - 0s - loss: 1.7990 - val_loss: 1.8324\n",
      "Epoch 61/300\n",
      "140/140 [==============================] - 0s - loss: 1.8797 - val_loss: 1.9040\n",
      "Epoch 62/300\n",
      "140/140 [==============================] - 0s - loss: 1.8587 - val_loss: 1.7392\n",
      "Epoch 63/300\n",
      "140/140 [==============================] - 0s - loss: 1.8839 - val_loss: 1.8093\n",
      "Epoch 64/300\n",
      "140/140 [==============================] - 0s - loss: 1.8331 - val_loss: 1.7242\n",
      "Epoch 65/300\n",
      "140/140 [==============================] - 0s - loss: 1.8506 - val_loss: 1.8596\n",
      "Epoch 66/300\n",
      "140/140 [==============================] - 0s - loss: 1.8639 - val_loss: 1.7993\n",
      "Epoch 67/300\n",
      "140/140 [==============================] - 0s - loss: 1.7795 - val_loss: 1.8290\n",
      "Epoch 68/300\n",
      "140/140 [==============================] - 0s - loss: 1.8792 - val_loss: 1.8082\n",
      "Epoch 69/300\n",
      "140/140 [==============================] - 0s - loss: 1.8781 - val_loss: 1.8690\n",
      "Epoch 70/300\n",
      "140/140 [==============================] - 0s - loss: 1.8823 - val_loss: 1.7399\n",
      "Epoch 71/300\n",
      "140/140 [==============================] - 0s - loss: 1.8167 - val_loss: 1.8892\n",
      "Epoch 72/300\n",
      "140/140 [==============================] - 0s - loss: 1.8581 - val_loss: 1.7839\n",
      "Epoch 73/300\n",
      "140/140 [==============================] - 0s - loss: 1.8112 - val_loss: 1.7463\n",
      "Epoch 74/300\n",
      "140/140 [==============================] - 0s - loss: 1.9062 - val_loss: 1.7872\n",
      "Epoch 75/300\n",
      "140/140 [==============================] - 0s - loss: 1.8246 - val_loss: 1.6767\n",
      "Epoch 76/300\n",
      "140/140 [==============================] - 0s - loss: 1.8195 - val_loss: 1.7844\n",
      "Epoch 77/300\n",
      "140/140 [==============================] - 0s - loss: 1.8200 - val_loss: 1.7846\n",
      "Epoch 78/300\n",
      "140/140 [==============================] - 0s - loss: 1.8155 - val_loss: 1.7364\n",
      "Epoch 79/300\n",
      "140/140 [==============================] - 0s - loss: 1.8422 - val_loss: 1.8054\n",
      "Epoch 80/300\n",
      "140/140 [==============================] - 0s - loss: 1.9323 - val_loss: 1.7696\n",
      "Epoch 81/300\n",
      "140/140 [==============================] - 0s - loss: 1.8067 - val_loss: 1.8178\n",
      "Epoch 82/300\n",
      "140/140 [==============================] - 0s - loss: 1.8098 - val_loss: 1.7761\n",
      "Epoch 83/300\n",
      "140/140 [==============================] - 0s - loss: 1.9371 - val_loss: 1.8556\n",
      "Epoch 84/300\n",
      "140/140 [==============================] - 0s - loss: 1.8311 - val_loss: 1.7918\n",
      "Epoch 85/300\n",
      "140/140 [==============================] - 0s - loss: 1.8186 - val_loss: 1.7637\n",
      "Epoch 86/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.7473\n",
      " Reduced learning rate to 0.00444444\n",
      "140/140 [==============================] - 0s - loss: 1.7456 - val_loss: 1.8035\n",
      "Epoch 87/300\n",
      "140/140 [==============================] - 0s - loss: 1.7990 - val_loss: 1.7861\n",
      "Epoch 88/300\n",
      "140/140 [==============================] - 0s - loss: 1.8796 - val_loss: 1.7396\n",
      "Epoch 89/300\n",
      "140/140 [==============================] - 0s - loss: 1.7799 - val_loss: 1.7084\n",
      "Epoch 90/300\n",
      "140/140 [==============================] - 0s - loss: 1.7529 - val_loss: 1.8149\n",
      "Epoch 91/300\n",
      "140/140 [==============================] - 0s - loss: 1.8508 - val_loss: 1.7988\n",
      "Epoch 92/300\n",
      "140/140 [==============================] - 0s - loss: 1.7788 - val_loss: 1.7410\n",
      "Epoch 93/300\n",
      "140/140 [==============================] - 0s - loss: 1.8449 - val_loss: 1.7767\n",
      "Epoch 94/300\n",
      "140/140 [==============================] - 0s - loss: 1.8399 - val_loss: 1.7881\n",
      "Epoch 95/300\n",
      "140/140 [==============================] - 0s - loss: 1.7711 - val_loss: 1.6532\n",
      "Epoch 96/300\n",
      "140/140 [==============================] - 0s - loss: 1.7699 - val_loss: 1.7043\n",
      "Epoch 97/300\n",
      "140/140 [==============================] - 0s - loss: 1.8178 - val_loss: 1.6690\n",
      "Epoch 98/300\n",
      "140/140 [==============================] - 0s - loss: 1.8303 - val_loss: 1.7448\n",
      "Epoch 99/300\n",
      "140/140 [==============================] - 0s - loss: 1.8086 - val_loss: 1.7016\n",
      "Epoch 100/300\n",
      "140/140 [==============================] - 0s - loss: 1.8012 - val_loss: 1.7812\n",
      "Epoch 101/300\n",
      "140/140 [==============================] - 0s - loss: 1.7958 - val_loss: 1.6931\n",
      "Epoch 102/300\n",
      "140/140 [==============================] - 0s - loss: 1.7419 - val_loss: 1.7623\n",
      "Epoch 103/300\n",
      "140/140 [==============================] - 0s - loss: 1.7760 - val_loss: 1.7627\n",
      "Epoch 104/300\n",
      "140/140 [==============================] - 0s - loss: 1.7732 - val_loss: 1.7245\n",
      "Epoch 105/300\n",
      "140/140 [==============================] - 0s - loss: 1.7691 - val_loss: 1.7245\n",
      "Epoch 106/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.7729\n",
      " Reduced learning rate to 0.00296296\n",
      "140/140 [==============================] - 0s - loss: 1.7663 - val_loss: 1.7152\n",
      "Epoch 107/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.7738 - val_loss: 1.6896\n",
      "Epoch 108/300\n",
      "140/140 [==============================] - 0s - loss: 1.7842 - val_loss: 1.6968\n",
      "Epoch 109/300\n",
      "140/140 [==============================] - 0s - loss: 1.7227 - val_loss: 1.7101\n",
      "Epoch 110/300\n",
      "140/140 [==============================] - 0s - loss: 1.7168 - val_loss: 1.6890\n",
      "Epoch 111/300\n",
      "140/140 [==============================] - 0s - loss: 1.7632 - val_loss: 1.6578\n",
      "Epoch 112/300\n",
      "140/140 [==============================] - 0s - loss: 1.7647 - val_loss: 1.6171\n",
      "Epoch 113/300\n",
      "140/140 [==============================] - 0s - loss: 1.8049 - val_loss: 1.7676\n",
      "Epoch 114/300\n",
      "140/140 [==============================] - 0s - loss: 1.7850 - val_loss: 1.7595\n",
      "Epoch 115/300\n",
      "140/140 [==============================] - 0s - loss: 1.8419 - val_loss: 1.7452\n",
      "Epoch 116/300\n",
      "140/140 [==============================] - 0s - loss: 1.8319 - val_loss: 1.7403\n",
      "Epoch 117/300\n",
      "140/140 [==============================] - 0s - loss: 1.7970 - val_loss: 1.7432\n",
      "Epoch 118/300\n",
      "140/140 [==============================] - 0s - loss: 1.7665 - val_loss: 1.6950\n",
      "Epoch 119/300\n",
      "140/140 [==============================] - 0s - loss: 1.7430 - val_loss: 1.8524\n",
      "Epoch 120/300\n",
      "140/140 [==============================] - 0s - loss: 1.7727 - val_loss: 1.7623\n",
      "Epoch 121/300\n",
      "140/140 [==============================] - 0s - loss: 1.7743 - val_loss: 1.8123\n",
      "Epoch 122/300\n",
      "140/140 [==============================] - 0s - loss: 1.7663 - val_loss: 1.7091\n",
      "Epoch 123/300\n",
      "127/140 [==========================>...] - ETA: 0s - loss: 1.7720\n",
      " Reduced learning rate to 0.00197531\n",
      "140/140 [==============================] - 0s - loss: 1.7682 - val_loss: 1.7322\n",
      "Epoch 124/300\n",
      "140/140 [==============================] - 0s - loss: 1.7530 - val_loss: 1.7211\n",
      "Epoch 125/300\n",
      "140/140 [==============================] - 0s - loss: 1.7205 - val_loss: 1.8034\n",
      "Epoch 126/300\n",
      "140/140 [==============================] - 0s - loss: 1.7736 - val_loss: 1.7202\n",
      "Epoch 127/300\n",
      "140/140 [==============================] - 0s - loss: 1.7994 - val_loss: 1.7856\n",
      "Epoch 128/300\n",
      "140/140 [==============================] - 0s - loss: 1.8143 - val_loss: 1.7263\n",
      "Epoch 129/300\n",
      "140/140 [==============================] - ETA: 0s - loss: 1.753 - 0s - loss: 1.7520 - val_loss: 1.6917\n",
      "Epoch 130/300\n",
      "140/140 [==============================] - 0s - loss: 1.8080 - val_loss: 1.6428\n",
      "Epoch 131/300\n",
      "140/140 [==============================] - 0s - loss: 1.7128 - val_loss: 1.6987\n",
      "Epoch 132/300\n",
      "140/140 [==============================] - 0s - loss: 1.7541 - val_loss: 1.7003\n",
      "Epoch 133/300\n",
      "140/140 [==============================] - 0s - loss: 1.7608 - val_loss: 1.7417\n",
      "Epoch 134/300\n",
      "134/140 [===========================>..] - ETA: 0s - loss: 1.7908\n",
      " Reduced learning rate to 0.00131687\n",
      "140/140 [==============================] - 0s - loss: 1.7991 - val_loss: 1.7157\n",
      "Epoch 135/300\n",
      "140/140 [==============================] - 0s - loss: 1.7095 - val_loss: 1.7515\n",
      "Epoch 136/300\n",
      "140/140 [==============================] - 0s - loss: 1.8037 - val_loss: 1.7626\n",
      "Epoch 137/300\n",
      "140/140 [==============================] - 0s - loss: 1.7706 - val_loss: 1.6819\n",
      "Epoch 138/300\n",
      "140/140 [==============================] - 0s - loss: 1.7682 - val_loss: 1.7794\n",
      "Epoch 139/300\n",
      "140/140 [==============================] - 0s - loss: 1.7619 - val_loss: 1.7278\n",
      "Epoch 140/300\n",
      "140/140 [==============================] - 0s - loss: 1.7215 - val_loss: 1.7252\n",
      "Epoch 141/300\n",
      "140/140 [==============================] - 0s - loss: 1.7597 - val_loss: 1.6895\n",
      "Epoch 142/300\n",
      "140/140 [==============================] - 0s - loss: 1.7133 - val_loss: 1.7263\n",
      "Epoch 143/300\n",
      "140/140 [==============================] - 0s - loss: 1.7833 - val_loss: 1.7005\n",
      "Epoch 144/300\n",
      "140/140 [==============================] - 0s - loss: 1.7277 - val_loss: 1.7004\n",
      "Epoch 145/300\n",
      "134/140 [===========================>..] - ETA: 0s - loss: 1.7718\n",
      " Reduced learning rate to 0.000877915\n",
      "140/140 [==============================] - 0s - loss: 1.7690 - val_loss: 1.7167\n",
      "Epoch 146/300\n",
      "140/140 [==============================] - 0s - loss: 1.7038 - val_loss: 1.7178\n",
      "Epoch 147/300\n",
      "140/140 [==============================] - 0s - loss: 1.7068 - val_loss: 1.6774\n",
      "Epoch 148/300\n",
      "140/140 [==============================] - 0s - loss: 1.7846 - val_loss: 1.7215\n",
      "Epoch 149/300\n",
      "140/140 [==============================] - 0s - loss: 1.7341 - val_loss: 1.7156\n",
      "Epoch 150/300\n",
      "140/140 [==============================] - 0s - loss: 1.7185 - val_loss: 1.7266\n",
      "Epoch 151/300\n",
      "140/140 [==============================] - 0s - loss: 1.7177 - val_loss: 1.7352\n",
      "Epoch 152/300\n",
      "140/140 [==============================] - 0s - loss: 1.7886 - val_loss: 1.7391\n",
      "Epoch 153/300\n",
      "140/140 [==============================] - 0s - loss: 1.7085 - val_loss: 1.6480\n",
      "Epoch 154/300\n",
      "140/140 [==============================] - 0s - loss: 1.7828 - val_loss: 1.7831\n",
      "Epoch 155/300\n",
      "140/140 [==============================] - 0s - loss: 1.7239 - val_loss: 1.6788\n",
      "Epoch 156/300\n",
      "130/140 [==========================>...] - ETA: 0s - loss: 1.7828\n",
      " Reduced learning rate to 0.000585277\n",
      "140/140 [==============================] - 0s - loss: 1.8082 - val_loss: 1.7155\n",
      "Epoch 157/300\n",
      "140/140 [==============================] - 0s - loss: 1.7574 - val_loss: 1.7012\n",
      "Epoch 158/300\n",
      "140/140 [==============================] - 0s - loss: 1.7414 - val_loss: 1.6351\n",
      "Epoch 159/300\n",
      "140/140 [==============================] - 0s - loss: 1.7249 - val_loss: 1.7731\n",
      "Epoch 160/300\n",
      "140/140 [==============================] - 0s - loss: 1.6836 - val_loss: 1.7082\n",
      "Epoch 161/300\n",
      "140/140 [==============================] - 0s - loss: 1.7278 - val_loss: 1.7569\n",
      "Epoch 162/300\n",
      "140/140 [==============================] - 0s - loss: 1.7099 - val_loss: 1.6676\n",
      "Epoch 163/300\n",
      "140/140 [==============================] - 0s - loss: 1.7875 - val_loss: 1.7077\n",
      "Epoch 164/300\n",
      "140/140 [==============================] - 0s - loss: 1.7975 - val_loss: 1.7650\n",
      "Epoch 165/300\n",
      "140/140 [==============================] - 0s - loss: 1.7901 - val_loss: 1.7156\n",
      "Epoch 166/300\n",
      "140/140 [==============================] - 0s - loss: 1.7229 - val_loss: 1.7421\n",
      "Epoch 167/300\n",
      "140/140 [==============================] - 0s - loss: 1.8026 - val_loss: 1.5787\n",
      "Epoch 168/300\n",
      "140/140 [==============================] - 0s - loss: 1.7087 - val_loss: 1.6784\n",
      "Epoch 169/300\n",
      "140/140 [==============================] - 0s - loss: 1.7514 - val_loss: 1.7237\n",
      "Epoch 170/300\n",
      "140/140 [==============================] - 0s - loss: 1.6895 - val_loss: 1.6655\n",
      "Epoch 171/300\n",
      "140/140 [==============================] - 0s - loss: 1.7149 - val_loss: 1.7424\n",
      "Epoch 172/300\n",
      "140/140 [==============================] - 0s - loss: 1.7772 - val_loss: 1.6808\n",
      "Epoch 173/300\n",
      "140/140 [==============================] - 0s - loss: 1.8999 - val_loss: 1.7480\n",
      "Epoch 174/300\n",
      "140/140 [==============================] - 0s - loss: 1.7566 - val_loss: 1.6967\n",
      "Epoch 175/300\n",
      "140/140 [==============================] - 0s - loss: 1.7784 - val_loss: 1.7704\n",
      "Epoch 176/300\n",
      "140/140 [==============================] - 0s - loss: 1.7336 - val_loss: 1.6874\n",
      "Epoch 177/300\n",
      "140/140 [==============================] - 0s - loss: 1.7649 - val_loss: 1.6920\n",
      "Epoch 178/300\n",
      "138/140 [============================>.] - ETA: 0s - loss: 1.7391\n",
      " Reduced learning rate to 0.000390184\n",
      "140/140 [==============================] - 0s - loss: 1.7396 - val_loss: 1.8072\n",
      "Epoch 179/300\n",
      "140/140 [==============================] - 0s - loss: 1.7080 - val_loss: 1.7020\n",
      "Epoch 180/300\n",
      "140/140 [==============================] - 0s - loss: 1.8228 - val_loss: 1.7239\n",
      "Epoch 181/300\n",
      "140/140 [==============================] - 0s - loss: 1.7402 - val_loss: 1.7157\n",
      "Epoch 182/300\n",
      "140/140 [==============================] - 0s - loss: 1.7321 - val_loss: 1.7601\n",
      "Epoch 183/300\n",
      "140/140 [==============================] - 0s - loss: 1.7476 - val_loss: 1.5777\n",
      "Epoch 184/300\n",
      "140/140 [==============================] - 0s - loss: 1.7500 - val_loss: 1.6759\n",
      "Epoch 185/300\n",
      "140/140 [==============================] - 0s - loss: 1.7032 - val_loss: 1.7470\n",
      "Epoch 186/300\n",
      "140/140 [==============================] - 0s - loss: 1.7484 - val_loss: 1.7181\n",
      "Epoch 187/300\n",
      "140/140 [==============================] - 0s - loss: 1.7224 - val_loss: 1.6903\n",
      "Epoch 188/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.7648 - val_loss: 1.7519\n",
      "Epoch 189/300\n",
      "140/140 [==============================] - 0s - loss: 1.7402 - val_loss: 1.7020\n",
      "Epoch 190/300\n",
      "140/140 [==============================] - 0s - loss: 1.7413 - val_loss: 1.7322\n",
      "Epoch 191/300\n",
      "140/140 [==============================] - 0s - loss: 1.7324 - val_loss: 1.6719\n",
      "Epoch 192/300\n",
      "140/140 [==============================] - 0s - loss: 1.7538 - val_loss: 1.6947\n",
      "Epoch 193/300\n",
      "140/140 [==============================] - 0s - loss: 1.7839 - val_loss: 1.7432\n",
      "Epoch 194/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.8430\n",
      " Reduced learning rate to 0.000260123\n",
      "140/140 [==============================] - 0s - loss: 1.8319 - val_loss: 1.6999\n",
      "Epoch 195/300\n",
      "140/140 [==============================] - 0s - loss: 1.7531 - val_loss: 1.6682\n",
      "Epoch 196/300\n",
      "140/140 [==============================] - 0s - loss: 1.7670 - val_loss: 1.7092\n",
      "Epoch 197/300\n",
      "140/140 [==============================] - 0s - loss: 1.7875 - val_loss: 1.6523\n",
      "Epoch 198/300\n",
      "140/140 [==============================] - 0s - loss: 1.7749 - val_loss: 1.6649\n",
      "Epoch 199/300\n",
      "140/140 [==============================] - 0s - loss: 1.7372 - val_loss: 1.7362\n",
      "Epoch 200/300\n",
      "140/140 [==============================] - 0s - loss: 1.7939 - val_loss: 1.6851\n",
      "Epoch 201/300\n",
      "140/140 [==============================] - 0s - loss: 1.7312 - val_loss: 1.7093\n",
      "Epoch 202/300\n",
      "140/140 [==============================] - 0s - loss: 1.8003 - val_loss: 1.7034\n",
      "Epoch 203/300\n",
      "140/140 [==============================] - 0s - loss: 1.7275 - val_loss: 1.7349\n",
      "Epoch 204/300\n",
      "140/140 [==============================] - 0s - loss: 1.7139 - val_loss: 1.7293\n",
      "Epoch 205/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 1.7341\n",
      " Reduced learning rate to 0.000173415\n",
      "140/140 [==============================] - 0s - loss: 1.7389 - val_loss: 1.6914\n",
      "Epoch 206/300\n",
      "140/140 [==============================] - 0s - loss: 1.7830 - val_loss: 1.7401\n",
      "Epoch 207/300\n",
      "140/140 [==============================] - 0s - loss: 1.7243 - val_loss: 1.6503\n",
      "Epoch 208/300\n",
      "140/140 [==============================] - 0s - loss: 1.8296 - val_loss: 1.7251\n",
      "Epoch 209/300\n",
      "140/140 [==============================] - 0s - loss: 1.6792 - val_loss: 1.6830\n",
      "Epoch 210/300\n",
      "140/140 [==============================] - 0s - loss: 1.7962 - val_loss: 1.7524\n",
      "Epoch 211/300\n",
      "140/140 [==============================] - 0s - loss: 1.7882 - val_loss: 1.6471\n",
      "Epoch 212/300\n",
      "140/140 [==============================] - 0s - loss: 1.8463 - val_loss: 1.6694\n",
      "Epoch 213/300\n",
      "140/140 [==============================] - 0s - loss: 1.7414 - val_loss: 1.7520\n",
      "Epoch 214/300\n",
      "140/140 [==============================] - 0s - loss: 1.7449 - val_loss: 1.7587\n",
      "Epoch 215/300\n",
      "140/140 [==============================] - 0s - loss: 1.7561 - val_loss: 1.6861\n",
      "Epoch 216/300\n",
      "138/140 [============================>.] - ETA: 0s - loss: 1.7804\n",
      " Reduced learning rate to 0.00011561\n",
      "140/140 [==============================] - 0s - loss: 1.7817 - val_loss: 1.6998\n",
      "Epoch 217/300\n",
      "140/140 [==============================] - 0s - loss: 1.7734 - val_loss: 1.7122\n",
      "Epoch 218/300\n",
      "140/140 [==============================] - 0s - loss: 1.6950 - val_loss: 1.7024s\n",
      "Epoch 219/300\n",
      "140/140 [==============================] - 0s - loss: 1.6978 - val_loss: 1.7667\n",
      "Epoch 220/300\n",
      "140/140 [==============================] - 0s - loss: 1.7017 - val_loss: 1.6646\n",
      "Epoch 221/300\n",
      "140/140 [==============================] - 0s - loss: 1.7230 - val_loss: 1.7022\n",
      "Epoch 222/300\n",
      "140/140 [==============================] - 0s - loss: 1.7327 - val_loss: 1.7468\n",
      "Epoch 223/300\n",
      "140/140 [==============================] - 0s - loss: 1.7218 - val_loss: 1.6724\n",
      "Epoch 224/300\n",
      "140/140 [==============================] - 0s - loss: 1.7314 - val_loss: 1.6583\n",
      "Epoch 225/300\n",
      "140/140 [==============================] - 0s - loss: 1.7108 - val_loss: 1.7097\n",
      "Epoch 226/300\n",
      "140/140 [==============================] - 0s - loss: 1.7667 - val_loss: 1.7346\n",
      "Epoch 227/300\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 1.7298\n",
      " Reduced learning rate to 7.70735e-05\n",
      "140/140 [==============================] - 0s - loss: 1.7322 - val_loss: 1.7812\n",
      "Epoch 1/300\n",
      "140/140 [==============================] - 2s - loss: 40.6526 - val_loss: 5.3918\n",
      "Epoch 2/300\n",
      "140/140 [==============================] - 0s - loss: 4.4887 - val_loss: 3.6237\n",
      "Epoch 3/300\n",
      "140/140 [==============================] - 0s - loss: 3.7336 - val_loss: 3.6861\n",
      "Epoch 4/300\n",
      "140/140 [==============================] - 0s - loss: 3.5312 - val_loss: 2.5828\n",
      "Epoch 5/300\n",
      "140/140 [==============================] - 0s - loss: 3.1765 - val_loss: 3.0647\n",
      "Epoch 6/300\n",
      "140/140 [==============================] - 0s - loss: 3.2444 - val_loss: 2.5573\n",
      "Epoch 7/300\n",
      "140/140 [==============================] - 0s - loss: 3.5624 - val_loss: 2.7305\n",
      "Epoch 8/300\n",
      "140/140 [==============================] - 0s - loss: 3.2910 - val_loss: 2.9126\n",
      "Epoch 9/300\n",
      "140/140 [==============================] - 0s - loss: 3.4086 - val_loss: 2.4621\n",
      "Epoch 10/300\n",
      "140/140 [==============================] - 0s - loss: 3.2519 - val_loss: 2.8431\n",
      "Epoch 11/300\n",
      "140/140 [==============================] - 0s - loss: 3.1617 - val_loss: 3.0751\n",
      "Epoch 12/300\n",
      "140/140 [==============================] - 0s - loss: 3.3269 - val_loss: 3.0649\n",
      "Epoch 13/300\n",
      "140/140 [==============================] - 0s - loss: 3.2412 - val_loss: 2.9578\n",
      "Epoch 14/300\n",
      "140/140 [==============================] - 0s - loss: 3.1909 - val_loss: 3.0513\n",
      "Epoch 15/300\n",
      "140/140 [==============================] - 0s - loss: 3.0233 - val_loss: 3.0481\n",
      "Epoch 16/300\n",
      "140/140 [==============================] - 0s - loss: 3.2583 - val_loss: 2.8071\n",
      "Epoch 17/300\n",
      "140/140 [==============================] - 0s - loss: 3.0650 - val_loss: 2.5678\n",
      "Epoch 18/300\n",
      "140/140 [==============================] - 0s - loss: 3.1701 - val_loss: 2.5732\n",
      "Epoch 19/300\n",
      "140/140 [==============================] - 0s - loss: 2.8657 - val_loss: 2.3085\n",
      "Epoch 20/300\n",
      "140/140 [==============================] - 0s - loss: 2.9195 - val_loss: 2.6030\n",
      "Epoch 21/300\n",
      "140/140 [==============================] - 0s - loss: 3.0587 - val_loss: 2.8312\n",
      "Epoch 22/300\n",
      "140/140 [==============================] - 0s - loss: 3.0177 - val_loss: 2.4597\n",
      "Epoch 23/300\n",
      "140/140 [==============================] - 0s - loss: 2.9354 - val_loss: 2.6309\n",
      "Epoch 24/300\n",
      "140/140 [==============================] - 0s - loss: 2.9558 - val_loss: 1.9786\n",
      "Epoch 25/300\n",
      "140/140 [==============================] - 0s - loss: 2.7181 - val_loss: 3.7219\n",
      "Epoch 26/300\n",
      "140/140 [==============================] - 0s - loss: 2.9716 - val_loss: 2.3289\n",
      "Epoch 27/300\n",
      "140/140 [==============================] - 0s - loss: 2.8977 - val_loss: 3.5984\n",
      "Epoch 28/300\n",
      "140/140 [==============================] - 0s - loss: 2.7692 - val_loss: 2.6409\n",
      "Epoch 29/300\n",
      "140/140 [==============================] - 0s - loss: 2.9435 - val_loss: 3.6886\n",
      "Epoch 30/300\n",
      "140/140 [==============================] - 0s - loss: 2.8325 - val_loss: 2.6800\n",
      "Epoch 31/300\n",
      "140/140 [==============================] - 0s - loss: 2.8175 - val_loss: 2.1219\n",
      "Epoch 32/300\n",
      "140/140 [==============================] - ETA: 0s - loss: 2.888 - 0s - loss: 2.8953 - val_loss: 3.0266\n",
      "Epoch 33/300\n",
      "140/140 [==============================] - 0s - loss: 2.7965 - val_loss: 2.1290\n",
      "Epoch 34/300\n",
      "140/140 [==============================] - 0s - loss: 2.8072 - val_loss: 1.9595\n",
      "Epoch 35/300\n",
      "140/140 [==============================] - 0s - loss: 2.8984 - val_loss: 2.4155\n",
      "Epoch 36/300\n",
      "140/140 [==============================] - 0s - loss: 2.7176 - val_loss: 2.4438\n",
      "Epoch 37/300\n",
      "140/140 [==============================] - 0s - loss: 2.7874 - val_loss: 2.2375\n",
      "Epoch 38/300\n",
      "140/140 [==============================] - 0s - loss: 2.7953 - val_loss: 2.6890\n",
      "Epoch 39/300\n",
      "140/140 [==============================] - 0s - loss: 2.6792 - val_loss: 2.0873\n",
      "Epoch 40/300\n",
      "140/140 [==============================] - 0s - loss: 2.6648 - val_loss: 2.9260\n",
      "Epoch 41/300\n",
      "140/140 [==============================] - 0s - loss: 2.7470 - val_loss: 2.6025\n",
      "Epoch 42/300\n",
      "140/140 [==============================] - 0s - loss: 2.7474 - val_loss: 2.2751\n",
      "Epoch 43/300\n",
      "140/140 [==============================] - 0s - loss: 2.7903 - val_loss: 2.6430\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 2.6002 - val_loss: 1.9176\n",
      "Epoch 45/300\n",
      "140/140 [==============================] - 0s - loss: 2.6987 - val_loss: 4.5418\n",
      "Epoch 46/300\n",
      "140/140 [==============================] - 0s - loss: 2.7335 - val_loss: 1.8737\n",
      "Epoch 47/300\n",
      "140/140 [==============================] - 0s - loss: 2.7831 - val_loss: 2.0513\n",
      "Epoch 48/300\n",
      "140/140 [==============================] - 0s - loss: 2.6025 - val_loss: 2.1689\n",
      "Epoch 49/300\n",
      "140/140 [==============================] - 0s - loss: 2.6782 - val_loss: 2.3475\n",
      "Epoch 50/300\n",
      "140/140 [==============================] - 0s - loss: 2.6129 - val_loss: 2.6707\n",
      "Epoch 51/300\n",
      "140/140 [==============================] - 0s - loss: 2.6680 - val_loss: 2.0759\n",
      "Epoch 52/300\n",
      "140/140 [==============================] - 0s - loss: 2.6656 - val_loss: 2.1186\n",
      "Epoch 53/300\n",
      "140/140 [==============================] - 0s - loss: 2.6290 - val_loss: 2.0609\n",
      "Epoch 54/300\n",
      "140/140 [==============================] - 0s - loss: 2.6142 - val_loss: 2.7569\n",
      "Epoch 55/300\n",
      "140/140 [==============================] - 0s - loss: 2.6037 - val_loss: 2.1117\n",
      "Epoch 56/300\n",
      "140/140 [==============================] - 0s - loss: 2.5494 - val_loss: 1.8136\n",
      "Epoch 57/300\n",
      "140/140 [==============================] - 0s - loss: 2.5188 - val_loss: 4.1193\n",
      "Epoch 58/300\n",
      "140/140 [==============================] - 0s - loss: 2.7112 - val_loss: 2.0879\n",
      "Epoch 59/300\n",
      "140/140 [==============================] - 0s - loss: 2.6526 - val_loss: 1.9001\n",
      "Epoch 60/300\n",
      "140/140 [==============================] - 0s - loss: 2.5551 - val_loss: 2.6239\n",
      "Epoch 61/300\n",
      "140/140 [==============================] - 0s - loss: 2.5140 - val_loss: 2.2772\n",
      "Epoch 62/300\n",
      "140/140 [==============================] - 0s - loss: 2.5661 - val_loss: 2.1572\n",
      "Epoch 63/300\n",
      "140/140 [==============================] - 0s - loss: 2.5678 - val_loss: 1.9863\n",
      "Epoch 64/300\n",
      "140/140 [==============================] - 0s - loss: 2.5052 - val_loss: 2.2874\n",
      "Epoch 65/300\n",
      "140/140 [==============================] - 0s - loss: 2.6247 - val_loss: 2.2748\n",
      "Epoch 66/300\n",
      "140/140 [==============================] - 0s - loss: 2.5091 - val_loss: 1.9727\n",
      "Epoch 67/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 2.4963\n",
      " Reduced learning rate to 0.01\n",
      "140/140 [==============================] - 1s - loss: 2.4565 - val_loss: 1.8620\n",
      "Epoch 68/300\n",
      "140/140 [==============================] - 0s - loss: 1.9180 - val_loss: 1.7161\n",
      "Epoch 69/300\n",
      "140/140 [==============================] - 0s - loss: 1.8880 - val_loss: 1.8018\n",
      "Epoch 70/300\n",
      "140/140 [==============================] - 0s - loss: 1.9410 - val_loss: 2.0553\n",
      "Epoch 71/300\n",
      "140/140 [==============================] - 0s - loss: 1.8828 - val_loss: 1.6773\n",
      "Epoch 72/300\n",
      "140/140 [==============================] - 0s - loss: 1.9443 - val_loss: 1.7971\n",
      "Epoch 73/300\n",
      "140/140 [==============================] - 0s - loss: 1.9393 - val_loss: 2.2893\n",
      "Epoch 74/300\n",
      "140/140 [==============================] - 0s - loss: 1.8814 - val_loss: 1.9677\n",
      "Epoch 75/300\n",
      "140/140 [==============================] - 0s - loss: 1.9813 - val_loss: 1.8133s\n",
      "Epoch 76/300\n",
      "140/140 [==============================] - 0s - loss: 1.9355 - val_loss: 1.9745\n",
      "Epoch 77/300\n",
      "140/140 [==============================] - 0s - loss: 1.9741 - val_loss: 2.1554\n",
      "Epoch 78/300\n",
      "140/140 [==============================] - 0s - loss: 1.9566 - val_loss: 1.7120\n",
      "Epoch 79/300\n",
      "140/140 [==============================] - 0s - loss: 1.9037 - val_loss: 2.1486\n",
      "Epoch 80/300\n",
      "140/140 [==============================] - 0s - loss: 2.0120 - val_loss: 1.8894\n",
      "Epoch 81/300\n",
      "140/140 [==============================] - 0s - loss: 1.9018 - val_loss: 1.8335\n",
      "Epoch 82/300\n",
      "134/140 [===========================>..] - ETA: 0s - loss: 1.9663\n",
      " Reduced learning rate to 0.00666667\n",
      "140/140 [==============================] - 0s - loss: 1.9863 - val_loss: 1.8258\n",
      "Epoch 83/300\n",
      "140/140 [==============================] - 0s - loss: 1.8509 - val_loss: 1.7381\n",
      "Epoch 84/300\n",
      "140/140 [==============================] - 0s - loss: 1.7799 - val_loss: 1.7678\n",
      "Epoch 85/300\n",
      "140/140 [==============================] - 0s - loss: 1.8553 - val_loss: 1.7727\n",
      "Epoch 86/300\n",
      "140/140 [==============================] - 0s - loss: 1.7761 - val_loss: 1.8462\n",
      "Epoch 87/300\n",
      "140/140 [==============================] - 0s - loss: 1.8040 - val_loss: 1.7014\n",
      "Epoch 88/300\n",
      "140/140 [==============================] - 0s - loss: 1.7731 - val_loss: 1.7618\n",
      "Epoch 89/300\n",
      "140/140 [==============================] - 0s - loss: 1.8136 - val_loss: 1.7812\n",
      "Epoch 90/300\n",
      "140/140 [==============================] - 0s - loss: 1.7798 - val_loss: 1.7354\n",
      "Epoch 91/300\n",
      "140/140 [==============================] - 0s - loss: 1.7707 - val_loss: 1.7371\n",
      "Epoch 92/300\n",
      "140/140 [==============================] - 0s - loss: 1.8165 - val_loss: 1.7950\n",
      "Epoch 93/300\n",
      "138/140 [============================>.] - ETA: 0s - loss: 1.8398\n",
      " Reduced learning rate to 0.00444444\n",
      "140/140 [==============================] - 0s - loss: 1.8390 - val_loss: 1.6816\n",
      "Epoch 94/300\n",
      "140/140 [==============================] - 0s - loss: 1.7910 - val_loss: 1.7814\n",
      "Epoch 95/300\n",
      "140/140 [==============================] - 0s - loss: 1.7282 - val_loss: 1.7421\n",
      "Epoch 96/300\n",
      "140/140 [==============================] - 0s - loss: 1.7986 - val_loss: 1.6696\n",
      "Epoch 97/300\n",
      "140/140 [==============================] - 0s - loss: 1.7896 - val_loss: 1.7046\n",
      "Epoch 98/300\n",
      "140/140 [==============================] - 0s - loss: 1.7966 - val_loss: 1.7376\n",
      "Epoch 99/300\n",
      "140/140 [==============================] - 0s - loss: 1.7584 - val_loss: 1.7747\n",
      "Epoch 100/300\n",
      "140/140 [==============================] - 0s - loss: 1.7900 - val_loss: 1.7448\n",
      "Epoch 101/300\n",
      "140/140 [==============================] - 0s - loss: 1.8244 - val_loss: 1.8234\n",
      "Epoch 102/300\n",
      "140/140 [==============================] - 0s - loss: 1.8418 - val_loss: 1.7268\n",
      "Epoch 103/300\n",
      "140/140 [==============================] - 0s - loss: 1.7303 - val_loss: 1.7500\n",
      "Epoch 104/300\n",
      "140/140 [==============================] - 0s - loss: 1.7520 - val_loss: 1.7881\n",
      "Epoch 105/300\n",
      "140/140 [==============================] - 0s - loss: 1.7787 - val_loss: 1.7958\n",
      "Epoch 106/300\n",
      "140/140 [==============================] - 0s - loss: 1.7520 - val_loss: 1.6441\n",
      "Epoch 107/300\n",
      "140/140 [==============================] - 0s - loss: 1.7997 - val_loss: 1.7778\n",
      "Epoch 108/300\n",
      "140/140 [==============================] - 0s - loss: 1.8030 - val_loss: 1.7850\n",
      "Epoch 109/300\n",
      "140/140 [==============================] - 0s - loss: 1.7682 - val_loss: 1.6847\n",
      "Epoch 110/300\n",
      "140/140 [==============================] - 0s - loss: 1.8096 - val_loss: 1.7014\n",
      "Epoch 111/300\n",
      "140/140 [==============================] - 0s - loss: 1.8603 - val_loss: 1.7307\n",
      "Epoch 112/300\n",
      "140/140 [==============================] - 0s - loss: 1.7691 - val_loss: 1.7100\n",
      "Epoch 113/300\n",
      "140/140 [==============================] - 0s - loss: 1.7463 - val_loss: 1.6540\n",
      "Epoch 114/300\n",
      "140/140 [==============================] - 0s - loss: 1.7654 - val_loss: 1.6932\n",
      "Epoch 115/300\n",
      "140/140 [==============================] - 0s - loss: 1.7617 - val_loss: 1.7048\n",
      "Epoch 116/300\n",
      "140/140 [==============================] - 0s - loss: 1.7350 - val_loss: 1.7494\n",
      "Epoch 117/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.8357- ETA: 0s - loss\n",
      " Reduced learning rate to 0.00296296\n",
      "140/140 [==============================] - 0s - loss: 1.8411 - val_loss: 1.7704\n",
      "Epoch 118/300\n",
      "140/140 [==============================] - 0s - loss: 1.7498 - val_loss: 1.6978\n",
      "Epoch 119/300\n",
      "140/140 [==============================] - 0s - loss: 1.7461 - val_loss: 1.6566\n",
      "Epoch 120/300\n",
      "140/140 [==============================] - 0s - loss: 1.7601 - val_loss: 1.7391\n",
      "Epoch 121/300\n",
      "140/140 [==============================] - 0s - loss: 1.7747 - val_loss: 1.7036\n",
      "Epoch 122/300\n",
      "140/140 [==============================] - 0s - loss: 1.7810 - val_loss: 1.6977\n",
      "Epoch 123/300\n",
      "140/140 [==============================] - 0s - loss: 1.7605 - val_loss: 1.7105\n",
      "Epoch 124/300\n",
      "140/140 [==============================] - 0s - loss: 1.7550 - val_loss: 1.7454\n",
      "Epoch 125/300\n",
      "140/140 [==============================] - 0s - loss: 1.7307 - val_loss: 1.6930\n",
      "Epoch 126/300\n",
      "140/140 [==============================] - 0s - loss: 1.7151 - val_loss: 1.6502\n",
      "Epoch 127/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.7579 - val_loss: 1.6757\n",
      "Epoch 128/300\n",
      "129/140 [==========================>...] - ETA: 0s - loss: 1.7554\n",
      " Reduced learning rate to 0.00197531\n",
      "140/140 [==============================] - 0s - loss: 1.7543 - val_loss: 1.7416\n",
      "Epoch 129/300\n",
      "140/140 [==============================] - 0s - loss: 1.7993 - val_loss: 1.7465\n",
      "Epoch 130/300\n",
      "140/140 [==============================] - 0s - loss: 1.7174 - val_loss: 1.7481\n",
      "Epoch 131/300\n",
      "140/140 [==============================] - 0s - loss: 1.8277 - val_loss: 1.7496\n",
      "Epoch 132/300\n",
      "140/140 [==============================] - 0s - loss: 1.7788 - val_loss: 1.6853\n",
      "Epoch 133/300\n",
      "140/140 [==============================] - 0s - loss: 1.7556 - val_loss: 1.7396\n",
      "Epoch 134/300\n",
      "140/140 [==============================] - 0s - loss: 1.7545 - val_loss: 1.7069\n",
      "Epoch 135/300\n",
      "140/140 [==============================] - 0s - loss: 1.7059 - val_loss: 1.6898\n",
      "Epoch 136/300\n",
      "140/140 [==============================] - 0s - loss: 1.8720 - val_loss: 1.7649\n",
      "Epoch 137/300\n",
      "140/140 [==============================] - 0s - loss: 1.8029 - val_loss: 1.6349\n",
      "Epoch 138/300\n",
      "140/140 [==============================] - 0s - loss: 1.8050 - val_loss: 1.7281\n",
      "Epoch 139/300\n",
      "140/140 [==============================] - 0s - loss: 1.8011 - val_loss: 1.7259\n",
      "Epoch 140/300\n",
      "140/140 [==============================] - 0s - loss: 1.7431 - val_loss: 1.6854\n",
      "Epoch 141/300\n",
      "140/140 [==============================] - 0s - loss: 1.7565 - val_loss: 1.7946\n",
      "Epoch 142/300\n",
      "140/140 [==============================] - 0s - loss: 1.7668 - val_loss: 1.7571\n",
      "Epoch 143/300\n",
      "140/140 [==============================] - 0s - loss: 1.7619 - val_loss: 1.6980\n",
      "Epoch 144/300\n",
      "140/140 [==============================] - 0s - loss: 1.7547 - val_loss: 1.6266\n",
      "Epoch 145/300\n",
      "140/140 [==============================] - 0s - loss: 1.7408 - val_loss: 1.7537\n",
      "Epoch 146/300\n",
      "140/140 [==============================] - 0s - loss: 1.7634 - val_loss: 1.6681\n",
      "Epoch 147/300\n",
      "140/140 [==============================] - 0s - loss: 1.8550 - val_loss: 1.7328\n",
      "Epoch 148/300\n",
      "140/140 [==============================] - 0s - loss: 1.7612 - val_loss: 1.6774\n",
      "Epoch 149/300\n",
      "140/140 [==============================] - 0s - loss: 1.7524 - val_loss: 1.7043\n",
      "Epoch 150/300\n",
      "140/140 [==============================] - 0s - loss: 1.8192 - val_loss: 1.8747\n",
      "Epoch 151/300\n",
      "140/140 [==============================] - 0s - loss: 1.8040 - val_loss: 1.7211\n",
      "Epoch 152/300\n",
      "140/140 [==============================] - 0s - loss: 1.7960 - val_loss: 1.6773\n",
      "Epoch 153/300\n",
      "140/140 [==============================] - 0s - loss: 1.7609 - val_loss: 1.7100\n",
      "Epoch 154/300\n",
      "140/140 [==============================] - 0s - loss: 1.7576 - val_loss: 1.6737\n",
      "Epoch 155/300\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1.7663\n",
      " Reduced learning rate to 0.00131687\n",
      "140/140 [==============================] - 0s - loss: 1.7671 - val_loss: 1.7088\n",
      "Epoch 156/300\n",
      "140/140 [==============================] - 0s - loss: 1.7954 - val_loss: 1.7542\n",
      "Epoch 157/300\n",
      "140/140 [==============================] - 0s - loss: 1.6882 - val_loss: 1.6850\n",
      "Epoch 158/300\n",
      "140/140 [==============================] - 0s - loss: 1.8002 - val_loss: 1.7729\n",
      "Epoch 159/300\n",
      "140/140 [==============================] - 0s - loss: 1.7793 - val_loss: 1.7743\n",
      "Epoch 160/300\n",
      "140/140 [==============================] - 0s - loss: 1.7547 - val_loss: 1.7302\n",
      "Epoch 161/300\n",
      "140/140 [==============================] - 0s - loss: 1.7479 - val_loss: 1.7161\n",
      "Epoch 162/300\n",
      "140/140 [==============================] - 0s - loss: 1.7624 - val_loss: 1.6539\n",
      "Epoch 163/300\n",
      "140/140 [==============================] - 0s - loss: 1.7518 - val_loss: 1.7584\n",
      "Epoch 164/300\n",
      "140/140 [==============================] - 0s - loss: 1.7802 - val_loss: 1.6818\n",
      "Epoch 165/300\n",
      "140/140 [==============================] - 0s - loss: 1.7311 - val_loss: 1.7626\n",
      "Epoch 166/300\n",
      "138/140 [============================>.] - ETA: 0s - loss: 1.7105\n",
      " Reduced learning rate to 0.000877915\n",
      "140/140 [==============================] - 0s - loss: 1.7086 - val_loss: 1.6738\n",
      "Epoch 167/300\n",
      "140/140 [==============================] - 0s - loss: 1.7755 - val_loss: 1.6305\n",
      "Epoch 168/300\n",
      "140/140 [==============================] - 0s - loss: 1.7792 - val_loss: 1.6588\n",
      "Epoch 169/300\n",
      "140/140 [==============================] - 0s - loss: 1.8130 - val_loss: 1.7338\n",
      "Epoch 170/300\n",
      "140/140 [==============================] - 1s - loss: 1.7833 - val_loss: 1.7389\n",
      "Epoch 171/300\n",
      "140/140 [==============================] - 0s - loss: 1.7241 - val_loss: 1.7003\n",
      "Epoch 172/300\n",
      "140/140 [==============================] - 0s - loss: 1.7090 - val_loss: 1.7883\n",
      "Epoch 173/300\n",
      "140/140 [==============================] - 0s - loss: 1.7094 - val_loss: 1.7318\n",
      "Epoch 174/300\n",
      "140/140 [==============================] - 0s - loss: 1.7285 - val_loss: 1.6982\n",
      "Epoch 175/300\n",
      "140/140 [==============================] - 0s - loss: 1.7203 - val_loss: 1.7051\n",
      "Epoch 176/300\n",
      "140/140 [==============================] - 0s - loss: 1.7533 - val_loss: 1.7122\n",
      "Epoch 177/300\n",
      "135/140 [===========================>..] - ETA: 0s - loss: 1.7300\n",
      " Reduced learning rate to 0.000585277\n",
      "140/140 [==============================] - 0s - loss: 1.7252 - val_loss: 1.7355\n",
      "Epoch 178/300\n",
      "140/140 [==============================] - 0s - loss: 1.7836 - val_loss: 1.7663\n",
      "Epoch 179/300\n",
      "140/140 [==============================] - 0s - loss: 1.7312 - val_loss: 1.6592\n",
      "Epoch 180/300\n",
      "140/140 [==============================] - 0s - loss: 1.7217 - val_loss: 1.7627\n",
      "Epoch 181/300\n",
      "140/140 [==============================] - 0s - loss: 1.7195 - val_loss: 1.6544\n",
      "Epoch 182/300\n",
      "140/140 [==============================] - 0s - loss: 1.6970 - val_loss: 1.6907ss\n",
      "Epoch 183/300\n",
      "140/140 [==============================] - 0s - loss: 1.7480 - val_loss: 1.7584\n",
      "Epoch 184/300\n",
      "140/140 [==============================] - 0s - loss: 1.7579 - val_loss: 1.7392\n",
      "Epoch 185/300\n",
      "140/140 [==============================] - 0s - loss: 1.7635 - val_loss: 1.7547\n",
      "Epoch 186/300\n",
      "140/140 [==============================] - 0s - loss: 1.7852 - val_loss: 1.6111\n",
      "Epoch 187/300\n",
      "140/140 [==============================] - 0s - loss: 1.7549 - val_loss: 1.7270\n",
      "Epoch 188/300\n",
      "140/140 [==============================] - 0s - loss: 1.7622 - val_loss: 1.7196\n",
      "Epoch 189/300\n",
      "140/140 [==============================] - 0s - loss: 1.7467 - val_loss: 1.7129\n",
      "Epoch 190/300\n",
      "140/140 [==============================] - 0s - loss: 1.7579 - val_loss: 1.7291\n",
      "Epoch 191/300\n",
      "140/140 [==============================] - 0s - loss: 1.7057 - val_loss: 1.7475\n",
      "Epoch 192/300\n",
      "140/140 [==============================] - 0s - loss: 1.7056 - val_loss: 1.8030\n",
      "Epoch 193/300\n",
      "140/140 [==============================] - 0s - loss: 1.7249 - val_loss: 1.7240\n",
      "Epoch 194/300\n",
      "140/140 [==============================] - 0s - loss: 1.7738 - val_loss: 1.8362\n",
      "Epoch 195/300\n",
      "140/140 [==============================] - 0s - loss: 1.6963 - val_loss: 1.7352\n",
      "Epoch 196/300\n",
      "140/140 [==============================] - 0s - loss: 1.7172 - val_loss: 1.6827\n",
      "Epoch 197/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.6883\n",
      " Reduced learning rate to 0.000390184\n",
      "140/140 [==============================] - 0s - loss: 1.6848 - val_loss: 1.8015\n",
      "Epoch 198/300\n",
      "140/140 [==============================] - 0s - loss: 1.7561 - val_loss: 1.7363\n",
      "Epoch 199/300\n",
      "140/140 [==============================] - 0s - loss: 1.7121 - val_loss: 1.6634\n",
      "Epoch 200/300\n",
      "140/140 [==============================] - 0s - loss: 1.7368 - val_loss: 1.7350\n",
      "Epoch 201/300\n",
      "140/140 [==============================] - 0s - loss: 1.8595 - val_loss: 1.6556\n",
      "Epoch 202/300\n",
      "140/140 [==============================] - 0s - loss: 1.7591 - val_loss: 1.6910\n",
      "Epoch 203/300\n",
      "140/140 [==============================] - 0s - loss: 1.7611 - val_loss: 1.6524\n",
      "Epoch 204/300\n",
      "140/140 [==============================] - 0s - loss: 1.6916 - val_loss: 1.7077\n",
      "Epoch 205/300\n",
      "140/140 [==============================] - 0s - loss: 1.7026 - val_loss: 1.7017\n",
      "Epoch 206/300\n",
      "140/140 [==============================] - 0s - loss: 1.7708 - val_loss: 1.7483\n",
      "Epoch 207/300\n",
      "140/140 [==============================] - 0s - loss: 1.7319 - val_loss: 1.7196\n",
      "Epoch 208/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/140 [============================>.] - ETA: 0s - loss: 1.7684\n",
      " Reduced learning rate to 0.000260123\n",
      "140/140 [==============================] - 0s - loss: 1.7674 - val_loss: 1.6638\n",
      "Epoch 209/300\n",
      "140/140 [==============================] - 0s - loss: 1.7233 - val_loss: 1.6642\n",
      "Epoch 210/300\n",
      "140/140 [==============================] - 0s - loss: 1.7037 - val_loss: 1.7119\n",
      "Epoch 211/300\n",
      "140/140 [==============================] - 0s - loss: 1.7113 - val_loss: 1.6805\n",
      "Epoch 212/300\n",
      "140/140 [==============================] - 0s - loss: 1.7489 - val_loss: 1.7271\n",
      "Epoch 213/300\n",
      "140/140 [==============================] - 0s - loss: 1.7682 - val_loss: 1.7409\n",
      "Epoch 214/300\n",
      "140/140 [==============================] - 0s - loss: 1.7350 - val_loss: 1.6699\n",
      "Epoch 215/300\n",
      "140/140 [==============================] - 0s - loss: 1.7279 - val_loss: 1.7375\n",
      "Epoch 216/300\n",
      "140/140 [==============================] - 0s - loss: 1.7118 - val_loss: 1.6696\n",
      "Epoch 217/300\n",
      "140/140 [==============================] - 0s - loss: 1.6941 - val_loss: 1.5966\n",
      "Epoch 218/300\n",
      "140/140 [==============================] - 0s - loss: 1.7264 - val_loss: 1.6710\n",
      "Epoch 219/300\n",
      "140/140 [==============================] - 0s - loss: 1.7633 - val_loss: 1.6761\n",
      "Epoch 220/300\n",
      "140/140 [==============================] - 0s - loss: 1.7953 - val_loss: 1.6491\n",
      "Epoch 221/300\n",
      "140/140 [==============================] - 0s - loss: 1.7475 - val_loss: 1.6614\n",
      "Epoch 222/300\n",
      "140/140 [==============================] - 0s - loss: 1.7109 - val_loss: 1.7227\n",
      "Epoch 223/300\n",
      "140/140 [==============================] - 0s - loss: 1.7273 - val_loss: 1.7015\n",
      "Epoch 224/300\n",
      "140/140 [==============================] - 0s - loss: 1.6986 - val_loss: 1.7251\n",
      "Epoch 225/300\n",
      "140/140 [==============================] - 0s - loss: 1.7259 - val_loss: 1.7472\n",
      "Epoch 226/300\n",
      "140/140 [==============================] - 0s - loss: 1.6857 - val_loss: 1.6128\n",
      "Epoch 227/300\n",
      "140/140 [==============================] - 0s - loss: 1.7946 - val_loss: 1.6559\n",
      "Epoch 228/300\n",
      "127/140 [==========================>...] - ETA: 0s - loss: 1.7650\n",
      " Reduced learning rate to 0.000173415\n",
      "140/140 [==============================] - 0s - loss: 1.7657 - val_loss: 1.6975\n",
      "Epoch 229/300\n",
      "140/140 [==============================] - 0s - loss: 1.7723 - val_loss: 1.6514\n",
      "Epoch 230/300\n",
      "140/140 [==============================] - 0s - loss: 1.7362 - val_loss: 1.7227\n",
      "Epoch 231/300\n",
      "140/140 [==============================] - 0s - loss: 1.7516 - val_loss: 1.6971\n",
      "Epoch 232/300\n",
      "140/140 [==============================] - 0s - loss: 1.6909 - val_loss: 1.7278\n",
      "Epoch 233/300\n",
      "140/140 [==============================] - 0s - loss: 1.6860 - val_loss: 1.7471\n",
      "Epoch 234/300\n",
      "140/140 [==============================] - 0s - loss: 1.7006 - val_loss: 1.7301\n",
      "Epoch 235/300\n",
      "140/140 [==============================] - 0s - loss: 1.7533 - val_loss: 1.6930\n",
      "Epoch 236/300\n",
      "140/140 [==============================] - 0s - loss: 1.7464 - val_loss: 1.6566\n",
      "Epoch 237/300\n",
      "140/140 [==============================] - 0s - loss: 1.7240 - val_loss: 1.7524\n",
      "Epoch 238/300\n",
      "140/140 [==============================] - 0s - loss: 1.7638 - val_loss: 1.7573\n",
      "Epoch 239/300\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 1.7442\n",
      " Reduced learning rate to 0.00011561\n",
      "140/140 [==============================] - 0s - loss: 1.7409 - val_loss: 1.6716\n",
      "Epoch 240/300\n",
      "140/140 [==============================] - 0s - loss: 1.7052 - val_loss: 1.6929\n",
      "Epoch 241/300\n",
      "140/140 [==============================] - 0s - loss: 1.7355 - val_loss: 1.6647\n",
      "Epoch 242/300\n",
      "140/140 [==============================] - 0s - loss: 1.7084 - val_loss: 1.7182\n",
      "Epoch 243/300\n",
      "140/140 [==============================] - 0s - loss: 1.7480 - val_loss: 1.6551\n",
      "Epoch 244/300\n",
      "140/140 [==============================] - 0s - loss: 1.7778 - val_loss: 1.7108\n",
      "Epoch 245/300\n",
      "140/140 [==============================] - 0s - loss: 1.7178 - val_loss: 1.6725\n",
      "Epoch 246/300\n",
      "140/140 [==============================] - 0s - loss: 1.7727 - val_loss: 1.7058\n",
      "Epoch 247/300\n",
      "140/140 [==============================] - 0s - loss: 1.6967 - val_loss: 1.6775\n",
      "Epoch 248/300\n",
      "140/140 [==============================] - 0s - loss: 1.7312 - val_loss: 1.7689\n",
      "Epoch 249/300\n",
      "140/140 [==============================] - 0s - loss: 1.7466 - val_loss: 1.6549\n",
      "Epoch 250/300\n",
      "137/140 [============================>.] - ETA: 0s - loss: 1.7526\n",
      " Reduced learning rate to 7.70735e-05\n",
      "140/140 [==============================] - 0s - loss: 1.7507 - val_loss: 1.7815\n",
      "Epoch 1/300\n",
      "140/140 [==============================] - 1s - loss: 44.0291 - val_loss: 5.8072\n",
      "Epoch 2/300\n",
      "140/140 [==============================] - 0s - loss: 4.4929 - val_loss: 3.7374\n",
      "Epoch 3/300\n",
      "140/140 [==============================] - 0s - loss: 3.6858 - val_loss: 3.4100\n",
      "Epoch 4/300\n",
      "140/140 [==============================] - 0s - loss: 3.3843 - val_loss: 2.9977\n",
      "Epoch 5/300\n",
      "140/140 [==============================] - 0s - loss: 3.4137 - val_loss: 2.4690\n",
      "Epoch 6/300\n",
      "140/140 [==============================] - 0s - loss: 3.4928 - val_loss: 4.2924\n",
      "Epoch 7/300\n",
      "140/140 [==============================] - 0s - loss: 3.3282 - val_loss: 3.6755\n",
      "Epoch 8/300\n",
      "140/140 [==============================] - 0s - loss: 3.3483 - val_loss: 3.7250\n",
      "Epoch 9/300\n",
      "140/140 [==============================] - 0s - loss: 3.4225 - val_loss: 4.1245\n",
      "Epoch 10/300\n",
      "140/140 [==============================] - 0s - loss: 3.1978 - val_loss: 3.3430\n",
      "Epoch 11/300\n",
      "140/140 [==============================] - 0s - loss: 3.1914 - val_loss: 2.6056\n",
      "Epoch 12/300\n",
      "140/140 [==============================] - 0s - loss: 3.1915 - val_loss: 2.4499\n",
      "Epoch 13/300\n",
      "140/140 [==============================] - 0s - loss: 3.1872 - val_loss: 2.5630\n",
      "Epoch 14/300\n",
      "140/140 [==============================] - 0s - loss: 3.1963 - val_loss: 2.8398\n",
      "Epoch 15/300\n",
      "140/140 [==============================] - 0s - loss: 3.1130 - val_loss: 3.2722\n",
      "Epoch 16/300\n",
      "140/140 [==============================] - 0s - loss: 3.1335 - val_loss: 3.7091\n",
      "Epoch 17/300\n",
      "140/140 [==============================] - 0s - loss: 2.9090 - val_loss: 3.7923\n",
      "Epoch 18/300\n",
      "140/140 [==============================] - 0s - loss: 3.0344 - val_loss: 2.3327\n",
      "Epoch 19/300\n",
      "140/140 [==============================] - 0s - loss: 2.9426 - val_loss: 3.0061\n",
      "Epoch 20/300\n",
      "140/140 [==============================] - 0s - loss: 3.0058 - val_loss: 4.1272\n",
      "Epoch 21/300\n",
      "140/140 [==============================] - 0s - loss: 2.9609 - val_loss: 2.3259\n",
      "Epoch 22/300\n",
      "140/140 [==============================] - 0s - loss: 3.0267 - val_loss: 6.0612\n",
      "Epoch 23/300\n",
      "140/140 [==============================] - 0s - loss: 3.0579 - val_loss: 3.4794\n",
      "Epoch 24/300\n",
      "140/140 [==============================] - 0s - loss: 2.8195 - val_loss: 2.0320\n",
      "Epoch 25/300\n",
      "140/140 [==============================] - 0s - loss: 3.0108 - val_loss: 2.8821\n",
      "Epoch 26/300\n",
      "140/140 [==============================] - 0s - loss: 2.8807 - val_loss: 1.9843\n",
      "Epoch 27/300\n",
      "140/140 [==============================] - 0s - loss: 2.9555 - val_loss: 2.7809\n",
      "Epoch 28/300\n",
      "140/140 [==============================] - 0s - loss: 2.9112 - val_loss: 3.6279\n",
      "Epoch 29/300\n",
      "140/140 [==============================] - 0s - loss: 2.9585 - val_loss: 1.8406\n",
      "Epoch 30/300\n",
      "140/140 [==============================] - 0s - loss: 2.8913 - val_loss: 2.7800\n",
      "Epoch 31/300\n",
      "140/140 [==============================] - 0s - loss: 2.8453 - val_loss: 2.1968\n",
      "Epoch 32/300\n",
      "140/140 [==============================] - 0s - loss: 2.8875 - val_loss: 3.0900\n",
      "Epoch 33/300\n",
      "140/140 [==============================] - 0s - loss: 2.8869 - val_loss: 2.3154\n",
      "Epoch 34/300\n",
      "140/140 [==============================] - 0s - loss: 2.7709 - val_loss: 2.5177\n",
      "Epoch 35/300\n",
      "140/140 [==============================] - 0s - loss: 2.8304 - val_loss: 2.5544\n",
      "Epoch 36/300\n",
      "140/140 [==============================] - 0s - loss: 2.6392 - val_loss: 1.9662\n",
      "Epoch 37/300\n",
      "140/140 [==============================] - 0s - loss: 2.7698 - val_loss: 2.3067\n",
      "Epoch 38/300\n",
      "140/140 [==============================] - 0s - loss: 2.7734 - val_loss: 2.3252\n",
      "Epoch 39/300\n",
      "140/140 [==============================] - 0s - loss: 2.6268 - val_loss: 1.9372\n",
      "Epoch 40/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 2.7853\n",
      " Reduced learning rate to 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s - loss: 2.7881 - val_loss: 2.5384\n",
      "Epoch 41/300\n",
      "140/140 [==============================] - 0s - loss: 1.9937 - val_loss: 2.6665\n",
      "Epoch 42/300\n",
      "140/140 [==============================] - 0s - loss: 1.9607 - val_loss: 1.8305\n",
      "Epoch 43/300\n",
      "140/140 [==============================] - 0s - loss: 1.9674 - val_loss: 2.4953\n",
      "Epoch 44/300\n",
      "140/140 [==============================] - 0s - loss: 2.0353 - val_loss: 1.8932\n",
      "Epoch 45/300\n",
      "140/140 [==============================] - 0s - loss: 1.9262 - val_loss: 1.9236\n",
      "Epoch 46/300\n",
      "140/140 [==============================] - 0s - loss: 2.0604 - val_loss: 2.0201\n",
      "Epoch 47/300\n",
      "140/140 [==============================] - 0s - loss: 2.1023 - val_loss: 1.8778\n",
      "Epoch 48/300\n",
      "140/140 [==============================] - 0s - loss: 1.9069 - val_loss: 1.8343\n",
      "Epoch 49/300\n",
      "140/140 [==============================] - 0s - loss: 1.9277 - val_loss: 1.8730\n",
      "Epoch 50/300\n",
      "140/140 [==============================] - 0s - loss: 2.0496 - val_loss: 2.0123\n",
      "Epoch 51/300\n",
      "140/140 [==============================] - 0s - loss: 1.9826 - val_loss: 2.1160\n",
      "Epoch 52/300\n",
      "140/140 [==============================] - 0s - loss: 1.9981 - val_loss: 1.7880\n",
      "Epoch 53/300\n",
      "140/140 [==============================] - 0s - loss: 2.0232 - val_loss: 1.7561ss\n",
      "Epoch 54/300\n",
      "140/140 [==============================] - 0s - loss: 1.8907 - val_loss: 1.7396\n",
      "Epoch 55/300\n",
      "140/140 [==============================] - 0s - loss: 2.0385 - val_loss: 2.1213\n",
      "Epoch 56/300\n",
      "140/140 [==============================] - 0s - loss: 2.0381 - val_loss: 1.8075\n",
      "Epoch 57/300\n",
      "140/140 [==============================] - 0s - loss: 1.9756 - val_loss: 1.8824\n",
      "Epoch 58/300\n",
      "140/140 [==============================] - 0s - loss: 2.0333 - val_loss: 1.6821\n",
      "Epoch 59/300\n",
      "140/140 [==============================] - 0s - loss: 2.1087 - val_loss: 2.0089\n",
      "Epoch 60/300\n",
      "140/140 [==============================] - 0s - loss: 1.9796 - val_loss: 2.1794\n",
      "Epoch 61/300\n",
      "140/140 [==============================] - 0s - loss: 2.0591 - val_loss: 1.7908\n",
      "Epoch 62/300\n",
      "140/140 [==============================] - 0s - loss: 2.0344 - val_loss: 1.8204\n",
      "Epoch 63/300\n",
      "140/140 [==============================] - 0s - loss: 1.9825 - val_loss: 2.0531\n",
      "Epoch 64/300\n",
      "140/140 [==============================] - 0s - loss: 2.0647 - val_loss: 2.0556\n",
      "Epoch 65/300\n",
      "140/140 [==============================] - 0s - loss: 2.0388 - val_loss: 1.8184\n",
      "Epoch 66/300\n",
      "140/140 [==============================] - 0s - loss: 2.0716 - val_loss: 1.8431\n",
      "Epoch 67/300\n",
      "140/140 [==============================] - 0s - loss: 2.0416 - val_loss: 1.7254\n",
      "Epoch 68/300\n",
      "140/140 [==============================] - 0s - loss: 1.9630 - val_loss: 2.1240\n",
      "Epoch 69/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 2.0261\n",
      " Reduced learning rate to 0.00666667\n",
      "140/140 [==============================] - 0s - loss: 2.0239 - val_loss: 2.2282\n",
      "Epoch 70/300\n",
      "140/140 [==============================] - 0s - loss: 1.8682 - val_loss: 1.7535\n",
      "Epoch 71/300\n",
      "140/140 [==============================] - 0s - loss: 1.8984 - val_loss: 1.8648\n",
      "Epoch 72/300\n",
      "140/140 [==============================] - 0s - loss: 1.8798 - val_loss: 1.7717\n",
      "Epoch 73/300\n",
      "140/140 [==============================] - 0s - loss: 1.7906 - val_loss: 2.0040\n",
      "Epoch 74/300\n",
      "140/140 [==============================] - 0s - loss: 1.9472 - val_loss: 1.7863\n",
      "Epoch 75/300\n",
      "140/140 [==============================] - 0s - loss: 1.7939 - val_loss: 1.7607\n",
      "Epoch 76/300\n",
      "140/140 [==============================] - 0s - loss: 1.8449 - val_loss: 1.8109\n",
      "Epoch 77/300\n",
      "140/140 [==============================] - 0s - loss: 1.8335 - val_loss: 1.7805\n",
      "Epoch 78/300\n",
      "140/140 [==============================] - 0s - loss: 1.8381 - val_loss: 1.8011\n",
      "Epoch 79/300\n",
      "140/140 [==============================] - 0s - loss: 1.8606 - val_loss: 1.8676\n",
      "Epoch 80/300\n",
      "129/140 [==========================>...] - ETA: 0s - loss: 1.8594\n",
      " Reduced learning rate to 0.00444444\n",
      "140/140 [==============================] - 0s - loss: 1.8630 - val_loss: 1.8480\n",
      "Epoch 81/300\n",
      "140/140 [==============================] - 0s - loss: 1.7750 - val_loss: 1.7930\n",
      "Epoch 82/300\n",
      "140/140 [==============================] - 0s - loss: 1.8085 - val_loss: 1.7697\n",
      "Epoch 83/300\n",
      "140/140 [==============================] - 0s - loss: 1.8612 - val_loss: 1.7218\n",
      "Epoch 84/300\n",
      "140/140 [==============================] - 0s - loss: 1.7524 - val_loss: 1.7699\n",
      "Epoch 85/300\n",
      "140/140 [==============================] - 0s - loss: 1.8373 - val_loss: 1.7388\n",
      "Epoch 86/300\n",
      "140/140 [==============================] - 0s - loss: 1.7874 - val_loss: 1.7544\n",
      "Epoch 87/300\n",
      "140/140 [==============================] - 0s - loss: 1.7307 - val_loss: 1.7411\n",
      "Epoch 88/300\n",
      "140/140 [==============================] - 0s - loss: 1.7610 - val_loss: 1.7417\n",
      "Epoch 89/300\n",
      "140/140 [==============================] - 0s - loss: 1.8029 - val_loss: 1.6983\n",
      "Epoch 90/300\n",
      "140/140 [==============================] - 0s - loss: 1.8024 - val_loss: 1.7605\n",
      "Epoch 91/300\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1.8340\n",
      " Reduced learning rate to 0.00296296\n",
      "140/140 [==============================] - 0s - loss: 1.8325 - val_loss: 1.8168\n",
      "Epoch 92/300\n",
      "140/140 [==============================] - 0s - loss: 1.7548 - val_loss: 1.7520\n",
      "Epoch 93/300\n",
      "140/140 [==============================] - 0s - loss: 1.8219 - val_loss: 1.6247\n",
      "Epoch 94/300\n",
      "140/140 [==============================] - 0s - loss: 1.7600 - val_loss: 1.7425\n",
      "Epoch 95/300\n",
      "140/140 [==============================] - 0s - loss: 1.7451 - val_loss: 1.8512\n",
      "Epoch 96/300\n",
      "140/140 [==============================] - 0s - loss: 1.7756 - val_loss: 1.7369\n",
      "Epoch 97/300\n",
      "140/140 [==============================] - 0s - loss: 1.7554 - val_loss: 1.7270\n",
      "Epoch 98/300\n",
      "140/140 [==============================] - 0s - loss: 1.8220 - val_loss: 1.7001\n",
      "Epoch 99/300\n",
      "140/140 [==============================] - 0s - loss: 1.7974 - val_loss: 1.8115\n",
      "Epoch 100/300\n",
      "140/140 [==============================] - 0s - loss: 1.7538 - val_loss: 1.7015\n",
      "Epoch 101/300\n",
      "140/140 [==============================] - 0s - loss: 1.8159 - val_loss: 1.6700\n",
      "Epoch 102/300\n",
      "140/140 [==============================] - 0s - loss: 1.7801 - val_loss: 1.7923\n",
      "Epoch 103/300\n",
      "140/140 [==============================] - 0s - loss: 1.7225 - val_loss: 1.7659\n",
      "Epoch 104/300\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1.8085\n",
      " Reduced learning rate to 0.00197531\n",
      "140/140 [==============================] - 0s - loss: 1.8052 - val_loss: 1.7080\n",
      "Epoch 105/300\n",
      "140/140 [==============================] - 0s - loss: 1.8217 - val_loss: 1.6563\n",
      "Epoch 106/300\n",
      "140/140 [==============================] - 0s - loss: 1.7290 - val_loss: 1.6391\n",
      "Epoch 107/300\n",
      "140/140 [==============================] - 0s - loss: 1.7484 - val_loss: 1.6690\n",
      "Epoch 108/300\n",
      "140/140 [==============================] - 0s - loss: 1.7449 - val_loss: 1.7156\n",
      "Epoch 109/300\n",
      "140/140 [==============================] - 0s - loss: 1.7034 - val_loss: 1.6826\n",
      "Epoch 110/300\n",
      "140/140 [==============================] - 0s - loss: 1.8250 - val_loss: 1.7639\n",
      "Epoch 111/300\n",
      "140/140 [==============================] - 0s - loss: 1.7302 - val_loss: 1.6747\n",
      "Epoch 112/300\n",
      "140/140 [==============================] - 0s - loss: 1.7592 - val_loss: 1.7809\n",
      "Epoch 113/300\n",
      "140/140 [==============================] - 0s - loss: 1.7689 - val_loss: 1.7145\n",
      "Epoch 114/300\n",
      "140/140 [==============================] - 0s - loss: 1.7419 - val_loss: 1.6962\n",
      "Epoch 115/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 1.7336\n",
      " Reduced learning rate to 0.00131687\n",
      "140/140 [==============================] - 0s - loss: 1.7305 - val_loss: 1.7694\n",
      "Epoch 116/300\n",
      "140/140 [==============================] - 0s - loss: 1.7743 - val_loss: 1.6595\n",
      "Epoch 117/300\n",
      "140/140 [==============================] - 0s - loss: 1.7422 - val_loss: 1.7426\n",
      "Epoch 118/300\n",
      "140/140 [==============================] - 0s - loss: 1.7016 - val_loss: 1.6440\n",
      "Epoch 119/300\n",
      "140/140 [==============================] - 0s - loss: 1.7696 - val_loss: 1.6762\n",
      "Epoch 120/300\n",
      "140/140 [==============================] - 0s - loss: 1.7821 - val_loss: 1.8169\n",
      "Epoch 121/300\n",
      "140/140 [==============================] - 0s - loss: 1.7309 - val_loss: 1.6729\n",
      "Epoch 122/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.7739 - val_loss: 1.6558\n",
      "Epoch 123/300\n",
      "140/140 [==============================] - 0s - loss: 1.7100 - val_loss: 1.7480\n",
      "Epoch 124/300\n",
      "140/140 [==============================] - 0s - loss: 1.7896 - val_loss: 1.6732\n",
      "Epoch 125/300\n",
      "140/140 [==============================] - 0s - loss: 1.7624 - val_loss: 1.7143\n",
      "Epoch 126/300\n",
      "129/140 [==========================>...] - ETA: 0s - loss: 1.7040\n",
      " Reduced learning rate to 0.000877915\n",
      "140/140 [==============================] - 0s - loss: 1.7079 - val_loss: 1.6637\n",
      "Epoch 127/300\n",
      "140/140 [==============================] - 0s - loss: 1.6915 - val_loss: 1.6352\n",
      "Epoch 128/300\n",
      "140/140 [==============================] - 0s - loss: 1.7950 - val_loss: 1.7268\n",
      "Epoch 129/300\n",
      "140/140 [==============================] - 0s - loss: 1.6684 - val_loss: 1.7235\n",
      "Epoch 130/300\n",
      "140/140 [==============================] - 0s - loss: 1.7214 - val_loss: 1.7024\n",
      "Epoch 131/300\n",
      "140/140 [==============================] - 0s - loss: 1.7298 - val_loss: 1.7285\n",
      "Epoch 132/300\n",
      "140/140 [==============================] - 0s - loss: 1.7898 - val_loss: 1.7531\n",
      "Epoch 133/300\n",
      "140/140 [==============================] - 0s - loss: 1.7882 - val_loss: 1.6873\n",
      "Epoch 134/300\n",
      "140/140 [==============================] - 0s - loss: 1.7234 - val_loss: 1.7827\n",
      "Epoch 135/300\n",
      "140/140 [==============================] - 0s - loss: 1.7313 - val_loss: 1.7063\n",
      "Epoch 136/300\n",
      "140/140 [==============================] - 0s - loss: 1.8056 - val_loss: 1.7207\n",
      "Epoch 137/300\n",
      "133/140 [===========================>..] - ETA: 0s - loss: 1.7633\n",
      " Reduced learning rate to 0.000585277\n",
      "140/140 [==============================] - 0s - loss: 1.7647 - val_loss: 1.7047\n",
      "Epoch 138/300\n",
      "140/140 [==============================] - 0s - loss: 1.6894 - val_loss: 1.7275\n",
      "Epoch 139/300\n",
      "140/140 [==============================] - 0s - loss: 1.7079 - val_loss: 1.6438\n",
      "Epoch 140/300\n",
      "140/140 [==============================] - 0s - loss: 1.6690 - val_loss: 1.7264\n",
      "Epoch 141/300\n",
      "140/140 [==============================] - 0s - loss: 1.7154 - val_loss: 1.7402\n",
      "Epoch 142/300\n",
      "140/140 [==============================] - 0s - loss: 1.7422 - val_loss: 1.7076\n",
      "Epoch 143/300\n",
      "140/140 [==============================] - 0s - loss: 1.7113 - val_loss: 1.7396\n",
      "Epoch 144/300\n",
      "140/140 [==============================] - 0s - loss: 1.7336 - val_loss: 1.6894\n",
      "Epoch 145/300\n",
      "140/140 [==============================] - 0s - loss: 1.7882 - val_loss: 1.6973\n",
      "Epoch 146/300\n",
      "140/140 [==============================] - 0s - loss: 1.7616 - val_loss: 1.7526\n",
      "Epoch 147/300\n",
      "140/140 [==============================] - 0s - loss: 1.8311 - val_loss: 1.6889\n",
      "Epoch 148/300\n",
      "129/140 [==========================>...] - ETA: 0s - loss: 1.7582\n",
      " Reduced learning rate to 0.000390184\n",
      "140/140 [==============================] - 0s - loss: 1.7531 - val_loss: 1.8190\n",
      "Epoch 149/300\n",
      "140/140 [==============================] - 0s - loss: 1.7130 - val_loss: 1.7225\n",
      "Epoch 150/300\n",
      "140/140 [==============================] - 0s - loss: 1.7522 - val_loss: 1.7343\n",
      "Epoch 151/300\n",
      "140/140 [==============================] - 0s - loss: 1.8141 - val_loss: 1.6786\n",
      "Epoch 152/300\n",
      "140/140 [==============================] - 0s - loss: 1.7676 - val_loss: 1.7224\n",
      "Epoch 153/300\n",
      "140/140 [==============================] - 0s - loss: 1.7279 - val_loss: 1.7089\n",
      "Epoch 154/300\n",
      "140/140 [==============================] - 0s - loss: 1.7737 - val_loss: 1.6429\n",
      "Epoch 155/300\n",
      "140/140 [==============================] - 0s - loss: 1.7601 - val_loss: 1.6612\n",
      "Epoch 156/300\n",
      "140/140 [==============================] - 0s - loss: 1.7596 - val_loss: 1.7303\n",
      "Epoch 157/300\n",
      "140/140 [==============================] - 0s - loss: 1.6964 - val_loss: 1.6301\n",
      "Epoch 158/300\n",
      "140/140 [==============================] - 0s - loss: 1.8341 - val_loss: 1.7614\n",
      "Epoch 159/300\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1.7276\n",
      " Reduced learning rate to 0.000260123\n",
      "140/140 [==============================] - 0s - loss: 1.7273 - val_loss: 1.6619\n",
      "Epoch 160/300\n",
      "140/140 [==============================] - 0s - loss: 1.7359 - val_loss: 1.6254\n",
      "Epoch 161/300\n",
      "140/140 [==============================] - 0s - loss: 1.7886 - val_loss: 1.6490\n",
      "Epoch 162/300\n",
      "140/140 [==============================] - 0s - loss: 1.7524 - val_loss: 1.7461\n",
      "Epoch 163/300\n",
      "140/140 [==============================] - 0s - loss: 1.7283 - val_loss: 1.6603\n",
      "Epoch 164/300\n",
      "140/140 [==============================] - 0s - loss: 1.8050 - val_loss: 1.6670\n",
      "Epoch 165/300\n",
      "140/140 [==============================] - 0s - loss: 1.7805 - val_loss: 1.7475\n",
      "Epoch 166/300\n",
      "140/140 [==============================] - 0s - loss: 1.7486 - val_loss: 1.7146\n",
      "Epoch 167/300\n",
      "140/140 [==============================] - 0s - loss: 1.7318 - val_loss: 1.7770\n",
      "Epoch 168/300\n",
      "140/140 [==============================] - 0s - loss: 1.7286 - val_loss: 1.6294\n",
      "Epoch 169/300\n",
      "140/140 [==============================] - 0s - loss: 1.7821 - val_loss: 1.7447\n",
      "Epoch 170/300\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 1.7798\n",
      " Reduced learning rate to 0.000173415\n",
      "140/140 [==============================] - 0s - loss: 1.7758 - val_loss: 1.6938\n",
      "Epoch 171/300\n",
      "140/140 [==============================] - 0s - loss: 1.6967 - val_loss: 1.6293\n",
      "Epoch 172/300\n",
      "140/140 [==============================] - 0s - loss: 1.7711 - val_loss: 1.6849\n",
      "Epoch 173/300\n",
      "140/140 [==============================] - 0s - loss: 1.7915 - val_loss: 1.6873\n",
      "Epoch 174/300\n",
      "140/140 [==============================] - 0s - loss: 1.6991 - val_loss: 1.7229\n",
      "Epoch 175/300\n",
      "140/140 [==============================] - 0s - loss: 1.8049 - val_loss: 1.7596\n",
      "Epoch 176/300\n",
      "140/140 [==============================] - 0s - loss: 1.7570 - val_loss: 1.6946\n",
      "Epoch 177/300\n",
      "140/140 [==============================] - 0s - loss: 1.7430 - val_loss: 1.7168\n",
      "Epoch 178/300\n",
      "140/140 [==============================] - 0s - loss: 1.8433 - val_loss: 1.7246\n",
      "Epoch 179/300\n",
      "140/140 [==============================] - 0s - loss: 1.7353 - val_loss: 1.7162\n",
      "Epoch 180/300\n",
      "140/140 [==============================] - 0s - loss: 1.7663 - val_loss: 1.6685\n",
      "Epoch 181/300\n",
      "139/140 [============================>.] - ETA: 0s - loss: 1.7113\n",
      " Reduced learning rate to 0.00011561\n",
      "140/140 [==============================] - 0s - loss: 1.7129 - val_loss: 1.6807\n",
      "Epoch 182/300\n",
      "140/140 [==============================] - 0s - loss: 1.7182 - val_loss: 1.6928\n",
      "Epoch 183/300\n",
      "140/140 [==============================] - 0s - loss: 1.7255 - val_loss: 1.7244\n",
      "Epoch 184/300\n",
      "140/140 [==============================] - 0s - loss: 1.6860 - val_loss: 1.6993\n",
      "Epoch 185/300\n",
      "140/140 [==============================] - 0s - loss: 1.7359 - val_loss: 1.7274\n",
      "Epoch 186/300\n",
      "140/140 [==============================] - 0s - loss: 1.7223 - val_loss: 1.7423\n",
      "Epoch 187/300\n",
      "140/140 [==============================] - 0s - loss: 1.7014 - val_loss: 1.8010\n",
      "Epoch 188/300\n",
      "140/140 [==============================] - 0s - loss: 1.7213 - val_loss: 1.7099\n",
      "Epoch 189/300\n",
      "140/140 [==============================] - 0s - loss: 1.7656 - val_loss: 1.6838\n",
      "Epoch 190/300\n",
      "140/140 [==============================] - 0s - loss: 1.7695 - val_loss: 1.6606\n",
      "Epoch 191/300\n",
      "140/140 [==============================] - 0s - loss: 1.7043 - val_loss: 1.7404\n",
      "Epoch 192/300\n",
      "130/140 [==========================>...] - ETA: 0s - loss: 1.7488\n",
      " Reduced learning rate to 7.70735e-05\n",
      "140/140 [==============================] - 0s - loss: 1.7341 - val_loss: 1.6925\n",
      "Epoch 1/300\n",
      "140/140 [==============================] - 2s - loss: 37.2355 - val_loss: 5.7211\n",
      "Epoch 2/300\n",
      "140/140 [==============================] - 0s - loss: 4.4032 - val_loss: 3.6445\n",
      "Epoch 3/300\n",
      "140/140 [==============================] - 0s - loss: 3.7375 - val_loss: 3.3684\n",
      "Epoch 4/300\n",
      "140/140 [==============================] - 0s - loss: 3.5269 - val_loss: 3.3037\n",
      "Epoch 5/300\n",
      "140/140 [==============================] - 0s - loss: 3.6120 - val_loss: 4.6574\n",
      "Epoch 6/300\n",
      "140/140 [==============================] - 0s - loss: 3.4693 - val_loss: 2.9758\n",
      "Epoch 7/300\n",
      "140/140 [==============================] - 0s - loss: 3.4969 - val_loss: 3.3840\n",
      "Epoch 8/300\n",
      "140/140 [==============================] - 0s - loss: 3.2680 - val_loss: 2.5410\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 3.4643 - val_loss: 2.8440\n",
      "Epoch 10/300\n",
      "140/140 [==============================] - 0s - loss: 3.3752 - val_loss: 3.2628\n",
      "Epoch 11/300\n",
      "140/140 [==============================] - 0s - loss: 3.1865 - val_loss: 2.2363\n",
      "Epoch 12/300\n",
      "140/140 [==============================] - 0s - loss: 3.2302 - val_loss: 3.7773\n",
      "Epoch 13/300\n",
      "140/140 [==============================] - 0s - loss: 3.1530 - val_loss: 2.2639\n",
      "Epoch 14/300\n",
      "140/140 [==============================] - 0s - loss: 3.2553 - val_loss: 3.4065\n",
      "Epoch 15/300\n",
      "140/140 [==============================] - 0s - loss: 3.2887 - val_loss: 2.6226\n",
      "Epoch 16/300\n",
      "140/140 [==============================] - 0s - loss: 3.0045 - val_loss: 3.2214\n",
      "Epoch 17/300\n",
      "140/140 [==============================] - 0s - loss: 3.2155 - val_loss: 3.3418\n",
      "Epoch 18/300\n",
      "140/140 [==============================] - 0s - loss: 3.1197 - val_loss: 2.3515\n",
      "Epoch 19/300\n",
      "140/140 [==============================] - 0s - loss: 2.9933 - val_loss: 2.2175\n",
      "Epoch 20/300\n",
      "140/140 [==============================] - 0s - loss: 3.0328 - val_loss: 3.6884\n",
      "Epoch 21/300\n",
      "140/140 [==============================] - 0s - loss: 2.9485 - val_loss: 2.8355\n",
      "Epoch 22/300\n",
      "140/140 [==============================] - 0s - loss: 2.9539 - val_loss: 2.5978\n",
      "Epoch 23/300\n",
      "140/140 [==============================] - 0s - loss: 2.9454 - val_loss: 2.6230\n",
      "Epoch 24/300\n",
      "140/140 [==============================] - 0s - loss: 3.0655 - val_loss: 3.5366\n",
      "Epoch 25/300\n",
      "140/140 [==============================] - 0s - loss: 2.9875 - val_loss: 3.2567\n",
      "Epoch 26/300\n",
      "140/140 [==============================] - 0s - loss: 2.8372 - val_loss: 2.1317\n",
      "Epoch 27/300\n",
      "140/140 [==============================] - 0s - loss: 3.0013 - val_loss: 3.1932\n",
      "Epoch 28/300\n",
      "140/140 [==============================] - 0s - loss: 2.8722 - val_loss: 4.6418\n",
      "Epoch 29/300\n",
      "140/140 [==============================] - 0s - loss: 2.8140 - val_loss: 3.1607\n",
      "Epoch 30/300\n",
      "140/140 [==============================] - 0s - loss: 2.8218 - val_loss: 3.3341\n",
      "Epoch 31/300\n",
      "140/140 [==============================] - 0s - loss: 2.8159 - val_loss: 3.2427\n",
      "Epoch 32/300\n",
      "140/140 [==============================] - 0s - loss: 2.7658 - val_loss: 3.0424\n",
      "Epoch 33/300\n",
      "140/140 [==============================] - 0s - loss: 2.7477 - val_loss: 2.5808\n",
      "Epoch 34/300\n",
      "140/140 [==============================] - 0s - loss: 2.7885 - val_loss: 2.3477\n",
      "Epoch 35/300\n",
      "140/140 [==============================] - 0s - loss: 2.8267 - val_loss: 2.3764\n",
      "Epoch 36/300\n",
      "140/140 [==============================] - 0s - loss: 2.7646 - val_loss: 1.9297\n",
      "Epoch 37/300\n",
      "140/140 [==============================] - 0s - loss: 2.7035 - val_loss: 3.8359\n",
      "Epoch 38/300\n",
      "140/140 [==============================] - 0s - loss: 2.7748 - val_loss: 2.4289\n",
      "Epoch 39/300\n",
      "140/140 [==============================] - 0s - loss: 2.6937 - val_loss: 1.9565s\n",
      "Epoch 40/300\n",
      "140/140 [==============================] - 0s - loss: 2.8082 - val_loss: 2.7021\n",
      "Epoch 41/300\n",
      "140/140 [==============================] - 0s - loss: 2.6688 - val_loss: 2.4873\n",
      "Epoch 42/300\n",
      "140/140 [==============================] - 0s - loss: 2.6821 - val_loss: 2.9029\n",
      "Epoch 43/300\n",
      "140/140 [==============================] - 0s - loss: 2.6707 - val_loss: 2.5168\n",
      "Epoch 44/300\n",
      "140/140 [==============================] - 0s - loss: 2.6682 - val_loss: 4.2796\n",
      "Epoch 45/300\n",
      "140/140 [==============================] - 0s - loss: 2.8136 - val_loss: 2.2563\n",
      "Epoch 46/300\n",
      "140/140 [==============================] - 0s - loss: 2.6209 - val_loss: 2.0651\n",
      "Epoch 47/300\n",
      "137/140 [============================>.] - ETA: 0s - loss: 2.5628\n",
      " Reduced learning rate to 0.01\n",
      "140/140 [==============================] - 1s - loss: 2.5761 - val_loss: 2.4224\n",
      "Epoch 48/300\n",
      "140/140 [==============================] - 0s - loss: 1.9411 - val_loss: 1.8386\n",
      "Epoch 49/300\n",
      "140/140 [==============================] - 0s - loss: 1.9604 - val_loss: 1.9856\n",
      "Epoch 50/300\n",
      "140/140 [==============================] - 0s - loss: 1.9593 - val_loss: 1.8974\n",
      "Epoch 51/300\n",
      "140/140 [==============================] - 0s - loss: 1.9409 - val_loss: 2.0716\n",
      "Epoch 52/300\n",
      "140/140 [==============================] - 0s - loss: 1.9729 - val_loss: 1.9563\n",
      "Epoch 53/300\n",
      "140/140 [==============================] - 0s - loss: 1.9747 - val_loss: 1.9444\n",
      "Epoch 54/300\n",
      "140/140 [==============================] - 0s - loss: 1.9666 - val_loss: 1.9000\n",
      "Epoch 55/300\n",
      "140/140 [==============================] - 0s - loss: 1.9895 - val_loss: 1.9037\n",
      "Epoch 56/300\n",
      "140/140 [==============================] - 0s - loss: 1.9822 - val_loss: 1.9175\n",
      "Epoch 57/300\n",
      "140/140 [==============================] - 0s - loss: 1.9775 - val_loss: 2.0610\n",
      "Epoch 58/300\n",
      "140/140 [==============================] - 0s - loss: 1.9232 - val_loss: 1.8942\n",
      "Epoch 59/300\n",
      "140/140 [==============================] - 0s - loss: 1.9661 - val_loss: 1.8300\n",
      "Epoch 60/300\n",
      "140/140 [==============================] - 0s - loss: 2.0365 - val_loss: 1.7336\n",
      "Epoch 61/300\n",
      "140/140 [==============================] - 0s - loss: 2.0414 - val_loss: 1.8213\n",
      "Epoch 62/300\n",
      "140/140 [==============================] - 0s - loss: 1.9342 - val_loss: 1.7441\n",
      "Epoch 63/300\n",
      "140/140 [==============================] - 0s - loss: 1.9736 - val_loss: 2.0626\n",
      "Epoch 64/300\n",
      "140/140 [==============================] - 0s - loss: 2.1019 - val_loss: 1.8116\n",
      "Epoch 65/300\n",
      "140/140 [==============================] - 0s - loss: 1.9843 - val_loss: 1.8253\n",
      "Epoch 66/300\n",
      "140/140 [==============================] - 0s - loss: 1.9161 - val_loss: 1.8337\n",
      "Epoch 67/300\n",
      "140/140 [==============================] - 0s - loss: 1.9605 - val_loss: 1.7791\n",
      "Epoch 68/300\n",
      "140/140 [==============================] - 0s - loss: 1.9921 - val_loss: 1.7315\n",
      "Epoch 69/300\n",
      "140/140 [==============================] - 0s - loss: 1.8671 - val_loss: 1.9226\n",
      "Epoch 70/300\n",
      "140/140 [==============================] - 0s - loss: 2.0442 - val_loss: 1.8579\n",
      "Epoch 71/300\n",
      "140/140 [==============================] - 0s - loss: 1.8633 - val_loss: 2.0857\n",
      "Epoch 72/300\n",
      "140/140 [==============================] - 0s - loss: 1.9275 - val_loss: 2.0009\n",
      "Epoch 73/300\n",
      "140/140 [==============================] - 0s - loss: 2.0779 - val_loss: 1.8911\n",
      "Epoch 74/300\n",
      "140/140 [==============================] - 0s - loss: 1.9189 - val_loss: 1.8092\n",
      "Epoch 75/300\n",
      "140/140 [==============================] - 0s - loss: 1.9382 - val_loss: 1.8077\n",
      "Epoch 76/300\n",
      "140/140 [==============================] - 0s - loss: 1.9496 - val_loss: 1.7741\n",
      "Epoch 77/300\n",
      "140/140 [==============================] - 0s - loss: 1.9706 - val_loss: 1.7302\n",
      "Epoch 78/300\n",
      "140/140 [==============================] - 0s - loss: 1.8991 - val_loss: 1.7899\n",
      "Epoch 79/300\n",
      "140/140 [==============================] - 0s - loss: 1.9775 - val_loss: 1.8461\n",
      "Epoch 80/300\n",
      "140/140 [==============================] - 0s - loss: 2.0162 - val_loss: 1.7702\n",
      "Epoch 81/300\n",
      "140/140 [==============================] - 0s - loss: 2.0209 - val_loss: 1.8526\n",
      "Epoch 82/300\n",
      "140/140 [==============================] - 0s - loss: 1.9408 - val_loss: 2.4958\n",
      "Epoch 83/300\n",
      "140/140 [==============================] - 0s - loss: 2.0061 - val_loss: 1.8915\n",
      "Epoch 84/300\n",
      "140/140 [==============================] - 0s - loss: 1.9383 - val_loss: 2.1056\n",
      "Epoch 85/300\n",
      "140/140 [==============================] - 0s - loss: 1.9350 - val_loss: 2.0074\n",
      "Epoch 86/300\n",
      "140/140 [==============================] - 0s - loss: 2.0290 - val_loss: 2.1282\n",
      "Epoch 87/300\n",
      "140/140 [==============================] - 0s - loss: 2.0268 - val_loss: 1.7554\n",
      "Epoch 88/300\n",
      "140/140 [==============================] - 0s - loss: 2.0064 - val_loss: 1.6972\n",
      "Epoch 89/300\n",
      "140/140 [==============================] - 0s - loss: 1.9343 - val_loss: 2.5967\n",
      "Epoch 90/300\n",
      "140/140 [==============================] - 0s - loss: 1.9381 - val_loss: 2.2293\n",
      "Epoch 91/300\n",
      "140/140 [==============================] - 0s - loss: 1.9348 - val_loss: 1.8659\n",
      "Epoch 92/300\n",
      "140/140 [==============================] - 0s - loss: 1.9336 - val_loss: 1.8314\n",
      "Epoch 93/300\n",
      "140/140 [==============================] - 0s - loss: 1.9761 - val_loss: 1.7445\n",
      "Epoch 94/300\n",
      "140/140 [==============================] - 0s - loss: 1.9594 - val_loss: 1.8652\n",
      "Epoch 95/300\n",
      "140/140 [==============================] - 0s - loss: 1.9652 - val_loss: 1.8050\n",
      "Epoch 96/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.8729 - val_loss: 1.9074\n",
      "Epoch 97/300\n",
      "140/140 [==============================] - 0s - loss: 1.9250 - val_loss: 2.0423\n",
      "Epoch 98/300\n",
      "140/140 [==============================] - 0s - loss: 2.0292 - val_loss: 1.9821\n",
      "Epoch 99/300\n",
      "130/140 [==========================>...] - ETA: 0s - loss: 1.9953\n",
      " Reduced learning rate to 0.00666667\n",
      "140/140 [==============================] - 0s - loss: 2.0220 - val_loss: 2.0023\n",
      "Epoch 100/300\n",
      "140/140 [==============================] - 0s - loss: 1.7947 - val_loss: 1.7839\n",
      "Epoch 101/300\n",
      "140/140 [==============================] - 0s - loss: 1.8116 - val_loss: 1.6693\n",
      "Epoch 102/300\n",
      "140/140 [==============================] - 0s - loss: 1.7668 - val_loss: 1.9587\n",
      "Epoch 103/300\n",
      "140/140 [==============================] - 0s - loss: 1.8149 - val_loss: 1.7112\n",
      "Epoch 104/300\n",
      "140/140 [==============================] - 0s - loss: 1.8763 - val_loss: 1.9231\n",
      "Epoch 105/300\n",
      "140/140 [==============================] - 0s - loss: 1.7695 - val_loss: 1.7523\n",
      "Epoch 106/300\n",
      "140/140 [==============================] - 0s - loss: 1.8005 - val_loss: 1.7179\n",
      "Epoch 107/300\n",
      "140/140 [==============================] - 0s - loss: 1.7547 - val_loss: 1.9378\n",
      "Epoch 108/300\n",
      "140/140 [==============================] - 0s - loss: 1.9025 - val_loss: 1.7380\n",
      "Epoch 109/300\n",
      "140/140 [==============================] - 0s - loss: 1.7939 - val_loss: 1.6772\n",
      "Epoch 110/300\n",
      "140/140 [==============================] - 0s - loss: 1.8538 - val_loss: 1.7838\n",
      "Epoch 111/300\n",
      "140/140 [==============================] - 0s - loss: 1.7743 - val_loss: 1.8141\n",
      "Epoch 112/300\n",
      "136/140 [============================>.] - ETA: 0s - loss: 1.7911\n",
      " Reduced learning rate to 0.00444444\n",
      "140/140 [==============================] - 0s - loss: 1.7928 - val_loss: 1.8051\n",
      "Epoch 113/300\n",
      "140/140 [==============================] - 0s - loss: 1.7865 - val_loss: 1.6936\n",
      "Epoch 114/300\n",
      "140/140 [==============================] - 0s - loss: 1.7593 - val_loss: 1.7393\n",
      "Epoch 115/300\n",
      "140/140 [==============================] - 0s - loss: 1.7511 - val_loss: 1.7916\n",
      "Epoch 116/300\n",
      "140/140 [==============================] - 0s - loss: 1.7255 - val_loss: 1.7784\n",
      "Epoch 117/300\n",
      "140/140 [==============================] - 0s - loss: 1.7848 - val_loss: 1.7457\n",
      "Epoch 118/300\n",
      "140/140 [==============================] - 0s - loss: 1.8276 - val_loss: 1.7881\n",
      "Epoch 119/300\n",
      "140/140 [==============================] - 0s - loss: 1.8113 - val_loss: 1.6779\n",
      "Epoch 120/300\n",
      "140/140 [==============================] - 0s - loss: 1.7536 - val_loss: 1.7331\n",
      "Epoch 121/300\n",
      "140/140 [==============================] - 0s - loss: 1.8079 - val_loss: 1.7647\n",
      "Epoch 122/300\n",
      "140/140 [==============================] - 0s - loss: 1.8018 - val_loss: 1.6994\n",
      "Epoch 123/300\n",
      "137/140 [============================>.] - ETA: 0s - loss: 1.7383\n",
      " Reduced learning rate to 0.00296296\n",
      "140/140 [==============================] - 0s - loss: 1.7406 - val_loss: 1.7617\n",
      "Epoch 124/300\n",
      "140/140 [==============================] - 0s - loss: 1.7769 - val_loss: 1.7160\n",
      "Epoch 125/300\n",
      "140/140 [==============================] - 0s - loss: 1.8122 - val_loss: 1.7393\n",
      "Epoch 126/300\n",
      "140/140 [==============================] - 0s - loss: 1.7451 - val_loss: 1.7246\n",
      "Epoch 127/300\n",
      "140/140 [==============================] - 0s - loss: 1.7631 - val_loss: 1.7039\n",
      "Epoch 128/300\n",
      "140/140 [==============================] - 0s - loss: 1.7311 - val_loss: 1.8345\n",
      "Epoch 129/300\n",
      "140/140 [==============================] - 0s - loss: 1.7651 - val_loss: 1.6840\n",
      "Epoch 130/300\n",
      "140/140 [==============================] - 0s - loss: 1.7948 - val_loss: 1.6935\n",
      "Epoch 131/300\n",
      "140/140 [==============================] - 0s - loss: 1.7726 - val_loss: 1.6835\n",
      "Epoch 132/300\n",
      "140/140 [==============================] - 0s - loss: 1.8407 - val_loss: 1.6954\n",
      "Epoch 133/300\n",
      "140/140 [==============================] - 0s - loss: 1.7609 - val_loss: 1.6938\n",
      "Epoch 134/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.7330\n",
      " Reduced learning rate to 0.00197531\n",
      "140/140 [==============================] - 0s - loss: 1.7310 - val_loss: 1.7172\n",
      "Epoch 135/300\n",
      "140/140 [==============================] - 0s - loss: 1.7512 - val_loss: 1.7250\n",
      "Epoch 136/300\n",
      "140/140 [==============================] - 0s - loss: 1.7003 - val_loss: 1.6746\n",
      "Epoch 137/300\n",
      "140/140 [==============================] - 0s - loss: 1.7347 - val_loss: 1.7332\n",
      "Epoch 138/300\n",
      "140/140 [==============================] - 0s - loss: 1.7586 - val_loss: 1.7016\n",
      "Epoch 139/300\n",
      "140/140 [==============================] - 0s - loss: 1.7362 - val_loss: 1.8185\n",
      "Epoch 140/300\n",
      "140/140 [==============================] - 0s - loss: 1.7589 - val_loss: 1.7204\n",
      "Epoch 141/300\n",
      "140/140 [==============================] - 0s - loss: 1.8430 - val_loss: 1.7330\n",
      "Epoch 142/300\n",
      "140/140 [==============================] - 0s - loss: 1.7611 - val_loss: 1.7436\n",
      "Epoch 143/300\n",
      "140/140 [==============================] - 0s - loss: 1.7599 - val_loss: 1.7219\n",
      "Epoch 144/300\n",
      "140/140 [==============================] - 0s - loss: 1.7131 - val_loss: 1.7165\n",
      "Epoch 145/300\n",
      "131/140 [===========================>..] - ETA: 0s - loss: 1.7394\n",
      " Reduced learning rate to 0.00131687\n",
      "140/140 [==============================] - 0s - loss: 1.7647 - val_loss: 1.7770\n",
      "Epoch 146/300\n",
      "140/140 [==============================] - 0s - loss: 1.7741 - val_loss: 1.7316\n",
      "Epoch 147/300\n",
      "140/140 [==============================] - 0s - loss: 1.7657 - val_loss: 1.7927\n",
      "Epoch 148/300\n",
      "140/140 [==============================] - 0s - loss: 1.7440 - val_loss: 1.7091\n",
      "Epoch 149/300\n",
      "140/140 [==============================] - 0s - loss: 1.7568 - val_loss: 1.7975\n",
      "Epoch 150/300\n",
      "140/140 [==============================] - 0s - loss: 1.7039 - val_loss: 1.7822\n",
      "Epoch 151/300\n",
      "140/140 [==============================] - 0s - loss: 1.7514 - val_loss: 1.7726\n",
      "Epoch 152/300\n",
      "140/140 [==============================] - 0s - loss: 1.7675 - val_loss: 1.7093\n",
      "Epoch 153/300\n",
      "140/140 [==============================] - 0s - loss: 1.8127 - val_loss: 1.6965\n",
      "Epoch 154/300\n",
      "140/140 [==============================] - 0s - loss: 1.7393 - val_loss: 1.7202\n",
      "Epoch 155/300\n",
      "140/140 [==============================] - 0s - loss: 1.8018 - val_loss: 1.7430\n",
      "Epoch 156/300\n",
      "138/140 [============================>.] - ETA: 0s - loss: 1.6967\n",
      " Reduced learning rate to 0.000877915\n",
      "140/140 [==============================] - 0s - loss: 1.6931 - val_loss: 1.7971\n",
      "Epoch 157/300\n",
      "140/140 [==============================] - 0s - loss: 1.7662 - val_loss: 1.6530\n",
      "Epoch 158/300\n",
      "140/140 [==============================] - 0s - loss: 1.7418 - val_loss: 1.6393\n",
      "Epoch 159/300\n",
      "140/140 [==============================] - 0s - loss: 1.7241 - val_loss: 1.6735\n",
      "Epoch 160/300\n",
      "140/140 [==============================] - 0s - loss: 1.7434 - val_loss: 1.7231\n",
      "Epoch 161/300\n",
      "140/140 [==============================] - 0s - loss: 1.7627 - val_loss: 1.6898\n",
      "Epoch 162/300\n",
      "140/140 [==============================] - 0s - loss: 1.7353 - val_loss: 1.6118\n",
      "Epoch 163/300\n",
      "140/140 [==============================] - 0s - loss: 1.7515 - val_loss: 1.6806\n",
      "Epoch 164/300\n",
      "140/140 [==============================] - 0s - loss: 1.7109 - val_loss: 1.7051\n",
      "Epoch 165/300\n",
      "140/140 [==============================] - 0s - loss: 1.7144 - val_loss: 1.7734\n",
      "Epoch 166/300\n",
      "140/140 [==============================] - 0s - loss: 1.7011 - val_loss: 1.7466\n",
      "Epoch 167/300\n",
      "140/140 [==============================] - 0s - loss: 1.7257 - val_loss: 1.6500\n",
      "Epoch 168/300\n",
      "140/140 [==============================] - 0s - loss: 1.7539 - val_loss: 1.6691\n",
      "Epoch 169/300\n",
      "140/140 [==============================] - 0s - loss: 1.7251 - val_loss: 1.7117\n",
      "Epoch 170/300\n",
      "140/140 [==============================] - 0s - loss: 1.7297 - val_loss: 1.6881\n",
      "Epoch 171/300\n",
      "140/140 [==============================] - 0s - loss: 1.7351 - val_loss: 1.7610\n",
      "Epoch 172/300\n",
      "140/140 [==============================] - 0s - loss: 1.6978 - val_loss: 1.7398\n",
      "Epoch 173/300\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 1.7352\n",
      " Reduced learning rate to 0.000585277\n",
      "140/140 [==============================] - 0s - loss: 1.7612 - val_loss: 1.7475\n",
      "Epoch 174/300\n",
      "140/140 [==============================] - 0s - loss: 1.7512 - val_loss: 1.7040\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 0s - loss: 1.8563 - val_loss: 1.7038\n",
      "Epoch 176/300\n",
      "140/140 [==============================] - 0s - loss: 1.7377 - val_loss: 1.6634\n",
      "Epoch 177/300\n",
      "140/140 [==============================] - 0s - loss: 1.7005 - val_loss: 1.7069\n",
      "Epoch 178/300\n",
      "140/140 [==============================] - 0s - loss: 1.7370 - val_loss: 1.6849\n",
      "Epoch 179/300\n",
      "140/140 [==============================] - 0s - loss: 1.7218 - val_loss: 1.7578\n",
      "Epoch 180/300\n",
      "140/140 [==============================] - 0s - loss: 1.7404 - val_loss: 1.7145\n",
      "Epoch 181/300\n",
      "140/140 [==============================] - 0s - loss: 1.7147 - val_loss: 1.6786\n",
      "Epoch 182/300\n",
      "140/140 [==============================] - 0s - loss: 1.7971 - val_loss: 1.6626\n",
      "Epoch 183/300\n",
      "140/140 [==============================] - 0s - loss: 1.7336 - val_loss: 1.6878\n",
      "Epoch 184/300\n",
      "132/140 [===========================>..] - ETA: 0s - loss: 1.6799\n",
      " Reduced learning rate to 0.000390184\n",
      "140/140 [==============================] - 0s - loss: 1.6829 - val_loss: 1.7102\n",
      "Epoch 185/300\n",
      "140/140 [==============================] - 0s - loss: 1.7347 - val_loss: 1.7889\n",
      "Epoch 186/300\n",
      "140/140 [==============================] - 0s - loss: 1.7183 - val_loss: 1.6345\n",
      "Epoch 187/300\n",
      "140/140 [==============================] - 0s - loss: 1.7279 - val_loss: 1.7221\n",
      "Epoch 188/300\n",
      "140/140 [==============================] - 0s - loss: 1.6900 - val_loss: 1.6934\n",
      "Epoch 189/300\n",
      "140/140 [==============================] - 0s - loss: 1.7834 - val_loss: 1.7284\n",
      "Epoch 190/300\n",
      "140/140 [==============================] - 0s - loss: 1.7218 - val_loss: 1.6930\n",
      "Epoch 191/300\n",
      "140/140 [==============================] - 0s - loss: 1.8076 - val_loss: 1.6482\n",
      "Epoch 192/300\n",
      "140/140 [==============================] - 0s - loss: 1.6948 - val_loss: 1.6612\n",
      "Epoch 193/300\n",
      "140/140 [==============================] - 0s - loss: 1.7749 - val_loss: 1.7694\n",
      "Epoch 194/300\n",
      "140/140 [==============================] - 0s - loss: 1.7660 - val_loss: 1.6353\n",
      "Epoch 195/300\n",
      "123/140 [=========================>....] - ETA: 0s - loss: 1.6983\n",
      " Reduced learning rate to 0.000260123\n",
      "140/140 [==============================] - 0s - loss: 1.7032 - val_loss: 1.7104\n",
      "Epoch 196/300\n",
      "140/140 [==============================] - 0s - loss: 1.6853 - val_loss: 1.6684\n",
      "Epoch 197/300\n",
      "140/140 [==============================] - 0s - loss: 1.7493 - val_loss: 1.6400\n",
      "Epoch 198/300\n",
      "140/140 [==============================] - 0s - loss: 1.7177 - val_loss: 1.7107\n",
      "Epoch 199/300\n",
      "140/140 [==============================] - 0s - loss: 1.6813 - val_loss: 1.7302\n",
      "Epoch 200/300\n",
      "140/140 [==============================] - 0s - loss: 1.7114 - val_loss: 1.6618\n",
      "Epoch 201/300\n",
      "140/140 [==============================] - 0s - loss: 1.7289 - val_loss: 1.6593\n",
      "Epoch 202/300\n",
      "140/140 [==============================] - 0s - loss: 1.7513 - val_loss: 1.6865\n",
      "Epoch 203/300\n",
      "140/140 [==============================] - 0s - loss: 1.6591 - val_loss: 1.6663\n",
      "Epoch 204/300\n",
      "140/140 [==============================] - 0s - loss: 1.7460 - val_loss: 1.6918\n",
      "Epoch 205/300\n",
      "140/140 [==============================] - 0s - loss: 1.7600 - val_loss: 1.7593\n",
      "Epoch 206/300\n",
      "135/140 [===========================>..] - ETA: 0s - loss: 1.6968\n",
      " Reduced learning rate to 0.000173415\n",
      "140/140 [==============================] - 0s - loss: 1.6962 - val_loss: 1.6954\n",
      "Epoch 207/300\n",
      "140/140 [==============================] - 0s - loss: 1.7065 - val_loss: 1.6996\n",
      "Epoch 208/300\n",
      "140/140 [==============================] - 0s - loss: 1.6874 - val_loss: 1.6933\n",
      "Epoch 209/300\n",
      "140/140 [==============================] - 0s - loss: 1.7027 - val_loss: 1.6538\n",
      "Epoch 210/300\n",
      "140/140 [==============================] - 0s - loss: 1.7297 - val_loss: 1.6717\n",
      "Epoch 211/300\n",
      "140/140 [==============================] - 0s - loss: 1.7543 - val_loss: 1.6660\n",
      "Epoch 212/300\n",
      "140/140 [==============================] - 0s - loss: 1.8458 - val_loss: 1.7508\n",
      "Epoch 213/300\n",
      "140/140 [==============================] - 0s - loss: 1.7754 - val_loss: 1.6634\n",
      "Epoch 214/300\n",
      "140/140 [==============================] - 0s - loss: 1.8094 - val_loss: 1.6952\n",
      "Epoch 215/300\n",
      "140/140 [==============================] - 0s - loss: 1.7227 - val_loss: 1.6512\n",
      "Epoch 216/300\n",
      "140/140 [==============================] - 0s - loss: 1.7212 - val_loss: 1.6832\n",
      "Epoch 217/300\n",
      "130/140 [==========================>...] - ETA: 0s - loss: 1.7194\n",
      " Reduced learning rate to 0.00011561\n",
      "140/140 [==============================] - 0s - loss: 1.7119 - val_loss: 1.7958\n",
      "Epoch 218/300\n",
      "140/140 [==============================] - 0s - loss: 1.7466 - val_loss: 1.7242\n",
      "Epoch 219/300\n",
      "140/140 [==============================] - 0s - loss: 1.7140 - val_loss: 1.7556\n",
      "Epoch 220/300\n",
      "140/140 [==============================] - 0s - loss: 1.7180 - val_loss: 1.7809\n",
      "Epoch 221/300\n",
      "140/140 [==============================] - 0s - loss: 1.7394 - val_loss: 1.6924\n",
      "Epoch 222/300\n",
      "140/140 [==============================] - 0s - loss: 1.7495 - val_loss: 1.6765\n",
      "Epoch 223/300\n",
      "140/140 [==============================] - 0s - loss: 1.7114 - val_loss: 1.7425\n",
      "Epoch 224/300\n",
      "140/140 [==============================] - 0s - loss: 1.7450 - val_loss: 1.6754\n",
      "Epoch 225/300\n",
      "140/140 [==============================] - 0s - loss: 1.7207 - val_loss: 1.6781\n",
      "Epoch 226/300\n",
      "140/140 [==============================] - 0s - loss: 1.7027 - val_loss: 1.7125\n",
      "Epoch 227/300\n",
      "140/140 [==============================] - 0s - loss: 1.7268 - val_loss: 1.7182\n",
      "Epoch 228/300\n",
      "137/140 [============================>.] - ETA: 0s - loss: 1.8081\n",
      " Reduced learning rate to 7.70735e-05\n",
      "140/140 [==============================] - 0s - loss: 1.8112 - val_loss: 1.7572\n",
      "Epoch 1/300\n",
      "703/703 [==============================] - 4s - loss: 9.9001 - val_loss: 3.9713\n",
      "Epoch 2/300\n",
      "703/703 [==============================] - 3s - loss: 3.2016 - val_loss: 2.7642\n",
      "Epoch 3/300\n",
      "703/703 [==============================] - 2s - loss: 3.0714 - val_loss: 2.6585\n",
      "Epoch 4/300\n",
      "703/703 [==============================] - 2s - loss: 2.9313 - val_loss: 3.7438\n",
      "Epoch 5/300\n",
      "703/703 [==============================] - 2s - loss: 2.8614 - val_loss: 2.3731\n",
      "Epoch 6/300\n",
      "703/703 [==============================] - 2s - loss: 2.7339 - val_loss: 2.1501\n",
      "Epoch 7/300\n",
      "703/703 [==============================] - 3s - loss: 2.7322 - val_loss: 2.7972\n",
      "Epoch 8/300\n",
      "703/703 [==============================] - 3s - loss: 2.5996 - val_loss: 3.1921\n",
      "Epoch 9/300\n",
      "703/703 [==============================] - 2s - loss: 2.6169 - val_loss: 3.3320\n",
      "Epoch 10/300\n",
      "703/703 [==============================] - 3s - loss: 2.5078 - val_loss: 1.9302\n",
      "Epoch 11/300\n",
      "703/703 [==============================] - 2s - loss: 2.4802 - val_loss: 2.2668\n",
      "Epoch 12/300\n",
      "703/703 [==============================] - 3s - loss: 2.4990 - val_loss: 2.0823\n",
      "Epoch 13/300\n",
      "703/703 [==============================] - 3s - loss: 2.4470 - val_loss: 2.3091\n",
      "Epoch 14/300\n",
      "703/703 [==============================] - 2s - loss: 2.3885 - val_loss: 2.1063\n",
      "Epoch 15/300\n",
      "703/703 [==============================] - 3s - loss: 2.3250 - val_loss: 2.4874\n",
      "Epoch 16/300\n",
      "703/703 [==============================] - 3s - loss: 2.3249 - val_loss: 1.9688\n",
      "Epoch 17/300\n",
      "703/703 [==============================] - 2s - loss: 2.3169 - val_loss: 2.2068\n",
      "Epoch 18/300\n",
      "703/703 [==============================] - 3s - loss: 2.2996 - val_loss: 2.4612\n",
      "Epoch 19/300\n",
      "703/703 [==============================] - 2s - loss: 2.3471 - val_loss: 1.8805\n",
      "Epoch 20/300\n",
      "703/703 [==============================] - 3s - loss: 2.2285 - val_loss: 2.7255\n",
      "Epoch 21/300\n",
      "703/703 [==============================] - 3s - loss: 2.2320 - val_loss: 2.3334\n",
      "Epoch 22/300\n",
      "703/703 [==============================] - 3s - loss: 2.2218 - val_loss: 1.9073\n",
      "Epoch 23/300\n",
      "703/703 [==============================] - 3s - loss: 2.1620 - val_loss: 1.8027\n",
      "Epoch 24/300\n",
      "703/703 [==============================] - 2s - loss: 2.1396 - val_loss: 1.9621\n",
      "Epoch 25/300\n",
      "703/703 [==============================] - 2s - loss: 2.1186 - val_loss: 1.8181\n",
      "Epoch 26/300\n",
      "703/703 [==============================] - 2s - loss: 2.1424 - val_loss: 2.7580\n",
      "Epoch 27/300\n",
      "703/703 [==============================] - 3s - loss: 2.1556 - val_loss: 1.8482\n",
      "Epoch 28/300\n",
      "703/703 [==============================] - 3s - loss: 2.1045 - val_loss: 1.9260\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 3s - loss: 2.0953 - val_loss: 2.1737\n",
      "Epoch 30/300\n",
      "703/703 [==============================] - 3s - loss: 2.0284 - val_loss: 1.9293\n",
      "Epoch 31/300\n",
      "703/703 [==============================] - 3s - loss: 2.0465 - val_loss: 1.8712\n",
      "Epoch 32/300\n",
      "703/703 [==============================] - 3s - loss: 2.0241 - val_loss: 1.8871\n",
      "Epoch 33/300\n",
      "703/703 [==============================] - 3s - loss: 2.0350 - val_loss: 2.5653\n",
      "Epoch 34/300\n",
      "695/703 [============================>.] - ETA: 0s - loss: 2.0176\n",
      " Reduced learning rate to 0.01\n",
      "703/703 [==============================] - 3s - loss: 2.0204 - val_loss: 2.2843\n",
      "Epoch 35/300\n",
      "703/703 [==============================] - 3s - loss: 1.7829 - val_loss: 1.7827\n",
      "Epoch 36/300\n",
      "703/703 [==============================] - 2s - loss: 1.7926 - val_loss: 1.7373\n",
      "Epoch 37/300\n",
      "703/703 [==============================] - 3s - loss: 1.7994 - val_loss: 2.0292\n",
      "Epoch 38/300\n",
      "703/703 [==============================] - 3s - loss: 1.7989 - val_loss: 1.7363\n",
      "Epoch 39/300\n",
      "703/703 [==============================] - 2s - loss: 1.8090 - val_loss: 1.7682\n",
      "Epoch 40/300\n",
      "703/703 [==============================] - 2s - loss: 1.7851 - val_loss: 1.8313\n",
      "Epoch 41/300\n",
      "703/703 [==============================] - 3s - loss: 1.7855 - val_loss: 1.8206\n",
      "Epoch 42/300\n",
      "703/703 [==============================] - 3s - loss: 1.7745 - val_loss: 1.6830\n",
      "Epoch 43/300\n",
      "703/703 [==============================] - 3s - loss: 1.7908 - val_loss: 1.8227\n",
      "Epoch 44/300\n",
      "703/703 [==============================] - 3s - loss: 1.7911 - val_loss: 1.7675\n",
      "Epoch 45/300\n",
      "703/703 [==============================] - 2s - loss: 1.7661 - val_loss: 1.7458\n",
      "Epoch 46/300\n",
      "703/703 [==============================] - 3s - loss: 1.7729 - val_loss: 2.1006\n",
      "Epoch 47/300\n",
      "703/703 [==============================] - 2s - loss: 1.8000 - val_loss: 1.7600\n",
      "Epoch 48/300\n",
      "703/703 [==============================] - 3s - loss: 1.7863 - val_loss: 1.8762\n",
      "Epoch 49/300\n",
      "703/703 [==============================] - 3s - loss: 1.7833 - val_loss: 1.7979\n",
      "Epoch 50/300\n",
      "703/703 [==============================] - 3s - loss: 1.7670 - val_loss: 1.7978\n",
      "Epoch 51/300\n",
      "703/703 [==============================] - 4s - loss: 1.7694 - val_loss: 1.7827\n",
      "Epoch 52/300\n",
      "703/703 [==============================] - 3s - loss: 1.7782 - val_loss: 1.7234\n",
      "Epoch 53/300\n",
      "697/703 [============================>.] - ETA: 0s - loss: 1.7954\n",
      " Reduced learning rate to 0.00666667\n",
      "703/703 [==============================] - 3s - loss: 1.7951 - val_loss: 1.7447\n",
      "Epoch 54/300\n",
      "703/703 [==============================] - 3s - loss: 1.7282 - val_loss: 1.7288\n",
      "Epoch 55/300\n",
      "703/703 [==============================] - 3s - loss: 1.7304 - val_loss: 1.7981\n",
      "Epoch 56/300\n",
      "703/703 [==============================] - 2s - loss: 1.7367 - val_loss: 1.7780\n",
      "Epoch 57/300\n",
      "703/703 [==============================] - 3s - loss: 1.7239 - val_loss: 1.7073\n",
      "Epoch 58/300\n",
      "703/703 [==============================] - 3s - loss: 1.7103 - val_loss: 1.7994\n",
      "Epoch 59/300\n",
      "703/703 [==============================] - 3s - loss: 1.7142 - val_loss: 1.7471\n",
      "Epoch 60/300\n",
      "703/703 [==============================] - 3s - loss: 1.7146 - val_loss: 1.7610\n",
      "Epoch 61/300\n",
      "703/703 [==============================] - 2s - loss: 1.7083 - val_loss: 1.7251\n",
      "Epoch 62/300\n",
      "703/703 [==============================] - 2s - loss: 1.7125 - val_loss: 1.7087\n",
      "Epoch 63/300\n",
      "703/703 [==============================] - 3s - loss: 1.7216 - val_loss: 1.7280\n",
      "Epoch 64/300\n",
      "698/703 [============================>.] - ETA: 0s - loss: 1.7157\n",
      " Reduced learning rate to 0.00444444\n",
      "703/703 [==============================] - 3s - loss: 1.7146 - val_loss: 1.7288\n",
      "Epoch 65/300\n",
      "703/703 [==============================] - 3s - loss: 1.7004 - val_loss: 1.7365\n",
      "Epoch 66/300\n",
      "703/703 [==============================] - 2s - loss: 1.6993 - val_loss: 1.7529\n",
      "Epoch 67/300\n",
      "703/703 [==============================] - 2s - loss: 1.7166 - val_loss: 1.8069\n",
      "Epoch 68/300\n",
      "703/703 [==============================] - 3s - loss: 1.6905 - val_loss: 1.7316\n",
      "Epoch 69/300\n",
      "703/703 [==============================] - 2s - loss: 1.6991 - val_loss: 1.7396\n",
      "Epoch 70/300\n",
      "703/703 [==============================] - 3s - loss: 1.7347 - val_loss: 1.8238\n",
      "Epoch 71/300\n",
      "703/703 [==============================] - 3s - loss: 1.7354 - val_loss: 1.6881\n",
      "Epoch 72/300\n",
      "703/703 [==============================] - 2s - loss: 1.7229 - val_loss: 1.8467\n",
      "Epoch 73/300\n",
      "703/703 [==============================] - 3s - loss: 1.7315 - val_loss: 1.7163\n",
      "Epoch 74/300\n",
      "703/703 [==============================] - 4s - loss: 1.7358 - val_loss: 1.7468\n",
      "Epoch 75/300\n",
      "695/703 [============================>.] - ETA: 0s - loss: 1.7056\n",
      " Reduced learning rate to 0.00296296\n",
      "703/703 [==============================] - 3s - loss: 1.7025 - val_loss: 1.7177\n",
      "Epoch 76/300\n",
      "703/703 [==============================] - 3s - loss: 1.6866 - val_loss: 1.7159\n",
      "Epoch 77/300\n",
      "703/703 [==============================] - 2s - loss: 1.7010 - val_loss: 1.6986\n",
      "Epoch 78/300\n",
      "703/703 [==============================] - 3s - loss: 1.6966 - val_loss: 1.7054\n",
      "Epoch 79/300\n",
      "703/703 [==============================] - 3s - loss: 1.6968 - val_loss: 1.6746\n",
      "Epoch 80/300\n",
      "703/703 [==============================] - 2s - loss: 1.6851 - val_loss: 1.7134\n",
      "Epoch 81/300\n",
      "703/703 [==============================] - 2s - loss: 1.6764 - val_loss: 1.7334\n",
      "Epoch 82/300\n",
      "703/703 [==============================] - 3s - loss: 1.7021 - val_loss: 1.7283\n",
      "Epoch 83/300\n",
      "703/703 [==============================] - 3s - loss: 1.6853 - val_loss: 1.6833\n",
      "Epoch 84/300\n",
      "703/703 [==============================] - 3s - loss: 1.6704 - val_loss: 1.6759\n",
      "Epoch 85/300\n",
      "703/703 [==============================] - 3s - loss: 1.6891 - val_loss: 1.7870\n",
      "Epoch 86/300\n",
      "703/703 [==============================] - 3s - loss: 1.6933 - val_loss: 1.6595\n",
      "Epoch 87/300\n",
      "703/703 [==============================] - 2s - loss: 1.7102 - val_loss: 1.6894\n",
      "Epoch 88/300\n",
      "703/703 [==============================] - 1s - loss: 1.7109 - val_loss: 1.7618\n",
      "Epoch 89/300\n",
      "703/703 [==============================] - 1s - loss: 1.6960 - val_loss: 1.6939\n",
      "Epoch 90/300\n",
      "703/703 [==============================] - 1s - loss: 1.7097 - val_loss: 1.7074\n",
      "Epoch 91/300\n",
      "703/703 [==============================] - 1s - loss: 1.6933 - val_loss: 1.7799\n",
      "Epoch 92/300\n",
      "703/703 [==============================] - 1s - loss: 1.6650 - val_loss: 1.7019\n",
      "Epoch 93/300\n",
      "703/703 [==============================] - 1s - loss: 1.6741 - val_loss: 1.6812\n",
      "Epoch 94/300\n",
      "703/703 [==============================] - 1s - loss: 1.6792 - val_loss: 1.6877\n",
      "Epoch 95/300\n",
      "703/703 [==============================] - 1s - loss: 1.6856 - val_loss: 1.6662\n",
      "Epoch 96/300\n",
      "703/703 [==============================] - 1s - loss: 1.6731 - val_loss: 1.6938\n",
      "Epoch 97/300\n",
      "703/703 [==============================] - 1s - loss: 1.7009 - val_loss: 1.6522\n",
      "Epoch 98/300\n",
      "703/703 [==============================] - 1s - loss: 1.6981 - val_loss: 1.6844\n",
      "Epoch 99/300\n",
      "703/703 [==============================] - 1s - loss: 1.6732 - val_loss: 1.6638\n",
      "Epoch 100/300\n",
      "703/703 [==============================] - 1s - loss: 1.6969 - val_loss: 1.7085\n",
      "Epoch 101/300\n",
      "703/703 [==============================] - 1s - loss: 1.6796 - val_loss: 1.6568\n",
      "Epoch 102/300\n",
      "703/703 [==============================] - 1s - loss: 1.6987 - val_loss: 1.7268\n",
      "Epoch 103/300\n",
      "703/703 [==============================] - 1s - loss: 1.6967 - val_loss: 1.6937\n",
      "Epoch 104/300\n",
      "703/703 [==============================] - 1s - loss: 1.6717 - val_loss: 1.6665\n",
      "Epoch 105/300\n",
      "703/703 [==============================] - 1s - loss: 1.6707 - val_loss: 1.6913\n",
      "Epoch 106/300\n",
      "703/703 [==============================] - 1s - loss: 1.6807 - val_loss: 1.7224\n",
      "Epoch 107/300\n",
      "703/703 [==============================] - 1s - loss: 1.6821 - val_loss: 1.6952\n",
      "Epoch 108/300\n",
      "692/703 [============================>.] - ETA: 0s - loss: 1.6696\n",
      " Reduced learning rate to 0.00197531\n",
      "703/703 [==============================] - 1s - loss: 1.6675 - val_loss: 1.6660\n",
      "Epoch 109/300\n",
      "703/703 [==============================] - 1s - loss: 1.6893 - val_loss: 1.7287\n",
      "Epoch 110/300\n",
      "703/703 [==============================] - 1s - loss: 1.6625 - val_loss: 1.7007\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.6990 - val_loss: 1.6920\n",
      "Epoch 112/300\n",
      "703/703 [==============================] - 1s - loss: 1.6855 - val_loss: 1.6882\n",
      "Epoch 113/300\n",
      "703/703 [==============================] - 1s - loss: 1.6771 - val_loss: 1.6766\n",
      "Epoch 114/300\n",
      "703/703 [==============================] - 1s - loss: 1.6917 - val_loss: 1.6725\n",
      "Epoch 115/300\n",
      "703/703 [==============================] - 1s - loss: 1.6855 - val_loss: 1.6996\n",
      "Epoch 116/300\n",
      "703/703 [==============================] - 1s - loss: 1.6681 - val_loss: 1.6997\n",
      "Epoch 117/300\n",
      "703/703 [==============================] - 1s - loss: 1.6754 - val_loss: 1.6765\n",
      "Epoch 118/300\n",
      "703/703 [==============================] - 1s - loss: 1.6771 - val_loss: 1.6955\n",
      "Epoch 119/300\n",
      "699/703 [============================>.] - ETA: 0s - loss: 1.6779\n",
      " Reduced learning rate to 0.00131687\n",
      "703/703 [==============================] - 1s - loss: 1.6777 - val_loss: 1.6863\n",
      "Epoch 120/300\n",
      "703/703 [==============================] - 1s - loss: 1.6958 - val_loss: 1.6950\n",
      "Epoch 121/300\n",
      "703/703 [==============================] - 1s - loss: 1.6522 - val_loss: 1.6968\n",
      "Epoch 122/300\n",
      "703/703 [==============================] - 1s - loss: 1.6724 - val_loss: 1.6526\n",
      "Epoch 123/300\n",
      "703/703 [==============================] - 1s - loss: 1.6784 - val_loss: 1.7019\n",
      "Epoch 124/300\n",
      "703/703 [==============================] - 1s - loss: 1.6832 - val_loss: 1.6901\n",
      "Epoch 125/300\n",
      "703/703 [==============================] - 1s - loss: 1.6681 - val_loss: 1.7029\n",
      "Epoch 126/300\n",
      "703/703 [==============================] - 1s - loss: 1.6770 - val_loss: 1.6818\n",
      "Epoch 127/300\n",
      "703/703 [==============================] - 1s - loss: 1.6746 - val_loss: 1.7138\n",
      "Epoch 128/300\n",
      "703/703 [==============================] - 1s - loss: 1.6738 - val_loss: 1.6750\n",
      "Epoch 129/300\n",
      "703/703 [==============================] - 1s - loss: 1.6650 - val_loss: 1.7147\n",
      "Epoch 130/300\n",
      "680/703 [============================>.] - ETA: 0s - loss: 1.6845\n",
      " Reduced learning rate to 0.000877915\n",
      "703/703 [==============================] - 1s - loss: 1.6881 - val_loss: 1.6626\n",
      "Epoch 131/300\n",
      "703/703 [==============================] - 1s - loss: 1.6924 - val_loss: 1.7001\n",
      "Epoch 132/300\n",
      "703/703 [==============================] - 1s - loss: 1.6505 - val_loss: 1.6729\n",
      "Epoch 133/300\n",
      "703/703 [==============================] - 1s - loss: 1.6756 - val_loss: 1.7034\n",
      "Epoch 134/300\n",
      "703/703 [==============================] - 1s - loss: 1.6705 - val_loss: 1.6829\n",
      "Epoch 135/300\n",
      "703/703 [==============================] - 1s - loss: 1.6786 - val_loss: 1.6656\n",
      "Epoch 136/300\n",
      "703/703 [==============================] - 1s - loss: 1.6708 - val_loss: 1.6805\n",
      "Epoch 137/300\n",
      "703/703 [==============================] - 1s - loss: 1.6810 - val_loss: 1.6950\n",
      "Epoch 138/300\n",
      "703/703 [==============================] - 1s - loss: 1.6665 - val_loss: 1.7048\n",
      "Epoch 139/300\n",
      "703/703 [==============================] - 1s - loss: 1.6833 - val_loss: 1.6902\n",
      "Epoch 140/300\n",
      "703/703 [==============================] - 1s - loss: 1.6510 - val_loss: 1.7069\n",
      "Epoch 141/300\n",
      "675/703 [===========================>..] - ETA: 0s - loss: 1.6598\n",
      " Reduced learning rate to 0.000585277\n",
      "703/703 [==============================] - 1s - loss: 1.6625 - val_loss: 1.6862\n",
      "Epoch 142/300\n",
      "703/703 [==============================] - 1s - loss: 1.6881 - val_loss: 1.6936\n",
      "Epoch 143/300\n",
      "703/703 [==============================] - 1s - loss: 1.6580 - val_loss: 1.6636\n",
      "Epoch 144/300\n",
      "703/703 [==============================] - 1s - loss: 1.6476 - val_loss: 1.6816\n",
      "Epoch 145/300\n",
      "703/703 [==============================] - 1s - loss: 1.6748 - val_loss: 1.6881\n",
      "Epoch 146/300\n",
      "703/703 [==============================] - 1s - loss: 1.6760 - val_loss: 1.6542\n",
      "Epoch 147/300\n",
      "703/703 [==============================] - 1s - loss: 1.6659 - val_loss: 1.6840\n",
      "Epoch 148/300\n",
      "703/703 [==============================] - 1s - loss: 1.6637 - val_loss: 1.6617\n",
      "Epoch 149/300\n",
      "703/703 [==============================] - 1s - loss: 1.6893 - val_loss: 1.7130\n",
      "Epoch 150/300\n",
      "703/703 [==============================] - 1s - loss: 1.6564 - val_loss: 1.6590\n",
      "Epoch 151/300\n",
      "703/703 [==============================] - 1s - loss: 1.6655 - val_loss: 1.6993\n",
      "Epoch 152/300\n",
      "689/703 [============================>.] - ETA: 0s - loss: 1.6792\n",
      " Reduced learning rate to 0.000390184\n",
      "703/703 [==============================] - 1s - loss: 1.6784 - val_loss: 1.6730\n",
      "Epoch 153/300\n",
      "703/703 [==============================] - 1s - loss: 1.6890 - val_loss: 1.6812\n",
      "Epoch 154/300\n",
      "703/703 [==============================] - 1s - loss: 1.6713 - val_loss: 1.6636\n",
      "Epoch 155/300\n",
      "703/703 [==============================] - 1s - loss: 1.6570 - val_loss: 1.6705\n",
      "Epoch 156/300\n",
      "703/703 [==============================] - 1s - loss: 1.6681 - val_loss: 1.6977\n",
      "Epoch 157/300\n",
      "703/703 [==============================] - 1s - loss: 1.6747 - val_loss: 1.6664\n",
      "Epoch 158/300\n",
      "703/703 [==============================] - 1s - loss: 1.6605 - val_loss: 1.6402\n",
      "Epoch 159/300\n",
      "703/703 [==============================] - 1s - loss: 1.6620 - val_loss: 1.6704\n",
      "Epoch 160/300\n",
      "703/703 [==============================] - 1s - loss: 1.6788 - val_loss: 1.6731\n",
      "Epoch 161/300\n",
      "703/703 [==============================] - 1s - loss: 1.6739 - val_loss: 1.6665\n",
      "Epoch 162/300\n",
      "703/703 [==============================] - 1s - loss: 1.6779 - val_loss: 1.6793\n",
      "Epoch 163/300\n",
      "703/703 [==============================] - 1s - loss: 1.6660 - val_loss: 1.6512\n",
      "Epoch 164/300\n",
      "703/703 [==============================] - ETA: 0s - loss: 1.684 - 1s - loss: 1.6846 - val_loss: 1.6985\n",
      "Epoch 165/300\n",
      "703/703 [==============================] - 1s - loss: 1.6614 - val_loss: 1.6664\n",
      "Epoch 166/300\n",
      "703/703 [==============================] - 1s - loss: 1.6707 - val_loss: 1.6954\n",
      "Epoch 167/300\n",
      "703/703 [==============================] - 1s - loss: 1.6602 - val_loss: 1.6636\n",
      "Epoch 168/300\n",
      "703/703 [==============================] - 1s - loss: 1.6706 - val_loss: 1.6758\n",
      "Epoch 169/300\n",
      "695/703 [============================>.] - ETA: 0s - loss: 1.6806\n",
      " Reduced learning rate to 0.000260123\n",
      "703/703 [==============================] - 1s - loss: 1.6823 - val_loss: 1.6819\n",
      "Epoch 170/300\n",
      "703/703 [==============================] - 1s - loss: 1.6777 - val_loss: 1.6748\n",
      "Epoch 171/300\n",
      "703/703 [==============================] - 1s - loss: 1.6580 - val_loss: 1.6661\n",
      "Epoch 172/300\n",
      "703/703 [==============================] - 1s - loss: 1.6617 - val_loss: 1.6927\n",
      "Epoch 173/300\n",
      "703/703 [==============================] - 1s - loss: 1.6865 - val_loss: 1.6967\n",
      "Epoch 174/300\n",
      "703/703 [==============================] - 1s - loss: 1.6707 - val_loss: 1.6574\n",
      "Epoch 175/300\n",
      "703/703 [==============================] - 1s - loss: 1.6935 - val_loss: 1.7174\n",
      "Epoch 176/300\n",
      "703/703 [==============================] - 1s - loss: 1.6574 - val_loss: 1.7034\n",
      "Epoch 177/300\n",
      "703/703 [==============================] - 1s - loss: 1.6787 - val_loss: 1.6739\n",
      "Epoch 178/300\n",
      "703/703 [==============================] - 1s - loss: 1.6565 - val_loss: 1.6912\n",
      "Epoch 179/300\n",
      "703/703 [==============================] - 1s - loss: 1.6719 - val_loss: 1.6711\n",
      "Epoch 180/300\n",
      "681/703 [============================>.] - ETA: 0s - loss: 1.6505\n",
      " Reduced learning rate to 0.000173415\n",
      "703/703 [==============================] - 1s - loss: 1.6503 - val_loss: 1.6974\n",
      "Epoch 181/300\n",
      "703/703 [==============================] - 1s - loss: 1.6774 - val_loss: 1.6894\n",
      "Epoch 182/300\n",
      "703/703 [==============================] - 1s - loss: 1.6858 - val_loss: 1.6607\n",
      "Epoch 183/300\n",
      "703/703 [==============================] - 1s - loss: 1.6657 - val_loss: 1.6787\n",
      "Epoch 184/300\n",
      "703/703 [==============================] - 1s - loss: 1.6598 - val_loss: 1.7024\n",
      "Epoch 185/300\n",
      "703/703 [==============================] - 1s - loss: 1.6509 - val_loss: 1.6777\n",
      "Epoch 186/300\n",
      "703/703 [==============================] - 1s - loss: 1.6486 - val_loss: 1.6781\n",
      "Epoch 187/300\n",
      "703/703 [==============================] - 1s - loss: 1.6764 - val_loss: 1.6851\n",
      "Epoch 188/300\n",
      "703/703 [==============================] - 1s - loss: 1.6407 - val_loss: 1.7036\n",
      "Epoch 189/300\n",
      "703/703 [==============================] - 1s - loss: 1.6618 - val_loss: 1.6746\n",
      "Epoch 190/300\n",
      "703/703 [==============================] - 1s - loss: 1.6832 - val_loss: 1.7214\n",
      "Epoch 191/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "679/703 [===========================>..] - ETA: 0s - loss: 1.6631\n",
      " Reduced learning rate to 0.00011561\n",
      "703/703 [==============================] - 1s - loss: 1.6637 - val_loss: 1.6569\n",
      "Epoch 192/300\n",
      "703/703 [==============================] - 1s - loss: 1.6857 - val_loss: 1.6845\n",
      "Epoch 193/300\n",
      "703/703 [==============================] - 1s - loss: 1.6760 - val_loss: 1.6918\n",
      "Epoch 194/300\n",
      "703/703 [==============================] - 1s - loss: 1.7013 - val_loss: 1.6358\n",
      "Epoch 195/300\n",
      "703/703 [==============================] - 1s - loss: 1.6551 - val_loss: 1.7229\n",
      "Epoch 196/300\n",
      "703/703 [==============================] - 1s - loss: 1.6435 - val_loss: 1.6916\n",
      "Epoch 197/300\n",
      "703/703 [==============================] - 1s - loss: 1.6702 - val_loss: 1.6414\n",
      "Epoch 198/300\n",
      "703/703 [==============================] - 1s - loss: 1.6852 - val_loss: 1.6863\n",
      "Epoch 199/300\n",
      "703/703 [==============================] - 1s - loss: 1.6625 - val_loss: 1.6381\n",
      "Epoch 200/300\n",
      "703/703 [==============================] - 1s - loss: 1.6811 - val_loss: 1.7057\n",
      "Epoch 201/300\n",
      "703/703 [==============================] - 1s - loss: 1.6774 - val_loss: 1.6754\n",
      "Epoch 202/300\n",
      "703/703 [==============================] - 1s - loss: 1.6658 - val_loss: 1.6990\n",
      "Epoch 203/300\n",
      "703/703 [==============================] - 1s - loss: 1.6797 - val_loss: 1.6433\n",
      "Epoch 204/300\n",
      "703/703 [==============================] - 1s - loss: 1.6993 - val_loss: 1.6842\n",
      "Epoch 205/300\n",
      "688/703 [============================>.] - ETA: 0s - loss: 1.6762\n",
      " Reduced learning rate to 7.70735e-05\n",
      "703/703 [==============================] - 1s - loss: 1.6775 - val_loss: 1.6421\n",
      "Epoch 1/300\n",
      "703/703 [==============================] - 2s - loss: 11.1144 - val_loss: 3.4277\n",
      "Epoch 2/300\n",
      "703/703 [==============================] - 1s - loss: 3.1234 - val_loss: 3.3257\n",
      "Epoch 3/300\n",
      "703/703 [==============================] - 1s - loss: 3.0987 - val_loss: 3.5627\n",
      "Epoch 4/300\n",
      "703/703 [==============================] - 1s - loss: 2.8821 - val_loss: 2.2117\n",
      "Epoch 5/300\n",
      "703/703 [==============================] - 1s - loss: 2.8829 - val_loss: 2.6327\n",
      "Epoch 6/300\n",
      "703/703 [==============================] - 1s - loss: 2.7757 - val_loss: 2.1448\n",
      "Epoch 7/300\n",
      "703/703 [==============================] - 1s - loss: 2.8137 - val_loss: 3.1497\n",
      "Epoch 8/300\n",
      "703/703 [==============================] - 1s - loss: 2.6276 - val_loss: 2.8220\n",
      "Epoch 9/300\n",
      "703/703 [==============================] - 1s - loss: 2.4950 - val_loss: 2.6896\n",
      "Epoch 10/300\n",
      "703/703 [==============================] - 1s - loss: 2.5712 - val_loss: 2.8381\n",
      "Epoch 11/300\n",
      "703/703 [==============================] - 1s - loss: 2.4616 - val_loss: 3.9890\n",
      "Epoch 12/300\n",
      "703/703 [==============================] - 1s - loss: 2.3877 - val_loss: 1.8900\n",
      "Epoch 13/300\n",
      "703/703 [==============================] - 1s - loss: 2.3820 - val_loss: 2.5281\n",
      "Epoch 14/300\n",
      "703/703 [==============================] - 1s - loss: 2.4281 - val_loss: 2.8842\n",
      "Epoch 15/300\n",
      "703/703 [==============================] - 1s - loss: 2.2400 - val_loss: 2.7463\n",
      "Epoch 16/300\n",
      "703/703 [==============================] - 1s - loss: 2.2529 - val_loss: 1.9580\n",
      "Epoch 17/300\n",
      "703/703 [==============================] - 1s - loss: 2.1876 - val_loss: 1.8737\n",
      "Epoch 18/300\n",
      "703/703 [==============================] - 1s - loss: 2.2056 - val_loss: 1.8855\n",
      "Epoch 19/300\n",
      "703/703 [==============================] - 1s - loss: 2.1709 - val_loss: 2.2174\n",
      "Epoch 20/300\n",
      "703/703 [==============================] - 1s - loss: 2.1688 - val_loss: 2.2928\n",
      "Epoch 21/300\n",
      "703/703 [==============================] - 1s - loss: 2.1000 - val_loss: 2.4529\n",
      "Epoch 22/300\n",
      "703/703 [==============================] - 1s - loss: 2.1401 - val_loss: 1.8432\n",
      "Epoch 23/300\n",
      "703/703 [==============================] - 1s - loss: 2.1136 - val_loss: 1.9081\n",
      "Epoch 24/300\n",
      "703/703 [==============================] - 1s - loss: 2.1023 - val_loss: 2.2308\n",
      "Epoch 25/300\n",
      "703/703 [==============================] - 1s - loss: 2.0931 - val_loss: 2.2330\n",
      "Epoch 26/300\n",
      "703/703 [==============================] - 1s - loss: 2.0837 - val_loss: 1.9608\n",
      "Epoch 27/300\n",
      "703/703 [==============================] - 1s - loss: 2.0568 - val_loss: 1.9159\n",
      "Epoch 28/300\n",
      "703/703 [==============================] - 1s - loss: 2.0208 - val_loss: 2.0906\n",
      "Epoch 29/300\n",
      "703/703 [==============================] - 1s - loss: 2.0003 - val_loss: 1.9125\n",
      "Epoch 30/300\n",
      "703/703 [==============================] - 1s - loss: 1.9962 - val_loss: 1.8137\n",
      "Epoch 31/300\n",
      "703/703 [==============================] - 1s - loss: 2.0922 - val_loss: 1.9618\n",
      "Epoch 32/300\n",
      "703/703 [==============================] - 1s - loss: 2.0233 - val_loss: 1.8039\n",
      "Epoch 33/300\n",
      "703/703 [==============================] - 1s - loss: 1.9865 - val_loss: 2.3479\n",
      "Epoch 34/300\n",
      "703/703 [==============================] - 1s - loss: 1.9952 - val_loss: 1.7467\n",
      "Epoch 35/300\n",
      "703/703 [==============================] - 1s - loss: 1.9945 - val_loss: 1.7496\n",
      "Epoch 36/300\n",
      "703/703 [==============================] - 1s - loss: 2.0060 - val_loss: 2.0500\n",
      "Epoch 37/300\n",
      "703/703 [==============================] - 1s - loss: 2.0004 - val_loss: 1.8778\n",
      "Epoch 38/300\n",
      "703/703 [==============================] - 1s - loss: 1.9652 - val_loss: 1.8735\n",
      "Epoch 39/300\n",
      "703/703 [==============================] - 1s - loss: 1.9130 - val_loss: 1.8786\n",
      "Epoch 40/300\n",
      "703/703 [==============================] - 1s - loss: 1.9384 - val_loss: 1.9029\n",
      "Epoch 41/300\n",
      "703/703 [==============================] - 1s - loss: 1.9478 - val_loss: 1.7500\n",
      "Epoch 42/300\n",
      "703/703 [==============================] - 1s - loss: 1.9047 - val_loss: 1.8333\n",
      "Epoch 43/300\n",
      "703/703 [==============================] - 1s - loss: 1.9598 - val_loss: 2.3968\n",
      "Epoch 44/300\n",
      "703/703 [==============================] - 1s - loss: 1.9485 - val_loss: 1.9143\n",
      "Epoch 45/300\n",
      "688/703 [============================>.] - ETA: 0s - loss: 1.8989\n",
      " Reduced learning rate to 0.01\n",
      "703/703 [==============================] - 1s - loss: 1.9025 - val_loss: 2.0333\n",
      "Epoch 46/300\n",
      "703/703 [==============================] - 1s - loss: 1.7618 - val_loss: 1.7182\n",
      "Epoch 47/300\n",
      "703/703 [==============================] - 1s - loss: 1.7968 - val_loss: 1.7682\n",
      "Epoch 48/300\n",
      "703/703 [==============================] - 1s - loss: 1.7858 - val_loss: 1.8047\n",
      "Epoch 49/300\n",
      "703/703 [==============================] - 1s - loss: 1.7468 - val_loss: 1.7796\n",
      "Epoch 50/300\n",
      "703/703 [==============================] - 1s - loss: 1.7912 - val_loss: 1.8602\n",
      "Epoch 51/300\n",
      "703/703 [==============================] - 1s - loss: 1.7742 - val_loss: 1.7871\n",
      "Epoch 52/300\n",
      "703/703 [==============================] - 1s - loss: 1.7659 - val_loss: 1.7623\n",
      "Epoch 53/300\n",
      "703/703 [==============================] - 1s - loss: 1.7555 - val_loss: 1.8512\n",
      "Epoch 54/300\n",
      "703/703 [==============================] - 1s - loss: 1.7494 - val_loss: 1.7943\n",
      "Epoch 55/300\n",
      "703/703 [==============================] - 1s - loss: 1.7503 - val_loss: 1.7708\n",
      "Epoch 56/300\n",
      "703/703 [==============================] - 1s - loss: 1.7687 - val_loss: 1.7554\n",
      "Epoch 57/300\n",
      "673/703 [===========================>..] - ETA: 0s - loss: 1.7738\n",
      " Reduced learning rate to 0.00666667\n",
      "703/703 [==============================] - 1s - loss: 1.7751 - val_loss: 1.9094\n",
      "Epoch 58/300\n",
      "703/703 [==============================] - 1s - loss: 1.7448 - val_loss: 1.8071\n",
      "Epoch 59/300\n",
      "703/703 [==============================] - 1s - loss: 1.7172 - val_loss: 1.6969\n",
      "Epoch 60/300\n",
      "703/703 [==============================] - 1s - loss: 1.7271 - val_loss: 1.7035\n",
      "Epoch 61/300\n",
      "703/703 [==============================] - 1s - loss: 1.7069 - val_loss: 1.7510\n",
      "Epoch 62/300\n",
      "703/703 [==============================] - 1s - loss: 1.7091 - val_loss: 1.7352\n",
      "Epoch 63/300\n",
      "703/703 [==============================] - 1s - loss: 1.6940 - val_loss: 1.6822\n",
      "Epoch 64/300\n",
      "703/703 [==============================] - 1s - loss: 1.7277 - val_loss: 1.7307\n",
      "Epoch 65/300\n",
      "703/703 [==============================] - 1s - loss: 1.7178 - val_loss: 1.7010\n",
      "Epoch 66/300\n",
      "703/703 [==============================] - 1s - loss: 1.7081 - val_loss: 1.7169\n",
      "Epoch 67/300\n",
      "703/703 [==============================] - 1s - loss: 1.7110 - val_loss: 1.7154\n",
      "Epoch 68/300\n",
      "703/703 [==============================] - 1s - loss: 1.7345 - val_loss: 1.7555\n",
      "Epoch 69/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.7035 - val_loss: 1.7383\n",
      "Epoch 70/300\n",
      "703/703 [==============================] - 1s - loss: 1.7085 - val_loss: 1.7353\n",
      "Epoch 71/300\n",
      "703/703 [==============================] - 1s - loss: 1.7083 - val_loss: 1.7282\n",
      "Epoch 72/300\n",
      "703/703 [==============================] - 1s - loss: 1.7228 - val_loss: 1.7016\n",
      "Epoch 73/300\n",
      "703/703 [==============================] - 1s - loss: 1.7372 - val_loss: 1.7012\n",
      "Epoch 74/300\n",
      "686/703 [============================>.] - ETA: 0s - loss: 1.7329\n",
      " Reduced learning rate to 0.00444444\n",
      "703/703 [==============================] - 1s - loss: 1.7336 - val_loss: 1.7270\n",
      "Epoch 75/300\n",
      "703/703 [==============================] - 1s - loss: 1.6985 - val_loss: 1.7459\n",
      "Epoch 76/300\n",
      "703/703 [==============================] - 1s - loss: 1.7198 - val_loss: 1.7179\n",
      "Epoch 77/300\n",
      "703/703 [==============================] - 1s - loss: 1.6698 - val_loss: 1.7198\n",
      "Epoch 78/300\n",
      "703/703 [==============================] - 1s - loss: 1.7005 - val_loss: 1.7649\n",
      "Epoch 79/300\n",
      "703/703 [==============================] - 1s - loss: 1.6934 - val_loss: 1.7052\n",
      "Epoch 80/300\n",
      "703/703 [==============================] - 1s - loss: 1.7289 - val_loss: 1.6910\n",
      "Epoch 81/300\n",
      "703/703 [==============================] - 1s - loss: 1.6973 - val_loss: 1.6930\n",
      "Epoch 82/300\n",
      "703/703 [==============================] - 1s - loss: 1.7017 - val_loss: 1.7123\n",
      "Epoch 83/300\n",
      "703/703 [==============================] - 1s - loss: 1.6910 - val_loss: 1.7089\n",
      "Epoch 84/300\n",
      "703/703 [==============================] - 1s - loss: 1.6966 - val_loss: 1.7248\n",
      "Epoch 85/300\n",
      "689/703 [============================>.] - ETA: 0s - loss: 1.7097\n",
      " Reduced learning rate to 0.00296296\n",
      "703/703 [==============================] - 1s - loss: 1.7085 - val_loss: 1.6877\n",
      "Epoch 86/300\n",
      "703/703 [==============================] - 1s - loss: 1.6800 - val_loss: 1.6860\n",
      "Epoch 87/300\n",
      "703/703 [==============================] - 1s - loss: 1.7022 - val_loss: 1.7042\n",
      "Epoch 88/300\n",
      "703/703 [==============================] - 1s - loss: 1.6933 - val_loss: 1.7249\n",
      "Epoch 89/300\n",
      "703/703 [==============================] - 1s - loss: 1.6962 - val_loss: 1.7158\n",
      "Epoch 90/300\n",
      "703/703 [==============================] - 1s - loss: 1.6808 - val_loss: 1.7190\n",
      "Epoch 91/300\n",
      "703/703 [==============================] - 1s - loss: 1.6916 - val_loss: 1.7118\n",
      "Epoch 92/300\n",
      "703/703 [==============================] - 1s - loss: 1.7006 - val_loss: 1.7153\n",
      "Epoch 93/300\n",
      "703/703 [==============================] - 1s - loss: 1.6674 - val_loss: 1.7399\n",
      "Epoch 94/300\n",
      "703/703 [==============================] - 1s - loss: 1.6958 - val_loss: 1.6725\n",
      "Epoch 95/300\n",
      "703/703 [==============================] - 1s - loss: 1.6794 - val_loss: 1.7367\n",
      "Epoch 96/300\n",
      "703/703 [==============================] - 1s - loss: 1.7101 - val_loss: 1.7034\n",
      "Epoch 97/300\n",
      "703/703 [==============================] - 1s - loss: 1.6858 - val_loss: 1.7003\n",
      "Epoch 98/300\n",
      "703/703 [==============================] - 1s - loss: 1.6897 - val_loss: 1.7080\n",
      "Epoch 99/300\n",
      "703/703 [==============================] - 1s - loss: 1.6892 - val_loss: 1.7033\n",
      "Epoch 100/300\n",
      "703/703 [==============================] - 1s - loss: 1.6845 - val_loss: 1.6494\n",
      "Epoch 101/300\n",
      "703/703 [==============================] - 1s - loss: 1.6734 - val_loss: 1.6764\n",
      "Epoch 102/300\n",
      "703/703 [==============================] - 1s - loss: 1.6889 - val_loss: 1.6985\n",
      "Epoch 103/300\n",
      "703/703 [==============================] - 1s - loss: 1.6796 - val_loss: 1.7534\n",
      "Epoch 104/300\n",
      "703/703 [==============================] - 1s - loss: 1.6789 - val_loss: 1.6438\n",
      "Epoch 105/300\n",
      "703/703 [==============================] - 1s - loss: 1.7039 - val_loss: 1.6976\n",
      "Epoch 106/300\n",
      "703/703 [==============================] - 1s - loss: 1.6718 - val_loss: 1.6866\n",
      "Epoch 107/300\n",
      "703/703 [==============================] - 1s - loss: 1.6666 - val_loss: 1.6804\n",
      "Epoch 108/300\n",
      "703/703 [==============================] - 1s - loss: 1.6746 - val_loss: 1.6860\n",
      "Epoch 109/300\n",
      "703/703 [==============================] - 1s - loss: 1.6991 - val_loss: 1.7141\n",
      "Epoch 110/300\n",
      "703/703 [==============================] - 1s - loss: 1.6909 - val_loss: 1.6657\n",
      "Epoch 111/300\n",
      "703/703 [==============================] - 1s - loss: 1.6792 - val_loss: 1.7138\n",
      "Epoch 112/300\n",
      "703/703 [==============================] - 1s - loss: 1.6933 - val_loss: 1.6946\n",
      "Epoch 113/300\n",
      "703/703 [==============================] - 1s - loss: 1.6973 - val_loss: 1.6749\n",
      "Epoch 114/300\n",
      "703/703 [==============================] - 1s - loss: 1.6710 - val_loss: 1.6867\n",
      "Epoch 115/300\n",
      "691/703 [============================>.] - ETA: 0s - loss: 1.6820\n",
      " Reduced learning rate to 0.00197531\n",
      "703/703 [==============================] - 1s - loss: 1.6812 - val_loss: 1.7297\n",
      "Epoch 116/300\n",
      "703/703 [==============================] - 1s - loss: 1.6684 - val_loss: 1.6865\n",
      "Epoch 117/300\n",
      "703/703 [==============================] - 1s - loss: 1.6760 - val_loss: 1.7200\n",
      "Epoch 118/300\n",
      "703/703 [==============================] - 1s - loss: 1.6587 - val_loss: 1.6839\n",
      "Epoch 119/300\n",
      "703/703 [==============================] - 1s - loss: 1.6869 - val_loss: 1.6884\n",
      "Epoch 120/300\n",
      "703/703 [==============================] - 1s - loss: 1.6942 - val_loss: 1.6902\n",
      "Epoch 121/300\n",
      "703/703 [==============================] - 1s - loss: 1.6791 - val_loss: 1.6907\n",
      "Epoch 122/300\n",
      "703/703 [==============================] - 1s - loss: 1.6690 - val_loss: 1.6817\n",
      "Epoch 123/300\n",
      "703/703 [==============================] - 1s - loss: 1.6766 - val_loss: 1.6526\n",
      "Epoch 124/300\n",
      "703/703 [==============================] - 1s - loss: 1.6875 - val_loss: 1.6773\n",
      "Epoch 125/300\n",
      "703/703 [==============================] - 1s - loss: 1.6764 - val_loss: 1.7079\n",
      "Epoch 126/300\n",
      "685/703 [============================>.] - ETA: 0s - loss: 1.6653\n",
      " Reduced learning rate to 0.00131687\n",
      "703/703 [==============================] - 1s - loss: 1.6644 - val_loss: 1.6814\n",
      "Epoch 127/300\n",
      "703/703 [==============================] - 1s - loss: 1.6806 - val_loss: 1.6854\n",
      "Epoch 128/300\n",
      "703/703 [==============================] - 1s - loss: 1.6791 - val_loss: 1.6784\n",
      "Epoch 129/300\n",
      "703/703 [==============================] - 1s - loss: 1.6534 - val_loss: 1.7251\n",
      "Epoch 130/300\n",
      "703/703 [==============================] - 1s - loss: 1.6609 - val_loss: 1.6919\n",
      "Epoch 131/300\n",
      "703/703 [==============================] - 1s - loss: 1.6772 - val_loss: 1.6711\n",
      "Epoch 132/300\n",
      "703/703 [==============================] - 1s - loss: 1.6897 - val_loss: 1.6549\n",
      "Epoch 133/300\n",
      "703/703 [==============================] - 1s - loss: 1.6713 - val_loss: 1.6710\n",
      "Epoch 134/300\n",
      "703/703 [==============================] - 1s - loss: 1.6695 - val_loss: 1.6934\n",
      "Epoch 135/300\n",
      "703/703 [==============================] - 1s - loss: 1.6750 - val_loss: 1.6913\n",
      "Epoch 136/300\n",
      "703/703 [==============================] - 1s - loss: 1.6991 - val_loss: 1.7158\n",
      "Epoch 137/300\n",
      "685/703 [============================>.] - ETA: 0s - loss: 1.6949\n",
      " Reduced learning rate to 0.000877915\n",
      "703/703 [==============================] - 1s - loss: 1.6943 - val_loss: 1.6727\n",
      "Epoch 138/300\n",
      "703/703 [==============================] - 1s - loss: 1.6729 - val_loss: 1.6816\n",
      "Epoch 139/300\n",
      "703/703 [==============================] - 1s - loss: 1.6982 - val_loss: 1.6922\n",
      "Epoch 140/300\n",
      "703/703 [==============================] - 1s - loss: 1.6734 - val_loss: 1.6708\n",
      "Epoch 141/300\n",
      "703/703 [==============================] - 1s - loss: 1.6558 - val_loss: 1.6902\n",
      "Epoch 142/300\n",
      "703/703 [==============================] - 1s - loss: 1.6576 - val_loss: 1.6824\n",
      "Epoch 143/300\n",
      "703/703 [==============================] - 1s - loss: 1.6728 - val_loss: 1.7111\n",
      "Epoch 144/300\n",
      "703/703 [==============================] - 1s - loss: 1.6679 - val_loss: 1.6733\n",
      "Epoch 145/300\n",
      "703/703 [==============================] - 1s - loss: 1.6732 - val_loss: 1.6995\n",
      "Epoch 146/300\n",
      "703/703 [==============================] - 1s - loss: 1.6708 - val_loss: 1.6784\n",
      "Epoch 147/300\n",
      "703/703 [==============================] - 1s - loss: 1.6673 - val_loss: 1.6780\n",
      "Epoch 148/300\n",
      "674/703 [===========================>..] - ETA: 0s - loss: 1.6876\n",
      " Reduced learning rate to 0.000585277\n",
      "703/703 [==============================] - 1s - loss: 1.6863 - val_loss: 1.6948\n",
      "Epoch 149/300\n",
      "703/703 [==============================] - 1s - loss: 1.6720 - val_loss: 1.6766\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.6880 - val_loss: 1.6726\n",
      "Epoch 151/300\n",
      "703/703 [==============================] - 1s - loss: 1.6590 - val_loss: 1.6820\n",
      "Epoch 152/300\n",
      "703/703 [==============================] - 1s - loss: 1.6801 - val_loss: 1.7030\n",
      "Epoch 153/300\n",
      "703/703 [==============================] - 1s - loss: 1.6779 - val_loss: 1.6978\n",
      "Epoch 154/300\n",
      "703/703 [==============================] - 1s - loss: 1.6715 - val_loss: 1.6709\n",
      "Epoch 155/300\n",
      "703/703 [==============================] - 1s - loss: 1.6837 - val_loss: 1.6586\n",
      "Epoch 156/300\n",
      "703/703 [==============================] - 1s - loss: 1.6798 - val_loss: 1.6691\n",
      "Epoch 157/300\n",
      "703/703 [==============================] - 1s - loss: 1.6819 - val_loss: 1.6789\n",
      "Epoch 158/300\n",
      "703/703 [==============================] - 1s - loss: 1.6648 - val_loss: 1.6788\n",
      "Epoch 159/300\n",
      "682/703 [============================>.] - ETA: 0s - loss: 1.6576\n",
      " Reduced learning rate to 0.000390184\n",
      "703/703 [==============================] - 1s - loss: 1.6613 - val_loss: 1.6560\n",
      "Epoch 160/300\n",
      "703/703 [==============================] - 1s - loss: 1.6718 - val_loss: 1.6832\n",
      "Epoch 161/300\n",
      "703/703 [==============================] - 1s - loss: 1.6545 - val_loss: 1.7063\n",
      "Epoch 162/300\n",
      "703/703 [==============================] - 1s - loss: 1.6602 - val_loss: 1.6910\n",
      "Epoch 163/300\n",
      "703/703 [==============================] - 1s - loss: 1.6894 - val_loss: 1.6696\n",
      "Epoch 164/300\n",
      "703/703 [==============================] - 1s - loss: 1.6451 - val_loss: 1.6601\n",
      "Epoch 165/300\n",
      "703/703 [==============================] - 1s - loss: 1.6637 - val_loss: 1.6777\n",
      "Epoch 166/300\n",
      "703/703 [==============================] - 1s - loss: 1.6694 - val_loss: 1.6930\n",
      "Epoch 167/300\n",
      "703/703 [==============================] - 1s - loss: 1.6730 - val_loss: 1.6948\n",
      "Epoch 168/300\n",
      "703/703 [==============================] - 1s - loss: 1.6617 - val_loss: 1.6934\n",
      "Epoch 169/300\n",
      "703/703 [==============================] - 1s - loss: 1.6644 - val_loss: 1.6960\n",
      "Epoch 170/300\n",
      "696/703 [============================>.] - ETA: 0s - loss: 1.6701\n",
      " Reduced learning rate to 0.000260123\n",
      "703/703 [==============================] - 1s - loss: 1.6697 - val_loss: 1.6792\n",
      "Epoch 171/300\n",
      "703/703 [==============================] - 1s - loss: 1.6788 - val_loss: 1.6835\n",
      "Epoch 172/300\n",
      "703/703 [==============================] - 1s - loss: 1.7028 - val_loss: 1.6988\n",
      "Epoch 173/300\n",
      "703/703 [==============================] - 1s - loss: 1.6678 - val_loss: 1.6700\n",
      "Epoch 174/300\n",
      "703/703 [==============================] - 1s - loss: 1.6958 - val_loss: 1.6935\n",
      "Epoch 175/300\n",
      "703/703 [==============================] - 1s - loss: 1.6828 - val_loss: 1.7079\n",
      "Epoch 176/300\n",
      "703/703 [==============================] - 1s - loss: 1.6478 - val_loss: 1.7251\n",
      "Epoch 177/300\n",
      "703/703 [==============================] - 1s - loss: 1.6644 - val_loss: 1.6655\n",
      "Epoch 178/300\n",
      "703/703 [==============================] - 1s - loss: 1.6624 - val_loss: 1.6943\n",
      "Epoch 179/300\n",
      "703/703 [==============================] - 1s - loss: 1.6569 - val_loss: 1.6360\n",
      "Epoch 180/300\n",
      "703/703 [==============================] - 1s - loss: 1.6765 - val_loss: 1.7091\n",
      "Epoch 181/300\n",
      "703/703 [==============================] - 1s - loss: 1.6741 - val_loss: 1.6547\n",
      "Epoch 182/300\n",
      "703/703 [==============================] - 1s - loss: 1.6696 - val_loss: 1.6598\n",
      "Epoch 183/300\n",
      "703/703 [==============================] - 1s - loss: 1.6579 - val_loss: 1.6610\n",
      "Epoch 184/300\n",
      "703/703 [==============================] - 1s - loss: 1.6708 - val_loss: 1.6536\n",
      "Epoch 185/300\n",
      "703/703 [==============================] - 1s - loss: 1.6583 - val_loss: 1.6522\n",
      "Epoch 186/300\n",
      "703/703 [==============================] - 1s - loss: 1.6987 - val_loss: 1.6927\n",
      "Epoch 187/300\n",
      "703/703 [==============================] - 1s - loss: 1.6815 - val_loss: 1.6814\n",
      "Epoch 188/300\n",
      "703/703 [==============================] - 1s - loss: 1.6747 - val_loss: 1.6998\n",
      "Epoch 189/300\n",
      "703/703 [==============================] - 1s - loss: 1.6668 - val_loss: 1.6709\n",
      "Epoch 190/300\n",
      "699/703 [============================>.] - ETA: 0s - loss: 1.6608\n",
      " Reduced learning rate to 0.000173415\n",
      "703/703 [==============================] - 1s - loss: 1.6601 - val_loss: 1.6816\n",
      "Epoch 191/300\n",
      "703/703 [==============================] - 1s - loss: 1.6568 - val_loss: 1.6943\n",
      "Epoch 192/300\n",
      "703/703 [==============================] - 1s - loss: 1.6628 - val_loss: 1.6790\n",
      "Epoch 193/300\n",
      "703/703 [==============================] - 1s - loss: 1.6698 - val_loss: 1.6628\n",
      "Epoch 194/300\n",
      "703/703 [==============================] - 1s - loss: 1.6615 - val_loss: 1.6950\n",
      "Epoch 195/300\n",
      "703/703 [==============================] - 1s - loss: 1.6522 - val_loss: 1.6907\n",
      "Epoch 196/300\n",
      "703/703 [==============================] - 1s - loss: 1.6925 - val_loss: 1.6858\n",
      "Epoch 197/300\n",
      "703/703 [==============================] - 1s - loss: 1.6636 - val_loss: 1.6747\n",
      "Epoch 198/300\n",
      "703/703 [==============================] - 1s - loss: 1.6692 - val_loss: 1.6515\n",
      "Epoch 199/300\n",
      "703/703 [==============================] - 1s - loss: 1.6682 - val_loss: 1.6855\n",
      "Epoch 200/300\n",
      "703/703 [==============================] - 1s - loss: 1.6713 - val_loss: 1.6742\n",
      "Epoch 201/300\n",
      "675/703 [===========================>..] - ETA: 0s - loss: 1.6644\n",
      " Reduced learning rate to 0.00011561\n",
      "703/703 [==============================] - 1s - loss: 1.6636 - val_loss: 1.6616\n",
      "Epoch 202/300\n",
      "703/703 [==============================] - 1s - loss: 1.6738 - val_loss: 1.7041\n",
      "Epoch 203/300\n",
      "703/703 [==============================] - 1s - loss: 1.6483 - val_loss: 1.6835\n",
      "Epoch 204/300\n",
      "703/703 [==============================] - 1s - loss: 1.6680 - val_loss: 1.6850\n",
      "Epoch 205/300\n",
      "703/703 [==============================] - 1s - loss: 1.6472 - val_loss: 1.6477\n",
      "Epoch 206/300\n",
      "703/703 [==============================] - 1s - loss: 1.6682 - val_loss: 1.6737\n",
      "Epoch 207/300\n",
      "703/703 [==============================] - 1s - loss: 1.6544 - val_loss: 1.6842\n",
      "Epoch 208/300\n",
      "703/703 [==============================] - 1s - loss: 1.6636 - val_loss: 1.6715\n",
      "Epoch 209/300\n",
      "703/703 [==============================] - 1s - loss: 1.6523 - val_loss: 1.6864\n",
      "Epoch 210/300\n",
      "703/703 [==============================] - 1s - loss: 1.6602 - val_loss: 1.6707\n",
      "Epoch 211/300\n",
      "703/703 [==============================] - 1s - loss: 1.6639 - val_loss: 1.6975\n",
      "Epoch 212/300\n",
      "674/703 [===========================>..] - ETA: 0s - loss: 1.6779\n",
      " Reduced learning rate to 7.70735e-05\n",
      "703/703 [==============================] - 1s - loss: 1.6793 - val_loss: 1.6802\n",
      "Epoch 1/300\n",
      "703/703 [==============================] - 2s - loss: 10.1884 - val_loss: 2.7687\n",
      "Epoch 2/300\n",
      "703/703 [==============================] - 1s - loss: 3.2574 - val_loss: 3.4046\n",
      "Epoch 3/300\n",
      "703/703 [==============================] - 1s - loss: 3.0580 - val_loss: 2.8350\n",
      "Epoch 4/300\n",
      "703/703 [==============================] - 1s - loss: 2.9945 - val_loss: 2.3924\n",
      "Epoch 5/300\n",
      "703/703 [==============================] - 1s - loss: 2.9066 - val_loss: 3.5095\n",
      "Epoch 6/300\n",
      "703/703 [==============================] - 1s - loss: 2.7503 - val_loss: 3.0047\n",
      "Epoch 7/300\n",
      "703/703 [==============================] - 1s - loss: 2.6924 - val_loss: 2.5625\n",
      "Epoch 8/300\n",
      "703/703 [==============================] - 1s - loss: 2.6232 - val_loss: 2.1135\n",
      "Epoch 9/300\n",
      "703/703 [==============================] - 1s - loss: 2.5926 - val_loss: 2.5115\n",
      "Epoch 10/300\n",
      "703/703 [==============================] - 1s - loss: 2.5617 - val_loss: 2.4456\n",
      "Epoch 11/300\n",
      "703/703 [==============================] - 1s - loss: 2.4304 - val_loss: 2.8005\n",
      "Epoch 12/300\n",
      "703/703 [==============================] - 1s - loss: 2.4624 - val_loss: 2.3368\n",
      "Epoch 13/300\n",
      "703/703 [==============================] - 1s - loss: 2.4347 - val_loss: 2.6934\n",
      "Epoch 14/300\n",
      "703/703 [==============================] - 1s - loss: 2.3456 - val_loss: 2.0312\n",
      "Epoch 15/300\n",
      "703/703 [==============================] - 1s - loss: 2.3309 - val_loss: 1.9100\n",
      "Epoch 16/300\n",
      "703/703 [==============================] - 1s - loss: 2.2879 - val_loss: 2.2273\n",
      "Epoch 17/300\n",
      "703/703 [==============================] - 1s - loss: 2.3319 - val_loss: 2.4814\n",
      "Epoch 18/300\n",
      "703/703 [==============================] - 1s - loss: 2.2029 - val_loss: 3.0729\n",
      "Epoch 19/300\n",
      "703/703 [==============================] - 1s - loss: 2.1772 - val_loss: 1.8954\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 2.1922 - val_loss: 2.5711\n",
      "Epoch 21/300\n",
      "703/703 [==============================] - 1s - loss: 2.1823 - val_loss: 2.1727\n",
      "Epoch 22/300\n",
      "703/703 [==============================] - 1s - loss: 2.1560 - val_loss: 2.3662\n",
      "Epoch 23/300\n",
      "703/703 [==============================] - 1s - loss: 2.1108 - val_loss: 1.8015\n",
      "Epoch 24/300\n",
      "703/703 [==============================] - 1s - loss: 2.0988 - val_loss: 1.9012\n",
      "Epoch 25/300\n",
      "703/703 [==============================] - 1s - loss: 2.1211 - val_loss: 1.7684\n",
      "Epoch 26/300\n",
      "703/703 [==============================] - 1s - loss: 2.0720 - val_loss: 1.9058\n",
      "Epoch 27/300\n",
      "703/703 [==============================] - 1s - loss: 2.0500 - val_loss: 1.9652\n",
      "Epoch 28/300\n",
      "703/703 [==============================] - 1s - loss: 2.0381 - val_loss: 2.1130\n",
      "Epoch 29/300\n",
      "703/703 [==============================] - 1s - loss: 2.0309 - val_loss: 2.7774\n",
      "Epoch 30/300\n",
      "703/703 [==============================] - 1s - loss: 2.0680 - val_loss: 1.7997\n",
      "Epoch 31/300\n",
      "703/703 [==============================] - 1s - loss: 2.0381 - val_loss: 2.5911\n",
      "Epoch 32/300\n",
      "703/703 [==============================] - 1s - loss: 1.9835 - val_loss: 1.8418\n",
      "Epoch 33/300\n",
      "703/703 [==============================] - 1s - loss: 1.9911 - val_loss: 1.8078\n",
      "Epoch 34/300\n",
      "703/703 [==============================] - 1s - loss: 1.9938 - val_loss: 1.7949\n",
      "Epoch 35/300\n",
      "703/703 [==============================] - 1s - loss: 2.0336 - val_loss: 1.8559\n",
      "Epoch 36/300\n",
      "673/703 [===========================>..] - ETA: 0s - loss: 1.9671\n",
      " Reduced learning rate to 0.01\n",
      "703/703 [==============================] - 1s - loss: 1.9680 - val_loss: 1.9285\n",
      "Epoch 37/300\n",
      "703/703 [==============================] - 1s - loss: 1.7950 - val_loss: 2.0120\n",
      "Epoch 38/300\n",
      "703/703 [==============================] - 1s - loss: 1.7685 - val_loss: 1.7417\n",
      "Epoch 39/300\n",
      "703/703 [==============================] - 1s - loss: 1.7668 - val_loss: 1.8673\n",
      "Epoch 40/300\n",
      "703/703 [==============================] - 1s - loss: 1.8122 - val_loss: 1.7274\n",
      "Epoch 41/300\n",
      "703/703 [==============================] - 1s - loss: 1.7910 - val_loss: 1.8124\n",
      "Epoch 42/300\n",
      "703/703 [==============================] - 1s - loss: 1.7827 - val_loss: 1.7393\n",
      "Epoch 43/300\n",
      "703/703 [==============================] - 1s - loss: 1.7837 - val_loss: 1.7937\n",
      "Epoch 44/300\n",
      "703/703 [==============================] - 1s - loss: 1.7827 - val_loss: 1.7831\n",
      "Epoch 45/300\n",
      "703/703 [==============================] - 1s - loss: 1.7825 - val_loss: 1.8420\n",
      "Epoch 46/300\n",
      "703/703 [==============================] - 1s - loss: 1.8039 - val_loss: 1.8170\n",
      "Epoch 47/300\n",
      "703/703 [==============================] - 1s - loss: 1.7812 - val_loss: 1.7530\n",
      "Epoch 48/300\n",
      "703/703 [==============================] - 1s - loss: 1.7753 - val_loss: 1.7659\n",
      "Epoch 49/300\n",
      "703/703 [==============================] - 1s - loss: 1.7865 - val_loss: 1.6819\n",
      "Epoch 50/300\n",
      "703/703 [==============================] - 1s - loss: 1.7936 - val_loss: 1.7522\n",
      "Epoch 51/300\n",
      "703/703 [==============================] - 1s - loss: 1.7836 - val_loss: 1.8070\n",
      "Epoch 52/300\n",
      "703/703 [==============================] - ETA: 0s - loss: 1.758 - 1s - loss: 1.7556 - val_loss: 1.7794\n",
      "Epoch 53/300\n",
      "703/703 [==============================] - 1s - loss: 1.7423 - val_loss: 1.9371\n",
      "Epoch 54/300\n",
      "703/703 [==============================] - 1s - loss: 1.7804 - val_loss: 1.7303\n",
      "Epoch 55/300\n",
      "703/703 [==============================] - 1s - loss: 1.7631 - val_loss: 1.9388\n",
      "Epoch 56/300\n",
      "703/703 [==============================] - 1s - loss: 1.7716 - val_loss: 1.7434\n",
      "Epoch 57/300\n",
      "703/703 [==============================] - 1s - loss: 1.7751 - val_loss: 1.7252\n",
      "Epoch 58/300\n",
      "703/703 [==============================] - 1s - loss: 1.7772 - val_loss: 1.7437\n",
      "Epoch 59/300\n",
      "703/703 [==============================] - 1s - loss: 1.7451 - val_loss: 1.8844\n",
      "Epoch 60/300\n",
      "694/703 [============================>.] - ETA: 0s - loss: 1.7947\n",
      " Reduced learning rate to 0.00666667\n",
      "703/703 [==============================] - 1s - loss: 1.7959 - val_loss: 1.6985\n",
      "Epoch 61/300\n",
      "703/703 [==============================] - 1s - loss: 1.7260 - val_loss: 1.7391\n",
      "Epoch 62/300\n",
      "703/703 [==============================] - 1s - loss: 1.7063 - val_loss: 1.7268\n",
      "Epoch 63/300\n",
      "703/703 [==============================] - 1s - loss: 1.7033 - val_loss: 1.7274\n",
      "Epoch 64/300\n",
      "703/703 [==============================] - 1s - loss: 1.7044 - val_loss: 1.7233\n",
      "Epoch 65/300\n",
      "703/703 [==============================] - 1s - loss: 1.7401 - val_loss: 1.7026\n",
      "Epoch 66/300\n",
      "703/703 [==============================] - 1s - loss: 1.7203 - val_loss: 1.7312\n",
      "Epoch 67/300\n",
      "703/703 [==============================] - 1s - loss: 1.7550 - val_loss: 1.7529\n",
      "Epoch 68/300\n",
      "703/703 [==============================] - 1s - loss: 1.7150 - val_loss: 1.8065\n",
      "Epoch 69/300\n",
      "703/703 [==============================] - 1s - loss: 1.7064 - val_loss: 1.6980\n",
      "Epoch 70/300\n",
      "703/703 [==============================] - 1s - loss: 1.7299 - val_loss: 1.7267\n",
      "Epoch 71/300\n",
      "703/703 [==============================] - 1s - loss: 1.7226 - val_loss: 1.6811\n",
      "Epoch 72/300\n",
      "703/703 [==============================] - 1s - loss: 1.7222 - val_loss: 1.6944\n",
      "Epoch 73/300\n",
      "703/703 [==============================] - 1s - loss: 1.6993 - val_loss: 1.6920\n",
      "Epoch 74/300\n",
      "703/703 [==============================] - 1s - loss: 1.7136 - val_loss: 1.7417\n",
      "Epoch 75/300\n",
      "703/703 [==============================] - 1s - loss: 1.7192 - val_loss: 1.7347\n",
      "Epoch 76/300\n",
      "703/703 [==============================] - 1s - loss: 1.7256 - val_loss: 1.7642\n",
      "Epoch 77/300\n",
      "703/703 [==============================] - 1s - loss: 1.7233 - val_loss: 1.7286\n",
      "Epoch 78/300\n",
      "703/703 [==============================] - 1s - loss: 1.7331 - val_loss: 1.7188\n",
      "Epoch 79/300\n",
      "703/703 [==============================] - 1s - loss: 1.7117 - val_loss: 1.7027\n",
      "Epoch 80/300\n",
      "703/703 [==============================] - 1s - loss: 1.7185 - val_loss: 1.7110\n",
      "Epoch 81/300\n",
      "703/703 [==============================] - 1s - loss: 1.7070 - val_loss: 1.7683\n",
      "Epoch 82/300\n",
      "682/703 [============================>.] - ETA: 0s - loss: 1.7251\n",
      " Reduced learning rate to 0.00444444\n",
      "703/703 [==============================] - 1s - loss: 1.7204 - val_loss: 1.6882\n",
      "Epoch 83/300\n",
      "703/703 [==============================] - 1s - loss: 1.6975 - val_loss: 1.6863\n",
      "Epoch 84/300\n",
      "703/703 [==============================] - 1s - loss: 1.7067 - val_loss: 1.7558\n",
      "Epoch 85/300\n",
      "703/703 [==============================] - 1s - loss: 1.6981 - val_loss: 1.7794\n",
      "Epoch 86/300\n",
      "703/703 [==============================] - 1s - loss: 1.7003 - val_loss: 1.6717\n",
      "Epoch 87/300\n",
      "703/703 [==============================] - 1s - loss: 1.6917 - val_loss: 1.6959\n",
      "Epoch 88/300\n",
      "703/703 [==============================] - 1s - loss: 1.6880 - val_loss: 1.7148\n",
      "Epoch 89/300\n",
      "703/703 [==============================] - 1s - loss: 1.7002 - val_loss: 1.7506\n",
      "Epoch 90/300\n",
      "703/703 [==============================] - 1s - loss: 1.6960 - val_loss: 1.6957\n",
      "Epoch 91/300\n",
      "703/703 [==============================] - 1s - loss: 1.6864 - val_loss: 1.6814\n",
      "Epoch 92/300\n",
      "703/703 [==============================] - 1s - loss: 1.6888 - val_loss: 1.7390\n",
      "Epoch 93/300\n",
      "703/703 [==============================] - 1s - loss: 1.7053 - val_loss: 1.6875\n",
      "Epoch 94/300\n",
      "703/703 [==============================] - 1s - loss: 1.7075 - val_loss: 1.7037\n",
      "Epoch 95/300\n",
      "703/703 [==============================] - 1s - loss: 1.7066 - val_loss: 1.6678\n",
      "Epoch 96/300\n",
      "703/703 [==============================] - 1s - loss: 1.6797 - val_loss: 1.7483\n",
      "Epoch 97/300\n",
      "703/703 [==============================] - 1s - loss: 1.7238 - val_loss: 1.7054\n",
      "Epoch 98/300\n",
      "703/703 [==============================] - 1s - loss: 1.6833 - val_loss: 1.6554\n",
      "Epoch 99/300\n",
      "703/703 [==============================] - 1s - loss: 1.6865 - val_loss: 1.7166\n",
      "Epoch 100/300\n",
      "703/703 [==============================] - 1s - loss: 1.6869 - val_loss: 1.6965\n",
      "Epoch 101/300\n",
      "703/703 [==============================] - 1s - loss: 1.6893 - val_loss: 1.7001\n",
      "Epoch 102/300\n",
      "703/703 [==============================] - 1s - loss: 1.6779 - val_loss: 1.6936\n",
      "Epoch 103/300\n",
      "703/703 [==============================] - 1s - loss: 1.6698 - val_loss: 1.7476\n",
      "Epoch 104/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.7065 - val_loss: 1.6826\n",
      "Epoch 105/300\n",
      "703/703 [==============================] - 1s - loss: 1.6923 - val_loss: 1.7046\n",
      "Epoch 106/300\n",
      "703/703 [==============================] - 1s - loss: 1.6893 - val_loss: 1.7346\n",
      "Epoch 107/300\n",
      "703/703 [==============================] - 1s - loss: 1.6924 - val_loss: 1.7322\n",
      "Epoch 108/300\n",
      "703/703 [==============================] - 1s - loss: 1.6848 - val_loss: 1.6827\n",
      "Epoch 109/300\n",
      "688/703 [============================>.] - ETA: 0s - loss: 1.6810\n",
      " Reduced learning rate to 0.00296296\n",
      "703/703 [==============================] - 1s - loss: 1.6781 - val_loss: 1.7693\n",
      "Epoch 110/300\n",
      "703/703 [==============================] - 1s - loss: 1.6961 - val_loss: 1.6988\n",
      "Epoch 111/300\n",
      "703/703 [==============================] - 1s - loss: 1.7014 - val_loss: 1.6932\n",
      "Epoch 112/300\n",
      "703/703 [==============================] - 1s - loss: 1.6812 - val_loss: 1.7015\n",
      "Epoch 113/300\n",
      "703/703 [==============================] - 1s - loss: 1.6832 - val_loss: 1.7234\n",
      "Epoch 114/300\n",
      "703/703 [==============================] - 1s - loss: 1.6757 - val_loss: 1.6845\n",
      "Epoch 115/300\n",
      "703/703 [==============================] - 1s - loss: 1.6887 - val_loss: 1.7063\n",
      "Epoch 116/300\n",
      "703/703 [==============================] - 1s - loss: 1.6652 - val_loss: 1.6580ss: 1.66\n",
      "Epoch 117/300\n",
      "703/703 [==============================] - 1s - loss: 1.6765 - val_loss: 1.7116\n",
      "Epoch 118/300\n",
      "703/703 [==============================] - 1s - loss: 1.6666 - val_loss: 1.6832\n",
      "Epoch 119/300\n",
      "703/703 [==============================] - 1s - loss: 1.6998 - val_loss: 1.6858\n",
      "Epoch 120/300\n",
      "701/703 [============================>.] - ETA: 0s - loss: 1.6802\n",
      " Reduced learning rate to 0.00197531\n",
      "703/703 [==============================] - 1s - loss: 1.6806 - val_loss: 1.7099\n",
      "Epoch 121/300\n",
      "703/703 [==============================] - 1s - loss: 1.6715 - val_loss: 1.6881\n",
      "Epoch 122/300\n",
      "703/703 [==============================] - 1s - loss: 1.6737 - val_loss: 1.7034\n",
      "Epoch 123/300\n",
      "703/703 [==============================] - 1s - loss: 1.6725 - val_loss: 1.6785\n",
      "Epoch 124/300\n",
      "703/703 [==============================] - 1s - loss: 1.6810 - val_loss: 1.6454\n",
      "Epoch 125/300\n",
      "703/703 [==============================] - 1s - loss: 1.6879 - val_loss: 1.7017\n",
      "Epoch 126/300\n",
      "703/703 [==============================] - 1s - loss: 1.6616 - val_loss: 1.6563\n",
      "Epoch 127/300\n",
      "703/703 [==============================] - 1s - loss: 1.6600 - val_loss: 1.7008\n",
      "Epoch 128/300\n",
      "703/703 [==============================] - 1s - loss: 1.6728 - val_loss: 1.6541\n",
      "Epoch 129/300\n",
      "703/703 [==============================] - 1s - loss: 1.6621 - val_loss: 1.6939\n",
      "Epoch 130/300\n",
      "703/703 [==============================] - 1s - loss: 1.6925 - val_loss: 1.6306\n",
      "Epoch 131/300\n",
      "703/703 [==============================] - 1s - loss: 1.6763 - val_loss: 1.7108\n",
      "Epoch 132/300\n",
      "703/703 [==============================] - 1s - loss: 1.6794 - val_loss: 1.6644\n",
      "Epoch 133/300\n",
      "703/703 [==============================] - 1s - loss: 1.6790 - val_loss: 1.7113\n",
      "Epoch 134/300\n",
      "703/703 [==============================] - 1s - loss: 1.6907 - val_loss: 1.6955\n",
      "Epoch 135/300\n",
      "703/703 [==============================] - 1s - loss: 1.6638 - val_loss: 1.6908\n",
      "Epoch 136/300\n",
      "703/703 [==============================] - 1s - loss: 1.6655 - val_loss: 1.6797\n",
      "Epoch 137/300\n",
      "703/703 [==============================] - 1s - loss: 1.6642 - val_loss: 1.6897\n",
      "Epoch 138/300\n",
      "703/703 [==============================] - 1s - loss: 1.6735 - val_loss: 1.6685\n",
      "Epoch 139/300\n",
      "703/703 [==============================] - 1s - loss: 1.6625 - val_loss: 1.7020\n",
      "Epoch 140/300\n",
      "703/703 [==============================] - 1s - loss: 1.6929 - val_loss: 1.6968\n",
      "Epoch 141/300\n",
      "695/703 [============================>.] - ETA: 0s - loss: 1.6916\n",
      " Reduced learning rate to 0.00131687\n",
      "703/703 [==============================] - 1s - loss: 1.6932 - val_loss: 1.6899\n",
      "Epoch 142/300\n",
      "703/703 [==============================] - 1s - loss: 1.6649 - val_loss: 1.6491\n",
      "Epoch 143/300\n",
      "703/703 [==============================] - 1s - loss: 1.6664 - val_loss: 1.6942\n",
      "Epoch 144/300\n",
      "703/703 [==============================] - 1s - loss: 1.6835 - val_loss: 1.6791\n",
      "Epoch 145/300\n",
      "703/703 [==============================] - 1s - loss: 1.6716 - val_loss: 1.7168\n",
      "Epoch 146/300\n",
      "703/703 [==============================] - 1s - loss: 1.6780 - val_loss: 1.7116\n",
      "Epoch 147/300\n",
      "703/703 [==============================] - 1s - loss: 1.6549 - val_loss: 1.6731\n",
      "Epoch 148/300\n",
      "703/703 [==============================] - 1s - loss: 1.6644 - val_loss: 1.6404\n",
      "Epoch 149/300\n",
      "703/703 [==============================] - 1s - loss: 1.6706 - val_loss: 1.7196\n",
      "Epoch 150/300\n",
      "703/703 [==============================] - 1s - loss: 1.6713 - val_loss: 1.7279\n",
      "Epoch 151/300\n",
      "703/703 [==============================] - 1s - loss: 1.6643 - val_loss: 1.6599\n",
      "Epoch 152/300\n",
      "660/703 [===========================>..] - ETA: 0s - loss: 1.6736\n",
      " Reduced learning rate to 0.000877915\n",
      "703/703 [==============================] - 1s - loss: 1.6714 - val_loss: 1.6953\n",
      "Epoch 153/300\n",
      "703/703 [==============================] - 1s - loss: 1.6496 - val_loss: 1.6665\n",
      "Epoch 154/300\n",
      "703/703 [==============================] - 1s - loss: 1.6497 - val_loss: 1.6632\n",
      "Epoch 155/300\n",
      "703/703 [==============================] - 1s - loss: 1.6668 - val_loss: 1.6376\n",
      "Epoch 156/300\n",
      "703/703 [==============================] - 1s - loss: 1.6959 - val_loss: 1.6469\n",
      "Epoch 157/300\n",
      "703/703 [==============================] - 0s - loss: 1.6858 - val_loss: 1.6765\n",
      "Epoch 158/300\n",
      "703/703 [==============================] - 0s - loss: 1.6464 - val_loss: 1.6746\n",
      "Epoch 159/300\n",
      "703/703 [==============================] - 0s - loss: 1.6570 - val_loss: 1.6722\n",
      "Epoch 160/300\n",
      "703/703 [==============================] - 0s - loss: 1.6644 - val_loss: 1.6881\n",
      "Epoch 161/300\n",
      "703/703 [==============================] - 0s - loss: 1.6635 - val_loss: 1.6597\n",
      "Epoch 162/300\n",
      "703/703 [==============================] - 1s - loss: 1.6721 - val_loss: 1.6658\n",
      "Epoch 163/300\n",
      "685/703 [============================>.] - ETA: 0s - loss: 1.6767\n",
      " Reduced learning rate to 0.000585277\n",
      "703/703 [==============================] - 1s - loss: 1.6759 - val_loss: 1.6588\n",
      "Epoch 164/300\n",
      "703/703 [==============================] - 1s - loss: 1.6546 - val_loss: 1.6720\n",
      "Epoch 165/300\n",
      "703/703 [==============================] - 1s - loss: 1.6550 - val_loss: 1.6445\n",
      "Epoch 166/300\n",
      "703/703 [==============================] - 1s - loss: 1.6493 - val_loss: 1.6484\n",
      "Epoch 167/300\n",
      "703/703 [==============================] - 1s - loss: 1.6591 - val_loss: 1.6432\n",
      "Epoch 168/300\n",
      "703/703 [==============================] - 1s - loss: 1.6402 - val_loss: 1.6656\n",
      "Epoch 169/300\n",
      "703/703 [==============================] - 1s - loss: 1.6970 - val_loss: 1.6559\n",
      "Epoch 170/300\n",
      "703/703 [==============================] - 1s - loss: 1.6635 - val_loss: 1.6407\n",
      "Epoch 171/300\n",
      "703/703 [==============================] - 1s - loss: 1.6788 - val_loss: 1.6668\n",
      "Epoch 172/300\n",
      "703/703 [==============================] - 1s - loss: 1.6789 - val_loss: 1.6897\n",
      "Epoch 173/300\n",
      "703/703 [==============================] - 1s - loss: 1.6638 - val_loss: 1.6884\n",
      "Epoch 174/300\n",
      "675/703 [===========================>..] - ETA: 0s - loss: 1.6805\n",
      " Reduced learning rate to 0.000390184\n",
      "703/703 [==============================] - 1s - loss: 1.6788 - val_loss: 1.6635\n",
      "Epoch 175/300\n",
      "703/703 [==============================] - 1s - loss: 1.6583 - val_loss: 1.6879\n",
      "Epoch 176/300\n",
      "703/703 [==============================] - 1s - loss: 1.6497 - val_loss: 1.6604\n",
      "Epoch 177/300\n",
      "703/703 [==============================] - 1s - loss: 1.6489 - val_loss: 1.6577\n",
      "Epoch 178/300\n",
      "703/703 [==============================] - 1s - loss: 1.6487 - val_loss: 1.6625\n",
      "Epoch 179/300\n",
      "703/703 [==============================] - 1s - loss: 1.6591 - val_loss: 1.6625\n",
      "Epoch 180/300\n",
      "703/703 [==============================] - 1s - loss: 1.6687 - val_loss: 1.6803\n",
      "Epoch 181/300\n",
      "703/703 [==============================] - 1s - loss: 1.6619 - val_loss: 1.6926\n",
      "Epoch 182/300\n",
      "703/703 [==============================] - 1s - loss: 1.6717 - val_loss: 1.7170\n",
      "Epoch 183/300\n",
      "703/703 [==============================] - 1s - loss: 1.6645 - val_loss: 1.6385\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.6590 - val_loss: 1.6758\n",
      "Epoch 185/300\n",
      "699/703 [============================>.] - ETA: 0s - loss: 1.6789\n",
      " Reduced learning rate to 0.000260123\n",
      "703/703 [==============================] - 1s - loss: 1.6787 - val_loss: 1.7263\n",
      "Epoch 186/300\n",
      "703/703 [==============================] - 1s - loss: 1.6719 - val_loss: 1.6704\n",
      "Epoch 187/300\n",
      "703/703 [==============================] - 1s - loss: 1.6568 - val_loss: 1.6941\n",
      "Epoch 188/300\n",
      "703/703 [==============================] - 1s - loss: 1.6763 - val_loss: 1.6955\n",
      "Epoch 189/300\n",
      "703/703 [==============================] - 1s - loss: 1.6629 - val_loss: 1.6445\n",
      "Epoch 190/300\n",
      "703/703 [==============================] - 1s - loss: 1.6571 - val_loss: 1.6794\n",
      "Epoch 191/300\n",
      "703/703 [==============================] - 1s - loss: 1.6682 - val_loss: 1.6428\n",
      "Epoch 192/300\n",
      "703/703 [==============================] - 1s - loss: 1.6634 - val_loss: 1.6461\n",
      "Epoch 193/300\n",
      "703/703 [==============================] - 1s - loss: 1.6731 - val_loss: 1.6795\n",
      "Epoch 194/300\n",
      "703/703 [==============================] - 1s - loss: 1.6644 - val_loss: 1.6722\n",
      "Epoch 195/300\n",
      "703/703 [==============================] - 0s - loss: 1.6416 - val_loss: 1.6960\n",
      "Epoch 196/300\n",
      "681/703 [============================>.] - ETA: 0s - loss: 1.6711\n",
      " Reduced learning rate to 0.000173415\n",
      "703/703 [==============================] - 1s - loss: 1.6716 - val_loss: 1.6699\n",
      "Epoch 197/300\n",
      "703/703 [==============================] - 1s - loss: 1.6835 - val_loss: 1.6812\n",
      "Epoch 198/300\n",
      "703/703 [==============================] - 1s - loss: 1.6577 - val_loss: 1.6734\n",
      "Epoch 199/300\n",
      "703/703 [==============================] - 1s - loss: 1.6648 - val_loss: 1.6565\n",
      "Epoch 200/300\n",
      "703/703 [==============================] - 1s - loss: 1.6911 - val_loss: 1.7215\n",
      "Epoch 201/300\n",
      "703/703 [==============================] - 1s - loss: 1.6747 - val_loss: 1.6741\n",
      "Epoch 202/300\n",
      "703/703 [==============================] - 1s - loss: 1.6501 - val_loss: 1.6512\n",
      "Epoch 203/300\n",
      "703/703 [==============================] - 1s - loss: 1.6638 - val_loss: 1.6672\n",
      "Epoch 204/300\n",
      "703/703 [==============================] - 1s - loss: 1.6812 - val_loss: 1.6481\n",
      "Epoch 205/300\n",
      "703/703 [==============================] - 1s - loss: 1.6558 - val_loss: 1.6666\n",
      "Epoch 206/300\n",
      "703/703 [==============================] - 1s - loss: 1.6723 - val_loss: 1.6897\n",
      "Epoch 207/300\n",
      "682/703 [============================>.] - ETA: 0s - loss: 1.6508\n",
      " Reduced learning rate to 0.00011561\n",
      "703/703 [==============================] - 1s - loss: 1.6494 - val_loss: 1.6891\n",
      "Epoch 208/300\n",
      "703/703 [==============================] - 1s - loss: 1.6766 - val_loss: 1.6577\n",
      "Epoch 209/300\n",
      "703/703 [==============================] - 1s - loss: 1.6709 - val_loss: 1.6887\n",
      "Epoch 210/300\n",
      "703/703 [==============================] - 1s - loss: 1.6647 - val_loss: 1.6609\n",
      "Epoch 211/300\n",
      "703/703 [==============================] - 1s - loss: 1.6745 - val_loss: 1.6481\n",
      "Epoch 212/300\n",
      "703/703 [==============================] - 1s - loss: 1.6675 - val_loss: 1.6812\n",
      "Epoch 213/300\n",
      "703/703 [==============================] - 1s - loss: 1.6490 - val_loss: 1.6724\n",
      "Epoch 214/300\n",
      "703/703 [==============================] - 1s - loss: 1.6510 - val_loss: 1.6860\n",
      "Epoch 215/300\n",
      "703/703 [==============================] - 1s - loss: 1.6605 - val_loss: 1.6526\n",
      "Epoch 216/300\n",
      "703/703 [==============================] - 1s - loss: 1.6440 - val_loss: 1.6803\n",
      "Epoch 217/300\n",
      "703/703 [==============================] - 1s - loss: 1.6552 - val_loss: 1.6717ss: 1.64\n",
      "Epoch 218/300\n",
      "675/703 [===========================>..] - ETA: 0s - loss: 1.6701\n",
      " Reduced learning rate to 7.70735e-05\n",
      "703/703 [==============================] - 1s - loss: 1.6713 - val_loss: 1.6639\n",
      "Epoch 1/300\n",
      "703/703 [==============================] - 2s - loss: 11.1414 - val_loss: 3.1289\n",
      "Epoch 2/300\n",
      "703/703 [==============================] - 1s - loss: 3.2368 - val_loss: 4.8779\n",
      "Epoch 3/300\n",
      "703/703 [==============================] - 1s - loss: 3.0436 - val_loss: 3.5449\n",
      "Epoch 4/300\n",
      "703/703 [==============================] - 1s - loss: 2.9639 - val_loss: 2.5283\n",
      "Epoch 5/300\n",
      "703/703 [==============================] - 1s - loss: 2.8603 - val_loss: 2.9275\n",
      "Epoch 6/300\n",
      "703/703 [==============================] - 1s - loss: 2.7668 - val_loss: 2.7131\n",
      "Epoch 7/300\n",
      "703/703 [==============================] - 1s - loss: 2.6949 - val_loss: 4.1911\n",
      "Epoch 8/300\n",
      "703/703 [==============================] - 1s - loss: 2.6721 - val_loss: 1.9406\n",
      "Epoch 9/300\n",
      "703/703 [==============================] - 1s - loss: 2.5420 - val_loss: 2.5895\n",
      "Epoch 10/300\n",
      "703/703 [==============================] - 1s - loss: 2.5884 - val_loss: 2.0037\n",
      "Epoch 11/300\n",
      "703/703 [==============================] - 1s - loss: 2.4877 - val_loss: 1.8834\n",
      "Epoch 12/300\n",
      "703/703 [==============================] - 1s - loss: 2.5231 - val_loss: 1.8528\n",
      "Epoch 13/300\n",
      "703/703 [==============================] - 1s - loss: 2.3353 - val_loss: 3.6778\n",
      "Epoch 14/300\n",
      "703/703 [==============================] - 1s - loss: 2.3512 - val_loss: 2.3191\n",
      "Epoch 15/300\n",
      "703/703 [==============================] - 1s - loss: 2.3253 - val_loss: 1.9200\n",
      "Epoch 16/300\n",
      "703/703 [==============================] - 1s - loss: 2.2865 - val_loss: 1.9560\n",
      "Epoch 17/300\n",
      "703/703 [==============================] - 1s - loss: 2.2226 - val_loss: 1.9829\n",
      "Epoch 18/300\n",
      "703/703 [==============================] - 1s - loss: 2.2397 - val_loss: 1.8348\n",
      "Epoch 19/300\n",
      "703/703 [==============================] - 1s - loss: 2.1947 - val_loss: 2.4063\n",
      "Epoch 20/300\n",
      "703/703 [==============================] - 1s - loss: 2.2037 - val_loss: 2.7232\n",
      "Epoch 21/300\n",
      "703/703 [==============================] - 1s - loss: 2.2057 - val_loss: 2.3417\n",
      "Epoch 22/300\n",
      "703/703 [==============================] - 1s - loss: 2.1776 - val_loss: 2.0762\n",
      "Epoch 23/300\n",
      "703/703 [==============================] - 1s - loss: 2.1075 - val_loss: 1.8005\n",
      "Epoch 24/300\n",
      "703/703 [==============================] - 1s - loss: 2.1107 - val_loss: 1.9022\n",
      "Epoch 25/300\n",
      "703/703 [==============================] - 1s - loss: 2.1079 - val_loss: 1.8906\n",
      "Epoch 26/300\n",
      "703/703 [==============================] - 1s - loss: 2.1045 - val_loss: 2.5492\n",
      "Epoch 27/300\n",
      "703/703 [==============================] - 1s - loss: 2.0561 - val_loss: 1.8486\n",
      "Epoch 28/300\n",
      "703/703 [==============================] - 1s - loss: 2.0306 - val_loss: 1.7965\n",
      "Epoch 29/300\n",
      "703/703 [==============================] - 1s - loss: 2.0794 - val_loss: 1.8941\n",
      "Epoch 30/300\n",
      "703/703 [==============================] - 1s - loss: 1.9959 - val_loss: 2.0169\n",
      "Epoch 31/300\n",
      "703/703 [==============================] - 1s - loss: 2.0072 - val_loss: 1.8069\n",
      "Epoch 32/300\n",
      "703/703 [==============================] - 1s - loss: 2.0028 - val_loss: 2.2405\n",
      "Epoch 33/300\n",
      "703/703 [==============================] - 1s - loss: 1.9940 - val_loss: 1.8101\n",
      "Epoch 34/300\n",
      "703/703 [==============================] - 1s - loss: 1.9792 - val_loss: 2.0823\n",
      "Epoch 35/300\n",
      "703/703 [==============================] - 1s - loss: 2.0156 - val_loss: 2.1505\n",
      "Epoch 36/300\n",
      "703/703 [==============================] - 1s - loss: 1.9539 - val_loss: 1.7883\n",
      "Epoch 37/300\n",
      "703/703 [==============================] - 1s - loss: 1.9480 - val_loss: 1.8425\n",
      "Epoch 38/300\n",
      "703/703 [==============================] - 1s - loss: 2.0161 - val_loss: 2.8934\n",
      "Epoch 39/300\n",
      "703/703 [==============================] - 1s - loss: 1.9468 - val_loss: 1.8110\n",
      "Epoch 40/300\n",
      "703/703 [==============================] - 1s - loss: 1.9784 - val_loss: 1.9133\n",
      "Epoch 41/300\n",
      "703/703 [==============================] - 1s - loss: 1.9372 - val_loss: 1.8371\n",
      "Epoch 42/300\n",
      "703/703 [==============================] - 1s - loss: 1.9515 - val_loss: 1.8410\n",
      "Epoch 43/300\n",
      "703/703 [==============================] - 1s - loss: 1.9627 - val_loss: 2.0191\n",
      "Epoch 44/300\n",
      "703/703 [==============================] - 1s - loss: 1.9495 - val_loss: 1.7650\n",
      "Epoch 45/300\n",
      "703/703 [==============================] - 1s - loss: 1.9146 - val_loss: 2.1820\n",
      "Epoch 46/300\n",
      "703/703 [==============================] - 1s - loss: 1.9226 - val_loss: 1.7983\n",
      "Epoch 47/300\n",
      "703/703 [==============================] - 1s - loss: 1.9060 - val_loss: 1.8578\n",
      "Epoch 48/300\n",
      "703/703 [==============================] - 1s - loss: 1.9057 - val_loss: 1.8930\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.8755 - val_loss: 1.7760\n",
      "Epoch 50/300\n",
      "703/703 [==============================] - 1s - loss: 1.8810 - val_loss: 2.1182\n",
      "Epoch 51/300\n",
      "703/703 [==============================] - 1s - loss: 1.9097 - val_loss: 2.0964\n",
      "Epoch 52/300\n",
      "703/703 [==============================] - 1s - loss: 1.8817 - val_loss: 1.7989\n",
      "Epoch 53/300\n",
      "703/703 [==============================] - 1s - loss: 1.8702 - val_loss: 2.8078\n",
      "Epoch 54/300\n",
      "703/703 [==============================] - 1s - loss: 1.9336 - val_loss: 1.7949\n",
      "Epoch 55/300\n",
      "688/703 [============================>.] - ETA: 0s - loss: 1.8893\n",
      " Reduced learning rate to 0.01\n",
      "703/703 [==============================] - 1s - loss: 1.8931 - val_loss: 1.7682\n",
      "Epoch 56/300\n",
      "703/703 [==============================] - 1s - loss: 1.7638 - val_loss: 1.7082\n",
      "Epoch 57/300\n",
      "703/703 [==============================] - 1s - loss: 1.7578 - val_loss: 1.8048\n",
      "Epoch 58/300\n",
      "703/703 [==============================] - 1s - loss: 1.7721 - val_loss: 1.7491\n",
      "Epoch 59/300\n",
      "703/703 [==============================] - 1s - loss: 1.7475 - val_loss: 1.7393\n",
      "Epoch 60/300\n",
      "703/703 [==============================] - 1s - loss: 1.7675 - val_loss: 1.9834\n",
      "Epoch 61/300\n",
      "703/703 [==============================] - 1s - loss: 1.7421 - val_loss: 2.0847\n",
      "Epoch 62/300\n",
      "703/703 [==============================] - 1s - loss: 1.7722 - val_loss: 1.7267\n",
      "Epoch 63/300\n",
      "703/703 [==============================] - 1s - loss: 1.7767 - val_loss: 1.9092\n",
      "Epoch 64/300\n",
      "703/703 [==============================] - 1s - loss: 1.7309 - val_loss: 1.8106\n",
      "Epoch 65/300\n",
      "703/703 [==============================] - 1s - loss: 1.7380 - val_loss: 1.7479\n",
      "Epoch 66/300\n",
      "703/703 [==============================] - 1s - loss: 1.7629 - val_loss: 1.7727\n",
      "Epoch 67/300\n",
      "690/703 [============================>.] - ETA: 0s - loss: 1.7584\n",
      " Reduced learning rate to 0.00666667\n",
      "703/703 [==============================] - 1s - loss: 1.7575 - val_loss: 1.7324\n",
      "Epoch 68/300\n",
      "703/703 [==============================] - 1s - loss: 1.7114 - val_loss: 1.7444\n",
      "Epoch 69/300\n",
      "703/703 [==============================] - 1s - loss: 1.7003 - val_loss: 1.7556\n",
      "Epoch 70/300\n",
      "703/703 [==============================] - 1s - loss: 1.7311 - val_loss: 1.7134\n",
      "Epoch 71/300\n",
      "703/703 [==============================] - 1s - loss: 1.6986 - val_loss: 1.7134\n",
      "Epoch 72/300\n",
      "703/703 [==============================] - 1s - loss: 1.7237 - val_loss: 1.7202\n",
      "Epoch 73/300\n",
      "703/703 [==============================] - 1s - loss: 1.7283 - val_loss: 1.7366\n",
      "Epoch 74/300\n",
      "703/703 [==============================] - 1s - loss: 1.7133 - val_loss: 1.7483\n",
      "Epoch 75/300\n",
      "703/703 [==============================] - 0s - loss: 1.7237 - val_loss: 1.8208\n",
      "Epoch 76/300\n",
      "703/703 [==============================] - 1s - loss: 1.7241 - val_loss: 1.7552\n",
      "Epoch 77/300\n",
      "703/703 [==============================] - 1s - loss: 1.7142 - val_loss: 1.8971\n",
      "Epoch 78/300\n",
      "671/703 [===========================>..] - ETA: 0s - loss: 1.7305\n",
      " Reduced learning rate to 0.00444444\n",
      "703/703 [==============================] - 1s - loss: 1.7322 - val_loss: 1.7094\n",
      "Epoch 79/300\n",
      "703/703 [==============================] - 1s - loss: 1.7022 - val_loss: 1.8127\n",
      "Epoch 80/300\n",
      "703/703 [==============================] - 1s - loss: 1.6979 - val_loss: 1.7311\n",
      "Epoch 81/300\n",
      "703/703 [==============================] - 1s - loss: 1.7025 - val_loss: 1.6899\n",
      "Epoch 82/300\n",
      "703/703 [==============================] - 1s - loss: 1.6994 - val_loss: 1.7186\n",
      "Epoch 83/300\n",
      "703/703 [==============================] - 1s - loss: 1.7193 - val_loss: 1.6676\n",
      "Epoch 84/300\n",
      "703/703 [==============================] - 1s - loss: 1.7079 - val_loss: 1.7520\n",
      "Epoch 85/300\n",
      "703/703 [==============================] - 1s - loss: 1.6853 - val_loss: 1.7558\n",
      "Epoch 86/300\n",
      "703/703 [==============================] - 1s - loss: 1.6695 - val_loss: 1.6958\n",
      "Epoch 87/300\n",
      "703/703 [==============================] - 1s - loss: 1.6973 - val_loss: 1.7187\n",
      "Epoch 88/300\n",
      "703/703 [==============================] - 1s - loss: 1.6886 - val_loss: 1.7186\n",
      "Epoch 89/300\n",
      "703/703 [==============================] - 1s - loss: 1.6813 - val_loss: 1.7093\n",
      "Epoch 90/300\n",
      "703/703 [==============================] - 1s - loss: 1.7254 - val_loss: 1.7195\n",
      "Epoch 91/300\n",
      "703/703 [==============================] - 1s - loss: 1.6808 - val_loss: 1.7579\n",
      "Epoch 92/300\n",
      "703/703 [==============================] - 1s - loss: 1.6693 - val_loss: 1.6978\n",
      "Epoch 93/300\n",
      "703/703 [==============================] - 1s - loss: 1.7032 - val_loss: 1.6975\n",
      "Epoch 94/300\n",
      "686/703 [============================>.] - ETA: 0s - loss: 1.6958\n",
      " Reduced learning rate to 0.00296296\n",
      "703/703 [==============================] - 1s - loss: 1.6952 - val_loss: 1.7418\n",
      "Epoch 95/300\n",
      "703/703 [==============================] - 1s - loss: 1.6672 - val_loss: 1.6874\n",
      "Epoch 96/300\n",
      "703/703 [==============================] - 1s - loss: 1.6829 - val_loss: 1.6646\n",
      "Epoch 97/300\n",
      "703/703 [==============================] - 1s - loss: 1.6772 - val_loss: 1.7103\n",
      "Epoch 98/300\n",
      "703/703 [==============================] - 1s - loss: 1.6952 - val_loss: 1.7060\n",
      "Epoch 99/300\n",
      "703/703 [==============================] - 1s - loss: 1.6694 - val_loss: 1.6990\n",
      "Epoch 100/300\n",
      "703/703 [==============================] - 1s - loss: 1.6913 - val_loss: 1.7162\n",
      "Epoch 101/300\n",
      "703/703 [==============================] - 1s - loss: 1.6875 - val_loss: 1.7003\n",
      "Epoch 102/300\n",
      "703/703 [==============================] - 1s - loss: 1.6774 - val_loss: 1.7224\n",
      "Epoch 103/300\n",
      "703/703 [==============================] - 1s - loss: 1.6775 - val_loss: 1.6763\n",
      "Epoch 104/300\n",
      "703/703 [==============================] - 1s - loss: 1.6722 - val_loss: 1.7156\n",
      "Epoch 105/300\n",
      "703/703 [==============================] - 1s - loss: 1.6952 - val_loss: 1.7118\n",
      "Epoch 106/300\n",
      "703/703 [==============================] - 1s - loss: 1.6794 - val_loss: 1.6717\n",
      "Epoch 107/300\n",
      "678/703 [===========================>..] - ETA: 0s - loss: 1.6757\n",
      " Reduced learning rate to 0.00197531\n",
      "703/703 [==============================] - 1s - loss: 1.6715 - val_loss: 1.7275\n",
      "Epoch 108/300\n",
      "703/703 [==============================] - 1s - loss: 1.6677 - val_loss: 1.6979\n",
      "Epoch 109/300\n",
      "703/703 [==============================] - 1s - loss: 1.6612 - val_loss: 1.6820\n",
      "Epoch 110/300\n",
      "703/703 [==============================] - 1s - loss: 1.6790 - val_loss: 1.7260\n",
      "Epoch 111/300\n",
      "703/703 [==============================] - 1s - loss: 1.6737 - val_loss: 1.7001\n",
      "Epoch 112/300\n",
      "703/703 [==============================] - 1s - loss: 1.6692 - val_loss: 1.7053\n",
      "Epoch 113/300\n",
      "703/703 [==============================] - 1s - loss: 1.6900 - val_loss: 1.6663\n",
      "Epoch 114/300\n",
      "703/703 [==============================] - 1s - loss: 1.6744 - val_loss: 1.6898\n",
      "Epoch 115/300\n",
      "703/703 [==============================] - 1s - loss: 1.6597 - val_loss: 1.7162\n",
      "Epoch 116/300\n",
      "703/703 [==============================] - 1s - loss: 1.6517 - val_loss: 1.7016\n",
      "Epoch 117/300\n",
      "703/703 [==============================] - 1s - loss: 1.6814 - val_loss: 1.6821\n",
      "Epoch 118/300\n",
      "692/703 [============================>.] - ETA: 0s - loss: 1.6563\n",
      " Reduced learning rate to 0.00131687\n",
      "703/703 [==============================] - 1s - loss: 1.6566 - val_loss: 1.6804\n",
      "Epoch 119/300\n",
      "703/703 [==============================] - 1s - loss: 1.6554 - val_loss: 1.6598\n",
      "Epoch 120/300\n",
      "703/703 [==============================] - 1s - loss: 1.6835 - val_loss: 1.6912\n",
      "Epoch 121/300\n",
      "703/703 [==============================] - 1s - loss: 1.6700 - val_loss: 1.6647\n",
      "Epoch 122/300\n",
      "703/703 [==============================] - 1s - loss: 1.6705 - val_loss: 1.6951\n",
      "Epoch 123/300\n",
      "703/703 [==============================] - 1s - loss: 1.6540 - val_loss: 1.6731\n",
      "Epoch 124/300\n",
      "703/703 [==============================] - 1s - loss: 1.6767 - val_loss: 1.7156\n",
      "Epoch 125/300\n",
      "703/703 [==============================] - 1s - loss: 1.6762 - val_loss: 1.6868\n",
      "Epoch 126/300\n",
      "703/703 [==============================] - 1s - loss: 1.6808 - val_loss: 1.7296\n",
      "Epoch 127/300\n",
      "703/703 [==============================] - 1s - loss: 1.6775 - val_loss: 1.6917\n",
      "Epoch 128/300\n",
      "703/703 [==============================] - 1s - loss: 1.6556 - val_loss: 1.6879\n",
      "Epoch 129/300\n",
      "703/703 [==============================] - 1s - loss: 1.6633 - val_loss: 1.6611\n",
      "Epoch 130/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.6884 - val_loss: 1.6455\n",
      "Epoch 131/300\n",
      "703/703 [==============================] - 1s - loss: 1.6730 - val_loss: 1.7163\n",
      "Epoch 132/300\n",
      "703/703 [==============================] - 1s - loss: 1.6932 - val_loss: 1.7180\n",
      "Epoch 133/300\n",
      "703/703 [==============================] - 1s - loss: 1.6588 - val_loss: 1.7391\n",
      "Epoch 134/300\n",
      "703/703 [==============================] - 1s - loss: 1.6473 - val_loss: 1.6953\n",
      "Epoch 135/300\n",
      "703/703 [==============================] - 1s - loss: 1.6626 - val_loss: 1.7151\n",
      "Epoch 136/300\n",
      "703/703 [==============================] - 1s - loss: 1.6784 - val_loss: 1.6838\n",
      "Epoch 137/300\n",
      "703/703 [==============================] - 1s - loss: 1.6558 - val_loss: 1.6961\n",
      "Epoch 138/300\n",
      "703/703 [==============================] - 1s - loss: 1.6663 - val_loss: 1.6893\n",
      "Epoch 139/300\n",
      "703/703 [==============================] - 1s - loss: 1.6540 - val_loss: 1.6621\n",
      "Epoch 140/300\n",
      "703/703 [==============================] - 1s - loss: 1.6560 - val_loss: 1.6707\n",
      "Epoch 141/300\n",
      "687/703 [============================>.] - ETA: 0s - loss: 1.6845\n",
      " Reduced learning rate to 0.000877915\n",
      "703/703 [==============================] - 1s - loss: 1.6851 - val_loss: 1.6731\n",
      "Epoch 142/300\n",
      "703/703 [==============================] - 1s - loss: 1.6642 - val_loss: 1.6853\n",
      "Epoch 143/300\n",
      "703/703 [==============================] - 1s - loss: 1.6674 - val_loss: 1.6724\n",
      "Epoch 144/300\n",
      "703/703 [==============================] - 1s - loss: 1.6738 - val_loss: 1.6715\n",
      "Epoch 145/300\n",
      "703/703 [==============================] - 1s - loss: 1.6683 - val_loss: 1.7049\n",
      "Epoch 146/300\n",
      "703/703 [==============================] - 1s - loss: 1.6844 - val_loss: 1.6541\n",
      "Epoch 147/300\n",
      "703/703 [==============================] - 1s - loss: 1.6842 - val_loss: 1.6607\n",
      "Epoch 148/300\n",
      "703/703 [==============================] - 1s - loss: 1.6434 - val_loss: 1.6762\n",
      "Epoch 149/300\n",
      "703/703 [==============================] - 1s - loss: 1.6625 - val_loss: 1.6973\n",
      "Epoch 150/300\n",
      "703/703 [==============================] - 1s - loss: 1.6733 - val_loss: 1.6773\n",
      "Epoch 151/300\n",
      "703/703 [==============================] - 1s - loss: 1.6735 - val_loss: 1.6479\n",
      "Epoch 152/300\n",
      "700/703 [============================>.] - ETA: 0s - loss: 1.6609\n",
      " Reduced learning rate to 0.000585277\n",
      "703/703 [==============================] - 1s - loss: 1.6610 - val_loss: 1.6643\n",
      "Epoch 153/300\n",
      "703/703 [==============================] - 1s - loss: 1.6665 - val_loss: 1.6986\n",
      "Epoch 154/300\n",
      "703/703 [==============================] - 1s - loss: 1.6677 - val_loss: 1.6726\n",
      "Epoch 155/300\n",
      "703/703 [==============================] - 1s - loss: 1.6937 - val_loss: 1.7147\n",
      "Epoch 156/300\n",
      "703/703 [==============================] - 1s - loss: 1.6694 - val_loss: 1.6855\n",
      "Epoch 157/300\n",
      "703/703 [==============================] - 1s - loss: 1.6538 - val_loss: 1.7017\n",
      "Epoch 158/300\n",
      "703/703 [==============================] - 1s - loss: 1.6578 - val_loss: 1.6996\n",
      "Epoch 159/300\n",
      "703/703 [==============================] - 1s - loss: 1.6737 - val_loss: 1.6720\n",
      "Epoch 160/300\n",
      "703/703 [==============================] - 1s - loss: 1.6657 - val_loss: 1.6498\n",
      "Epoch 161/300\n",
      "703/703 [==============================] - 1s - loss: 1.6510 - val_loss: 1.7072\n",
      "Epoch 162/300\n",
      "703/703 [==============================] - 1s - loss: 1.6834 - val_loss: 1.6677\n",
      "Epoch 163/300\n",
      "685/703 [============================>.] - ETA: 0s - loss: 1.6629\n",
      " Reduced learning rate to 0.000390184\n",
      "703/703 [==============================] - 1s - loss: 1.6625 - val_loss: 1.6946\n",
      "Epoch 164/300\n",
      "703/703 [==============================] - 1s - loss: 1.6559 - val_loss: 1.7049\n",
      "Epoch 165/300\n",
      "703/703 [==============================] - 1s - loss: 1.6609 - val_loss: 1.6909\n",
      "Epoch 166/300\n",
      "703/703 [==============================] - 1s - loss: 1.6523 - val_loss: 1.7025\n",
      "Epoch 167/300\n",
      "703/703 [==============================] - 2s - loss: 1.6591 - val_loss: 1.6788\n",
      "Epoch 168/300\n",
      "703/703 [==============================] - 1s - loss: 1.6434 - val_loss: 1.6723\n",
      "Epoch 169/300\n",
      "703/703 [==============================] - 1s - loss: 1.6754 - val_loss: 1.6763\n",
      "Epoch 170/300\n",
      "703/703 [==============================] - 1s - loss: 1.6744 - val_loss: 1.6642\n",
      "Epoch 171/300\n",
      "703/703 [==============================] - 1s - loss: 1.6859 - val_loss: 1.6675\n",
      "Epoch 172/300\n",
      "703/703 [==============================] - 1s - loss: 1.6313 - val_loss: 1.7262\n",
      "Epoch 173/300\n",
      "703/703 [==============================] - 1s - loss: 1.6637 - val_loss: 1.7120\n",
      "Epoch 174/300\n",
      "682/703 [============================>.] - ETA: 0s - loss: 1.7008\n",
      " Reduced learning rate to 0.000260123\n",
      "703/703 [==============================] - 1s - loss: 1.6972 - val_loss: 1.6571\n",
      "Epoch 175/300\n",
      "703/703 [==============================] - 1s - loss: 1.7040 - val_loss: 1.7385\n",
      "Epoch 176/300\n",
      "703/703 [==============================] - 1s - loss: 1.6796 - val_loss: 1.6507\n",
      "Epoch 177/300\n",
      "703/703 [==============================] - 1s - loss: 1.6789 - val_loss: 1.6811\n",
      "Epoch 178/300\n",
      "703/703 [==============================] - 1s - loss: 1.6638 - val_loss: 1.6857\n",
      "Epoch 179/300\n",
      "703/703 [==============================] - 1s - loss: 1.6691 - val_loss: 1.6719\n",
      "Epoch 180/300\n",
      "703/703 [==============================] - 1s - loss: 1.6503 - val_loss: 1.6715\n",
      "Epoch 181/300\n",
      "703/703 [==============================] - 1s - loss: 1.6800 - val_loss: 1.7089\n",
      "Epoch 182/300\n",
      "703/703 [==============================] - 1s - loss: 1.6803 - val_loss: 1.7025\n",
      "Epoch 183/300\n",
      "703/703 [==============================] - 1s - loss: 1.6582 - val_loss: 1.6590\n",
      "Epoch 184/300\n",
      "703/703 [==============================] - 1s - loss: 1.6596 - val_loss: 1.6440\n",
      "Epoch 185/300\n",
      "703/703 [==============================] - 1s - loss: 1.6741 - val_loss: 1.6816\n",
      "Epoch 186/300\n",
      "703/703 [==============================] - 1s - loss: 1.6518 - val_loss: 1.6874\n",
      "Epoch 187/300\n",
      "703/703 [==============================] - 1s - loss: 1.6688 - val_loss: 1.6834\n",
      "Epoch 188/300\n",
      "703/703 [==============================] - 1s - loss: 1.6690 - val_loss: 1.6936\n",
      "Epoch 189/300\n",
      "703/703 [==============================] - 1s - loss: 1.6683 - val_loss: 1.6666\n",
      "Epoch 190/300\n",
      "703/703 [==============================] - 1s - loss: 1.6524 - val_loss: 1.6982\n",
      "Epoch 191/300\n",
      "703/703 [==============================] - 2s - loss: 1.6853 - val_loss: 1.6428\n",
      "Epoch 192/300\n",
      "703/703 [==============================] - 1s - loss: 1.6768 - val_loss: 1.6791\n",
      "Epoch 193/300\n",
      "703/703 [==============================] - 1s - loss: 1.6945 - val_loss: 1.6438\n",
      "Epoch 194/300\n",
      "703/703 [==============================] - 1s - loss: 1.6425 - val_loss: 1.6825\n",
      "Epoch 195/300\n",
      "703/703 [==============================] - 1s - loss: 1.6757 - val_loss: 1.7015\n",
      "Epoch 196/300\n",
      "703/703 [==============================] - 1s - loss: 1.6748 - val_loss: 1.6704\n",
      "Epoch 197/300\n",
      "703/703 [==============================] - 1s - loss: 1.6541 - val_loss: 1.6687\n",
      "Epoch 198/300\n",
      "703/703 [==============================] - 1s - loss: 1.6448 - val_loss: 1.7137\n",
      "Epoch 199/300\n",
      "703/703 [==============================] - 1s - loss: 1.6829 - val_loss: 1.6742\n",
      "Epoch 200/300\n",
      "703/703 [==============================] - 1s - loss: 1.6759 - val_loss: 1.6713\n",
      "Epoch 201/300\n",
      "703/703 [==============================] - 1s - loss: 1.6677 - val_loss: 1.6734\n",
      "Epoch 202/300\n",
      "680/703 [============================>.] - ETA: 0s - loss: 1.6440\n",
      " Reduced learning rate to 0.000173415\n",
      "703/703 [==============================] - 1s - loss: 1.6424 - val_loss: 1.6837\n",
      "Epoch 203/300\n",
      "703/703 [==============================] - 1s - loss: 1.6889 - val_loss: 1.6782\n",
      "Epoch 204/300\n",
      "703/703 [==============================] - 1s - loss: 1.6571 - val_loss: 1.6939\n",
      "Epoch 205/300\n",
      "703/703 [==============================] - 1s - loss: 1.6614 - val_loss: 1.6953\n",
      "Epoch 206/300\n",
      "703/703 [==============================] - 1s - loss: 1.6694 - val_loss: 1.6709\n",
      "Epoch 207/300\n",
      "703/703 [==============================] - 1s - loss: 1.6433 - val_loss: 1.6935\n",
      "Epoch 208/300\n",
      "703/703 [==============================] - 1s - loss: 1.6767 - val_loss: 1.6928\n",
      "Epoch 209/300\n",
      "703/703 [==============================] - 1s - loss: 1.6458 - val_loss: 1.6460\n",
      "Epoch 210/300\n",
      "703/703 [==============================] - 1s - loss: 1.6515 - val_loss: 1.6916\n",
      "Epoch 211/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.6900 - val_loss: 1.7091\n",
      "Epoch 212/300\n",
      "703/703 [==============================] - 1s - loss: 1.6424 - val_loss: 1.6952\n",
      "Epoch 213/300\n",
      "701/703 [============================>.] - ETA: 0s - loss: 1.6622\n",
      " Reduced learning rate to 0.00011561\n",
      "703/703 [==============================] - 1s - loss: 1.6624 - val_loss: 1.6905\n",
      "Epoch 214/300\n",
      "703/703 [==============================] - 1s - loss: 1.6589 - val_loss: 1.6759\n",
      "Epoch 215/300\n",
      "703/703 [==============================] - 1s - loss: 1.6504 - val_loss: 1.7048\n",
      "Epoch 216/300\n",
      "703/703 [==============================] - 1s - loss: 1.6437 - val_loss: 1.6759\n",
      "Epoch 217/300\n",
      "703/703 [==============================] - 1s - loss: 1.6631 - val_loss: 1.6826\n",
      "Epoch 218/300\n",
      "703/703 [==============================] - 1s - loss: 1.6752 - val_loss: 1.6575\n",
      "Epoch 219/300\n",
      "703/703 [==============================] - 1s - loss: 1.6902 - val_loss: 1.6485\n",
      "Epoch 220/300\n",
      "703/703 [==============================] - 1s - loss: 1.6792 - val_loss: 1.7083\n",
      "Epoch 221/300\n",
      "703/703 [==============================] - 1s - loss: 1.6487 - val_loss: 1.7198\n",
      "Epoch 222/300\n",
      "703/703 [==============================] - 1s - loss: 1.6725 - val_loss: 1.7040\n",
      "Epoch 223/300\n",
      "703/703 [==============================] - 1s - loss: 1.6693 - val_loss: 1.6745\n",
      "Epoch 224/300\n",
      "681/703 [============================>.] - ETA: 0s - loss: 1.6507\n",
      " Reduced learning rate to 7.70735e-05\n",
      "703/703 [==============================] - 1s - loss: 1.6506 - val_loss: 1.6593\n",
      "Epoch 1/300\n",
      "703/703 [==============================] - 2s - loss: 11.3739 - val_loss: 3.5560\n",
      "Epoch 2/300\n",
      "703/703 [==============================] - 1s - loss: 3.2147 - val_loss: 2.7226\n",
      "Epoch 3/300\n",
      "703/703 [==============================] - 1s - loss: 3.0616 - val_loss: 2.7205\n",
      "Epoch 4/300\n",
      "703/703 [==============================] - 1s - loss: 3.0294 - val_loss: 2.9047\n",
      "Epoch 5/300\n",
      "703/703 [==============================] - 1s - loss: 2.8859 - val_loss: 2.7725\n",
      "Epoch 6/300\n",
      "703/703 [==============================] - 1s - loss: 2.7340 - val_loss: 3.0964\n",
      "Epoch 7/300\n",
      "703/703 [==============================] - 1s - loss: 2.6591 - val_loss: 2.7625\n",
      "Epoch 8/300\n",
      "703/703 [==============================] - 1s - loss: 2.6189 - val_loss: 2.3341\n",
      "Epoch 9/300\n",
      "703/703 [==============================] - 1s - loss: 2.5531 - val_loss: 2.4279\n",
      "Epoch 10/300\n",
      "703/703 [==============================] - 1s - loss: 2.5467 - val_loss: 2.4521\n",
      "Epoch 11/300\n",
      "703/703 [==============================] - 1s - loss: 2.4142 - val_loss: 2.1113\n",
      "Epoch 12/300\n",
      "703/703 [==============================] - 1s - loss: 2.4299 - val_loss: 2.2308\n",
      "Epoch 13/300\n",
      "703/703 [==============================] - 1s - loss: 2.3752 - val_loss: 2.5931\n",
      "Epoch 14/300\n",
      "703/703 [==============================] - 1s - loss: 2.3924 - val_loss: 2.5828\n",
      "Epoch 15/300\n",
      "703/703 [==============================] - 1s - loss: 2.3292 - val_loss: 2.6426\n",
      "Epoch 16/300\n",
      "703/703 [==============================] - 1s - loss: 2.2977 - val_loss: 2.1979\n",
      "Epoch 17/300\n",
      "703/703 [==============================] - 1s - loss: 2.2746 - val_loss: 1.9858\n",
      "Epoch 18/300\n",
      "703/703 [==============================] - 1s - loss: 2.2211 - val_loss: 1.8582\n",
      "Epoch 19/300\n",
      "703/703 [==============================] - 1s - loss: 2.2047 - val_loss: 1.9380\n",
      "Epoch 20/300\n",
      "703/703 [==============================] - 1s - loss: 2.1401 - val_loss: 2.9395\n",
      "Epoch 21/300\n",
      "703/703 [==============================] - 1s - loss: 2.1793 - val_loss: 3.3081\n",
      "Epoch 22/300\n",
      "703/703 [==============================] - 1s - loss: 2.1829 - val_loss: 1.9360\n",
      "Epoch 23/300\n",
      "703/703 [==============================] - 1s - loss: 2.1401 - val_loss: 2.0194\n",
      "Epoch 24/300\n",
      "703/703 [==============================] - 1s - loss: 2.0885 - val_loss: 1.8446\n",
      "Epoch 25/300\n",
      "703/703 [==============================] - 1s - loss: 2.0680 - val_loss: 1.8396\n",
      "Epoch 26/300\n",
      "703/703 [==============================] - 1s - loss: 2.0861 - val_loss: 1.8421\n",
      "Epoch 27/300\n",
      "703/703 [==============================] - 1s - loss: 2.0906 - val_loss: 1.9898\n",
      "Epoch 28/300\n",
      "703/703 [==============================] - 1s - loss: 2.0697 - val_loss: 1.8496\n",
      "Epoch 29/300\n",
      "703/703 [==============================] - 1s - loss: 2.0587 - val_loss: 2.5815\n",
      "Epoch 30/300\n",
      "703/703 [==============================] - 1s - loss: 1.9776 - val_loss: 1.8315\n",
      "Epoch 31/300\n",
      "703/703 [==============================] - 1s - loss: 2.0528 - val_loss: 2.8804\n",
      "Epoch 32/300\n",
      "703/703 [==============================] - 1s - loss: 2.0188 - val_loss: 2.5986\n",
      "Epoch 33/300\n",
      "703/703 [==============================] - 1s - loss: 1.9739 - val_loss: 1.7803\n",
      "Epoch 34/300\n",
      "703/703 [==============================] - 1s - loss: 1.9893 - val_loss: 1.8661\n",
      "Epoch 35/300\n",
      "703/703 [==============================] - 1s - loss: 2.0051 - val_loss: 1.7377\n",
      "Epoch 36/300\n",
      "703/703 [==============================] - 1s - loss: 1.9680 - val_loss: 1.9419\n",
      "Epoch 37/300\n",
      "703/703 [==============================] - 1s - loss: 2.0017 - val_loss: 1.8200\n",
      "Epoch 38/300\n",
      "703/703 [==============================] - 1s - loss: 1.9186 - val_loss: 2.0534\n",
      "Epoch 39/300\n",
      "703/703 [==============================] - 1s - loss: 1.9397 - val_loss: 1.8601\n",
      "Epoch 40/300\n",
      "703/703 [==============================] - 1s - loss: 1.9297 - val_loss: 1.7923\n",
      "Epoch 41/300\n",
      "703/703 [==============================] - 1s - loss: 1.9367 - val_loss: 1.7732\n",
      "Epoch 42/300\n",
      "703/703 [==============================] - 1s - loss: 1.8931 - val_loss: 1.8128\n",
      "Epoch 43/300\n",
      "703/703 [==============================] - 1s - loss: 1.9307 - val_loss: 1.7992\n",
      "Epoch 44/300\n",
      "703/703 [==============================] - 1s - loss: 1.9121 - val_loss: 1.7962\n",
      "Epoch 45/300\n",
      "703/703 [==============================] - 1s - loss: 1.9343 - val_loss: 1.8175\n",
      "Epoch 46/300\n",
      "689/703 [============================>.] - ETA: 0s - loss: 1.9461\n",
      " Reduced learning rate to 0.01\n",
      "703/703 [==============================] - 1s - loss: 1.9447 - val_loss: 2.1980\n",
      "Epoch 47/300\n",
      "703/703 [==============================] - 1s - loss: 1.7517 - val_loss: 1.7483\n",
      "Epoch 48/300\n",
      "703/703 [==============================] - 1s - loss: 1.7526 - val_loss: 1.8465\n",
      "Epoch 49/300\n",
      "703/703 [==============================] - 1s - loss: 1.7847 - val_loss: 1.8016\n",
      "Epoch 50/300\n",
      "703/703 [==============================] - 1s - loss: 1.7924 - val_loss: 1.7973\n",
      "Epoch 51/300\n",
      "703/703 [==============================] - 1s - loss: 1.7690 - val_loss: 1.7601\n",
      "Epoch 52/300\n",
      "703/703 [==============================] - 1s - loss: 1.7547 - val_loss: 1.7980\n",
      "Epoch 53/300\n",
      "703/703 [==============================] - 1s - loss: 1.7696 - val_loss: 1.7702\n",
      "Epoch 54/300\n",
      "703/703 [==============================] - 1s - loss: 1.7663 - val_loss: 1.8758\n",
      "Epoch 55/300\n",
      "703/703 [==============================] - 1s - loss: 1.7711 - val_loss: 1.7128\n",
      "Epoch 56/300\n",
      "703/703 [==============================] - 1s - loss: 1.7610 - val_loss: 1.8402\n",
      "Epoch 57/300\n",
      "703/703 [==============================] - 1s - loss: 1.7682 - val_loss: 1.7429\n",
      "Epoch 58/300\n",
      "703/703 [==============================] - 1s - loss: 1.7459 - val_loss: 1.7274\n",
      "Epoch 59/300\n",
      "703/703 [==============================] - 1s - loss: 1.7512 - val_loss: 1.7434\n",
      "Epoch 60/300\n",
      "703/703 [==============================] - 1s - loss: 1.7399 - val_loss: 1.7454\n",
      "Epoch 61/300\n",
      "703/703 [==============================] - 1s - loss: 1.7520 - val_loss: 1.8452\n",
      "Epoch 62/300\n",
      "703/703 [==============================] - 1s - loss: 1.7782 - val_loss: 1.8180\n",
      "Epoch 63/300\n",
      "703/703 [==============================] - 1s - loss: 1.7525 - val_loss: 1.7005\n",
      "Epoch 64/300\n",
      "703/703 [==============================] - 1s - loss: 1.7825 - val_loss: 1.7082\n",
      "Epoch 65/300\n",
      "703/703 [==============================] - 1s - loss: 1.7612 - val_loss: 1.7247\n",
      "Epoch 66/300\n",
      "703/703 [==============================] - 1s - loss: 1.7342 - val_loss: 1.7634\n",
      "Epoch 67/300\n",
      "703/703 [==============================] - 1s - loss: 1.8010 - val_loss: 1.7993\n",
      "Epoch 68/300\n",
      "703/703 [==============================] - 1s - loss: 1.7626 - val_loss: 1.7856\n",
      "Epoch 69/300\n",
      "703/703 [==============================] - 1s - loss: 1.7534 - val_loss: 1.7361\n",
      "Epoch 70/300\n",
      "703/703 [==============================] - 1s - loss: 1.7650 - val_loss: 1.7104\n",
      "Epoch 71/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.7676 - val_loss: 1.7310\n",
      "Epoch 72/300\n",
      "703/703 [==============================] - 1s - loss: 1.7511 - val_loss: 1.9243\n",
      "Epoch 73/300\n",
      "703/703 [==============================] - 1s - loss: 1.7691 - val_loss: 1.7212\n",
      "Epoch 74/300\n",
      "682/703 [============================>.] - ETA: 0s - loss: 1.7748\n",
      " Reduced learning rate to 0.00666667\n",
      "703/703 [==============================] - 1s - loss: 1.7727 - val_loss: 1.7463\n",
      "Epoch 75/300\n",
      "703/703 [==============================] - 1s - loss: 1.6820 - val_loss: 1.7013\n",
      "Epoch 76/300\n",
      "703/703 [==============================] - 1s - loss: 1.6905 - val_loss: 1.7480\n",
      "Epoch 77/300\n",
      "703/703 [==============================] - 1s - loss: 1.7268 - val_loss: 1.7323\n",
      "Epoch 78/300\n",
      "703/703 [==============================] - 1s - loss: 1.7398 - val_loss: 1.7352\n",
      "Epoch 79/300\n",
      "703/703 [==============================] - 1s - loss: 1.7432 - val_loss: 1.8020\n",
      "Epoch 80/300\n",
      "703/703 [==============================] - 1s - loss: 1.7251 - val_loss: 1.7830\n",
      "Epoch 81/300\n",
      "703/703 [==============================] - 1s - loss: 1.7054 - val_loss: 1.7230\n",
      "Epoch 82/300\n",
      "703/703 [==============================] - 1s - loss: 1.7051 - val_loss: 1.7427\n",
      "Epoch 83/300\n",
      "703/703 [==============================] - 1s - loss: 1.7171 - val_loss: 1.7683\n",
      "Epoch 84/300\n",
      "703/703 [==============================] - 1s - loss: 1.7120 - val_loss: 1.6893\n",
      "Epoch 85/300\n",
      "703/703 [==============================] - 1s - loss: 1.7294 - val_loss: 1.7807\n",
      "Epoch 86/300\n",
      "703/703 [==============================] - 1s - loss: 1.7169 - val_loss: 1.7672\n",
      "Epoch 87/300\n",
      "703/703 [==============================] - 1s - loss: 1.7115 - val_loss: 1.7102\n",
      "Epoch 88/300\n",
      "703/703 [==============================] - ETA: 0s - loss: 1.715 - 1s - loss: 1.7165 - val_loss: 1.7297\n",
      "Epoch 89/300\n",
      "703/703 [==============================] - 1s - loss: 1.6925 - val_loss: 1.7243\n",
      "Epoch 90/300\n",
      "703/703 [==============================] - 1s - loss: 1.6861 - val_loss: 1.7401\n",
      "Epoch 91/300\n",
      "703/703 [==============================] - 1s - loss: 1.7026 - val_loss: 1.7242\n",
      "Epoch 92/300\n",
      "703/703 [==============================] - 1s - loss: 1.7070 - val_loss: 1.7274\n",
      "Epoch 93/300\n",
      "703/703 [==============================] - 1s - loss: 1.7289 - val_loss: 1.7450\n",
      "Epoch 94/300\n",
      "703/703 [==============================] - 1s - loss: 1.7145 - val_loss: 1.7048\n",
      "Epoch 95/300\n",
      "697/703 [============================>.] - ETA: 0s - loss: 1.7090\n",
      " Reduced learning rate to 0.00444444\n",
      "703/703 [==============================] - 1s - loss: 1.7082 - val_loss: 1.9370\n",
      "Epoch 96/300\n",
      "703/703 [==============================] - 1s - loss: 1.7001 - val_loss: 1.7166\n",
      "Epoch 97/300\n",
      "703/703 [==============================] - 1s - loss: 1.6759 - val_loss: 1.7312\n",
      "Epoch 98/300\n",
      "703/703 [==============================] - 1s - loss: 1.6778 - val_loss: 1.7310\n",
      "Epoch 99/300\n",
      "703/703 [==============================] - 1s - loss: 1.6869 - val_loss: 1.6724\n",
      "Epoch 100/300\n",
      "703/703 [==============================] - 1s - loss: 1.6870 - val_loss: 1.6989\n",
      "Epoch 101/300\n",
      "703/703 [==============================] - 1s - loss: 1.6839 - val_loss: 1.6702\n",
      "Epoch 102/300\n",
      "703/703 [==============================] - 1s - loss: 1.7108 - val_loss: 1.6982\n",
      "Epoch 103/300\n",
      "703/703 [==============================] - 1s - loss: 1.6801 - val_loss: 1.7144\n",
      "Epoch 104/300\n",
      "703/703 [==============================] - 1s - loss: 1.6824 - val_loss: 1.6976\n",
      "Epoch 105/300\n",
      "703/703 [==============================] - 1s - loss: 1.6987 - val_loss: 1.7372\n",
      "Epoch 106/300\n",
      "703/703 [==============================] - 1s - loss: 1.6768 - val_loss: 1.6880\n",
      "Epoch 107/300\n",
      "703/703 [==============================] - 1s - loss: 1.6837 - val_loss: 1.6976\n",
      "Epoch 108/300\n",
      "703/703 [==============================] - 1s - loss: 1.6850 - val_loss: 1.7187\n",
      "Epoch 109/300\n",
      "703/703 [==============================] - 1s - loss: 1.6962 - val_loss: 1.7228\n",
      "Epoch 110/300\n",
      "703/703 [==============================] - 1s - loss: 1.6885 - val_loss: 1.6926\n",
      "Epoch 111/300\n",
      "703/703 [==============================] - ETA: 0s - loss: 1.691 - 1s - loss: 1.6922 - val_loss: 1.6560\n",
      "Epoch 112/300\n",
      "703/703 [==============================] - 1s - loss: 1.6950 - val_loss: 1.7000\n",
      "Epoch 113/300\n",
      "703/703 [==============================] - 1s - loss: 1.6775 - val_loss: 1.6991\n",
      "Epoch 114/300\n",
      "703/703 [==============================] - 1s - loss: 1.6907 - val_loss: 1.6753\n",
      "Epoch 115/300\n",
      "703/703 [==============================] - 1s - loss: 1.6810 - val_loss: 1.7406\n",
      "Epoch 116/300\n",
      "703/703 [==============================] - 1s - loss: 1.6942 - val_loss: 1.7019\n",
      "Epoch 117/300\n",
      "703/703 [==============================] - 1s - loss: 1.6540 - val_loss: 1.7000\n",
      "Epoch 118/300\n",
      "703/703 [==============================] - 1s - loss: 1.7131 - val_loss: 1.7114\n",
      "Epoch 119/300\n",
      "703/703 [==============================] - 1s - loss: 1.6904 - val_loss: 1.6771\n",
      "Epoch 120/300\n",
      "703/703 [==============================] - 1s - loss: 1.6746 - val_loss: 1.6988\n",
      "Epoch 121/300\n",
      "703/703 [==============================] - 1s - loss: 1.7102 - val_loss: 1.7072\n",
      "Epoch 122/300\n",
      "693/703 [============================>.] - ETA: 0s - loss: 1.6959\n",
      " Reduced learning rate to 0.00296296\n",
      "703/703 [==============================] - 1s - loss: 1.6987 - val_loss: 1.7157\n",
      "Epoch 123/300\n",
      "703/703 [==============================] - 1s - loss: 1.6738 - val_loss: 1.7242\n",
      "Epoch 124/300\n",
      "703/703 [==============================] - 1s - loss: 1.6743 - val_loss: 1.6831\n",
      "Epoch 125/300\n",
      "703/703 [==============================] - 1s - loss: 1.6970 - val_loss: 1.6775\n",
      "Epoch 126/300\n",
      "703/703 [==============================] - 1s - loss: 1.6655 - val_loss: 1.7074\n",
      "Epoch 127/300\n",
      "703/703 [==============================] - 1s - loss: 1.6806 - val_loss: 1.6924\n",
      "Epoch 128/300\n",
      "703/703 [==============================] - 1s - loss: 1.6837 - val_loss: 1.7063\n",
      "Epoch 129/300\n",
      "703/703 [==============================] - 1s - loss: 1.6803 - val_loss: 1.7245\n",
      "Epoch 130/300\n",
      "703/703 [==============================] - 1s - loss: 1.7209 - val_loss: 1.6697\n",
      "Epoch 131/300\n",
      "703/703 [==============================] - 1s - loss: 1.6740 - val_loss: 1.6808\n",
      "Epoch 132/300\n",
      "703/703 [==============================] - 1s - loss: 1.6821 - val_loss: 1.6396\n",
      "Epoch 133/300\n",
      "703/703 [==============================] - 1s - loss: 1.6767 - val_loss: 1.6752\n",
      "Epoch 134/300\n",
      "703/703 [==============================] - 1s - loss: 1.6767 - val_loss: 1.6825\n",
      "Epoch 135/300\n",
      "703/703 [==============================] - 1s - loss: 1.6663 - val_loss: 1.7394\n",
      "Epoch 136/300\n",
      "703/703 [==============================] - 1s - loss: 1.6642 - val_loss: 1.6892\n",
      "Epoch 137/300\n",
      "703/703 [==============================] - 1s - loss: 1.6726 - val_loss: 1.7083\n",
      "Epoch 138/300\n",
      "703/703 [==============================] - 1s - loss: 1.6674 - val_loss: 1.6787\n",
      "Epoch 139/300\n",
      "703/703 [==============================] - 1s - loss: 1.6858 - val_loss: 1.6780\n",
      "Epoch 140/300\n",
      "703/703 [==============================] - 1s - loss: 1.6918 - val_loss: 1.6878\n",
      "Epoch 141/300\n",
      "703/703 [==============================] - 1s - loss: 1.6802 - val_loss: 1.6506\n",
      "Epoch 142/300\n",
      "703/703 [==============================] - 1s - loss: 1.6969 - val_loss: 1.7161\n",
      "Epoch 143/300\n",
      "681/703 [============================>.] - ETA: 0s - loss: 1.6770\n",
      " Reduced learning rate to 0.00197531\n",
      "703/703 [==============================] - 1s - loss: 1.6756 - val_loss: 1.6612\n",
      "Epoch 144/300\n",
      "703/703 [==============================] - 1s - loss: 1.6770 - val_loss: 1.7051\n",
      "Epoch 145/300\n",
      "703/703 [==============================] - 1s - loss: 1.6660 - val_loss: 1.6881\n",
      "Epoch 146/300\n",
      "703/703 [==============================] - 1s - loss: 1.6617 - val_loss: 1.7039\n",
      "Epoch 147/300\n",
      "703/703 [==============================] - 1s - loss: 1.6846 - val_loss: 1.6657\n",
      "Epoch 148/300\n",
      "703/703 [==============================] - 1s - loss: 1.6768 - val_loss: 1.6915\n",
      "Epoch 149/300\n",
      "703/703 [==============================] - 1s - loss: 1.6808 - val_loss: 1.6990\n",
      "Epoch 150/300\n",
      "703/703 [==============================] - 1s - loss: 1.6755 - val_loss: 1.6849\n",
      "Epoch 151/300\n",
      "703/703 [==============================] - 1s - loss: 1.6567 - val_loss: 1.6595\n",
      "Epoch 152/300\n",
      "703/703 [==============================] - 1s - loss: 1.6648 - val_loss: 1.7130\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703/703 [==============================] - 1s - loss: 1.6659 - val_loss: 1.6720\n",
      "Epoch 154/300\n",
      "690/703 [============================>.] - ETA: 0s - loss: 1.6721\n",
      " Reduced learning rate to 0.00131687\n",
      "703/703 [==============================] - 1s - loss: 1.6725 - val_loss: 1.6729\n",
      "Epoch 155/300\n",
      "703/703 [==============================] - 1s - loss: 1.6715 - val_loss: 1.7445\n",
      "Epoch 156/300\n",
      "703/703 [==============================] - 1s - loss: 1.6479 - val_loss: 1.6912\n",
      "Epoch 157/300\n",
      "703/703 [==============================] - 1s - loss: 1.6697 - val_loss: 1.7268\n",
      "Epoch 158/300\n",
      "703/703 [==============================] - 1s - loss: 1.6705 - val_loss: 1.6758\n",
      "Epoch 159/300\n",
      "703/703 [==============================] - 1s - loss: 1.6677 - val_loss: 1.6624\n",
      "Epoch 160/300\n",
      "703/703 [==============================] - 1s - loss: 1.6571 - val_loss: 1.6647\n",
      "Epoch 161/300\n",
      "703/703 [==============================] - 1s - loss: 1.6701 - val_loss: 1.6880\n",
      "Epoch 162/300\n",
      "703/703 [==============================] - ETA: 0s - loss: 1.654 - 1s - loss: 1.6532 - val_loss: 1.6802\n",
      "Epoch 163/300\n",
      "703/703 [==============================] - 1s - loss: 1.6643 - val_loss: 1.6702\n",
      "Epoch 164/300\n",
      "703/703 [==============================] - 1s - loss: 1.6604 - val_loss: 1.6891\n",
      "Epoch 165/300\n",
      "689/703 [============================>.] - ETA: 0s - loss: 1.6725\n",
      " Reduced learning rate to 0.000877915\n",
      "703/703 [==============================] - 1s - loss: 1.6730 - val_loss: 1.6924\n",
      "Epoch 166/300\n",
      "703/703 [==============================] - 1s - loss: 1.6566 - val_loss: 1.6718\n",
      "Epoch 167/300\n",
      "703/703 [==============================] - 1s - loss: 1.6697 - val_loss: 1.6736\n",
      "Epoch 168/300\n",
      "703/703 [==============================] - 1s - loss: 1.6676 - val_loss: 1.6588\n",
      "Epoch 169/300\n",
      "703/703 [==============================] - 1s - loss: 1.6657 - val_loss: 1.6714\n",
      "Epoch 170/300\n",
      "703/703 [==============================] - 1s - loss: 1.6499 - val_loss: 1.6571\n",
      "Epoch 171/300\n",
      "703/703 [==============================] - 1s - loss: 1.6892 - val_loss: 1.6646\n",
      "Epoch 172/300\n",
      "703/703 [==============================] - 1s - loss: 1.6599 - val_loss: 1.6367\n",
      "Epoch 173/300\n",
      "703/703 [==============================] - 1s - loss: 1.6616 - val_loss: 1.6563\n",
      "Epoch 174/300\n",
      "703/703 [==============================] - 1s - loss: 1.6686 - val_loss: 1.6721\n",
      "Epoch 175/300\n",
      "703/703 [==============================] - 1s - loss: 1.6565 - val_loss: 1.6829\n",
      "Epoch 176/300\n",
      "703/703 [==============================] - 1s - loss: 1.6446 - val_loss: 1.7047\n",
      "Epoch 177/300\n",
      "703/703 [==============================] - 1s - loss: 1.6726 - val_loss: 1.6707\n",
      "Epoch 178/300\n",
      "703/703 [==============================] - 1s - loss: 1.6577 - val_loss: 1.6452\n",
      "Epoch 179/300\n",
      "703/703 [==============================] - 1s - loss: 1.6691 - val_loss: 1.6962\n",
      "Epoch 180/300\n",
      "703/703 [==============================] - 1s - loss: 1.6670 - val_loss: 1.6709\n",
      "Epoch 181/300\n",
      "703/703 [==============================] - 1s - loss: 1.6664 - val_loss: 1.6571\n",
      "Epoch 182/300\n",
      "703/703 [==============================] - 1s - loss: 1.6680 - val_loss: 1.6691\n",
      "Epoch 183/300\n",
      "701/703 [============================>.] - ETA: 0s - loss: 1.6765\n",
      " Reduced learning rate to 0.000585277\n",
      "703/703 [==============================] - 1s - loss: 1.6762 - val_loss: 1.6481\n",
      "Epoch 184/300\n",
      "703/703 [==============================] - 1s - loss: 1.6697 - val_loss: 1.6924\n",
      "Epoch 185/300\n",
      "703/703 [==============================] - 1s - loss: 1.6670 - val_loss: 1.6757\n",
      "Epoch 186/300\n",
      "703/703 [==============================] - 1s - loss: 1.6575 - val_loss: 1.6733\n",
      "Epoch 187/300\n",
      "703/703 [==============================] - 1s - loss: 1.6665 - val_loss: 1.6679\n",
      "Epoch 188/300\n",
      "703/703 [==============================] - 1s - loss: 1.6656 - val_loss: 1.6652\n",
      "Epoch 189/300\n",
      "703/703 [==============================] - 1s - loss: 1.6576 - val_loss: 1.6734\n",
      "Epoch 190/300\n",
      "703/703 [==============================] - 1s - loss: 1.6539 - val_loss: 1.6806\n",
      "Epoch 191/300\n",
      "703/703 [==============================] - 1s - loss: 1.6618 - val_loss: 1.7097\n",
      "Epoch 192/300\n",
      "703/703 [==============================] - 1s - loss: 1.6734 - val_loss: 1.6650\n",
      "Epoch 193/300\n",
      "703/703 [==============================] - 1s - loss: 1.6472 - val_loss: 1.6858\n",
      "Epoch 194/300\n",
      "674/703 [===========================>..] - ETA: 0s - loss: 1.6855\n",
      " Reduced learning rate to 0.000390184\n",
      "703/703 [==============================] - 1s - loss: 1.6811 - val_loss: 1.6672\n",
      "Epoch 195/300\n",
      "703/703 [==============================] - 1s - loss: 1.6583 - val_loss: 1.7044\n",
      "Epoch 196/300\n",
      "703/703 [==============================] - 1s - loss: 1.6765 - val_loss: 1.7006\n",
      "Epoch 197/300\n",
      "703/703 [==============================] - 1s - loss: 1.6622 - val_loss: 1.6533\n",
      "Epoch 198/300\n",
      "703/703 [==============================] - 1s - loss: 1.6682 - val_loss: 1.6474\n",
      "Epoch 199/300\n",
      "703/703 [==============================] - 1s - loss: 1.6668 - val_loss: 1.6714\n",
      "Epoch 200/300\n",
      "703/703 [==============================] - 1s - loss: 1.6666 - val_loss: 1.6258\n",
      "Epoch 201/300\n",
      "703/703 [==============================] - 1s - loss: 1.6655 - val_loss: 1.6899\n",
      "Epoch 202/300\n",
      "703/703 [==============================] - 1s - loss: 1.6662 - val_loss: 1.6641\n",
      "Epoch 203/300\n",
      "703/703 [==============================] - 1s - loss: 1.6846 - val_loss: 1.6581\n",
      "Epoch 204/300\n",
      "703/703 [==============================] - 1s - loss: 1.6571 - val_loss: 1.6751\n",
      "Epoch 205/300\n",
      "703/703 [==============================] - 1s - loss: 1.6626 - val_loss: 1.6702\n",
      "Epoch 206/300\n",
      "703/703 [==============================] - 1s - loss: 1.6567 - val_loss: 1.6634\n",
      "Epoch 207/300\n",
      "703/703 [==============================] - 1s - loss: 1.6659 - val_loss: 1.6516\n",
      "Epoch 208/300\n",
      "703/703 [==============================] - 1s - loss: 1.6638 - val_loss: 1.6739\n",
      "Epoch 209/300\n",
      "703/703 [==============================] - 1s - loss: 1.6511 - val_loss: 1.7134\n",
      "Epoch 210/300\n",
      "703/703 [==============================] - 1s - loss: 1.6737 - val_loss: 1.6459\n",
      "Epoch 211/300\n",
      "694/703 [============================>.] - ETA: 0s - loss: 1.6820\n",
      " Reduced learning rate to 0.000260123\n",
      "703/703 [==============================] - 1s - loss: 1.6802 - val_loss: 1.6965\n",
      "Epoch 212/300\n",
      "703/703 [==============================] - 1s - loss: 1.6448 - val_loss: 1.6700\n",
      "Epoch 213/300\n",
      "703/703 [==============================] - 1s - loss: 1.6731 - val_loss: 1.6823\n",
      "Epoch 214/300\n",
      "703/703 [==============================] - 1s - loss: 1.6671 - val_loss: 1.6641\n",
      "Epoch 215/300\n",
      "703/703 [==============================] - 1s - loss: 1.6630 - val_loss: 1.6537\n",
      "Epoch 216/300\n",
      "703/703 [==============================] - 1s - loss: 1.6455 - val_loss: 1.7030\n",
      "Epoch 217/300\n",
      "703/703 [==============================] - 1s - loss: 1.6689 - val_loss: 1.6721\n",
      "Epoch 218/300\n",
      "703/703 [==============================] - 1s - loss: 1.6585 - val_loss: 1.6655\n",
      "Epoch 219/300\n",
      "703/703 [==============================] - 1s - loss: 1.6393 - val_loss: 1.6787\n",
      "Epoch 220/300\n",
      "703/703 [==============================] - 1s - loss: 1.6539 - val_loss: 1.6742\n",
      "Epoch 221/300\n",
      "703/703 [==============================] - 1s - loss: 1.6691 - val_loss: 1.6835\n",
      "Epoch 222/300\n",
      "685/703 [============================>.] - ETA: 0s - loss: 1.6823\n",
      " Reduced learning rate to 0.000173415\n",
      "703/703 [==============================] - 1s - loss: 1.6812 - val_loss: 1.6984\n",
      "Epoch 223/300\n",
      "703/703 [==============================] - 1s - loss: 1.6455 - val_loss: 1.6678\n",
      "Epoch 224/300\n",
      "703/703 [==============================] - 1s - loss: 1.6710 - val_loss: 1.6996\n",
      "Epoch 225/300\n",
      "703/703 [==============================] - 1s - loss: 1.6520 - val_loss: 1.6874\n",
      "Epoch 226/300\n",
      "703/703 [==============================] - 1s - loss: 1.6394 - val_loss: 1.6677\n",
      "Epoch 227/300\n",
      "703/703 [==============================] - 1s - loss: 1.6731 - val_loss: 1.6685\n",
      "Epoch 228/300\n",
      "703/703 [==============================] - 1s - loss: 1.6598 - val_loss: 1.6734\n",
      "Epoch 229/300\n",
      "703/703 [==============================] - 1s - loss: 1.6658 - val_loss: 1.6703\n",
      "Epoch 230/300\n",
      "703/703 [==============================] - 1s - loss: 1.6560 - val_loss: 1.6920\n",
      "Epoch 231/300\n",
      "703/703 [==============================] - 1s - loss: 1.6690 - val_loss: 1.6649\n",
      "Epoch 232/300\n",
      "703/703 [==============================] - 1s - loss: 1.6681 - val_loss: 1.7141\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694/703 [============================>.] - ETA: 0s - loss: 1.6608\n",
      " Reduced learning rate to 0.00011561\n",
      "703/703 [==============================] - 1s - loss: 1.6609 - val_loss: 1.6791\n",
      "Epoch 234/300\n",
      "703/703 [==============================] - 1s - loss: 1.6759 - val_loss: 1.6757\n",
      "Epoch 235/300\n",
      "703/703 [==============================] - 1s - loss: 1.6512 - val_loss: 1.6943\n",
      "Epoch 236/300\n",
      "703/703 [==============================] - 1s - loss: 1.6474 - val_loss: 1.6703\n",
      "Epoch 237/300\n",
      "703/703 [==============================] - 1s - loss: 1.6391 - val_loss: 1.6535\n",
      "Epoch 238/300\n",
      "703/703 [==============================] - 1s - loss: 1.6588 - val_loss: 1.6698\n",
      "Epoch 239/300\n",
      "703/703 [==============================] - 1s - loss: 1.6588 - val_loss: 1.6531\n",
      "Epoch 240/300\n",
      "703/703 [==============================] - 1s - loss: 1.6536 - val_loss: 1.6751\n",
      "Epoch 241/300\n",
      "703/703 [==============================] - 1s - loss: 1.6569 - val_loss: 1.6748\n",
      "Epoch 242/300\n",
      "703/703 [==============================] - 1s - loss: 1.6662 - val_loss: 1.6759\n",
      "Epoch 243/300\n",
      "703/703 [==============================] - 1s - loss: 1.6686 - val_loss: 1.6665\n",
      "Epoch 244/300\n",
      "695/703 [============================>.] - ETA: 0s - loss: 1.6736\n",
      " Reduced learning rate to 7.70735e-05\n",
      "703/703 [==============================] - 1s - loss: 1.6731 - val_loss: 1.6697\n",
      "Epoch 1/300\n",
      "1406/1406 [==============================] - 3s - loss: 6.7943 - val_loss: 2.4863\n",
      "Epoch 2/300\n",
      "1406/1406 [==============================] - 2s - loss: 3.0638 - val_loss: 4.5186\n",
      "Epoch 3/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.8615 - val_loss: 3.8038\n",
      "Epoch 4/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.7169 - val_loss: 2.4259\n",
      "Epoch 5/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.5358 - val_loss: 2.3291\n",
      "Epoch 6/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.4843 - val_loss: 1.9470\n",
      "Epoch 7/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.3872 - val_loss: 2.0146\n",
      "Epoch 8/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.3281 - val_loss: 2.7910\n",
      "Epoch 9/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.2395 - val_loss: 2.1559\n",
      "Epoch 10/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1889 - val_loss: 2.7666\n",
      "Epoch 11/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1670 - val_loss: 1.8301\n",
      "Epoch 12/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1124 - val_loss: 2.0303\n",
      "Epoch 13/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1214 - val_loss: 2.0361\n",
      "Epoch 14/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.0395 - val_loss: 2.0064\n",
      "Epoch 15/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.0234 - val_loss: 2.4683\n",
      "Epoch 16/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.0280 - val_loss: 1.9553\n",
      "Epoch 17/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9799 - val_loss: 2.2504\n",
      "Epoch 18/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9786 - val_loss: 2.3432\n",
      "Epoch 19/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9827 - val_loss: 2.0113\n",
      "Epoch 20/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9712 - val_loss: 1.8763\n",
      "Epoch 21/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9413 - val_loss: 1.8233\n",
      "Epoch 22/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9324 - val_loss: 2.1464\n",
      "Epoch 23/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8953 - val_loss: 1.8946\n",
      "Epoch 24/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9186 - val_loss: 1.9858\n",
      "Epoch 25/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8979 - val_loss: 1.7624\n",
      "Epoch 26/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8918 - val_loss: 2.0330\n",
      "Epoch 27/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8990 - val_loss: 1.8493\n",
      "Epoch 28/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8907 - val_loss: 2.0529\n",
      "Epoch 29/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8607 - val_loss: 1.8689\n",
      "Epoch 30/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8820 - val_loss: 1.8035\n",
      "Epoch 31/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8675 - val_loss: 2.0598\n",
      "Epoch 32/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8477 - val_loss: 2.1163\n",
      "Epoch 33/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8529 - val_loss: 1.8911\n",
      "Epoch 34/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8578 - val_loss: 1.8577\n",
      "Epoch 35/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8655 - val_loss: 2.3480\n",
      "Epoch 36/300\n",
      "1389/1406 [============================>.] - ETA: 0s - loss: 1.8386\n",
      " Reduced learning rate to 0.01\n",
      "1406/1406 [==============================] - 2s - loss: 1.8403 - val_loss: 2.0108\n",
      "Epoch 37/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7374 - val_loss: 1.9654\n",
      "Epoch 38/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7544 - val_loss: 1.8358\n",
      "Epoch 39/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7567 - val_loss: 1.8365\n",
      "Epoch 40/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7343 - val_loss: 1.8628\n",
      "Epoch 41/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7424 - val_loss: 1.7476\n",
      "Epoch 42/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7590 - val_loss: 1.9585\n",
      "Epoch 43/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7413 - val_loss: 1.7757\n",
      "Epoch 44/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7374 - val_loss: 1.7175\n",
      "Epoch 45/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7440 - val_loss: 1.9103\n",
      "Epoch 46/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7410 - val_loss: 1.7581\n",
      "Epoch 47/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7343 - val_loss: 1.8057\n",
      "Epoch 48/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7408 - val_loss: 1.8116\n",
      "Epoch 49/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7233 - val_loss: 1.7627\n",
      "Epoch 50/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7447 - val_loss: 1.7425\n",
      "Epoch 51/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7414 - val_loss: 1.7309\n",
      "Epoch 52/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7299 - val_loss: 1.7781\n",
      "Epoch 53/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7421 - val_loss: 1.7916\n",
      "Epoch 54/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7309 - val_loss: 1.8972\n",
      "Epoch 55/300\n",
      "1376/1406 [============================>.] - ETA: 0s - loss: 1.7469\n",
      " Reduced learning rate to 0.00666667\n",
      "1406/1406 [==============================] - 2s - loss: 1.7457 - val_loss: 1.7810\n",
      "Epoch 56/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6973 - val_loss: 1.7229\n",
      "Epoch 57/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6955 - val_loss: 1.7236\n",
      "Epoch 58/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6984 - val_loss: 1.7707\n",
      "Epoch 59/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7083 - val_loss: 1.7653\n",
      "Epoch 60/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7060 - val_loss: 1.7709\n",
      "Epoch 61/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7067 - val_loss: 1.7417\n",
      "Epoch 62/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7072 - val_loss: 1.7336\n",
      "Epoch 63/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6960 - val_loss: 1.7413\n",
      "Epoch 64/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.7019 - val_loss: 1.7370\n",
      "Epoch 65/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7116 - val_loss: 1.7272\n",
      "Epoch 66/300\n",
      "1397/1406 [============================>.] - ETA: 0s - loss: 1.7130\n",
      " Reduced learning rate to 0.00444444\n",
      "1406/1406 [==============================] - 4s - loss: 1.7128 - val_loss: 1.7935\n",
      "Epoch 67/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6763 - val_loss: 1.7187\n",
      "Epoch 68/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6830 - val_loss: 1.7222\n",
      "Epoch 69/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6789 - val_loss: 1.7090\n",
      "Epoch 70/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.6742 - val_loss: 1.7852\n",
      "Epoch 71/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6769 - val_loss: 1.7038\n",
      "Epoch 72/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6798 - val_loss: 1.6897\n",
      "Epoch 73/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6882 - val_loss: 1.6814\n",
      "Epoch 74/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6745 - val_loss: 1.7307\n",
      "Epoch 75/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6965 - val_loss: 1.7165\n",
      "Epoch 76/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6986 - val_loss: 1.7002\n",
      "Epoch 77/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6914 - val_loss: 1.7092\n",
      "Epoch 78/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6896 - val_loss: 1.7417\n",
      "Epoch 79/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6792 - val_loss: 1.8274\n",
      "Epoch 80/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6920 - val_loss: 1.7011\n",
      "Epoch 81/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6921 - val_loss: 1.7022\n",
      "Epoch 82/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6739 - val_loss: 1.7329\n",
      "Epoch 83/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6947 - val_loss: 1.7433\n",
      "Epoch 84/300\n",
      "1393/1406 [============================>.] - ETA: 0s - loss: 1.6883\n",
      " Reduced learning rate to 0.00296296\n",
      "1406/1406 [==============================] - 4s - loss: 1.6885 - val_loss: 1.7112\n",
      "Epoch 85/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6792 - val_loss: 1.6872\n",
      "Epoch 86/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6725 - val_loss: 1.7310\n",
      "Epoch 87/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6803 - val_loss: 1.7175\n",
      "Epoch 88/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6714 - val_loss: 1.6990\n",
      "Epoch 89/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6685 - val_loss: 1.7579\n",
      "Epoch 90/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6695 - val_loss: 1.7624\n",
      "Epoch 91/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6706 - val_loss: 1.7004\n",
      "Epoch 92/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6641 - val_loss: 1.7665\n",
      "Epoch 93/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6718 - val_loss: 1.7225\n",
      "Epoch 94/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6689 - val_loss: 1.7322\n",
      "Epoch 95/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6726 - val_loss: 1.6578\n",
      "Epoch 96/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6717 - val_loss: 1.7451\n",
      "Epoch 97/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6593 - val_loss: 1.7239\n",
      "Epoch 98/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6676 - val_loss: 1.7005\n",
      "Epoch 99/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6714 - val_loss: 1.7409\n",
      "Epoch 100/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6787 - val_loss: 1.7105\n",
      "Epoch 101/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6801 - val_loss: 1.7165\n",
      "Epoch 102/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6693 - val_loss: 1.6911\n",
      "Epoch 103/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6730 - val_loss: 1.6993\n",
      "Epoch 104/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6640 - val_loss: 1.6817\n",
      "Epoch 105/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6868 - val_loss: 1.7161\n",
      "Epoch 106/300\n",
      "1398/1406 [============================>.] - ETA: 0s - loss: 1.6719\n",
      " Reduced learning rate to 0.00197531\n",
      "1406/1406 [==============================] - 4s - loss: 1.6715 - val_loss: 1.7232\n",
      "Epoch 107/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6718 - val_loss: 1.6978\n",
      "Epoch 108/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6583 - val_loss: 1.6915\n",
      "Epoch 109/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6690 - val_loss: 1.7139\n",
      "Epoch 110/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6669 - val_loss: 1.7180\n",
      "Epoch 111/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6696 - val_loss: 1.7128\n",
      "Epoch 112/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6757 - val_loss: 1.7370\n",
      "Epoch 113/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6645 - val_loss: 1.7114\n",
      "Epoch 114/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6758 - val_loss: 1.6961\n",
      "Epoch 115/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6528 - val_loss: 1.6788\n",
      "Epoch 116/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6820 - val_loss: 1.7222\n",
      "Epoch 117/300\n",
      "1389/1406 [============================>.] - ETA: 0s - loss: 1.6697\n",
      " Reduced learning rate to 0.00131687\n",
      "1406/1406 [==============================] - 4s - loss: 1.6699 - val_loss: 1.7073\n",
      "Epoch 118/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6627 - val_loss: 1.6859\n",
      "Epoch 119/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6640 - val_loss: 1.7322\n",
      "Epoch 120/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6668 - val_loss: 1.6912\n",
      "Epoch 121/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6613 - val_loss: 1.6817\n",
      "Epoch 122/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6590 - val_loss: 1.6787\n",
      "Epoch 123/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6582 - val_loss: 1.6916\n",
      "Epoch 124/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6585 - val_loss: 1.7151\n",
      "Epoch 125/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6607 - val_loss: 1.6927\n",
      "Epoch 126/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6766 - val_loss: 1.6997\n",
      "Epoch 127/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6720 - val_loss: 1.7172\n",
      "Epoch 128/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6638\n",
      " Reduced learning rate to 0.000877915\n",
      "1406/1406 [==============================] - 4s - loss: 1.6638 - val_loss: 1.7009\n",
      "Epoch 129/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6660 - val_loss: 1.6987\n",
      "Epoch 130/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6584 - val_loss: 1.7100\n",
      "Epoch 131/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6578 - val_loss: 1.6887\n",
      "Epoch 132/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6597 - val_loss: 1.6918\n",
      "Epoch 133/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6622 - val_loss: 1.6898\n",
      "Epoch 134/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6691 - val_loss: 1.6921\n",
      "Epoch 135/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6611 - val_loss: 1.7138\n",
      "Epoch 136/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6674 - val_loss: 1.7069\n",
      "Epoch 137/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6571 - val_loss: 1.7127\n",
      "Epoch 138/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6567 - val_loss: 1.6840\n",
      "Epoch 139/300\n",
      "1393/1406 [============================>.] - ETA: 0s - loss: 1.6549\n",
      " Reduced learning rate to 0.000585277\n",
      "1406/1406 [==============================] - 4s - loss: 1.6552 - val_loss: 1.6909\n",
      "Epoch 140/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6538 - val_loss: 1.6870\n",
      "Epoch 141/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6447 - val_loss: 1.7165\n",
      "Epoch 142/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6652 - val_loss: 1.6976\n",
      "Epoch 143/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6650 - val_loss: 1.6973\n",
      "Epoch 144/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6560 - val_loss: 1.7016\n",
      "Epoch 145/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6665 - val_loss: 1.6706\n",
      "Epoch 146/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6554 - val_loss: 1.7143\n",
      "Epoch 147/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6552 - val_loss: 1.7026\n",
      "Epoch 148/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6656 - val_loss: 1.7268\n",
      "Epoch 149/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6573 - val_loss: 1.6884\n",
      "Epoch 150/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1394/1406 [============================>.] - ETA: 0s - loss: 1.6494\n",
      " Reduced learning rate to 0.000390184\n",
      "1406/1406 [==============================] - 4s - loss: 1.6498 - val_loss: 1.7102\n",
      "Epoch 151/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6511 - val_loss: 1.7117\n",
      "Epoch 152/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6634 - val_loss: 1.6912\n",
      "Epoch 153/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6611 - val_loss: 1.6631\n",
      "Epoch 154/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6616 - val_loss: 1.7043\n",
      "Epoch 155/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6694 - val_loss: 1.7004\n",
      "Epoch 156/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6670 - val_loss: 1.6882\n",
      "Epoch 157/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6572 - val_loss: 1.6958\n",
      "Epoch 158/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6673 - val_loss: 1.6708\n",
      "Epoch 159/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6584 - val_loss: 1.7202\n",
      "Epoch 160/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6576 - val_loss: 1.7000\n",
      "Epoch 161/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6612\n",
      " Reduced learning rate to 0.000260123\n",
      "1406/1406 [==============================] - 4s - loss: 1.6614 - val_loss: 1.7210\n",
      "Epoch 162/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6578 - val_loss: 1.7007\n",
      "Epoch 163/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6683 - val_loss: 1.7198\n",
      "Epoch 164/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6568 - val_loss: 1.7048\n",
      "Epoch 165/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6694 - val_loss: 1.7188\n",
      "Epoch 166/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6502 - val_loss: 1.7024\n",
      "Epoch 167/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6655 - val_loss: 1.6745\n",
      "Epoch 168/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6546 - val_loss: 1.7136\n",
      "Epoch 169/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6517 - val_loss: 1.7022\n",
      "Epoch 170/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6608 - val_loss: 1.7078\n",
      "Epoch 171/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6646 - val_loss: 1.7287\n",
      "Epoch 172/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6750\n",
      " Reduced learning rate to 0.000173415\n",
      "1406/1406 [==============================] - 4s - loss: 1.6752 - val_loss: 1.6855\n",
      "Epoch 173/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6644 - val_loss: 1.6929\n",
      "Epoch 174/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6578 - val_loss: 1.7012\n",
      "Epoch 175/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6523 - val_loss: 1.6934\n",
      "Epoch 176/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6562 - val_loss: 1.7123\n",
      "Epoch 177/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6558 - val_loss: 1.7095\n",
      "Epoch 178/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6443 - val_loss: 1.7085\n",
      "Epoch 179/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6635 - val_loss: 1.6797\n",
      "Epoch 180/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6531 - val_loss: 1.7063\n",
      "Epoch 181/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6579 - val_loss: 1.7048\n",
      "Epoch 182/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6704 - val_loss: 1.7167\n",
      "Epoch 183/300\n",
      "1399/1406 [============================>.] - ETA: 0s - loss: 1.6613\n",
      " Reduced learning rate to 0.00011561\n",
      "1406/1406 [==============================] - 4s - loss: 1.6620 - val_loss: 1.6797\n",
      "Epoch 184/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6513 - val_loss: 1.6821\n",
      "Epoch 185/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6466 - val_loss: 1.6866\n",
      "Epoch 186/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6540 - val_loss: 1.7029\n",
      "Epoch 187/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6513 - val_loss: 1.7097\n",
      "Epoch 188/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6433 - val_loss: 1.6993\n",
      "Epoch 189/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6529 - val_loss: 1.7034\n",
      "Epoch 190/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6592 - val_loss: 1.6878\n",
      "Epoch 191/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6674 - val_loss: 1.6963\n",
      "Epoch 192/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6522 - val_loss: 1.6814\n",
      "Epoch 193/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6640 - val_loss: 1.7027\n",
      "Epoch 194/300\n",
      "1400/1406 [============================>.] - ETA: 0s - loss: 1.6590\n",
      " Reduced learning rate to 7.70735e-05\n",
      "1406/1406 [==============================] - 4s - loss: 1.6595 - val_loss: 1.7017\n",
      "Epoch 1/300\n",
      "1406/1406 [==============================] - 5s - loss: 6.6361 - val_loss: 4.2470\n",
      "Epoch 2/300\n",
      "1406/1406 [==============================] - 4s - loss: 3.0538 - val_loss: 3.1241\n",
      "Epoch 3/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.8389 - val_loss: 2.0728\n",
      "Epoch 4/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.6571 - val_loss: 2.8370\n",
      "Epoch 5/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.6234 - val_loss: 2.8261\n",
      "Epoch 6/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.4653 - val_loss: 2.2718\n",
      "Epoch 7/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.4277 - val_loss: 2.4307\n",
      "Epoch 8/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.3259 - val_loss: 2.5967\n",
      "Epoch 9/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.2486 - val_loss: 2.1894\n",
      "Epoch 10/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.2014 - val_loss: 2.0541\n",
      "Epoch 11/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1795 - val_loss: 1.9971\n",
      "Epoch 12/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1516 - val_loss: 1.8825\n",
      "Epoch 13/300\n",
      "1406/1406 [==============================] - 3s - loss: 2.0979 - val_loss: 2.0986\n",
      "Epoch 14/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0656 - val_loss: 2.0610\n",
      "Epoch 15/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0575 - val_loss: 2.0566\n",
      "Epoch 16/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0627 - val_loss: 1.9696\n",
      "Epoch 17/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9984 - val_loss: 2.2026\n",
      "Epoch 18/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9848 - val_loss: 1.8521\n",
      "Epoch 19/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0110 - val_loss: 1.8449\n",
      "Epoch 20/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9716 - val_loss: 1.8567\n",
      "Epoch 21/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9347 - val_loss: 1.8708\n",
      "Epoch 22/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9402 - val_loss: 1.9517\n",
      "Epoch 23/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9431 - val_loss: 2.1419\n",
      "Epoch 24/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9179 - val_loss: 1.7991\n",
      "Epoch 25/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9100 - val_loss: 2.0086\n",
      "Epoch 26/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9158 - val_loss: 2.0248\n",
      "Epoch 27/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9013 - val_loss: 1.7915\n",
      "Epoch 28/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8848 - val_loss: 1.9764\n",
      "Epoch 29/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9103 - val_loss: 1.8638\n",
      "Epoch 30/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.8720 - val_loss: 1.9256\n",
      "Epoch 31/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8742 - val_loss: 1.7762\n",
      "Epoch 32/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8531 - val_loss: 1.7777\n",
      "Epoch 33/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8652 - val_loss: 1.8510\n",
      "Epoch 34/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8416 - val_loss: 1.7689\n",
      "Epoch 35/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8421 - val_loss: 1.7847\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.8434 - val_loss: 1.9080\n",
      "Epoch 37/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8473 - val_loss: 1.7736\n",
      "Epoch 38/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8318 - val_loss: 1.9154\n",
      "Epoch 39/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8312 - val_loss: 1.8408\n",
      "Epoch 40/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8519 - val_loss: 1.8818\n",
      "Epoch 41/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8363 - val_loss: 1.8044\n",
      "Epoch 42/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8268 - val_loss: 1.8709\n",
      "Epoch 43/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8333 - val_loss: 1.7739\n",
      "Epoch 44/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8356 - val_loss: 1.7210\n",
      "Epoch 45/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8237 - val_loss: 1.8947\n",
      "Epoch 46/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8339 - val_loss: 1.7648\n",
      "Epoch 47/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8102 - val_loss: 1.9987\n",
      "Epoch 48/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8380 - val_loss: 1.7829\n",
      "Epoch 49/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8503 - val_loss: 1.7741\n",
      "Epoch 50/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8249 - val_loss: 1.7459\n",
      "Epoch 51/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8010 - val_loss: 1.7759\n",
      "Epoch 52/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7980 - val_loss: 1.9537\n",
      "Epoch 53/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7987 - val_loss: 1.7576\n",
      "Epoch 54/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8208 - val_loss: 1.8113\n",
      "Epoch 55/300\n",
      "1395/1406 [============================>.] - ETA: 0s - loss: 1.8184\n",
      " Reduced learning rate to 0.01\n",
      "1406/1406 [==============================] - 4s - loss: 1.8176 - val_loss: 1.7559\n",
      "Epoch 56/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7248 - val_loss: 1.7571\n",
      "Epoch 57/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7270 - val_loss: 1.7498\n",
      "Epoch 58/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7519 - val_loss: 1.7197\n",
      "Epoch 59/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7376 - val_loss: 1.7236\n",
      "Epoch 60/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7367 - val_loss: 1.8003\n",
      "Epoch 61/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7224 - val_loss: 1.6972\n",
      "Epoch 62/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7178 - val_loss: 1.8086\n",
      "Epoch 63/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7196 - val_loss: 1.7720\n",
      "Epoch 64/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7357 - val_loss: 1.7393\n",
      "Epoch 65/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7284 - val_loss: 1.7210\n",
      "Epoch 66/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7285 - val_loss: 1.6976\n",
      "Epoch 67/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7380 - val_loss: 1.7688\n",
      "Epoch 68/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7265 - val_loss: 1.7727\n",
      "Epoch 69/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7329 - val_loss: 1.7611\n",
      "Epoch 70/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7123 - val_loss: 1.6975\n",
      "Epoch 71/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7324 - val_loss: 1.7448\n",
      "Epoch 72/300\n",
      "1399/1406 [============================>.] - ETA: 0s - loss: 1.7298\n",
      " Reduced learning rate to 0.00666667\n",
      "1406/1406 [==============================] - 4s - loss: 1.7302 - val_loss: 1.7952\n",
      "Epoch 73/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6925 - val_loss: 1.7563\n",
      "Epoch 74/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6983 - val_loss: 1.7421\n",
      "Epoch 75/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6906 - val_loss: 1.6907\n",
      "Epoch 76/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6895 - val_loss: 1.7346\n",
      "Epoch 77/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7032 - val_loss: 1.7437\n",
      "Epoch 78/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6952 - val_loss: 1.7932\n",
      "Epoch 79/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6923 - val_loss: 1.7148\n",
      "Epoch 80/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6967 - val_loss: 1.7275\n",
      "Epoch 81/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6934 - val_loss: 1.7966\n",
      "Epoch 82/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6979 - val_loss: 1.7473\n",
      "Epoch 83/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6883 - val_loss: 1.7579\n",
      "Epoch 84/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6934 - val_loss: 1.8308\n",
      "Epoch 85/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6949 - val_loss: 1.7380\n",
      "Epoch 86/300\n",
      "1405/1406 [============================>.] - ETA: 0s - loss: 1.6940\n",
      " Reduced learning rate to 0.00444444\n",
      "1406/1406 [==============================] - 4s - loss: 1.6941 - val_loss: 1.7273\n",
      "Epoch 87/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6760 - val_loss: 1.7068\n",
      "Epoch 88/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6813 - val_loss: 1.6990\n",
      "Epoch 89/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6915 - val_loss: 1.7463\n",
      "Epoch 90/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6888 - val_loss: 1.7380\n",
      "Epoch 91/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6752 - val_loss: 1.7207\n",
      "Epoch 92/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6838 - val_loss: 1.7128\n",
      "Epoch 93/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6686 - val_loss: 1.7144\n",
      "Epoch 94/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6737 - val_loss: 1.7127\n",
      "Epoch 95/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6823 - val_loss: 1.7263\n",
      "Epoch 96/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6900 - val_loss: 1.6974\n",
      "Epoch 97/300\n",
      "1397/1406 [============================>.] - ETA: 0s - loss: 1.6784\n",
      " Reduced learning rate to 0.00296296\n",
      "1406/1406 [==============================] - 4s - loss: 1.6785 - val_loss: 1.6997\n",
      "Epoch 98/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6735 - val_loss: 1.7185\n",
      "Epoch 99/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6647 - val_loss: 1.7375\n",
      "Epoch 100/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6758 - val_loss: 1.6887\n",
      "Epoch 101/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6683 - val_loss: 1.7141\n",
      "Epoch 102/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6729 - val_loss: 1.6870\n",
      "Epoch 103/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6587 - val_loss: 1.7069\n",
      "Epoch 104/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6693 - val_loss: 1.7040\n",
      "Epoch 105/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6701 - val_loss: 1.7320\n",
      "Epoch 106/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6754 - val_loss: 1.7122\n",
      "Epoch 107/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6708 - val_loss: 1.7080\n",
      "Epoch 108/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6613 - val_loss: 1.7187\n",
      "Epoch 109/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6614 - val_loss: 1.6970\n",
      "Epoch 110/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6696 - val_loss: 1.7087\n",
      "Epoch 111/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6647 - val_loss: 1.6963\n",
      "Epoch 112/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6707 - val_loss: 1.7115\n",
      "Epoch 113/300\n",
      "1405/1406 [============================>.] - ETA: 0s - loss: 1.6710\n",
      " Reduced learning rate to 0.00197531\n",
      "1406/1406 [==============================] - 4s - loss: 1.6712 - val_loss: 1.7242\n",
      "Epoch 114/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6618 - val_loss: 1.6948\n",
      "Epoch 115/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6622 - val_loss: 1.7064\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.6616 - val_loss: 1.6975\n",
      "Epoch 117/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6694 - val_loss: 1.7158\n",
      "Epoch 118/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6677 - val_loss: 1.7012\n",
      "Epoch 119/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6683 - val_loss: 1.6850\n",
      "Epoch 120/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6654 - val_loss: 1.6831\n",
      "Epoch 121/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6772 - val_loss: 1.6677\n",
      "Epoch 122/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6661 - val_loss: 1.7095\n",
      "Epoch 123/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6722 - val_loss: 1.6829\n",
      "Epoch 124/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6616 - val_loss: 1.6978\n",
      "Epoch 125/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6765 - val_loss: 1.7120\n",
      "Epoch 126/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6680 - val_loss: 1.7070\n",
      "Epoch 127/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6481 - val_loss: 1.6910\n",
      "Epoch 128/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6672 - val_loss: 1.7015\n",
      "Epoch 129/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6520 - val_loss: 1.6888\n",
      "Epoch 130/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6651 - val_loss: 1.7241\n",
      "Epoch 131/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6767 - val_loss: 1.6927\n",
      "Epoch 132/300\n",
      "1395/1406 [============================>.] - ETA: 0s - loss: 1.6619\n",
      " Reduced learning rate to 0.00131687\n",
      "1406/1406 [==============================] - 4s - loss: 1.6619 - val_loss: 1.6872\n",
      "Epoch 133/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6543 - val_loss: 1.7216\n",
      "Epoch 134/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6612 - val_loss: 1.7007\n",
      "Epoch 135/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6565 - val_loss: 1.7073\n",
      "Epoch 136/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6699 - val_loss: 1.7041\n",
      "Epoch 137/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6633 - val_loss: 1.7023\n",
      "Epoch 138/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6564 - val_loss: 1.7178\n",
      "Epoch 139/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6736 - val_loss: 1.7239\n",
      "Epoch 140/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6729 - val_loss: 1.6856\n",
      "Epoch 141/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6652 - val_loss: 1.7005\n",
      "Epoch 142/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6553 - val_loss: 1.6982\n",
      "Epoch 143/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6599 - val_loss: 1.6579\n",
      "Epoch 144/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6658 - val_loss: 1.7039\n",
      "Epoch 145/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6569 - val_loss: 1.6846\n",
      "Epoch 146/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6556 - val_loss: 1.6929\n",
      "Epoch 147/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6545 - val_loss: 1.7302\n",
      "Epoch 148/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6668 - val_loss: 1.7077\n",
      "Epoch 149/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6574 - val_loss: 1.7056\n",
      "Epoch 150/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6622 - val_loss: 1.6986\n",
      "Epoch 151/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6597 - val_loss: 1.7256\n",
      "Epoch 152/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6630 - val_loss: 1.7046\n",
      "Epoch 153/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6506 - val_loss: 1.7041\n",
      "Epoch 154/300\n",
      "1399/1406 [============================>.] - ETA: 0s - loss: 1.6637\n",
      " Reduced learning rate to 0.000877915\n",
      "1406/1406 [==============================] - 4s - loss: 1.6643 - val_loss: 1.6932\n",
      "Epoch 155/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6701 - val_loss: 1.6813\n",
      "Epoch 156/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6575 - val_loss: 1.6958\n",
      "Epoch 157/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6420 - val_loss: 1.7075\n",
      "Epoch 158/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6547 - val_loss: 1.7037\n",
      "Epoch 159/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6493 - val_loss: 1.7190\n",
      "Epoch 160/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6669 - val_loss: 1.6980\n",
      "Epoch 161/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6671 - val_loss: 1.6876\n",
      "Epoch 162/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6692 - val_loss: 1.7393\n",
      "Epoch 163/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6592 - val_loss: 1.6961\n",
      "Epoch 164/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6616 - val_loss: 1.6988\n",
      "Epoch 165/300\n",
      "1388/1406 [============================>.] - ETA: 0s - loss: 1.6612\n",
      " Reduced learning rate to 0.000585277\n",
      "1406/1406 [==============================] - 4s - loss: 1.6599 - val_loss: 1.6851\n",
      "Epoch 166/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6681 - val_loss: 1.6975\n",
      "Epoch 167/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6450 - val_loss: 1.6736\n",
      "Epoch 168/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6497 - val_loss: 1.7007\n",
      "Epoch 169/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6603 - val_loss: 1.7326\n",
      "Epoch 170/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6618 - val_loss: 1.7070\n",
      "Epoch 171/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6652 - val_loss: 1.6900\n",
      "Epoch 172/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6510 - val_loss: 1.6779\n",
      "Epoch 173/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6519 - val_loss: 1.7112\n",
      "Epoch 174/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6485 - val_loss: 1.7064\n",
      "Epoch 175/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6636 - val_loss: 1.6773\n",
      "Epoch 176/300\n",
      "1387/1406 [============================>.] - ETA: 0s - loss: 1.6653\n",
      " Reduced learning rate to 0.000390184\n",
      "1406/1406 [==============================] - 4s - loss: 1.6650 - val_loss: 1.6974\n",
      "Epoch 177/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6528 - val_loss: 1.6949\n",
      "Epoch 178/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6543 - val_loss: 1.7062\n",
      "Epoch 179/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6663 - val_loss: 1.7082\n",
      "Epoch 180/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6541 - val_loss: 1.7121\n",
      "Epoch 181/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6596 - val_loss: 1.6934\n",
      "Epoch 182/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6620 - val_loss: 1.6965\n",
      "Epoch 183/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6496 - val_loss: 1.6965\n",
      "Epoch 184/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6530 - val_loss: 1.6971\n",
      "Epoch 185/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6679 - val_loss: 1.7029\n",
      "Epoch 186/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6595 - val_loss: 1.6839\n",
      "Epoch 187/300\n",
      "1391/1406 [============================>.] - ETA: 0s - loss: 1.6562\n",
      " Reduced learning rate to 0.000260123\n",
      "1406/1406 [==============================] - 4s - loss: 1.6567 - val_loss: 1.6722\n",
      "Epoch 188/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6534 - val_loss: 1.6951\n",
      "Epoch 189/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6612 - val_loss: 1.6943\n",
      "Epoch 190/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6549 - val_loss: 1.6907\n",
      "Epoch 191/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6422 - val_loss: 1.7012\n",
      "Epoch 192/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6608 - val_loss: 1.6911\n",
      "Epoch 193/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6573 - val_loss: 1.6975\n",
      "Epoch 194/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6690 - val_loss: 1.7017\n",
      "Epoch 195/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.6597 - val_loss: 1.6812\n",
      "Epoch 196/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6569 - val_loss: 1.7116\n",
      "Epoch 197/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6680 - val_loss: 1.6995\n",
      "Epoch 198/300\n",
      "1398/1406 [============================>.] - ETA: 0s - loss: 1.6635\n",
      " Reduced learning rate to 0.000173415\n",
      "1406/1406 [==============================] - 4s - loss: 1.6639 - val_loss: 1.6875\n",
      "Epoch 199/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6516 - val_loss: 1.6982\n",
      "Epoch 200/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6590 - val_loss: 1.6802\n",
      "Epoch 201/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6581 - val_loss: 1.7092\n",
      "Epoch 202/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6663 - val_loss: 1.6988\n",
      "Epoch 203/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6503 - val_loss: 1.6954\n",
      "Epoch 204/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6598 - val_loss: 1.6844\n",
      "Epoch 205/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6431 - val_loss: 1.6716\n",
      "Epoch 206/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6493 - val_loss: 1.6937\n",
      "Epoch 207/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6422 - val_loss: 1.6956\n",
      "Epoch 208/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6513 - val_loss: 1.6890\n",
      "Epoch 209/300\n",
      "1391/1406 [============================>.] - ETA: 0s - loss: 1.6524\n",
      " Reduced learning rate to 0.00011561\n",
      "1406/1406 [==============================] - 4s - loss: 1.6523 - val_loss: 1.7023\n",
      "Epoch 210/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6561 - val_loss: 1.6953\n",
      "Epoch 211/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6550 - val_loss: 1.6787\n",
      "Epoch 212/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6622 - val_loss: 1.7189\n",
      "Epoch 213/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6630 - val_loss: 1.6992\n",
      "Epoch 214/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6498 - val_loss: 1.6926\n",
      "Epoch 215/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6569 - val_loss: 1.6887\n",
      "Epoch 216/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6519 - val_loss: 1.6809\n",
      "Epoch 217/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6555 - val_loss: 1.7036\n",
      "Epoch 218/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6641 - val_loss: 1.7039\n",
      "Epoch 219/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6501 - val_loss: 1.7002\n",
      "Epoch 220/300\n",
      "1397/1406 [============================>.] - ETA: 0s - loss: 1.6529\n",
      " Reduced learning rate to 7.70735e-05\n",
      "1406/1406 [==============================] - 4s - loss: 1.6523 - val_loss: 1.6749\n",
      "Epoch 1/300\n",
      "1406/1406 [==============================] - 5s - loss: 7.0250 - val_loss: 3.3707\n",
      "Epoch 2/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.9889 - val_loss: 3.1015\n",
      "Epoch 3/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.8473 - val_loss: 3.3413\n",
      "Epoch 4/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.6305 - val_loss: 2.3582\n",
      "Epoch 5/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.5700 - val_loss: 3.2972\n",
      "Epoch 6/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.4557 - val_loss: 2.1756\n",
      "Epoch 7/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.3667 - val_loss: 2.0317\n",
      "Epoch 8/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.3009 - val_loss: 2.0402\n",
      "Epoch 9/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.2605 - val_loss: 2.2433\n",
      "Epoch 10/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.2096 - val_loss: 2.0269\n",
      "Epoch 11/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1468 - val_loss: 2.4921\n",
      "Epoch 12/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1361 - val_loss: 1.9216\n",
      "Epoch 13/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1252 - val_loss: 2.4725\n",
      "Epoch 14/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0747 - val_loss: 2.3244\n",
      "Epoch 15/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0645 - val_loss: 2.1530\n",
      "Epoch 16/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0350 - val_loss: 1.8233\n",
      "Epoch 17/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9618 - val_loss: 1.8501\n",
      "Epoch 18/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9842 - val_loss: 1.8548\n",
      "Epoch 19/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9953 - val_loss: 3.0384\n",
      "Epoch 20/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9659 - val_loss: 1.9434\n",
      "Epoch 21/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9701 - val_loss: 2.0195\n",
      "Epoch 22/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9339 - val_loss: 1.9055\n",
      "Epoch 23/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9318 - val_loss: 1.8852\n",
      "Epoch 24/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9258 - val_loss: 1.8086\n",
      "Epoch 25/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9129 - val_loss: 2.2412\n",
      "Epoch 26/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8984 - val_loss: 2.0000\n",
      "Epoch 27/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8990 - val_loss: 1.7823\n",
      "Epoch 28/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8818 - val_loss: 1.8198\n",
      "Epoch 29/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8951 - val_loss: 2.0483\n",
      "Epoch 30/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8758 - val_loss: 1.8743\n",
      "Epoch 31/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8857 - val_loss: 1.8037\n",
      "Epoch 32/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8652 - val_loss: 1.8892\n",
      "Epoch 33/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8734 - val_loss: 1.8726\n",
      "Epoch 34/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8586 - val_loss: 2.3297\n",
      "Epoch 35/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8546 - val_loss: 1.8913\n",
      "Epoch 36/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8490 - val_loss: 1.8044\n",
      "Epoch 37/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8540 - val_loss: 1.8218\n",
      "Epoch 38/300\n",
      "1391/1406 [============================>.] - ETA: 0s - loss: 1.8489\n",
      " Reduced learning rate to 0.01\n",
      "1406/1406 [==============================] - 5s - loss: 1.8485 - val_loss: 2.9697\n",
      "Epoch 39/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7453 - val_loss: 1.7319\n",
      "Epoch 40/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7381 - val_loss: 1.7280\n",
      "Epoch 41/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7445 - val_loss: 1.7864\n",
      "Epoch 42/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7488 - val_loss: 1.7134\n",
      "Epoch 43/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7482 - val_loss: 1.8470\n",
      "Epoch 44/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7392 - val_loss: 1.7441\n",
      "Epoch 45/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7463 - val_loss: 1.7184\n",
      "Epoch 46/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7363 - val_loss: 1.8010\n",
      "Epoch 47/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7501 - val_loss: 1.7994\n",
      "Epoch 48/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7260 - val_loss: 1.7803\n",
      "Epoch 49/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7337 - val_loss: 1.7967\n",
      "Epoch 50/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7380 - val_loss: 1.7342\n",
      "Epoch 51/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7378 - val_loss: 1.8093\n",
      "Epoch 52/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7309 - val_loss: 1.9922\n",
      "Epoch 53/300\n",
      "1398/1406 [============================>.] - ETA: 0s - loss: 1.7503\n",
      " Reduced learning rate to 0.00666667\n",
      "1406/1406 [==============================] - 4s - loss: 1.7500 - val_loss: 1.7476\n",
      "Epoch 54/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6952 - val_loss: 1.7595\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.7017 - val_loss: 1.7564\n",
      "Epoch 56/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6919 - val_loss: 1.7392\n",
      "Epoch 57/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7008 - val_loss: 1.7029\n",
      "Epoch 58/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6925 - val_loss: 1.7405\n",
      "Epoch 59/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6843 - val_loss: 1.7491\n",
      "Epoch 60/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6941 - val_loss: 1.7459\n",
      "Epoch 61/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7241 - val_loss: 1.7319\n",
      "Epoch 62/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6939 - val_loss: 1.7226\n",
      "Epoch 63/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7167 - val_loss: 1.7181\n",
      "Epoch 64/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7184 - val_loss: 1.7720\n",
      "Epoch 65/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7050 - val_loss: 1.7661\n",
      "Epoch 66/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7121 - val_loss: 1.7720\n",
      "Epoch 67/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7010 - val_loss: 1.7244\n",
      "Epoch 68/300\n",
      "1393/1406 [============================>.] - ETA: 0s - loss: 1.7149\n",
      " Reduced learning rate to 0.00444444\n",
      "1406/1406 [==============================] - 4s - loss: 1.7153 - val_loss: 1.7223\n",
      "Epoch 69/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6940 - val_loss: 1.6851\n",
      "Epoch 70/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6840 - val_loss: 1.7267\n",
      "Epoch 71/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6728 - val_loss: 1.7129\n",
      "Epoch 72/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6754 - val_loss: 1.7229\n",
      "Epoch 73/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6835 - val_loss: 1.6941\n",
      "Epoch 74/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6907 - val_loss: 1.7302\n",
      "Epoch 75/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6894 - val_loss: 1.7041\n",
      "Epoch 76/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6805 - val_loss: 1.7510\n",
      "Epoch 77/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6922 - val_loss: 1.7212\n",
      "Epoch 78/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6926 - val_loss: 1.7092\n",
      "Epoch 79/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6953 - val_loss: 1.7065\n",
      "Epoch 80/300\n",
      "1400/1406 [============================>.] - ETA: 0s - loss: 1.6627\n",
      " Reduced learning rate to 0.00296296\n",
      "1406/1406 [==============================] - 4s - loss: 1.6625 - val_loss: 1.7087\n",
      "Epoch 81/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6770 - val_loss: 1.7073\n",
      "Epoch 82/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6723 - val_loss: 1.7185\n",
      "Epoch 83/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6642 - val_loss: 1.7214\n",
      "Epoch 84/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6712 - val_loss: 1.7106\n",
      "Epoch 85/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6859 - val_loss: 1.7019\n",
      "Epoch 86/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6756 - val_loss: 1.7322\n",
      "Epoch 87/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6858 - val_loss: 1.7184\n",
      "Epoch 88/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6619 - val_loss: 1.7120\n",
      "Epoch 89/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6703 - val_loss: 1.6956\n",
      "Epoch 90/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6625 - val_loss: 1.7278\n",
      "Epoch 91/300\n",
      "1388/1406 [============================>.] - ETA: 0s - loss: 1.6730\n",
      " Reduced learning rate to 0.00197531\n",
      "1406/1406 [==============================] - 4s - loss: 1.6741 - val_loss: 1.6960\n",
      "Epoch 92/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6771 - val_loss: 1.7144\n",
      "Epoch 93/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6706 - val_loss: 1.6783\n",
      "Epoch 94/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6713 - val_loss: 1.6985\n",
      "Epoch 95/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6795 - val_loss: 1.7461\n",
      "Epoch 96/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6652 - val_loss: 1.7100\n",
      "Epoch 97/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6671 - val_loss: 1.7031\n",
      "Epoch 98/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6697 - val_loss: 1.7299\n",
      "Epoch 99/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6683 - val_loss: 1.7100\n",
      "Epoch 100/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6799 - val_loss: 1.7061\n",
      "Epoch 101/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6615 - val_loss: 1.7012\n",
      "Epoch 102/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6656 - val_loss: 1.6975\n",
      "Epoch 103/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6700 - val_loss: 1.6967\n",
      "Epoch 104/300\n",
      "1391/1406 [============================>.] - ETA: 0s - loss: 1.6688\n",
      " Reduced learning rate to 0.00131687\n",
      "1406/1406 [==============================] - 4s - loss: 1.6686 - val_loss: 1.7058\n",
      "Epoch 105/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6735 - val_loss: 1.6965\n",
      "Epoch 106/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6671 - val_loss: 1.6756\n",
      "Epoch 107/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6674 - val_loss: 1.7106\n",
      "Epoch 108/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6812 - val_loss: 1.7062\n",
      "Epoch 109/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6726 - val_loss: 1.7078\n",
      "Epoch 110/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6788 - val_loss: 1.6843\n",
      "Epoch 111/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6742 - val_loss: 1.7105\n",
      "Epoch 112/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6602 - val_loss: 1.7156\n",
      "Epoch 113/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6508 - val_loss: 1.6865\n",
      "Epoch 114/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6594 - val_loss: 1.7003\n",
      "Epoch 115/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6795 - val_loss: 1.7317\n",
      "Epoch 116/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6725 - val_loss: 1.7163\n",
      "Epoch 117/300\n",
      "1399/1406 [============================>.] - ETA: 0s - loss: 1.6655\n",
      " Reduced learning rate to 0.000877915\n",
      "1406/1406 [==============================] - 4s - loss: 1.6652 - val_loss: 1.7187\n",
      "Epoch 118/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6609 - val_loss: 1.7075\n",
      "Epoch 119/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6625 - val_loss: 1.6865\n",
      "Epoch 120/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6708 - val_loss: 1.6885\n",
      "Epoch 121/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6573 - val_loss: 1.7001\n",
      "Epoch 122/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6664 - val_loss: 1.7191\n",
      "Epoch 123/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6607 - val_loss: 1.6977\n",
      "Epoch 124/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6768 - val_loss: 1.6904\n",
      "Epoch 125/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6740 - val_loss: 1.7156\n",
      "Epoch 126/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6722 - val_loss: 1.6990\n",
      "Epoch 127/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6789 - val_loss: 1.7110\n",
      "Epoch 128/300\n",
      "1401/1406 [============================>.] - ETA: 0s - loss: 1.6708\n",
      " Reduced learning rate to 0.000585277\n",
      "1406/1406 [==============================] - 4s - loss: 1.6710 - val_loss: 1.6993\n",
      "Epoch 129/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6650 - val_loss: 1.7308\n",
      "Epoch 130/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6663 - val_loss: 1.6885\n",
      "Epoch 131/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6476 - val_loss: 1.6858\n",
      "Epoch 132/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6524 - val_loss: 1.6984\n",
      "Epoch 133/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6543 - val_loss: 1.7105\n",
      "Epoch 134/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.6597 - val_loss: 1.6919\n",
      "Epoch 135/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6518 - val_loss: 1.7010\n",
      "Epoch 136/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6628 - val_loss: 1.7012\n",
      "Epoch 137/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6599 - val_loss: 1.6878\n",
      "Epoch 138/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6709 - val_loss: 1.6967\n",
      "Epoch 139/300\n",
      "1399/1406 [============================>.] - ETA: 0s - loss: 1.6520\n",
      " Reduced learning rate to 0.000390184\n",
      "1406/1406 [==============================] - 4s - loss: 1.6525 - val_loss: 1.7085\n",
      "Epoch 140/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6605 - val_loss: 1.6895\n",
      "Epoch 141/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6523 - val_loss: 1.6830\n",
      "Epoch 142/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6578 - val_loss: 1.6807\n",
      "Epoch 143/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6602 - val_loss: 1.6877\n",
      "Epoch 144/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6667 - val_loss: 1.6744\n",
      "Epoch 145/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6635 - val_loss: 1.6926\n",
      "Epoch 146/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6649 - val_loss: 1.7362\n",
      "Epoch 147/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6571 - val_loss: 1.6948\n",
      "Epoch 148/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6649 - val_loss: 1.7048\n",
      "Epoch 149/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6524 - val_loss: 1.7010\n",
      "Epoch 150/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6523 - val_loss: 1.6841\n",
      "Epoch 151/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6638 - val_loss: 1.6824\n",
      "Epoch 152/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6582 - val_loss: 1.6928\n",
      "Epoch 153/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6531 - val_loss: 1.7010\n",
      "Epoch 154/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6561 - val_loss: 1.7119\n",
      "Epoch 155/300\n",
      "1400/1406 [============================>.] - ETA: 0s - loss: 1.6548\n",
      " Reduced learning rate to 0.000260123\n",
      "1406/1406 [==============================] - 4s - loss: 1.6552 - val_loss: 1.6985\n",
      "Epoch 156/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6677 - val_loss: 1.6923\n",
      "Epoch 157/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6676 - val_loss: 1.7014\n",
      "Epoch 158/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6693 - val_loss: 1.6856\n",
      "Epoch 159/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6506 - val_loss: 1.7043\n",
      "Epoch 160/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6630 - val_loss: 1.6973\n",
      "Epoch 161/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6726 - val_loss: 1.6923\n",
      "Epoch 162/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6661 - val_loss: 1.7085\n",
      "Epoch 163/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6682 - val_loss: 1.7212\n",
      "Epoch 164/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6666 - val_loss: 1.7039\n",
      "Epoch 165/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6519 - val_loss: 1.6850\n",
      "Epoch 166/300\n",
      "1396/1406 [============================>.] - ETA: 0s - loss: 1.6471\n",
      " Reduced learning rate to 0.000173415\n",
      "1406/1406 [==============================] - 4s - loss: 1.6477 - val_loss: 1.7211\n",
      "Epoch 167/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6600 - val_loss: 1.7236\n",
      "Epoch 168/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6639 - val_loss: 1.7014\n",
      "Epoch 169/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6535 - val_loss: 1.7102\n",
      "Epoch 170/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6638 - val_loss: 1.6990\n",
      "Epoch 171/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6643 - val_loss: 1.6939\n",
      "Epoch 172/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6511 - val_loss: 1.6951\n",
      "Epoch 173/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6543 - val_loss: 1.7167\n",
      "Epoch 174/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6529 - val_loss: 1.6768\n",
      "Epoch 175/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6677 - val_loss: 1.7265\n",
      "Epoch 176/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6533 - val_loss: 1.7040\n",
      "Epoch 177/300\n",
      "1403/1406 [============================>.] - ETA: 0s - loss: 1.6637\n",
      " Reduced learning rate to 0.00011561\n",
      "1406/1406 [==============================] - 4s - loss: 1.6635 - val_loss: 1.6918\n",
      "Epoch 178/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6573 - val_loss: 1.7141\n",
      "Epoch 179/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6740 - val_loss: 1.6977\n",
      "Epoch 180/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6600 - val_loss: 1.6853\n",
      "Epoch 181/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6576 - val_loss: 1.6940\n",
      "Epoch 182/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6482 - val_loss: 1.7093\n",
      "Epoch 183/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6573 - val_loss: 1.7063\n",
      "Epoch 184/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6553 - val_loss: 1.7026\n",
      "Epoch 185/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6496 - val_loss: 1.7184\n",
      "Epoch 186/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6678 - val_loss: 1.7048\n",
      "Epoch 187/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6668 - val_loss: 1.6990\n",
      "Epoch 188/300\n",
      "1389/1406 [============================>.] - ETA: 0s - loss: 1.6519\n",
      " Reduced learning rate to 7.70735e-05\n",
      "1406/1406 [==============================] - 4s - loss: 1.6521 - val_loss: 1.6926\n",
      "Epoch 1/300\n",
      "1406/1406 [==============================] - 6s - loss: 6.7625 - val_loss: 3.5918\n",
      "Epoch 2/300\n",
      "1406/1406 [==============================] - 4s - loss: 3.0204 - val_loss: 2.8348\n",
      "Epoch 3/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.8222 - val_loss: 2.3751\n",
      "Epoch 4/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.6799 - val_loss: 2.4344\n",
      "Epoch 5/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.5489 - val_loss: 2.3864\n",
      "Epoch 6/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.4492 - val_loss: 3.6508\n",
      "Epoch 7/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.3941 - val_loss: 2.3129\n",
      "Epoch 8/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.3186 - val_loss: 1.9693\n",
      "Epoch 9/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.2227 - val_loss: 2.9839\n",
      "Epoch 10/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.2451 - val_loss: 1.9213\n",
      "Epoch 11/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1710 - val_loss: 2.7457\n",
      "Epoch 12/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1565 - val_loss: 1.9211\n",
      "Epoch 13/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1065 - val_loss: 1.8516\n",
      "Epoch 14/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.1034 - val_loss: 2.1646\n",
      "Epoch 15/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0309 - val_loss: 2.1974\n",
      "Epoch 16/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0482 - val_loss: 1.8857\n",
      "Epoch 17/300\n",
      "1406/1406 [==============================] - 4s - loss: 2.0403 - val_loss: 2.1587\n",
      "Epoch 18/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9729 - val_loss: 1.9981\n",
      "Epoch 19/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9773 - val_loss: 1.9050\n",
      "Epoch 20/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9689 - val_loss: 1.7937\n",
      "Epoch 21/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9630 - val_loss: 1.8079\n",
      "Epoch 22/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9552 - val_loss: 1.8804\n",
      "Epoch 23/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9449 - val_loss: 2.2428\n",
      "Epoch 24/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9473 - val_loss: 1.9072\n",
      "Epoch 25/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9226 - val_loss: 2.8535\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.8968 - val_loss: 1.8697\n",
      "Epoch 27/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.9002 - val_loss: 1.7937\n",
      "Epoch 28/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8899 - val_loss: 1.7978\n",
      "Epoch 29/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8949 - val_loss: 1.7554\n",
      "Epoch 30/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8827 - val_loss: 1.7778\n",
      "Epoch 31/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8826 - val_loss: 1.7395\n",
      "Epoch 32/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8854 - val_loss: 1.7510\n",
      "Epoch 33/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8865 - val_loss: 1.8105\n",
      "Epoch 34/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8524 - val_loss: 1.8923\n",
      "Epoch 35/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8738 - val_loss: 1.8347\n",
      "Epoch 36/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8477 - val_loss: 1.9341\n",
      "Epoch 37/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8517 - val_loss: 1.7871\n",
      "Epoch 38/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8512 - val_loss: 2.3085\n",
      "Epoch 39/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8397 - val_loss: 1.8211\n",
      "Epoch 40/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8216 - val_loss: 1.8325\n",
      "Epoch 41/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.8553 - val_loss: 1.8181\n",
      "Epoch 42/300\n",
      "1403/1406 [============================>.] - ETA: 0s - loss: 1.8603\n",
      " Reduced learning rate to 0.01\n",
      "1406/1406 [==============================] - 5s - loss: 1.8600 - val_loss: 1.8220\n",
      "Epoch 43/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7499 - val_loss: 1.7225\n",
      "Epoch 44/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7328 - val_loss: 1.7180\n",
      "Epoch 45/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7343 - val_loss: 1.7496\n",
      "Epoch 46/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7424 - val_loss: 1.7393\n",
      "Epoch 47/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7396 - val_loss: 1.7229\n",
      "Epoch 48/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7293 - val_loss: 1.7484\n",
      "Epoch 49/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7304 - val_loss: 1.8269\n",
      "Epoch 50/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7357 - val_loss: 1.7803\n",
      "Epoch 51/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7470 - val_loss: 1.8540\n",
      "Epoch 52/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7460 - val_loss: 1.7717\n",
      "Epoch 53/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7369 - val_loss: 1.7603\n",
      "Epoch 54/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7368 - val_loss: 1.7603\n",
      "Epoch 55/300\n",
      "1397/1406 [============================>.] - ETA: 0s - loss: 1.7325\n",
      " Reduced learning rate to 0.00666667\n",
      "1406/1406 [==============================] - 4s - loss: 1.7330 - val_loss: 1.7188\n",
      "Epoch 56/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6953 - val_loss: 1.7239\n",
      "Epoch 57/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6888 - val_loss: 1.7175\n",
      "Epoch 58/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6955 - val_loss: 1.7293\n",
      "Epoch 59/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7002 - val_loss: 1.7131\n",
      "Epoch 60/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6942 - val_loss: 1.7179\n",
      "Epoch 61/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7047 - val_loss: 1.7175\n",
      "Epoch 62/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6971 - val_loss: 1.7007\n",
      "Epoch 63/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7025 - val_loss: 1.7208\n",
      "Epoch 64/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7015 - val_loss: 1.7002\n",
      "Epoch 65/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7133 - val_loss: 1.7341\n",
      "Epoch 66/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6979 - val_loss: 1.6968\n",
      "Epoch 67/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7062 - val_loss: 1.7089\n",
      "Epoch 68/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7004 - val_loss: 1.7520\n",
      "Epoch 69/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7043 - val_loss: 1.7309\n",
      "Epoch 70/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6942 - val_loss: 1.7350\n",
      "Epoch 71/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7132 - val_loss: 1.7907\n",
      "Epoch 72/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7096 - val_loss: 1.7115\n",
      "Epoch 73/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6947 - val_loss: 1.7045\n",
      "Epoch 74/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6937 - val_loss: 1.7590\n",
      "Epoch 75/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7032 - val_loss: 1.7246\n",
      "Epoch 76/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6984 - val_loss: 1.7554\n",
      "Epoch 77/300\n",
      "1388/1406 [============================>.] - ETA: 0s - loss: 1.7041\n",
      " Reduced learning rate to 0.00444444\n",
      "1406/1406 [==============================] - 4s - loss: 1.7026 - val_loss: 1.7070\n",
      "Epoch 78/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6723 - val_loss: 1.7092\n",
      "Epoch 79/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6903 - val_loss: 1.6962\n",
      "Epoch 80/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6784 - val_loss: 1.7270\n",
      "Epoch 81/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6805 - val_loss: 1.7510\n",
      "Epoch 82/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6934 - val_loss: 1.7144\n",
      "Epoch 83/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6809 - val_loss: 1.7519\n",
      "Epoch 84/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.7016 - val_loss: 1.6892\n",
      "Epoch 85/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6763 - val_loss: 1.7300\n",
      "Epoch 86/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6713 - val_loss: 1.7325\n",
      "Epoch 87/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6801 - val_loss: 1.7129\n",
      "Epoch 88/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6870 - val_loss: 1.7222\n",
      "Epoch 89/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6729 - val_loss: 1.7136\n",
      "Epoch 90/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6840 - val_loss: 1.7485\n",
      "Epoch 91/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6687 - val_loss: 1.7199\n",
      "Epoch 92/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6741 - val_loss: 1.7099\n",
      "Epoch 93/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6781 - val_loss: 1.7034\n",
      "Epoch 94/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6791 - val_loss: 1.7087\n",
      "Epoch 95/300\n",
      "1401/1406 [============================>.] - ETA: 0s - loss: 1.6780\n",
      " Reduced learning rate to 0.00296296\n",
      "1406/1406 [==============================] - 4s - loss: 1.6782 - val_loss: 1.7345\n",
      "Epoch 96/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6741 - val_loss: 1.7390\n",
      "Epoch 97/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6736 - val_loss: 1.7080\n",
      "Epoch 98/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6721 - val_loss: 1.6945\n",
      "Epoch 99/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6672 - val_loss: 1.7007\n",
      "Epoch 100/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6805 - val_loss: 1.7095\n",
      "Epoch 101/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6702 - val_loss: 1.7089\n",
      "Epoch 102/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6733 - val_loss: 1.6832\n",
      "Epoch 103/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6791 - val_loss: 1.7073\n",
      "Epoch 104/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6756 - val_loss: 1.6904\n",
      "Epoch 105/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6690 - val_loss: 1.6883\n",
      "Epoch 106/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6715 - val_loss: 1.7161\n",
      "Epoch 107/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 3s - loss: 1.6780 - val_loss: 1.7184\n",
      "Epoch 108/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6664 - val_loss: 1.7390\n",
      "Epoch 109/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6765 - val_loss: 1.7302\n",
      "Epoch 110/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6623 - val_loss: 1.6968\n",
      "Epoch 111/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6815 - val_loss: 1.6878\n",
      "Epoch 112/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6766 - val_loss: 1.7000\n",
      "Epoch 113/300\n",
      "1388/1406 [============================>.] - ETA: 0s - loss: 1.6735\n",
      " Reduced learning rate to 0.00197531\n",
      "1406/1406 [==============================] - 3s - loss: 1.6732 - val_loss: 1.7723\n",
      "Epoch 114/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6523 - val_loss: 1.7080\n",
      "Epoch 115/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6749 - val_loss: 1.6979\n",
      "Epoch 116/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6612 - val_loss: 1.6630\n",
      "Epoch 117/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6675 - val_loss: 1.7225\n",
      "Epoch 118/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6634 - val_loss: 1.7204\n",
      "Epoch 119/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6694 - val_loss: 1.6958\n",
      "Epoch 120/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6754 - val_loss: 1.6877\n",
      "Epoch 121/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6560 - val_loss: 1.7009\n",
      "Epoch 122/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6676 - val_loss: 1.6824\n",
      "Epoch 123/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6684 - val_loss: 1.7319\n",
      "Epoch 124/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6739 - val_loss: 1.7117\n",
      "Epoch 125/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6600 - val_loss: 1.7200\n",
      "Epoch 126/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6636 - val_loss: 1.7080\n",
      "Epoch 127/300\n",
      "1400/1406 [============================>.] - ETA: 0s - loss: 1.6636\n",
      " Reduced learning rate to 0.00131687\n",
      "1406/1406 [==============================] - 3s - loss: 1.6635 - val_loss: 1.7027\n",
      "Epoch 128/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6673 - val_loss: 1.6912\n",
      "Epoch 129/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6656 - val_loss: 1.7141\n",
      "Epoch 130/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6538 - val_loss: 1.6917\n",
      "Epoch 131/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6590 - val_loss: 1.7012\n",
      "Epoch 132/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6622 - val_loss: 1.6909\n",
      "Epoch 133/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6753 - val_loss: 1.6941\n",
      "Epoch 134/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6575 - val_loss: 1.7361\n",
      "Epoch 135/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6540 - val_loss: 1.6995\n",
      "Epoch 136/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6616 - val_loss: 1.6889\n",
      "Epoch 137/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6636 - val_loss: 1.7170\n",
      "Epoch 138/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6730\n",
      " Reduced learning rate to 0.000877915\n",
      "1406/1406 [==============================] - 2s - loss: 1.6728 - val_loss: 1.6880\n",
      "Epoch 139/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6584 - val_loss: 1.6919\n",
      "Epoch 140/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6750 - val_loss: 1.6758\n",
      "Epoch 141/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6603 - val_loss: 1.7034\n",
      "Epoch 142/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6670 - val_loss: 1.6817\n",
      "Epoch 143/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6683 - val_loss: 1.6819\n",
      "Epoch 144/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6640 - val_loss: 1.7209\n",
      "Epoch 145/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6667 - val_loss: 1.6738\n",
      "Epoch 146/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6583 - val_loss: 1.6907\n",
      "Epoch 147/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6623 - val_loss: 1.6843\n",
      "Epoch 148/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6525 - val_loss: 1.6853\n",
      "Epoch 149/300\n",
      "1405/1406 [============================>.] - ETA: 0s - loss: 1.6551\n",
      " Reduced learning rate to 0.000585277\n",
      "1406/1406 [==============================] - 2s - loss: 1.6552 - val_loss: 1.6987\n",
      "Epoch 150/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6569 - val_loss: 1.6880\n",
      "Epoch 151/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6597 - val_loss: 1.6785\n",
      "Epoch 152/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6512 - val_loss: 1.6909\n",
      "Epoch 153/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6424 - val_loss: 1.6892\n",
      "Epoch 154/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6536 - val_loss: 1.6699\n",
      "Epoch 155/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6665 - val_loss: 1.7005\n",
      "Epoch 156/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6688 - val_loss: 1.6677\n",
      "Epoch 157/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6651 - val_loss: 1.6975\n",
      "Epoch 158/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6630 - val_loss: 1.7139\n",
      "Epoch 159/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6685 - val_loss: 1.6966\n",
      "Epoch 160/300\n",
      "1389/1406 [============================>.] - ETA: 0s - loss: 1.6703\n",
      " Reduced learning rate to 0.000390184\n",
      "1406/1406 [==============================] - 2s - loss: 1.6699 - val_loss: 1.7022\n",
      "Epoch 161/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6571 - val_loss: 1.7078\n",
      "Epoch 162/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6600 - val_loss: 1.7004\n",
      "Epoch 163/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6524 - val_loss: 1.6968\n",
      "Epoch 164/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6551 - val_loss: 1.6960\n",
      "Epoch 165/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6617 - val_loss: 1.6819\n",
      "Epoch 166/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6585 - val_loss: 1.6904\n",
      "Epoch 167/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6722 - val_loss: 1.6929\n",
      "Epoch 168/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6436 - val_loss: 1.7111\n",
      "Epoch 169/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6582 - val_loss: 1.6819\n",
      "Epoch 170/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6564 - val_loss: 1.6777\n",
      "Epoch 171/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6650\n",
      " Reduced learning rate to 0.000260123\n",
      "1406/1406 [==============================] - 2s - loss: 1.6651 - val_loss: 1.6977\n",
      "Epoch 172/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6658 - val_loss: 1.6953\n",
      "Epoch 173/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6617 - val_loss: 1.7026\n",
      "Epoch 174/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6541 - val_loss: 1.7036\n",
      "Epoch 175/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6611 - val_loss: 1.6949\n",
      "Epoch 176/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6563 - val_loss: 1.7239\n",
      "Epoch 177/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6609 - val_loss: 1.6853\n",
      "Epoch 178/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6595 - val_loss: 1.6946\n",
      "Epoch 179/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6512 - val_loss: 1.6900\n",
      "Epoch 180/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6503 - val_loss: 1.6907\n",
      "Epoch 181/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6495 - val_loss: 1.6750\n",
      "Epoch 182/300\n",
      "1389/1406 [============================>.] - ETA: 0s - loss: 1.6573\n",
      " Reduced learning rate to 0.000173415\n",
      "1406/1406 [==============================] - 2s - loss: 1.6582 - val_loss: 1.6875\n",
      "Epoch 183/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6631 - val_loss: 1.6938\n",
      "Epoch 184/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 2s - loss: 1.6482 - val_loss: 1.6687\n",
      "Epoch 185/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6503 - val_loss: 1.6794\n",
      "Epoch 186/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6495 - val_loss: 1.7044\n",
      "Epoch 187/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6534 - val_loss: 1.6887\n",
      "Epoch 188/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6429 - val_loss: 1.7163\n",
      "Epoch 189/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6577 - val_loss: 1.6958\n",
      "Epoch 190/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6529 - val_loss: 1.6712\n",
      "Epoch 191/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6531 - val_loss: 1.6782\n",
      "Epoch 192/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6618 - val_loss: 1.6934\n",
      "Epoch 193/300\n",
      "1382/1406 [============================>.] - ETA: 0s - loss: 1.6482\n",
      " Reduced learning rate to 0.00011561\n",
      "1406/1406 [==============================] - 2s - loss: 1.6486 - val_loss: 1.6899\n",
      "Epoch 194/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6618 - val_loss: 1.6961\n",
      "Epoch 195/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6596 - val_loss: 1.7112\n",
      "Epoch 196/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6675 - val_loss: 1.6833\n",
      "Epoch 197/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6594 - val_loss: 1.6993\n",
      "Epoch 198/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6691 - val_loss: 1.7056\n",
      "Epoch 199/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6662 - val_loss: 1.7019\n",
      "Epoch 200/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6633 - val_loss: 1.6951\n",
      "Epoch 201/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6658 - val_loss: 1.7080\n",
      "Epoch 202/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6494 - val_loss: 1.6846\n",
      "Epoch 203/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6632 - val_loss: 1.6899\n",
      "Epoch 204/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6547\n",
      " Reduced learning rate to 7.70735e-05\n",
      "1406/1406 [==============================] - 2s - loss: 1.6553 - val_loss: 1.7141\n",
      "Epoch 1/300\n",
      "1406/1406 [==============================] - 4s - loss: 7.3145 - val_loss: 4.1200\n",
      "Epoch 2/300\n",
      "1406/1406 [==============================] - 2s - loss: 3.0218 - val_loss: 4.2296\n",
      "Epoch 3/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.8092 - val_loss: 3.5220\n",
      "Epoch 4/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.6190 - val_loss: 2.0637\n",
      "Epoch 5/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.5323 - val_loss: 2.6553\n",
      "Epoch 6/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.4242 - val_loss: 3.4839\n",
      "Epoch 7/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.3235 - val_loss: 3.0028\n",
      "Epoch 8/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.3119 - val_loss: 1.9124\n",
      "Epoch 9/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.2368 - val_loss: 2.9131\n",
      "Epoch 10/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1895 - val_loss: 2.5314\n",
      "Epoch 11/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1477 - val_loss: 2.6591\n",
      "Epoch 12/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1105 - val_loss: 1.9222\n",
      "Epoch 13/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.1212 - val_loss: 2.0232\n",
      "Epoch 14/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.0827 - val_loss: 2.5832\n",
      "Epoch 15/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.0353 - val_loss: 2.0057\n",
      "Epoch 16/300\n",
      "1406/1406 [==============================] - 2s - loss: 2.0160 - val_loss: 2.0700\n",
      "Epoch 17/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9789 - val_loss: 1.8491\n",
      "Epoch 18/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9708 - val_loss: 1.8789\n",
      "Epoch 19/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9912 - val_loss: 2.2720\n",
      "Epoch 20/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9534 - val_loss: 1.8537\n",
      "Epoch 21/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9322 - val_loss: 2.1186\n",
      "Epoch 22/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9230 - val_loss: 2.4264\n",
      "Epoch 23/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9099 - val_loss: 1.8782\n",
      "Epoch 24/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9179 - val_loss: 1.8794\n",
      "Epoch 25/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.9073 - val_loss: 1.7722\n",
      "Epoch 26/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8973 - val_loss: 1.8043\n",
      "Epoch 27/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8886 - val_loss: 1.8721\n",
      "Epoch 28/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8886 - val_loss: 1.9101\n",
      "Epoch 29/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8659 - val_loss: 1.8923\n",
      "Epoch 30/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8623 - val_loss: 1.8423\n",
      "Epoch 31/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8652 - val_loss: 2.0856\n",
      "Epoch 32/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8613 - val_loss: 1.7984\n",
      "Epoch 33/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8702 - val_loss: 1.8286\n",
      "Epoch 34/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8521 - val_loss: 1.8758\n",
      "Epoch 35/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.8411 - val_loss: 1.8818\n",
      "Epoch 36/300\n",
      "1394/1406 [============================>.] - ETA: 0s - loss: 1.8398\n",
      " Reduced learning rate to 0.01\n",
      "1406/1406 [==============================] - 3s - loss: 1.8395 - val_loss: 1.9601\n",
      "Epoch 37/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7387 - val_loss: 1.8232\n",
      "Epoch 38/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7474 - val_loss: 1.7564\n",
      "Epoch 39/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7327 - val_loss: 2.0107\n",
      "Epoch 40/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7326 - val_loss: 1.7556\n",
      "Epoch 41/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7440 - val_loss: 1.7576\n",
      "Epoch 42/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7540 - val_loss: 1.7948\n",
      "Epoch 43/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7375 - val_loss: 1.7410\n",
      "Epoch 44/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7390 - val_loss: 1.7373\n",
      "Epoch 45/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7493 - val_loss: 1.7315\n",
      "Epoch 46/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7437 - val_loss: 1.7385\n",
      "Epoch 47/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7425 - val_loss: 1.7603\n",
      "Epoch 48/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7513 - val_loss: 1.7393\n",
      "Epoch 49/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7345 - val_loss: 1.7304\n",
      "Epoch 50/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7421 - val_loss: 1.7397\n",
      "Epoch 51/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7410 - val_loss: 1.7049\n",
      "Epoch 52/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7414 - val_loss: 1.7317\n",
      "Epoch 53/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7495 - val_loss: 1.7613\n",
      "Epoch 54/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7438 - val_loss: 1.7620\n",
      "Epoch 55/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7388 - val_loss: 1.8014\n",
      "Epoch 56/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7284 - val_loss: 1.7642\n",
      "Epoch 57/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7351 - val_loss: 1.7690\n",
      "Epoch 58/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7539 - val_loss: 1.7614\n",
      "Epoch 59/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7476 - val_loss: 1.7603\n",
      "Epoch 60/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7494 - val_loss: 1.7951\n",
      "Epoch 61/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7469 - val_loss: 1.7114\n",
      "Epoch 62/300\n",
      "1402/1406 [============================>.] - ETA: 0s - loss: 1.7249\n",
      " Reduced learning rate to 0.00666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 2s - loss: 1.7247 - val_loss: 1.8649\n",
      "Epoch 63/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7041 - val_loss: 1.7673\n",
      "Epoch 64/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7023 - val_loss: 1.7666\n",
      "Epoch 65/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6873 - val_loss: 1.7458\n",
      "Epoch 66/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7064 - val_loss: 1.7390\n",
      "Epoch 67/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6900 - val_loss: 1.7944\n",
      "Epoch 68/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6868 - val_loss: 1.8018\n",
      "Epoch 69/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6933 - val_loss: 1.7104\n",
      "Epoch 70/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6936 - val_loss: 1.7253\n",
      "Epoch 71/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.7045 - val_loss: 1.7072\n",
      "Epoch 72/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6879 - val_loss: 1.7058\n",
      "Epoch 73/300\n",
      "1386/1406 [============================>.] - ETA: 0s - loss: 1.7043\n",
      " Reduced learning rate to 0.00444444\n",
      "1406/1406 [==============================] - 2s - loss: 1.7033 - val_loss: 1.7470\n",
      "Epoch 74/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6856 - val_loss: 1.7280\n",
      "Epoch 75/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6961 - val_loss: 1.6926\n",
      "Epoch 76/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6925 - val_loss: 1.7266\n",
      "Epoch 77/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6763 - val_loss: 1.6807\n",
      "Epoch 78/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6878 - val_loss: 1.7625\n",
      "Epoch 79/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6888 - val_loss: 1.7087\n",
      "Epoch 80/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6816 - val_loss: 1.7273\n",
      "Epoch 81/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6801 - val_loss: 1.7048\n",
      "Epoch 82/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6821 - val_loss: 1.7291\n",
      "Epoch 83/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6783 - val_loss: 1.7442\n",
      "Epoch 84/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6933 - val_loss: 1.7152\n",
      "Epoch 85/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6874 - val_loss: 1.7137\n",
      "Epoch 86/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6797 - val_loss: 1.7431\n",
      "Epoch 87/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6774 - val_loss: 1.7136\n",
      "Epoch 88/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6844 - val_loss: 1.6760\n",
      "Epoch 89/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6799 - val_loss: 1.7107\n",
      "Epoch 90/300\n",
      "1406/1406 [==============================] - 2s - loss: 1.6773 - val_loss: 1.7236\n",
      "Epoch 91/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6845 - val_loss: 1.6924\n",
      "Epoch 92/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6956 - val_loss: 1.7095\n",
      "Epoch 93/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6924 - val_loss: 1.7441\n",
      "Epoch 94/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6806 - val_loss: 1.7178\n",
      "Epoch 95/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6864 - val_loss: 1.7021\n",
      "Epoch 96/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6896 - val_loss: 1.6998\n",
      "Epoch 97/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6874 - val_loss: 1.7161\n",
      "Epoch 98/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6873 - val_loss: 1.7251\n",
      "Epoch 99/300\n",
      "1391/1406 [============================>.] - ETA: 0s - loss: 1.6883\n",
      " Reduced learning rate to 0.00296296\n",
      "1406/1406 [==============================] - 3s - loss: 1.6886 - val_loss: 1.7772\n",
      "Epoch 100/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6751 - val_loss: 1.6971\n",
      "Epoch 101/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6704 - val_loss: 1.7293\n",
      "Epoch 102/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6835 - val_loss: 1.7136\n",
      "Epoch 103/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6717 - val_loss: 1.6894\n",
      "Epoch 104/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6665 - val_loss: 1.7249\n",
      "Epoch 105/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6756 - val_loss: 1.7331\n",
      "Epoch 106/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6719 - val_loss: 1.7129\n",
      "Epoch 107/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6672 - val_loss: 1.6875\n",
      "Epoch 108/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6733 - val_loss: 1.7231\n",
      "Epoch 109/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6805 - val_loss: 1.7083\n",
      "Epoch 110/300\n",
      "1392/1406 [============================>.] - ETA: 0s - loss: 1.6791\n",
      " Reduced learning rate to 0.00197531\n",
      "1406/1406 [==============================] - 3s - loss: 1.6792 - val_loss: 1.7183\n",
      "Epoch 111/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6696 - val_loss: 1.7048\n",
      "Epoch 112/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6637 - val_loss: 1.7132\n",
      "Epoch 113/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6639 - val_loss: 1.6951\n",
      "Epoch 114/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6579 - val_loss: 1.6943\n",
      "Epoch 115/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6605 - val_loss: 1.6912\n",
      "Epoch 116/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6737 - val_loss: 1.6812\n",
      "Epoch 117/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6593 - val_loss: 1.6680\n",
      "Epoch 118/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6716 - val_loss: 1.6692\n",
      "Epoch 119/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6616 - val_loss: 1.6951\n",
      "Epoch 120/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6715 - val_loss: 1.6684\n",
      "Epoch 121/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6786 - val_loss: 1.6943\n",
      "Epoch 122/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6695 - val_loss: 1.7070\n",
      "Epoch 123/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6620 - val_loss: 1.6968\n",
      "Epoch 124/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6638 - val_loss: 1.7063\n",
      "Epoch 125/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6696 - val_loss: 1.6848\n",
      "Epoch 126/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6589 - val_loss: 1.7202\n",
      "Epoch 127/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6666 - val_loss: 1.7043\n",
      "Epoch 128/300\n",
      "1386/1406 [============================>.] - ETA: 0s - loss: 1.6628\n",
      " Reduced learning rate to 0.00131687\n",
      "1406/1406 [==============================] - 4s - loss: 1.6636 - val_loss: 1.6792\n",
      "Epoch 129/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6594 - val_loss: 1.6855\n",
      "Epoch 130/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6627 - val_loss: 1.7093\n",
      "Epoch 131/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6777 - val_loss: 1.7076\n",
      "Epoch 132/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6648 - val_loss: 1.7092\n",
      "Epoch 133/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6540 - val_loss: 1.6799\n",
      "Epoch 134/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6630 - val_loss: 1.7058\n",
      "Epoch 135/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6661 - val_loss: 1.7117\n",
      "Epoch 136/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6574 - val_loss: 1.7012\n",
      "Epoch 137/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6674 - val_loss: 1.7261\n",
      "Epoch 138/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6489 - val_loss: 1.6858\n",
      "Epoch 139/300\n",
      "1401/1406 [============================>.] - ETA: 0s - loss: 1.6639\n",
      " Reduced learning rate to 0.000877915\n",
      "1406/1406 [==============================] - 4s - loss: 1.6641 - val_loss: 1.6819\n",
      "Epoch 140/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6475 - val_loss: 1.6973\n",
      "Epoch 141/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6597 - val_loss: 1.7204\n",
      "Epoch 142/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406/1406 [==============================] - 4s - loss: 1.6623 - val_loss: 1.6838\n",
      "Epoch 143/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6514 - val_loss: 1.7171\n",
      "Epoch 144/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6529 - val_loss: 1.6794\n",
      "Epoch 145/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6599 - val_loss: 1.7020\n",
      "Epoch 146/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6632 - val_loss: 1.6986\n",
      "Epoch 147/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6815 - val_loss: 1.6752\n",
      "Epoch 148/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6597 - val_loss: 1.6907\n",
      "Epoch 149/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6641 - val_loss: 1.7163\n",
      "Epoch 150/300\n",
      "1404/1406 [============================>.] - ETA: 0s - loss: 1.6759\n",
      " Reduced learning rate to 0.000585277\n",
      "1406/1406 [==============================] - 3s - loss: 1.6758 - val_loss: 1.7285\n",
      "Epoch 151/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6515 - val_loss: 1.6714\n",
      "Epoch 152/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6644 - val_loss: 1.6919\n",
      "Epoch 153/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6543 - val_loss: 1.7012\n",
      "Epoch 154/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6649 - val_loss: 1.6966\n",
      "Epoch 155/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6686 - val_loss: 1.7075\n",
      "Epoch 156/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6613 - val_loss: 1.6960\n",
      "Epoch 157/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6706 - val_loss: 1.6950\n",
      "Epoch 158/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6553 - val_loss: 1.6942\n",
      "Epoch 159/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6556 - val_loss: 1.6806\n",
      "Epoch 160/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6599 - val_loss: 1.6765\n",
      "Epoch 161/300\n",
      "1386/1406 [============================>.] - ETA: 0s - loss: 1.6604\n",
      " Reduced learning rate to 0.000390184\n",
      "1406/1406 [==============================] - 4s - loss: 1.6611 - val_loss: 1.7085\n",
      "Epoch 162/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6591 - val_loss: 1.6880\n",
      "Epoch 163/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6590 - val_loss: 1.7005\n",
      "Epoch 164/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6493 - val_loss: 1.7086\n",
      "Epoch 165/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6664 - val_loss: 1.6851\n",
      "Epoch 166/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6613 - val_loss: 1.6789\n",
      "Epoch 167/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6694 - val_loss: 1.6941\n",
      "Epoch 168/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6751 - val_loss: 1.7182\n",
      "Epoch 169/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6557 - val_loss: 1.6999\n",
      "Epoch 170/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6699 - val_loss: 1.6929\n",
      "Epoch 171/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6631 - val_loss: 1.7305\n",
      "Epoch 172/300\n",
      "1389/1406 [============================>.] - ETA: 0s - loss: 1.6477\n",
      " Reduced learning rate to 0.000260123\n",
      "1406/1406 [==============================] - 3s - loss: 1.6477 - val_loss: 1.6836\n",
      "Epoch 173/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6581 - val_loss: 1.6896\n",
      "Epoch 174/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6512 - val_loss: 1.6731\n",
      "Epoch 175/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6641 - val_loss: 1.6885\n",
      "Epoch 176/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6605 - val_loss: 1.6919\n",
      "Epoch 177/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6666 - val_loss: 1.7116\n",
      "Epoch 178/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6546 - val_loss: 1.6816\n",
      "Epoch 179/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6647 - val_loss: 1.6963\n",
      "Epoch 180/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6495 - val_loss: 1.6794\n",
      "Epoch 181/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6498 - val_loss: 1.6804\n",
      "Epoch 182/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6473 - val_loss: 1.7034\n",
      "Epoch 183/300\n",
      "1402/1406 [============================>.] - ETA: 0s - loss: 1.6545\n",
      " Reduced learning rate to 0.000173415\n",
      "1406/1406 [==============================] - 3s - loss: 1.6547 - val_loss: 1.7198\n",
      "Epoch 184/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6568 - val_loss: 1.6890\n",
      "Epoch 185/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6457 - val_loss: 1.6784\n",
      "Epoch 186/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6670 - val_loss: 1.6961\n",
      "Epoch 187/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6664 - val_loss: 1.6884\n",
      "Epoch 188/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6535 - val_loss: 1.6843\n",
      "Epoch 189/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6540 - val_loss: 1.6699\n",
      "Epoch 190/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6482 - val_loss: 1.6953\n",
      "Epoch 191/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6609 - val_loss: 1.6788\n",
      "Epoch 192/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6556 - val_loss: 1.6931\n",
      "Epoch 193/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6532 - val_loss: 1.6821\n",
      "Epoch 194/300\n",
      "1392/1406 [============================>.] - ETA: 0s - loss: 1.6565\n",
      " Reduced learning rate to 0.00011561\n",
      "1406/1406 [==============================] - 3s - loss: 1.6583 - val_loss: 1.6849\n",
      "Epoch 195/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6587 - val_loss: 1.6912\n",
      "Epoch 196/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6510 - val_loss: 1.6975\n",
      "Epoch 197/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6536 - val_loss: 1.6768\n",
      "Epoch 198/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6427 - val_loss: 1.7061\n",
      "Epoch 199/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6426 - val_loss: 1.6907\n",
      "Epoch 200/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6590 - val_loss: 1.6792\n",
      "Epoch 201/300\n",
      "1406/1406 [==============================] - 4s - loss: 1.6525 - val_loss: 1.7000\n",
      "Epoch 202/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6472 - val_loss: 1.7220\n",
      "Epoch 203/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6495 - val_loss: 1.6965\n",
      "Epoch 204/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6562 - val_loss: 1.6646\n",
      "Epoch 205/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6645 - val_loss: 1.7007\n",
      "Epoch 206/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6663 - val_loss: 1.6702\n",
      "Epoch 207/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6564 - val_loss: 1.6846\n",
      "Epoch 208/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6490 - val_loss: 1.6839\n",
      "Epoch 209/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6632 - val_loss: 1.7049\n",
      "Epoch 210/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6487 - val_loss: 1.6887\n",
      "Epoch 211/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6467 - val_loss: 1.7195\n",
      "Epoch 212/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6569 - val_loss: 1.6809\n",
      "Epoch 213/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6552 - val_loss: 1.6790\n",
      "Epoch 214/300\n",
      "1406/1406 [==============================] - 3s - loss: 1.6590 - val_loss: 1.6951\n",
      "Epoch 215/300\n",
      "1388/1406 [============================>.] - ETA: 0s - loss: 1.6552\n",
      " Reduced learning rate to 7.70735e-05\n",
      "1406/1406 [==============================] - 3s - loss: 1.6553 - val_loss: 1.6912\n",
      "Epoch 1/300\n",
      "7031/7031 [==============================] - 23s - loss: 3.6716 - val_loss: 3.3422\n",
      "Epoch 2/300\n",
      "7031/7031 [==============================] - 20s - loss: 2.3494 - val_loss: 2.2173\n",
      "Epoch 3/300\n",
      "7031/7031 [==============================] - 20s - loss: 2.1077 - val_loss: 1.9525\n",
      "Epoch 4/300\n",
      "7031/7031 [==============================] - 20s - loss: 2.0016 - val_loss: 2.1016\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 20s - loss: 1.9352 - val_loss: 2.1459\n",
      "Epoch 6/300\n",
      "7031/7031 [==============================] - 22s - loss: 1.8964 - val_loss: 1.8008\n",
      "Epoch 7/300\n",
      "7031/7031 [==============================] - 20s - loss: 1.8696 - val_loss: 1.8770\n",
      "Epoch 8/300\n",
      "7031/7031 [==============================] - 21s - loss: 1.8586 - val_loss: 1.7800\n",
      "Epoch 9/300\n",
      "7031/7031 [==============================] - 20s - loss: 1.8429 - val_loss: 1.9193\n",
      "Epoch 10/300\n",
      "7031/7031 [==============================] - 20s - loss: 1.8285 - val_loss: 1.7208\n",
      "Epoch 11/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.8198 - val_loss: 1.8835\n",
      "Epoch 12/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.8240 - val_loss: 1.7676\n",
      "Epoch 13/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.8142 - val_loss: 1.9888\n",
      "Epoch 14/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.8104 - val_loss: 1.7076\n",
      "Epoch 15/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.8012 - val_loss: 1.7689\n",
      "Epoch 16/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.7914 - val_loss: 1.7819\n",
      "Epoch 17/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7986 - val_loss: 1.7266\n",
      "Epoch 18/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7874 - val_loss: 1.8478\n",
      "Epoch 19/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7852 - val_loss: 1.6952\n",
      "Epoch 20/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7825 - val_loss: 1.7280\n",
      "Epoch 21/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7807 - val_loss: 1.7317\n",
      "Epoch 22/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.7749 - val_loss: 1.7117\n",
      "Epoch 23/300\n",
      "7031/7031 [==============================] - 19s - loss: 1.7777 - val_loss: 1.7383\n",
      "Epoch 24/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7693 - val_loss: 1.7108\n",
      "Epoch 25/300\n",
      "7031/7031 [==============================] - 18s - loss: 1.7819 - val_loss: 1.7618\n",
      "Epoch 26/300\n",
      "7031/7031 [==============================] - 14s - loss: 1.7803 - val_loss: 1.8612\n",
      "Epoch 27/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7685 - val_loss: 1.7306\n",
      "Epoch 28/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7734 - val_loss: 1.7097\n",
      "Epoch 29/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7700 - val_loss: 1.9219\n",
      "Epoch 30/300\n",
      "7019/7031 [============================>.] - ETA: 0s - loss: 1.7738\n",
      " Reduced learning rate to 0.01\n",
      "7031/7031 [==============================] - 12s - loss: 1.7735 - val_loss: 1.7623\n",
      "Epoch 31/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7198 - val_loss: 1.6770\n",
      "Epoch 32/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7190 - val_loss: 1.6902\n",
      "Epoch 33/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7023 - val_loss: 1.6869\n",
      "Epoch 34/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7234 - val_loss: 1.7058\n",
      "Epoch 35/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7182 - val_loss: 1.7180\n",
      "Epoch 36/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7132 - val_loss: 2.0859\n",
      "Epoch 37/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7237 - val_loss: 1.7657\n",
      "Epoch 38/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7155 - val_loss: 1.7264\n",
      "Epoch 39/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7196 - val_loss: 1.8165\n",
      "Epoch 40/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7168 - val_loss: 1.7072\n",
      "Epoch 41/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.7096 - val_loss: 1.7506\n",
      "Epoch 42/300\n",
      "7013/7031 [============================>.] - ETA: 0s - loss: 1.7056\n",
      " Reduced learning rate to 0.00666667\n",
      "7031/7031 [==============================] - 11s - loss: 1.7055 - val_loss: 1.7039\n",
      "Epoch 43/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.6905 - val_loss: 1.6654\n",
      "Epoch 44/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.6934 - val_loss: 1.6681\n",
      "Epoch 45/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.6859 - val_loss: 1.6659\n",
      "Epoch 46/300\n",
      "7031/7031 [==============================] - 11s - loss: 1.6925 - val_loss: 1.7070\n",
      "Epoch 47/300\n",
      "7031/7031 [==============================] - 9s - loss: 1.6907 - val_loss: 1.6836\n",
      "Epoch 48/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6878 - val_loss: 1.6795\n",
      "Epoch 49/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6893 - val_loss: 1.7006\n",
      "Epoch 50/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6917 - val_loss: 1.6726\n",
      "Epoch 51/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6872 - val_loss: 1.6640\n",
      "Epoch 52/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6856 - val_loss: 1.7005\n",
      "Epoch 53/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6814 - val_loss: 1.6717\n",
      "Epoch 54/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6902 - val_loss: 1.6971\n",
      "Epoch 55/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6911 - val_loss: 1.6758\n",
      "Epoch 56/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6872 - val_loss: 1.6901\n",
      "Epoch 57/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6905 - val_loss: 1.6659\n",
      "Epoch 58/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6847 - val_loss: 1.7482\n",
      "Epoch 59/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6898 - val_loss: 1.6674\n",
      "Epoch 60/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6917 - val_loss: 1.6641\n",
      "Epoch 61/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6856 - val_loss: 1.6602\n",
      "Epoch 62/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6832 - val_loss: 1.6707\n",
      "Epoch 63/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6852 - val_loss: 1.7052\n",
      "Epoch 64/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6819 - val_loss: 1.6699\n",
      "Epoch 65/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6789 - val_loss: 1.7369\n",
      "Epoch 66/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6858 - val_loss: 1.6986\n",
      "Epoch 67/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6897 - val_loss: 1.6662\n",
      "Epoch 68/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6844 - val_loss: 1.6721\n",
      "Epoch 69/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6951 - val_loss: 1.6901\n",
      "Epoch 70/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6863 - val_loss: 1.6719\n",
      "Epoch 71/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6868 - val_loss: 1.6590\n",
      "Epoch 72/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6870 - val_loss: 1.6863\n",
      "Epoch 73/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6846 - val_loss: 1.6751\n",
      "Epoch 74/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6887 - val_loss: 1.6861\n",
      "Epoch 75/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6849 - val_loss: 1.6628\n",
      "Epoch 76/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6830 - val_loss: 1.6641\n",
      "Epoch 77/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6871 - val_loss: 1.6777\n",
      "Epoch 78/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6891 - val_loss: 1.6816\n",
      "Epoch 79/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6809 - val_loss: 1.6588\n",
      "Epoch 80/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6817 - val_loss: 1.7090\n",
      "Epoch 81/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6864 - val_loss: 1.6848\n",
      "Epoch 82/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6849 - val_loss: 1.6633\n",
      "Epoch 83/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6879 - val_loss: 1.6584\n",
      "Epoch 84/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6955 - val_loss: 1.6582\n",
      "Epoch 85/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6851 - val_loss: 1.6498\n",
      "Epoch 86/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6904 - val_loss: 1.7807\n",
      "Epoch 87/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6786 - val_loss: 1.7233\n",
      "Epoch 88/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6878 - val_loss: 1.6875\n",
      "Epoch 89/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6844 - val_loss: 1.6627\n",
      "Epoch 90/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6847 - val_loss: 1.7071\n",
      "Epoch 91/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6852 - val_loss: 1.6564\n",
      "Epoch 92/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6823 - val_loss: 1.6764\n",
      "Epoch 93/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6910 - val_loss: 1.6916\n",
      "Epoch 94/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6914 - val_loss: 1.6756\n",
      "Epoch 95/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6900 - val_loss: 1.6783\n",
      "Epoch 96/300\n",
      "6999/7031 [============================>.] - ETA: 0s - loss: 1.6876\n",
      " Reduced learning rate to 0.00444444\n",
      "7031/7031 [==============================] - 8s - loss: 1.6880 - val_loss: 1.6857\n",
      "Epoch 97/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6710 - val_loss: 1.6733\n",
      "Epoch 98/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6637 - val_loss: 1.6524\n",
      "Epoch 99/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6760 - val_loss: 1.6621\n",
      "Epoch 100/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6777 - val_loss: 1.6752\n",
      "Epoch 101/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6745 - val_loss: 1.6758\n",
      "Epoch 102/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6728 - val_loss: 1.6818\n",
      "Epoch 103/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6713 - val_loss: 1.6732\n",
      "Epoch 104/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6686 - val_loss: 1.6680\n",
      "Epoch 105/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6710 - val_loss: 1.6562\n",
      "Epoch 106/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6684 - val_loss: 1.6621\n",
      "Epoch 107/300\n",
      "6988/7031 [============================>.] - ETA: 0s - loss: 1.6824\n",
      " Reduced learning rate to 0.00296296\n",
      "7031/7031 [==============================] - 8s - loss: 1.6822 - val_loss: 1.6719\n",
      "Epoch 108/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6591 - val_loss: 1.6815\n",
      "Epoch 109/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6659 - val_loss: 1.6779\n",
      "Epoch 110/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6656 - val_loss: 1.6439\n",
      "Epoch 111/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6613 - val_loss: 1.6589\n",
      "Epoch 112/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6701 - val_loss: 1.6971\n",
      "Epoch 113/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6698 - val_loss: 1.6758\n",
      "Epoch 114/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6670 - val_loss: 1.6662\n",
      "Epoch 115/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6613 - val_loss: 1.6654\n",
      "Epoch 116/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6599 - val_loss: 1.6639\n",
      "Epoch 117/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6739 - val_loss: 1.6522\n",
      "Epoch 118/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6697 - val_loss: 1.6759\n",
      "Epoch 119/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6690 - val_loss: 1.6590\n",
      "Epoch 120/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6677 - val_loss: 1.6660\n",
      "Epoch 121/300\n",
      "7027/7031 [============================>.] - ETA: 0s - loss: 1.6702\n",
      " Reduced learning rate to 0.00197531\n",
      "7031/7031 [==============================] - 8s - loss: 1.6703 - val_loss: 1.6568\n",
      "Epoch 122/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6621 - val_loss: 1.6613\n",
      "Epoch 123/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6617 - val_loss: 1.6574\n",
      "Epoch 124/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6478\n",
      "Epoch 125/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6594 - val_loss: 1.6658\n",
      "Epoch 126/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6615 - val_loss: 1.6465\n",
      "Epoch 127/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6636 - val_loss: 1.6522\n",
      "Epoch 128/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6571 - val_loss: 1.6445\n",
      "Epoch 129/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6636 - val_loss: 1.6569\n",
      "Epoch 130/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6606 - val_loss: 1.6635\n",
      "Epoch 131/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6543 - val_loss: 1.6555\n",
      "Epoch 132/300\n",
      "7013/7031 [============================>.] - ETA: 0s - loss: 1.6623\n",
      " Reduced learning rate to 0.00131687\n",
      "7031/7031 [==============================] - 8s - loss: 1.6622 - val_loss: 1.6516\n",
      "Epoch 133/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6549 - val_loss: 1.6603\n",
      "Epoch 134/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6559 - val_loss: 1.6502\n",
      "Epoch 135/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6596 - val_loss: 1.6443\n",
      "Epoch 136/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6517 - val_loss: 1.6576\n",
      "Epoch 137/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6445\n",
      "Epoch 138/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6570 - val_loss: 1.6536\n",
      "Epoch 139/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6533 - val_loss: 1.6580\n",
      "Epoch 140/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6659 - val_loss: 1.6542\n",
      "Epoch 141/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6562\n",
      "Epoch 142/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6556 - val_loss: 1.6563\n",
      "Epoch 143/300\n",
      "7030/7031 [============================>.] - ETA: 0s - loss: 1.6488\n",
      " Reduced learning rate to 0.000877915\n",
      "7031/7031 [==============================] - 8s - loss: 1.6487 - val_loss: 1.6467\n",
      "Epoch 144/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6601 - val_loss: 1.6541\n",
      "Epoch 145/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6549 - val_loss: 1.6484\n",
      "Epoch 146/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6568 - val_loss: 1.6524\n",
      "Epoch 147/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6531 - val_loss: 1.6443\n",
      "Epoch 148/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6522\n",
      "Epoch 149/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6560 - val_loss: 1.6570\n",
      "Epoch 150/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6499 - val_loss: 1.6505\n",
      "Epoch 151/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6524 - val_loss: 1.6543\n",
      "Epoch 152/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6525 - val_loss: 1.6447\n",
      "Epoch 153/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6627\n",
      "Epoch 154/300\n",
      "7013/7031 [============================>.] - ETA: 0s - loss: 1.6628\n",
      " Reduced learning rate to 0.000585277\n",
      "7031/7031 [==============================] - 8s - loss: 1.6627 - val_loss: 1.6502\n",
      "Epoch 155/300\n",
      "7031/7031 [==============================] - ETA: 0s - loss: 1.649 - 8s - loss: 1.6498 - val_loss: 1.6530\n",
      "Epoch 156/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6518 - val_loss: 1.6413\n",
      "Epoch 157/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6560 - val_loss: 1.6563\n",
      "Epoch 158/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6625 - val_loss: 1.6549\n",
      "Epoch 159/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6564 - val_loss: 1.6563\n",
      "Epoch 160/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6510 - val_loss: 1.6678\n",
      "Epoch 161/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6521 - val_loss: 1.6504\n",
      "Epoch 162/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6603\n",
      "Epoch 163/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6553 - val_loss: 1.6523\n",
      "Epoch 164/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6636 - val_loss: 1.6621\n",
      "Epoch 165/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6501 - val_loss: 1.6543\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6558 - val_loss: 1.6600\n",
      "Epoch 167/300\n",
      "7018/7031 [============================>.] - ETA: 0s - loss: 1.6582\n",
      " Reduced learning rate to 0.000390184\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6518\n",
      "Epoch 168/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6599 - val_loss: 1.6600\n",
      "Epoch 169/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6570 - val_loss: 1.6433\n",
      "Epoch 170/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6587 - val_loss: 1.6477\n",
      "Epoch 171/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6569 - val_loss: 1.6380\n",
      "Epoch 172/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6548 - val_loss: 1.6451\n",
      "Epoch 173/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6528 - val_loss: 1.6600\n",
      "Epoch 174/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6551 - val_loss: 1.6510\n",
      "Epoch 175/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6473\n",
      "Epoch 176/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6513 - val_loss: 1.6379\n",
      "Epoch 177/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6504 - val_loss: 1.6545\n",
      "Epoch 178/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6486\n",
      "Epoch 179/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6511 - val_loss: 1.6615\n",
      "Epoch 180/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6556 - val_loss: 1.6492\n",
      "Epoch 181/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6487 - val_loss: 1.6562\n",
      "Epoch 182/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6592 - val_loss: 1.6510\n",
      "Epoch 183/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6572 - val_loss: 1.6503\n",
      "Epoch 184/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6501 - val_loss: 1.6471\n",
      "Epoch 185/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6525 - val_loss: 1.6496\n",
      "Epoch 186/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6602\n",
      "Epoch 187/300\n",
      "7006/7031 [============================>.] - ETA: 0s - loss: 1.6504\n",
      " Reduced learning rate to 0.000260123\n",
      "7031/7031 [==============================] - 8s - loss: 1.6503 - val_loss: 1.6502\n",
      "Epoch 188/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6499 - val_loss: 1.6438\n",
      "Epoch 189/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6623\n",
      "Epoch 190/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6557\n",
      "Epoch 191/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6562 - val_loss: 1.6563\n",
      "Epoch 192/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6578 - val_loss: 1.6465\n",
      "Epoch 193/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6528 - val_loss: 1.6543\n",
      "Epoch 194/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6573 - val_loss: 1.6549\n",
      "Epoch 195/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6404\n",
      "Epoch 196/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6582\n",
      "Epoch 197/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6580 - val_loss: 1.6444\n",
      "Epoch 198/300\n",
      "7013/7031 [============================>.] - ETA: 0s - loss: 1.6548\n",
      " Reduced learning rate to 0.000173415\n",
      "7031/7031 [==============================] - 8s - loss: 1.6549 - val_loss: 1.6424\n",
      "Epoch 199/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6439\n",
      "Epoch 200/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6548 - val_loss: 1.6498\n",
      "Epoch 201/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6510 - val_loss: 1.6342\n",
      "Epoch 202/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6545 - val_loss: 1.6498\n",
      "Epoch 203/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6507 - val_loss: 1.6452\n",
      "Epoch 204/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6513 - val_loss: 1.6329\n",
      "Epoch 205/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6589 - val_loss: 1.6471\n",
      "Epoch 206/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6507 - val_loss: 1.6485\n",
      "Epoch 207/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6485\n",
      "Epoch 208/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6524\n",
      "Epoch 209/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6529\n",
      "Epoch 210/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6525\n",
      "Epoch 211/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6503 - val_loss: 1.6498\n",
      "Epoch 212/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6538 - val_loss: 1.6510\n",
      "Epoch 213/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6522 - val_loss: 1.6556\n",
      "Epoch 214/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6510 - val_loss: 1.6444\n",
      "Epoch 215/300\n",
      "6995/7031 [============================>.] - ETA: 0s - loss: 1.6545\n",
      " Reduced learning rate to 0.00011561\n",
      "7031/7031 [==============================] - 8s - loss: 1.6543 - val_loss: 1.6484\n",
      "Epoch 216/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6515 - val_loss: 1.6477\n",
      "Epoch 217/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6516\n",
      "Epoch 218/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6447\n",
      "Epoch 219/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6361\n",
      "Epoch 220/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6539 - val_loss: 1.6518\n",
      "Epoch 221/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6516 - val_loss: 1.6529\n",
      "Epoch 222/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6526 - val_loss: 1.6419\n",
      "Epoch 223/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6467 - val_loss: 1.6427\n",
      "Epoch 224/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6529 - val_loss: 1.6414\n",
      "Epoch 225/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6531\n",
      "Epoch 226/300\n",
      "7022/7031 [============================>.] - ETA: 0s - loss: 1.6553\n",
      " Reduced learning rate to 7.70735e-05\n",
      "7031/7031 [==============================] - 8s - loss: 1.6553 - val_loss: 1.6439\n",
      "Epoch 1/300\n",
      "7031/7031 [==============================] - 10s - loss: 3.5912 - val_loss: 2.5039\n",
      "Epoch 2/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.3368 - val_loss: 1.8002\n",
      "Epoch 3/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.1058 - val_loss: 2.1875\n",
      "Epoch 4/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.0231 - val_loss: 1.7709\n",
      "Epoch 5/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9560 - val_loss: 1.8358\n",
      "Epoch 6/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9098 - val_loss: 2.1920\n",
      "Epoch 7/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8749 - val_loss: 1.8022\n",
      "Epoch 8/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8797 - val_loss: 1.8282\n",
      "Epoch 9/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8639 - val_loss: 1.7701\n",
      "Epoch 10/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8370 - val_loss: 1.7689\n",
      "Epoch 11/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8387 - val_loss: 1.7846\n",
      "Epoch 12/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8215 - val_loss: 1.7741\n",
      "Epoch 13/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8134 - val_loss: 1.8594\n",
      "Epoch 14/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8112 - val_loss: 1.9048\n",
      "Epoch 15/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8022 - val_loss: 1.8100\n",
      "Epoch 16/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8076 - val_loss: 1.7616\n",
      "Epoch 17/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8015 - val_loss: 1.7970\n",
      "Epoch 18/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7901 - val_loss: 1.7852\n",
      "Epoch 19/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8042 - val_loss: 1.7872\n",
      "Epoch 20/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.7907 - val_loss: 1.7935\n",
      "Epoch 21/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7877 - val_loss: 1.7427\n",
      "Epoch 22/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7708 - val_loss: 1.7578\n",
      "Epoch 23/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7715 - val_loss: 1.7949\n",
      "Epoch 24/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7750 - val_loss: 1.7631\n",
      "Epoch 25/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7783 - val_loss: 1.7234\n",
      "Epoch 26/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7744 - val_loss: 1.7228\n",
      "Epoch 27/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7786 - val_loss: 1.7459\n",
      "Epoch 28/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7792 - val_loss: 1.7590\n",
      "Epoch 29/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7738 - val_loss: 1.7168\n",
      "Epoch 30/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7616 - val_loss: 1.7129\n",
      "Epoch 31/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7623 - val_loss: 1.8204\n",
      "Epoch 32/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7564 - val_loss: 1.7455\n",
      "Epoch 33/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7653 - val_loss: 1.9025\n",
      "Epoch 34/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7567 - val_loss: 1.7482\n",
      "Epoch 35/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7538 - val_loss: 1.6959\n",
      "Epoch 36/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7596 - val_loss: 1.7051\n",
      "Epoch 37/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7523 - val_loss: 1.7539\n",
      "Epoch 38/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7486 - val_loss: 1.7053\n",
      "Epoch 39/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7660 - val_loss: 1.7018\n",
      "Epoch 40/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7538 - val_loss: 1.7612\n",
      "Epoch 41/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7535 - val_loss: 1.7443\n",
      "Epoch 42/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7533 - val_loss: 1.6705\n",
      "Epoch 43/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7496 - val_loss: 1.6900\n",
      "Epoch 44/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7482 - val_loss: 1.7136\n",
      "Epoch 45/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7591 - val_loss: 1.6951\n",
      "Epoch 46/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7573 - val_loss: 1.7369\n",
      "Epoch 47/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7484 - val_loss: 1.7493\n",
      "Epoch 48/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7487 - val_loss: 1.6855\n",
      "Epoch 49/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7502 - val_loss: 1.7559\n",
      "Epoch 50/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7502 - val_loss: 1.8458\n",
      "Epoch 51/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7544 - val_loss: 1.7650\n",
      "Epoch 52/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7458 - val_loss: 1.8471\n",
      "Epoch 53/300\n",
      "6992/7031 [============================>.] - ETA: 0s - loss: 1.7474\n",
      " Reduced learning rate to 0.01\n",
      "7031/7031 [==============================] - 9s - loss: 1.7473 - val_loss: 1.7063\n",
      "Epoch 54/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7069 - val_loss: 1.6974\n",
      "Epoch 55/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7112 - val_loss: 1.7721\n",
      "Epoch 56/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7058 - val_loss: 1.6932\n",
      "Epoch 57/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7017 - val_loss: 1.6830\n",
      "Epoch 58/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7055 - val_loss: 1.6985\n",
      "Epoch 59/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7042 - val_loss: 1.7501\n",
      "Epoch 60/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7012 - val_loss: 1.6809\n",
      "Epoch 61/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7021 - val_loss: 1.6961\n",
      "Epoch 62/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7049 - val_loss: 1.7108\n",
      "Epoch 63/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7088 - val_loss: 1.6953\n",
      "Epoch 64/300\n",
      "6997/7031 [============================>.] - ETA: 0s - loss: 1.7029\n",
      " Reduced learning rate to 0.00666667\n",
      "7031/7031 [==============================] - 8s - loss: 1.7028 - val_loss: 1.6758\n",
      "Epoch 65/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6906 - val_loss: 1.6740\n",
      "Epoch 66/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6820 - val_loss: 1.6815\n",
      "Epoch 67/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6793 - val_loss: 1.7018\n",
      "Epoch 68/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6782 - val_loss: 1.6998\n",
      "Epoch 69/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6850 - val_loss: 1.6738\n",
      "Epoch 70/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6837 - val_loss: 1.6641\n",
      "Epoch 71/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6881 - val_loss: 1.6725\n",
      "Epoch 72/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6836 - val_loss: 1.6790\n",
      "Epoch 73/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6807 - val_loss: 1.6752\n",
      "Epoch 74/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6836 - val_loss: 1.6594\n",
      "Epoch 75/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6782 - val_loss: 1.6622\n",
      "Epoch 76/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6798 - val_loss: 1.6674\n",
      "Epoch 77/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6849 - val_loss: 1.6740\n",
      "Epoch 78/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6841 - val_loss: 1.6902\n",
      "Epoch 79/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6751 - val_loss: 1.6522\n",
      "Epoch 80/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6855 - val_loss: 1.6680\n",
      "Epoch 81/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6812 - val_loss: 1.6648\n",
      "Epoch 82/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6811 - val_loss: 1.6614\n",
      "Epoch 83/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6892 - val_loss: 1.6628\n",
      "Epoch 84/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6840 - val_loss: 1.6615\n",
      "Epoch 85/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6845 - val_loss: 1.6603\n",
      "Epoch 86/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6758 - val_loss: 1.6491\n",
      "Epoch 87/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6807 - val_loss: 1.6955\n",
      "Epoch 88/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6827 - val_loss: 1.6666\n",
      "Epoch 89/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6815 - val_loss: 1.6777\n",
      "Epoch 90/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6827 - val_loss: 1.6810\n",
      "Epoch 91/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6819 - val_loss: 1.6822\n",
      "Epoch 92/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6801 - val_loss: 1.6869\n",
      "Epoch 93/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6926 - val_loss: 1.6913\n",
      "Epoch 94/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6848 - val_loss: 1.6686\n",
      "Epoch 95/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6837 - val_loss: 1.6719\n",
      "Epoch 96/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6787 - val_loss: 1.6916\n",
      "Epoch 97/300\n",
      "7029/7031 [============================>.] - ETA: 0s - loss: 1.6884\n",
      " Reduced learning rate to 0.00444444\n",
      "7031/7031 [==============================] - 8s - loss: 1.6884 - val_loss: 1.7129\n",
      "Epoch 98/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6689 - val_loss: 1.6564\n",
      "Epoch 99/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6673 - val_loss: 1.6740\n",
      "Epoch 100/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6656 - val_loss: 1.6555\n",
      "Epoch 101/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6778 - val_loss: 1.6842\n",
      "Epoch 102/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6708 - val_loss: 1.6602\n",
      "Epoch 103/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6731 - val_loss: 1.6713\n",
      "Epoch 104/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6744 - val_loss: 1.7070\n",
      "Epoch 105/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6635 - val_loss: 1.6666\n",
      "Epoch 106/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6756 - val_loss: 1.6600\n",
      "Epoch 107/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6669 - val_loss: 1.6557\n",
      "Epoch 108/300\n",
      "7011/7031 [============================>.] - ETA: 0s - loss: 1.6715\n",
      " Reduced learning rate to 0.00296296\n",
      "7031/7031 [==============================] - 8s - loss: 1.6712 - val_loss: 1.6713\n",
      "Epoch 109/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6641\n",
      "Epoch 110/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6622 - val_loss: 1.6497\n",
      "Epoch 111/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6652 - val_loss: 1.6482\n",
      "Epoch 112/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6664 - val_loss: 1.6608\n",
      "Epoch 113/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6630 - val_loss: 1.6581\n",
      "Epoch 114/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6618 - val_loss: 1.6530\n",
      "Epoch 115/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6602\n",
      "Epoch 116/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6680 - val_loss: 1.6522\n",
      "Epoch 117/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6632 - val_loss: 1.6555\n",
      "Epoch 118/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6709 - val_loss: 1.6498\n",
      "Epoch 119/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6702 - val_loss: 1.6529\n",
      "Epoch 120/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6623 - val_loss: 1.6412\n",
      "Epoch 121/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6642 - val_loss: 1.6602\n",
      "Epoch 122/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6701 - val_loss: 1.6459\n",
      "Epoch 123/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6667 - val_loss: 1.6471\n",
      "Epoch 124/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6720 - val_loss: 1.6589\n",
      "Epoch 125/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6653 - val_loss: 1.6576\n",
      "Epoch 126/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6713 - val_loss: 1.6941\n",
      "Epoch 127/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6682 - val_loss: 1.6490\n",
      "Epoch 128/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6604 - val_loss: 1.6576\n",
      "Epoch 129/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6633 - val_loss: 1.6498\n",
      "Epoch 130/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6692\n",
      "Epoch 131/300\n",
      "7016/7031 [============================>.] - ETA: 0s - loss: 1.6607\n",
      " Reduced learning rate to 0.00197531\n",
      "7031/7031 [==============================] - 8s - loss: 1.6606 - val_loss: 1.6738\n",
      "Epoch 132/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6541 - val_loss: 1.6503\n",
      "Epoch 133/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6568\n",
      "Epoch 134/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6590 - val_loss: 1.6595\n",
      "Epoch 135/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6616 - val_loss: 1.6647\n",
      "Epoch 136/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6630 - val_loss: 1.6529\n",
      "Epoch 137/300\n",
      "7031/7031 [==============================] - ETA: 0s - loss: 1.655 - 8s - loss: 1.6551 - val_loss: 1.6505\n",
      "Epoch 138/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6569 - val_loss: 1.6510\n",
      "Epoch 139/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6586 - val_loss: 1.6485\n",
      "Epoch 140/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6560 - val_loss: 1.6609\n",
      "Epoch 141/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6575 - val_loss: 1.6627\n",
      "Epoch 142/300\n",
      "7027/7031 [============================>.] - ETA: 0s - loss: 1.6678\n",
      " Reduced learning rate to 0.00131687\n",
      "7031/7031 [==============================] - 8s - loss: 1.6679 - val_loss: 1.6549\n",
      "Epoch 143/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6530 - val_loss: 1.6412\n",
      "Epoch 144/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6543 - val_loss: 1.6640\n",
      "Epoch 145/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6522 - val_loss: 1.6603\n",
      "Epoch 146/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6512\n",
      "Epoch 147/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6653 - val_loss: 1.6412\n",
      "Epoch 148/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6632 - val_loss: 1.6564\n",
      "Epoch 149/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6522 - val_loss: 1.6660\n",
      "Epoch 150/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6601\n",
      "Epoch 151/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6575 - val_loss: 1.6510\n",
      "Epoch 152/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6530 - val_loss: 1.6452\n",
      "Epoch 153/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6536 - val_loss: 1.6601\n",
      "Epoch 154/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6635 - val_loss: 1.6584\n",
      "Epoch 155/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6560 - val_loss: 1.6394\n",
      "Epoch 156/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6617 - val_loss: 1.6576\n",
      "Epoch 157/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6459\n",
      "Epoch 158/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6640 - val_loss: 1.6486\n",
      "Epoch 159/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6498 - val_loss: 1.6477\n",
      "Epoch 160/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6523 - val_loss: 1.6530\n",
      "Epoch 161/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6522 - val_loss: 1.6609\n",
      "Epoch 162/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6565 - val_loss: 1.6516\n",
      "Epoch 163/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6516 - val_loss: 1.6639\n",
      "Epoch 164/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6576 - val_loss: 1.6543\n",
      "Epoch 165/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6516\n",
      "Epoch 166/300\n",
      "6993/7031 [============================>.] - ETA: 0s - loss: 1.6616\n",
      " Reduced learning rate to 0.000877915\n",
      "7031/7031 [==============================] - 8s - loss: 1.6616 - val_loss: 1.6426\n",
      "Epoch 167/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6556 - val_loss: 1.6472\n",
      "Epoch 168/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6522 - val_loss: 1.6490\n",
      "Epoch 169/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6533 - val_loss: 1.6498\n",
      "Epoch 170/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6536 - val_loss: 1.6543\n",
      "Epoch 171/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6477\n",
      "Epoch 172/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6502 - val_loss: 1.6498\n",
      "Epoch 173/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6582 - val_loss: 1.6556\n",
      "Epoch 174/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6660 - val_loss: 1.6556\n",
      "Epoch 175/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6502 - val_loss: 1.6561\n",
      "Epoch 176/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6544 - val_loss: 1.6575\n",
      "Epoch 177/300\n",
      "7002/7031 [============================>.] - ETA: 0s - loss: 1.6570\n",
      " Reduced learning rate to 0.000585277\n",
      "7031/7031 [==============================] - 8s - loss: 1.6567 - val_loss: 1.6424\n",
      "Epoch 178/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6611 - val_loss: 1.6477\n",
      "Epoch 179/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6438\n",
      "Epoch 180/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6578 - val_loss: 1.6516\n",
      "Epoch 181/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6524 - val_loss: 1.6518\n",
      "Epoch 182/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6557 - val_loss: 1.6497\n",
      "Epoch 183/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6567 - val_loss: 1.6445\n",
      "Epoch 184/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6594\n",
      "Epoch 185/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6499 - val_loss: 1.6478\n",
      "Epoch 186/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6552 - val_loss: 1.6425\n",
      "Epoch 187/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6486 - val_loss: 1.6522\n",
      "Epoch 188/300\n",
      "7004/7031 [============================>.] - ETA: 0s - loss: 1.6576\n",
      " Reduced learning rate to 0.000390184\n",
      "7031/7031 [==============================] - 8s - loss: 1.6576 - val_loss: 1.6504\n",
      "Epoch 189/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6507 - val_loss: 1.6467\n",
      "Epoch 190/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6532 - val_loss: 1.6516\n",
      "Epoch 191/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6502\n",
      "Epoch 192/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6520 - val_loss: 1.6368\n",
      "Epoch 193/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6556 - val_loss: 1.6568\n",
      "Epoch 194/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6420 - val_loss: 1.6516\n",
      "Epoch 195/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6522\n",
      "Epoch 196/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6523\n",
      "Epoch 197/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6483 - val_loss: 1.6511\n",
      "Epoch 198/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6555 - val_loss: 1.6555\n",
      "Epoch 199/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6525 - val_loss: 1.6556\n",
      "Epoch 200/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6513 - val_loss: 1.6549\n",
      "Epoch 201/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6531 - val_loss: 1.6502\n",
      "Epoch 202/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6515 - val_loss: 1.6543\n",
      "Epoch 203/300\n",
      "6990/7031 [============================>.] - ETA: 0s - loss: 1.6444\n",
      " Reduced learning rate to 0.000260123\n",
      "7031/7031 [==============================] - 8s - loss: 1.6447 - val_loss: 1.6459\n",
      "Epoch 204/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6453\n",
      "Epoch 205/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6369\n",
      "Epoch 206/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6512 - val_loss: 1.6504\n",
      "Epoch 207/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6475 - val_loss: 1.6535\n",
      "Epoch 208/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6584 - val_loss: 1.6424\n",
      "Epoch 209/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6517 - val_loss: 1.6465\n",
      "Epoch 210/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6485\n",
      "Epoch 211/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6498 - val_loss: 1.6562\n",
      "Epoch 212/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6477 - val_loss: 1.6463\n",
      "Epoch 213/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6509 - val_loss: 1.6485\n",
      "Epoch 214/300\n",
      "7008/7031 [============================>.] - ETA: 0s - loss: 1.6547\n",
      " Reduced learning rate to 0.000173415\n",
      "7031/7031 [==============================] - 8s - loss: 1.6545 - val_loss: 1.6584\n",
      "Epoch 215/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6572 - val_loss: 1.6471\n",
      "Epoch 216/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6503 - val_loss: 1.6452\n",
      "Epoch 217/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6485 - val_loss: 1.6443\n",
      "Epoch 218/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6517 - val_loss: 1.6465\n",
      "Epoch 219/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6445\n",
      "Epoch 220/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6468 - val_loss: 1.6518\n",
      "Epoch 221/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6320\n",
      "Epoch 222/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6541 - val_loss: 1.6522\n",
      "Epoch 223/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6473 - val_loss: 1.6478\n",
      "Epoch 224/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6451\n",
      "Epoch 225/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6529 - val_loss: 1.6466\n",
      "Epoch 226/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6476 - val_loss: 1.6365\n",
      "Epoch 227/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6496 - val_loss: 1.6446\n",
      "Epoch 228/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6517 - val_loss: 1.6576\n",
      "Epoch 229/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6520 - val_loss: 1.6498\n",
      "Epoch 230/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6523\n",
      "Epoch 231/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6473 - val_loss: 1.6575\n",
      "Epoch 232/300\n",
      "6988/7031 [============================>.] - ETA: 0s - loss: 1.6529\n",
      " Reduced learning rate to 0.00011561\n",
      "7031/7031 [==============================] - 8s - loss: 1.6527 - val_loss: 1.6388\n",
      "Epoch 233/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6552 - val_loss: 1.6576\n",
      "Epoch 234/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6576 - val_loss: 1.6477\n",
      "Epoch 235/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6550 - val_loss: 1.6375\n",
      "Epoch 236/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6535 - val_loss: 1.6496\n",
      "Epoch 237/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6427\n",
      "Epoch 238/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6493 - val_loss: 1.6434\n",
      "Epoch 239/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6483 - val_loss: 1.6483\n",
      "Epoch 240/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6546 - val_loss: 1.6502\n",
      "Epoch 241/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6587 - val_loss: 1.6406\n",
      "Epoch 242/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6485\n",
      "Epoch 243/300\n",
      "7010/7031 [============================>.] - ETA: 0s - loss: 1.6559\n",
      " Reduced learning rate to 7.70735e-05\n",
      "7031/7031 [==============================] - 8s - loss: 1.6559 - val_loss: 1.6477\n",
      "Epoch 1/300\n",
      "7031/7031 [==============================] - 10s - loss: 3.6637 - val_loss: 2.5626\n",
      "Epoch 2/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.3136 - val_loss: 1.7983\n",
      "Epoch 3/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.0993 - val_loss: 2.1738\n",
      "Epoch 4/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9830 - val_loss: 1.8210\n",
      "Epoch 5/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9161 - val_loss: 1.7443\n",
      "Epoch 6/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8785 - val_loss: 1.8203\n",
      "Epoch 7/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8738 - val_loss: 1.7148\n",
      "Epoch 8/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8521 - val_loss: 1.7278\n",
      "Epoch 9/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8434 - val_loss: 1.7859\n",
      "Epoch 10/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8193 - val_loss: 1.7336\n",
      "Epoch 11/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8232 - val_loss: 1.7506\n",
      "Epoch 12/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8101 - val_loss: 1.7076\n",
      "Epoch 13/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8044 - val_loss: 1.7436\n",
      "Epoch 14/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8071 - val_loss: 2.0384\n",
      "Epoch 15/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7992 - val_loss: 1.8553\n",
      "Epoch 16/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7900 - val_loss: 1.9128\n",
      "Epoch 17/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7932 - val_loss: 1.7577\n",
      "Epoch 18/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7937 - val_loss: 1.6954\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.7838 - val_loss: 1.7461\n",
      "Epoch 20/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7816 - val_loss: 1.7076\n",
      "Epoch 21/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7825 - val_loss: 1.7306\n",
      "Epoch 22/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7781 - val_loss: 1.7220\n",
      "Epoch 23/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7742 - val_loss: 1.7638\n",
      "Epoch 24/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7748 - val_loss: 2.0312\n",
      "Epoch 25/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7726 - val_loss: 1.7011\n",
      "Epoch 26/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7722 - val_loss: 1.7898\n",
      "Epoch 27/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7765 - val_loss: 1.7766\n",
      "Epoch 28/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7692 - val_loss: 1.7310\n",
      "Epoch 29/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7639 - val_loss: 1.6757\n",
      "Epoch 30/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7573 - val_loss: 1.7486\n",
      "Epoch 31/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7613 - val_loss: 1.7344\n",
      "Epoch 32/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7610 - val_loss: 1.7219\n",
      "Epoch 33/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7605 - val_loss: 1.6856\n",
      "Epoch 34/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7680 - val_loss: 1.6795\n",
      "Epoch 35/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7605 - val_loss: 1.8456\n",
      "Epoch 36/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7585 - val_loss: 1.7480\n",
      "Epoch 37/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7668 - val_loss: 1.8607\n",
      "Epoch 38/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7584 - val_loss: 1.7291\n",
      "Epoch 39/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7593 - val_loss: 1.7779\n",
      "Epoch 40/300\n",
      "7007/7031 [============================>.] - ETA: 0s - loss: 1.7585\n",
      " Reduced learning rate to 0.01\n",
      "7031/7031 [==============================] - 9s - loss: 1.7584 - val_loss: 1.8419\n",
      "Epoch 41/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7102 - val_loss: 1.6745\n",
      "Epoch 42/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7017 - val_loss: 1.6791\n",
      "Epoch 43/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7078 - val_loss: 1.7429\n",
      "Epoch 44/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7025 - val_loss: 1.6830\n",
      "Epoch 45/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7054 - val_loss: 1.7539\n",
      "Epoch 46/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7069 - val_loss: 1.7345\n",
      "Epoch 47/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7131 - val_loss: 1.6789\n",
      "Epoch 48/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7064 - val_loss: 1.6946\n",
      "Epoch 49/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7097 - val_loss: 1.7248\n",
      "Epoch 50/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7108 - val_loss: 1.7377\n",
      "Epoch 51/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7042 - val_loss: 1.7083\n",
      "Epoch 52/300\n",
      "7015/7031 [============================>.] - ETA: 0s - loss: 1.7105\n",
      " Reduced learning rate to 0.00666667\n",
      "7031/7031 [==============================] - 8s - loss: 1.7104 - val_loss: 1.7266\n",
      "Epoch 53/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6792 - val_loss: 1.6887\n",
      "Epoch 54/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6785 - val_loss: 1.6672\n",
      "Epoch 55/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6841 - val_loss: 1.6739\n",
      "Epoch 56/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6811 - val_loss: 1.6717\n",
      "Epoch 57/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6850 - val_loss: 1.7032\n",
      "Epoch 58/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6847 - val_loss: 1.6777\n",
      "Epoch 59/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6824 - val_loss: 1.6721\n",
      "Epoch 60/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6829 - val_loss: 1.7258\n",
      "Epoch 61/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6801 - val_loss: 1.6672\n",
      "Epoch 62/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6846 - val_loss: 1.6662\n",
      "Epoch 63/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6847 - val_loss: 1.6790\n",
      "Epoch 64/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6800 - val_loss: 1.6863\n",
      "Epoch 65/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6837 - val_loss: 1.6914\n",
      "Epoch 66/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6866 - val_loss: 1.6693\n",
      "Epoch 67/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6904 - val_loss: 1.6653\n",
      "Epoch 68/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6954 - val_loss: 1.6733\n",
      "Epoch 69/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6808 - val_loss: 1.6798\n",
      "Epoch 70/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6897 - val_loss: 1.6713\n",
      "Epoch 71/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6865 - val_loss: 1.6648\n",
      "Epoch 72/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6901 - val_loss: 1.6772\n",
      "Epoch 73/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6873 - val_loss: 1.6920\n",
      "Epoch 74/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6857 - val_loss: 1.6602\n",
      "Epoch 75/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6832 - val_loss: 1.6680\n",
      "Epoch 76/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6833 - val_loss: 1.6717\n",
      "Epoch 77/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6817 - val_loss: 1.6974\n",
      "Epoch 78/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6888 - val_loss: 1.6549\n",
      "Epoch 79/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6821 - val_loss: 1.6666\n",
      "Epoch 80/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6851 - val_loss: 1.6744\n",
      "Epoch 81/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6809 - val_loss: 1.6843\n",
      "Epoch 82/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6835 - val_loss: 1.6960\n",
      "Epoch 83/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6813 - val_loss: 1.6881\n",
      "Epoch 84/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6808 - val_loss: 1.7070\n",
      "Epoch 85/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6820 - val_loss: 1.6576\n",
      "Epoch 86/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6875 - val_loss: 1.7189\n",
      "Epoch 87/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6873 - val_loss: 1.6693\n",
      "Epoch 88/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6951 - val_loss: 1.6736\n",
      "Epoch 89/300\n",
      "7023/7031 [============================>.] - ETA: 0s - loss: 1.6858\n",
      " Reduced learning rate to 0.00444444\n",
      "7031/7031 [==============================] - 8s - loss: 1.6856 - val_loss: 1.6955\n",
      "Epoch 90/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6730 - val_loss: 1.6603\n",
      "Epoch 91/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6691 - val_loss: 1.6720\n",
      "Epoch 92/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6660 - val_loss: 1.6661\n",
      "Epoch 93/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6687 - val_loss: 1.6660\n",
      "Epoch 94/300\n",
      "7031/7031 [==============================] - 9s - loss: 1.6739 - val_loss: 1.6492\n",
      "Epoch 95/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6749 - val_loss: 1.7063\n",
      "Epoch 96/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6699 - val_loss: 1.6654\n",
      "Epoch 97/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6676 - val_loss: 1.6699\n",
      "Epoch 98/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6734 - val_loss: 1.6510\n",
      "Epoch 99/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6701 - val_loss: 1.6720\n",
      "Epoch 100/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6779 - val_loss: 1.6724\n",
      "Epoch 101/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6760 - val_loss: 1.6609\n",
      "Epoch 102/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6697 - val_loss: 1.6486\n",
      "Epoch 103/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6770 - val_loss: 1.6477\n",
      "Epoch 104/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6698 - val_loss: 1.6594\n",
      "Epoch 105/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6740 - val_loss: 1.6752\n",
      "Epoch 106/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6674 - val_loss: 1.6791\n",
      "Epoch 107/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6767 - val_loss: 1.6687\n",
      "Epoch 108/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6723 - val_loss: 1.6863\n",
      "Epoch 109/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6674 - val_loss: 1.6601\n",
      "Epoch 110/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6742 - val_loss: 1.6705\n",
      "Epoch 111/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6703 - val_loss: 1.6620\n",
      "Epoch 112/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6721 - val_loss: 1.6672\n",
      "Epoch 113/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6688 - val_loss: 1.6746\n",
      "Epoch 114/300\n",
      "7029/7031 [============================>.] - ETA: 0s - loss: 1.6727\n",
      " Reduced learning rate to 0.00296296\n",
      "7031/7031 [==============================] - 8s - loss: 1.6726 - val_loss: 1.6588\n",
      "Epoch 115/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6628 - val_loss: 1.6615\n",
      "Epoch 116/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6620 - val_loss: 1.6641\n",
      "Epoch 117/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6677 - val_loss: 1.6654\n",
      "Epoch 118/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6675 - val_loss: 1.6446\n",
      "Epoch 119/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6690 - val_loss: 1.6867\n",
      "Epoch 120/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6619 - val_loss: 1.6601\n",
      "Epoch 121/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6656 - val_loss: 1.6584\n",
      "Epoch 122/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6620 - val_loss: 1.6678\n",
      "Epoch 123/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6708 - val_loss: 1.6496\n",
      "Epoch 124/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6669 - val_loss: 1.6609\n",
      "Epoch 125/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6767 - val_loss: 1.6668\n",
      "Epoch 126/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6636 - val_loss: 1.6640\n",
      "Epoch 127/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6700 - val_loss: 1.6583\n",
      "Epoch 128/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6631 - val_loss: 1.6699\n",
      "Epoch 129/300\n",
      "6998/7031 [============================>.] - ETA: 0s - loss: 1.6622\n",
      " Reduced learning rate to 0.00197531\n",
      "7031/7031 [==============================] - 8s - loss: 1.6619 - val_loss: 1.6785\n",
      "Epoch 130/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6548 - val_loss: 1.6483\n",
      "Epoch 131/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6603 - val_loss: 1.6523\n",
      "Epoch 132/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6642\n",
      "Epoch 133/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6596 - val_loss: 1.6662\n",
      "Epoch 134/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6620 - val_loss: 1.6492\n",
      "Epoch 135/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6589 - val_loss: 1.6653\n",
      "Epoch 136/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6682 - val_loss: 1.6563\n",
      "Epoch 137/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6536\n",
      "Epoch 138/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6574 - val_loss: 1.6518\n",
      "Epoch 139/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6592 - val_loss: 1.6517\n",
      "Epoch 140/300\n",
      "7020/7031 [============================>.] - ETA: 0s - loss: 1.6572\n",
      " Reduced learning rate to 0.00131687\n",
      "7031/7031 [==============================] - 8s - loss: 1.6573 - val_loss: 1.6543\n",
      "Epoch 141/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6596 - val_loss: 1.6590\n",
      "Epoch 142/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6553 - val_loss: 1.6641\n",
      "Epoch 143/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6576 - val_loss: 1.6590\n",
      "Epoch 144/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6604 - val_loss: 1.6522\n",
      "Epoch 145/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6562 - val_loss: 1.6478\n",
      "Epoch 146/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6516\n",
      "Epoch 147/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6585 - val_loss: 1.6588\n",
      "Epoch 148/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6601\n",
      "Epoch 149/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6539 - val_loss: 1.6498\n",
      "Epoch 150/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6527 - val_loss: 1.6504\n",
      "Epoch 151/300\n",
      "7002/7031 [============================>.] - ETA: 0s - loss: 1.6568\n",
      " Reduced learning rate to 0.000877915\n",
      "7031/7031 [==============================] - 8s - loss: 1.6573 - val_loss: 1.6549\n",
      "Epoch 152/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6564 - val_loss: 1.6486\n",
      "Epoch 153/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6559 - val_loss: 1.6608\n",
      "Epoch 154/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6656 - val_loss: 1.6537\n",
      "Epoch 155/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6621\n",
      "Epoch 156/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6524\n",
      "Epoch 157/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6617 - val_loss: 1.6580\n",
      "Epoch 158/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6534 - val_loss: 1.6406\n",
      "Epoch 159/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6576 - val_loss: 1.6497\n",
      "Epoch 160/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6490 - val_loss: 1.6473\n",
      "Epoch 161/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6566 - val_loss: 1.6614\n",
      "Epoch 162/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6516 - val_loss: 1.6452\n",
      "Epoch 163/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6596 - val_loss: 1.6603\n",
      "Epoch 164/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6515 - val_loss: 1.6510\n",
      "Epoch 165/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6539 - val_loss: 1.6438\n",
      "Epoch 166/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6529 - val_loss: 1.6544\n",
      "Epoch 167/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6536\n",
      "Epoch 168/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6486 - val_loss: 1.6445\n",
      "Epoch 169/300\n",
      "7030/7031 [============================>.] - ETA: 0s - loss: 1.6536\n",
      " Reduced learning rate to 0.000585277\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6478\n",
      "Epoch 170/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6576 - val_loss: 1.6385\n",
      "Epoch 171/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6554 - val_loss: 1.6531\n",
      "Epoch 172/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6559 - val_loss: 1.6490\n",
      "Epoch 173/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6572 - val_loss: 1.6472\n",
      "Epoch 174/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6555 - val_loss: 1.6492\n",
      "Epoch 175/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6517 - val_loss: 1.6471\n",
      "Epoch 176/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6569 - val_loss: 1.6555\n",
      "Epoch 177/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6539 - val_loss: 1.6596\n",
      "Epoch 178/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6504\n",
      "Epoch 179/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6501 - val_loss: 1.6550\n",
      "Epoch 180/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6546 - val_loss: 1.6459\n",
      "Epoch 181/300\n",
      "7011/7031 [============================>.] - ETA: 0s - loss: 1.6495\n",
      " Reduced learning rate to 0.000390184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6523\n",
      "Epoch 182/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6505 - val_loss: 1.6418\n",
      "Epoch 183/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6485\n",
      "Epoch 184/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6570 - val_loss: 1.6439\n",
      "Epoch 185/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6503 - val_loss: 1.6471\n",
      "Epoch 186/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6433\n",
      "Epoch 187/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6551 - val_loss: 1.6635\n",
      "Epoch 188/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6566 - val_loss: 1.6439\n",
      "Epoch 189/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6550 - val_loss: 1.6445\n",
      "Epoch 190/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6582 - val_loss: 1.6600\n",
      "Epoch 191/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6503 - val_loss: 1.6424\n",
      "Epoch 192/300\n",
      "7022/7031 [============================>.] - ETA: 0s - loss: 1.6566\n",
      " Reduced learning rate to 0.000260123\n",
      "7031/7031 [==============================] - 8s - loss: 1.6566 - val_loss: 1.6498\n",
      "Epoch 193/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6581 - val_loss: 1.6447\n",
      "Epoch 194/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6433\n",
      "Epoch 195/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6504\n",
      "Epoch 196/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6526 - val_loss: 1.6463\n",
      "Epoch 197/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6485 - val_loss: 1.6486\n",
      "Epoch 198/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6500 - val_loss: 1.6516\n",
      "Epoch 199/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6609 - val_loss: 1.6525\n",
      "Epoch 200/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6559 - val_loss: 1.6531\n",
      "Epoch 201/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6540 - val_loss: 1.6375\n",
      "Epoch 202/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6535 - val_loss: 1.6531\n",
      "Epoch 203/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6471 - val_loss: 1.6562\n",
      "Epoch 204/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6539 - val_loss: 1.6543\n",
      "Epoch 205/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6544 - val_loss: 1.6459\n",
      "Epoch 206/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6534 - val_loss: 1.6471\n",
      "Epoch 207/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6472 - val_loss: 1.6492\n",
      "Epoch 208/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6608 - val_loss: 1.6639\n",
      "Epoch 209/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6501 - val_loss: 1.6400\n",
      "Epoch 210/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6594 - val_loss: 1.6634\n",
      "Epoch 211/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6536 - val_loss: 1.6511\n",
      "Epoch 212/300\n",
      "7028/7031 [============================>.] - ETA: 0s - loss: 1.6608\n",
      " Reduced learning rate to 0.000173415\n",
      "7031/7031 [==============================] - 8s - loss: 1.6607 - val_loss: 1.6561\n",
      "Epoch 213/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6438 - val_loss: 1.6537\n",
      "Epoch 214/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6512 - val_loss: 1.6445\n",
      "Epoch 215/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6504 - val_loss: 1.6443\n",
      "Epoch 216/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6486 - val_loss: 1.6418\n",
      "Epoch 217/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6539 - val_loss: 1.6512\n",
      "Epoch 218/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6441 - val_loss: 1.6424\n",
      "Epoch 219/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6475 - val_loss: 1.6385\n",
      "Epoch 220/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6534 - val_loss: 1.6522\n",
      "Epoch 221/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6509 - val_loss: 1.6561\n",
      "Epoch 222/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6450 - val_loss: 1.6601\n",
      "Epoch 223/300\n",
      "7021/7031 [============================>.] - ETA: 0s - loss: 1.6482\n",
      " Reduced learning rate to 0.00011561\n",
      "7031/7031 [==============================] - 8s - loss: 1.6482 - val_loss: 1.6603\n",
      "Epoch 224/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6470 - val_loss: 1.6537\n",
      "Epoch 225/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6484 - val_loss: 1.6458\n",
      "Epoch 226/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6504 - val_loss: 1.6603\n",
      "Epoch 227/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6462 - val_loss: 1.6490\n",
      "Epoch 228/300\n",
      "7031/7031 [==============================] - 9s - loss: 1.6489 - val_loss: 1.6524\n",
      "Epoch 229/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6485 - val_loss: 1.6531\n",
      "Epoch 230/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6479 - val_loss: 1.6428\n",
      "Epoch 231/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6487 - val_loss: 1.6420\n",
      "Epoch 232/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6521 - val_loss: 1.6424\n",
      "Epoch 233/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6470 - val_loss: 1.6393\n",
      "Epoch 234/300\n",
      "6992/7031 [============================>.] - ETA: 0s - loss: 1.6593\n",
      " Reduced learning rate to 7.70735e-05\n",
      "7031/7031 [==============================] - 8s - loss: 1.6590 - val_loss: 1.6541\n",
      "Epoch 1/300\n",
      "7031/7031 [==============================] - 10s - loss: 3.6279 - val_loss: 2.5551\n",
      "Epoch 2/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.3321 - val_loss: 1.8327\n",
      "Epoch 3/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.0956 - val_loss: 2.1621\n",
      "Epoch 4/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9759 - val_loss: 3.1695\n",
      "Epoch 5/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9339 - val_loss: 1.7538\n",
      "Epoch 6/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8904 - val_loss: 1.8163\n",
      "Epoch 7/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8653 - val_loss: 1.7375\n",
      "Epoch 8/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8605 - val_loss: 2.0435\n",
      "Epoch 9/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8455 - val_loss: 1.7253\n",
      "Epoch 10/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8291 - val_loss: 1.7990\n",
      "Epoch 11/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8251 - val_loss: 1.7635\n",
      "Epoch 12/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8114 - val_loss: 2.1216\n",
      "Epoch 13/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8121 - val_loss: 1.9842\n",
      "Epoch 14/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8112 - val_loss: 1.8029\n",
      "Epoch 15/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7961 - val_loss: 1.9907\n",
      "Epoch 16/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7949 - val_loss: 1.7912\n",
      "Epoch 17/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7954 - val_loss: 1.7065\n",
      "Epoch 18/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7930 - val_loss: 1.7063\n",
      "Epoch 19/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7830 - val_loss: 1.7468\n",
      "Epoch 20/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7925 - val_loss: 1.6850\n",
      "Epoch 21/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7771 - val_loss: 1.7571\n",
      "Epoch 22/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7816 - val_loss: 1.6867\n",
      "Epoch 23/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7770 - val_loss: 1.7929\n",
      "Epoch 24/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7834 - val_loss: 1.6895\n",
      "Epoch 25/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7704 - val_loss: 1.7175\n",
      "Epoch 26/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7748 - val_loss: 1.7097\n",
      "Epoch 27/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7741 - val_loss: 1.7461\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.7698 - val_loss: 1.7024\n",
      "Epoch 29/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7678 - val_loss: 1.7597\n",
      "Epoch 30/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7722 - val_loss: 1.7225\n",
      "Epoch 31/300\n",
      "7026/7031 [============================>.] - ETA: 0s - loss: 1.7659\n",
      " Reduced learning rate to 0.01\n",
      "7031/7031 [==============================] - 9s - loss: 1.7660 - val_loss: 1.7832\n",
      "Epoch 32/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7164 - val_loss: 1.6745\n",
      "Epoch 33/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7190 - val_loss: 1.6889\n",
      "Epoch 34/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7155 - val_loss: 1.6835\n",
      "Epoch 35/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7066 - val_loss: 1.6990\n",
      "Epoch 36/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7088 - val_loss: 1.7014\n",
      "Epoch 37/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7128 - val_loss: 1.6908\n",
      "Epoch 38/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7135 - val_loss: 1.7650\n",
      "Epoch 39/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7156 - val_loss: 1.7716\n",
      "Epoch 40/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7177 - val_loss: 1.7506\n",
      "Epoch 41/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7095 - val_loss: 1.7188\n",
      "Epoch 42/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7190 - val_loss: 1.7136\n",
      "Epoch 43/300\n",
      "6998/7031 [============================>.] - ETA: 0s - loss: 1.6998\n",
      " Reduced learning rate to 0.00666667\n",
      "7031/7031 [==============================] - 8s - loss: 1.6997 - val_loss: 1.6953\n",
      "Epoch 44/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6877 - val_loss: 1.7253\n",
      "Epoch 45/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6830 - val_loss: 1.6809\n",
      "Epoch 46/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6829 - val_loss: 1.6662\n",
      "Epoch 47/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6809 - val_loss: 1.7475\n",
      "Epoch 48/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6868 - val_loss: 1.6771\n",
      "Epoch 49/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6904 - val_loss: 1.6868\n",
      "Epoch 50/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6870 - val_loss: 1.6855\n",
      "Epoch 51/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6825 - val_loss: 1.6544\n",
      "Epoch 52/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6885 - val_loss: 1.6717\n",
      "Epoch 53/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6890 - val_loss: 1.6760\n",
      "Epoch 54/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6782 - val_loss: 1.6692\n",
      "Epoch 55/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6938 - val_loss: 1.6563\n",
      "Epoch 56/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6881 - val_loss: 1.6790\n",
      "Epoch 57/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6860 - val_loss: 1.6693\n",
      "Epoch 58/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6919 - val_loss: 1.6777\n",
      "Epoch 59/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6910 - val_loss: 1.6902\n",
      "Epoch 60/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6755 - val_loss: 1.6660\n",
      "Epoch 61/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6854 - val_loss: 1.6705\n",
      "Epoch 62/300\n",
      "6997/7031 [============================>.] - ETA: 0s - loss: 1.6796\n",
      " Reduced learning rate to 0.00444444\n",
      "7031/7031 [==============================] - 8s - loss: 1.6798 - val_loss: 1.6951\n",
      "Epoch 63/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6789 - val_loss: 1.6711\n",
      "Epoch 64/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6691 - val_loss: 1.6861\n",
      "Epoch 65/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6657 - val_loss: 1.6477\n",
      "Epoch 66/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6701 - val_loss: 1.6804\n",
      "Epoch 67/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6729 - val_loss: 1.6600\n",
      "Epoch 68/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6706 - val_loss: 1.6561\n",
      "Epoch 69/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6700 - val_loss: 1.6583\n",
      "Epoch 70/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6637 - val_loss: 1.6608\n",
      "Epoch 71/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6711 - val_loss: 1.6678\n",
      "Epoch 72/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6779 - val_loss: 1.6588\n",
      "Epoch 73/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6760 - val_loss: 1.6623\n",
      "Epoch 74/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6700 - val_loss: 1.6623\n",
      "Epoch 75/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6751 - val_loss: 1.6584\n",
      "Epoch 76/300\n",
      "7026/7031 [============================>.] - ETA: 0s - loss: 1.6700\n",
      " Reduced learning rate to 0.00296296\n",
      "7031/7031 [==============================] - 8s - loss: 1.6701 - val_loss: 1.6557\n",
      "Epoch 77/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6653 - val_loss: 1.6561\n",
      "Epoch 78/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6675 - val_loss: 1.6502\n",
      "Epoch 79/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6574\n",
      "Epoch 80/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6674 - val_loss: 1.6633\n",
      "Epoch 81/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6659 - val_loss: 1.6731\n",
      "Epoch 82/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6932\n",
      "Epoch 83/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6673 - val_loss: 1.6535\n",
      "Epoch 84/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6678 - val_loss: 1.6614\n",
      "Epoch 85/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6664 - val_loss: 1.6491\n",
      "Epoch 86/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6665 - val_loss: 1.6576\n",
      "Epoch 87/300\n",
      "7024/7031 [============================>.] - ETA: 0s - loss: 1.6707\n",
      " Reduced learning rate to 0.00197531\n",
      "7031/7031 [==============================] - 8s - loss: 1.6706 - val_loss: 1.6556\n",
      "Epoch 88/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6615 - val_loss: 1.6562\n",
      "Epoch 89/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6669 - val_loss: 1.6498\n",
      "Epoch 90/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6614 - val_loss: 1.6545\n",
      "Epoch 91/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6597 - val_loss: 1.6453\n",
      "Epoch 92/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6667 - val_loss: 1.6561\n",
      "Epoch 93/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6594 - val_loss: 1.6484\n",
      "Epoch 94/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6624 - val_loss: 1.6764\n",
      "Epoch 95/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6594 - val_loss: 1.6686\n",
      "Epoch 96/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6639 - val_loss: 1.6660\n",
      "Epoch 97/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6609 - val_loss: 1.6484\n",
      "Epoch 98/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6665 - val_loss: 1.6473\n",
      "Epoch 99/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6548 - val_loss: 1.6576\n",
      "Epoch 100/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6619 - val_loss: 1.6497\n",
      "Epoch 101/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6580 - val_loss: 1.6522\n",
      "Epoch 102/300\n",
      "7009/7031 [============================>.] - ETA: 0s - loss: 1.6578\n",
      " Reduced learning rate to 0.00131687\n",
      "7031/7031 [==============================] - 8s - loss: 1.6577 - val_loss: 1.6498\n",
      "Epoch 103/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6573 - val_loss: 1.6492\n",
      "Epoch 104/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6616 - val_loss: 1.6531\n",
      "Epoch 105/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6568 - val_loss: 1.6463\n",
      "Epoch 106/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6550 - val_loss: 1.6640\n",
      "Epoch 107/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6717\n",
      "Epoch 108/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6572 - val_loss: 1.6518\n",
      "Epoch 109/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6591 - val_loss: 1.6570\n",
      "Epoch 110/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6660 - val_loss: 1.6564\n",
      "Epoch 111/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6523 - val_loss: 1.6399\n",
      "Epoch 112/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6600 - val_loss: 1.6505\n",
      "Epoch 113/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6591 - val_loss: 1.6445\n",
      "Epoch 114/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6596 - val_loss: 1.6523\n",
      "Epoch 115/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6568 - val_loss: 1.6412\n",
      "Epoch 116/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6491\n",
      "Epoch 117/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6596 - val_loss: 1.6453\n",
      "Epoch 118/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6591 - val_loss: 1.6620\n",
      "Epoch 119/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6542 - val_loss: 1.6472\n",
      "Epoch 120/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6555 - val_loss: 1.6524\n",
      "Epoch 121/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6582 - val_loss: 1.6642\n",
      "Epoch 122/300\n",
      "6991/7031 [============================>.] - ETA: 0s - loss: 1.6541\n",
      " Reduced learning rate to 0.000877915\n",
      "7031/7031 [==============================] - 8s - loss: 1.6544 - val_loss: 1.6498\n",
      "Epoch 123/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6565 - val_loss: 1.6486\n",
      "Epoch 124/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6650 - val_loss: 1.6537\n",
      "Epoch 125/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6613 - val_loss: 1.6541\n",
      "Epoch 126/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6438\n",
      "Epoch 127/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6574 - val_loss: 1.6439\n",
      "Epoch 128/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6521 - val_loss: 1.6575\n",
      "Epoch 129/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6518 - val_loss: 1.6478\n",
      "Epoch 130/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6645 - val_loss: 1.6580\n",
      "Epoch 131/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6521 - val_loss: 1.6516\n",
      "Epoch 132/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6541 - val_loss: 1.6555\n",
      "Epoch 133/300\n",
      "7020/7031 [============================>.] - ETA: 0s - loss: 1.6595\n",
      " Reduced learning rate to 0.000585277\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6523\n",
      "Epoch 134/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6560 - val_loss: 1.6662\n",
      "Epoch 135/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6593 - val_loss: 1.6594\n",
      "Epoch 136/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6578 - val_loss: 1.6556\n",
      "Epoch 137/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6523 - val_loss: 1.6543\n",
      "Epoch 138/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6535 - val_loss: 1.6498\n",
      "Epoch 139/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6544 - val_loss: 1.6385\n",
      "Epoch 140/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6514 - val_loss: 1.6562\n",
      "Epoch 141/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6486\n",
      "Epoch 142/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6576\n",
      "Epoch 143/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6555 - val_loss: 1.6524\n",
      "Epoch 144/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6516 - val_loss: 1.6607\n",
      "Epoch 145/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6535 - val_loss: 1.6467\n",
      "Epoch 146/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6632 - val_loss: 1.6517\n",
      "Epoch 147/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6543 - val_loss: 1.6590\n",
      "Epoch 148/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6454 - val_loss: 1.6556\n",
      "Epoch 149/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6585 - val_loss: 1.6426\n",
      "Epoch 150/300\n",
      "6998/7031 [============================>.] - ETA: 0s - loss: 1.6582\n",
      " Reduced learning rate to 0.000390184\n",
      "7031/7031 [==============================] - 8s - loss: 1.6584 - val_loss: 1.6505\n",
      "Epoch 151/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6565 - val_loss: 1.6447\n",
      "Epoch 152/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6524 - val_loss: 1.6569\n",
      "Epoch 153/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6538 - val_loss: 1.6484\n",
      "Epoch 154/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6563 - val_loss: 1.6543\n",
      "Epoch 155/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6640 - val_loss: 1.6506\n",
      "Epoch 156/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6558 - val_loss: 1.6486\n",
      "Epoch 157/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6499 - val_loss: 1.6465\n",
      "Epoch 158/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6591 - val_loss: 1.6483\n",
      "Epoch 159/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6568 - val_loss: 1.6459\n",
      "Epoch 160/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6530 - val_loss: 1.6471\n",
      "Epoch 161/300\n",
      "7009/7031 [============================>.] - ETA: 0s - loss: 1.6562\n",
      " Reduced learning rate to 0.000260123\n",
      "7031/7031 [==============================] - 8s - loss: 1.6562 - val_loss: 1.6537\n",
      "Epoch 162/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6492\n",
      "Epoch 163/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6518 - val_loss: 1.6545\n",
      "Epoch 164/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6439\n",
      "Epoch 165/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6525 - val_loss: 1.6432\n",
      "Epoch 166/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6587 - val_loss: 1.6654\n",
      "Epoch 167/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6548 - val_loss: 1.6543\n",
      "Epoch 168/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6572 - val_loss: 1.6503\n",
      "Epoch 169/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6498\n",
      "Epoch 170/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6603 - val_loss: 1.6420\n",
      "Epoch 171/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6529 - val_loss: 1.6525\n",
      "Epoch 172/300\n",
      "7007/7031 [============================>.] - ETA: 0s - loss: 1.6585\n",
      " Reduced learning rate to 0.000173415\n",
      "7031/7031 [==============================] - 8s - loss: 1.6585 - val_loss: 1.6463\n",
      "Epoch 173/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6518 - val_loss: 1.6447\n",
      "Epoch 174/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6508 - val_loss: 1.6594\n",
      "Epoch 175/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6557 - val_loss: 1.6549\n",
      "Epoch 176/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6501 - val_loss: 1.6525\n",
      "Epoch 177/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6511 - val_loss: 1.6621\n",
      "Epoch 178/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6447 - val_loss: 1.6609\n",
      "Epoch 179/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6593 - val_loss: 1.6471\n",
      "Epoch 180/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6473 - val_loss: 1.6530\n",
      "Epoch 181/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6498 - val_loss: 1.6516\n",
      "Epoch 182/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6515 - val_loss: 1.6477\n",
      "Epoch 183/300\n",
      "6988/7031 [============================>.] - ETA: 0s - loss: 1.6495\n",
      " Reduced learning rate to 0.00011561\n",
      "7031/7031 [==============================] - 8s - loss: 1.6496 - val_loss: 1.6529\n",
      "Epoch 184/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6536 - val_loss: 1.6473\n",
      "Epoch 185/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6574 - val_loss: 1.6451\n",
      "Epoch 186/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6551 - val_loss: 1.6484\n",
      "Epoch 187/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6531 - val_loss: 1.6367\n",
      "Epoch 188/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6355\n",
      "Epoch 189/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6518 - val_loss: 1.6517\n",
      "Epoch 190/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6523 - val_loss: 1.6459\n",
      "Epoch 191/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6530 - val_loss: 1.6443\n",
      "Epoch 192/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6554 - val_loss: 1.6439\n",
      "Epoch 193/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6445 - val_loss: 1.6486\n",
      "Epoch 194/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6479 - val_loss: 1.6555\n",
      "Epoch 195/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6619 - val_loss: 1.6529\n",
      "Epoch 196/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6426\n",
      "Epoch 197/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6484\n",
      "Epoch 198/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6514 - val_loss: 1.6453\n",
      "Epoch 199/300\n",
      "7028/7031 [============================>.] - ETA: 0s - loss: 1.6579\n",
      " Reduced learning rate to 7.70735e-05\n",
      "7031/7031 [==============================] - 8s - loss: 1.6578 - val_loss: 1.6545\n",
      "Epoch 1/300\n",
      "7031/7031 [==============================] - 10s - loss: 3.6312 - val_loss: 2.8889\n",
      "Epoch 2/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.3181 - val_loss: 2.1704\n",
      "Epoch 3/300\n",
      "7031/7031 [==============================] - 8s - loss: 2.0947 - val_loss: 2.7245\n",
      "Epoch 4/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9870 - val_loss: 1.8842\n",
      "Epoch 5/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.9247 - val_loss: 1.7786\n",
      "Epoch 6/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8881 - val_loss: 1.7662\n",
      "Epoch 7/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8619 - val_loss: 1.7813\n",
      "Epoch 8/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8426 - val_loss: 1.8595\n",
      "Epoch 9/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8313 - val_loss: 1.7194\n",
      "Epoch 10/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8274 - val_loss: 2.0255\n",
      "Epoch 11/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8165 - val_loss: 1.8457\n",
      "Epoch 12/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8152 - val_loss: 1.7637\n",
      "Epoch 13/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8053 - val_loss: 1.7244\n",
      "Epoch 14/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.8034 - val_loss: 1.7045\n",
      "Epoch 15/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7968 - val_loss: 1.9120\n",
      "Epoch 16/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7954 - val_loss: 1.7479\n",
      "Epoch 17/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7915 - val_loss: 1.8313\n",
      "Epoch 18/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7908 - val_loss: 1.8869\n",
      "Epoch 19/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7772 - val_loss: 1.7064\n",
      "Epoch 20/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7828 - val_loss: 1.8169\n",
      "Epoch 21/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7847 - val_loss: 1.8087\n",
      "Epoch 22/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7748 - val_loss: 1.7812\n",
      "Epoch 23/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7801 - val_loss: 1.7502\n",
      "Epoch 24/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7699 - val_loss: 1.7200\n",
      "Epoch 25/300\n",
      "7013/7031 [============================>.] - ETA: 0s - loss: 1.7690\n",
      " Reduced learning rate to 0.01\n",
      "7031/7031 [==============================] - 9s - loss: 1.7687 - val_loss: 1.7402\n",
      "Epoch 26/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7090 - val_loss: 1.7051\n",
      "Epoch 27/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7149 - val_loss: 1.7037\n",
      "Epoch 28/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7186 - val_loss: 1.7365\n",
      "Epoch 29/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7139 - val_loss: 1.6854\n",
      "Epoch 30/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7138 - val_loss: 1.6939\n",
      "Epoch 31/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7163 - val_loss: 1.6920\n",
      "Epoch 32/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7150 - val_loss: 1.7669\n",
      "Epoch 33/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7067 - val_loss: 1.6889\n",
      "Epoch 34/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7084 - val_loss: 1.7291\n",
      "Epoch 35/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7082 - val_loss: 1.6869\n",
      "Epoch 36/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7123 - val_loss: 1.6770\n",
      "Epoch 37/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7175 - val_loss: 1.9751\n",
      "Epoch 38/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7112 - val_loss: 1.6896\n",
      "Epoch 39/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7122 - val_loss: 1.8497\n",
      "Epoch 40/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7195 - val_loss: 1.6713\n",
      "Epoch 41/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7096 - val_loss: 1.6912\n",
      "Epoch 42/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7136 - val_loss: 1.7044\n",
      "Epoch 43/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7079 - val_loss: 1.7088\n",
      "Epoch 44/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7117 - val_loss: 1.6804\n",
      "Epoch 45/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7047 - val_loss: 1.7030\n",
      "Epoch 46/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7132 - val_loss: 1.6815\n",
      "Epoch 47/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7092 - val_loss: 1.6726\n",
      "Epoch 48/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7118 - val_loss: 1.7311\n",
      "Epoch 49/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7095 - val_loss: 1.7064\n",
      "Epoch 50/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.7009 - val_loss: 1.6895\n",
      "Epoch 51/300\n",
      "6999/7031 [============================>.] - ETA: 0s - loss: 1.7143\n",
      " Reduced learning rate to 0.00666667\n",
      "7031/7031 [==============================] - 8s - loss: 1.7140 - val_loss: 1.7129\n",
      "Epoch 52/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6831 - val_loss: 1.6736\n",
      "Epoch 53/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6898 - val_loss: 1.6751\n",
      "Epoch 54/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6785 - val_loss: 1.6850\n",
      "Epoch 55/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6849 - val_loss: 1.6914\n",
      "Epoch 56/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6801 - val_loss: 1.6731\n",
      "Epoch 57/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6826 - val_loss: 1.6818\n",
      "Epoch 58/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6874 - val_loss: 1.6731\n",
      "Epoch 59/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6764 - val_loss: 1.6682\n",
      "Epoch 60/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6804 - val_loss: 1.6875\n",
      "Epoch 61/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6828 - val_loss: 1.6815\n",
      "Epoch 62/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6861 - val_loss: 1.6750\n",
      "Epoch 63/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6888 - val_loss: 1.7031\n",
      "Epoch 64/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6991 - val_loss: 1.6603\n",
      "Epoch 65/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6837 - val_loss: 1.6779\n",
      "Epoch 66/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6875 - val_loss: 1.6614\n",
      "Epoch 67/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6835 - val_loss: 1.6584\n",
      "Epoch 68/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6907 - val_loss: 1.6933\n",
      "Epoch 69/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6928 - val_loss: 1.6681\n",
      "Epoch 70/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6833 - val_loss: 1.6562\n",
      "Epoch 71/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6826 - val_loss: 1.6750\n",
      "Epoch 72/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6798 - val_loss: 1.6575\n",
      "Epoch 73/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6860 - val_loss: 1.6974\n",
      "Epoch 74/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6792 - val_loss: 1.6556\n",
      "Epoch 75/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6837 - val_loss: 1.6740\n",
      "Epoch 76/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6816 - val_loss: 1.6613\n",
      "Epoch 77/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6801 - val_loss: 1.6875\n",
      "Epoch 78/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6930 - val_loss: 1.6648\n",
      "Epoch 79/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6908 - val_loss: 1.6720\n",
      "Epoch 80/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6934 - val_loss: 1.6771\n",
      "Epoch 81/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6895 - val_loss: 1.6549\n",
      "Epoch 82/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6796 - val_loss: 1.6726\n",
      "Epoch 83/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6892 - val_loss: 1.7369\n",
      "Epoch 84/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6835 - val_loss: 1.6777\n",
      "Epoch 85/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6930 - val_loss: 1.6739\n",
      "Epoch 86/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6892 - val_loss: 1.6765\n",
      "Epoch 87/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6815 - val_loss: 1.6803\n",
      "Epoch 88/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6826 - val_loss: 1.6765\n",
      "Epoch 89/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6845 - val_loss: 1.6653\n",
      "Epoch 90/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6915 - val_loss: 1.7403\n",
      "Epoch 91/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6826 - val_loss: 1.6795\n",
      "Epoch 92/300\n",
      "7022/7031 [============================>.] - ETA: 0s - loss: 1.6849\n",
      " Reduced learning rate to 0.00444444\n",
      "7031/7031 [==============================] - 8s - loss: 1.6850 - val_loss: 1.7109\n",
      "Epoch 93/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6728 - val_loss: 1.6640\n",
      "Epoch 94/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6695 - val_loss: 1.6705\n",
      "Epoch 95/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6737 - val_loss: 1.6738\n",
      "Epoch 96/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6678 - val_loss: 1.6718\n",
      "Epoch 97/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6739 - val_loss: 1.6775\n",
      "Epoch 98/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6691 - val_loss: 1.6818\n",
      "Epoch 99/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6732 - val_loss: 1.6779\n",
      "Epoch 100/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6701 - val_loss: 1.6875\n",
      "Epoch 101/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6774 - val_loss: 1.6706\n",
      "Epoch 102/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6704 - val_loss: 1.6914\n",
      "Epoch 103/300\n",
      "7000/7031 [============================>.] - ETA: 0s - loss: 1.6745\n",
      " Reduced learning rate to 0.00296296\n",
      "7031/7031 [==============================] - 8s - loss: 1.6745 - val_loss: 1.6549\n",
      "Epoch 104/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6672 - val_loss: 1.6379\n",
      "Epoch 105/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6618 - val_loss: 1.6426\n",
      "Epoch 106/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6674 - val_loss: 1.6633\n",
      "Epoch 107/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6738 - val_loss: 1.6672\n",
      "Epoch 108/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6639 - val_loss: 1.6680\n",
      "Epoch 109/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6635 - val_loss: 1.6516\n",
      "Epoch 110/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6595 - val_loss: 1.6947\n",
      "Epoch 111/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6676 - val_loss: 1.6580\n",
      "Epoch 112/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6636 - val_loss: 1.6594\n",
      "Epoch 113/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6650 - val_loss: 1.6601\n",
      "Epoch 114/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6625 - val_loss: 1.6809\n",
      "Epoch 115/300\n",
      "7027/7031 [============================>.] - ETA: 0s - loss: 1.6650\n",
      " Reduced learning rate to 0.00197531\n",
      "7031/7031 [==============================] - 8s - loss: 1.6650 - val_loss: 1.6607\n",
      "Epoch 116/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6563 - val_loss: 1.6557\n",
      "Epoch 117/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6587 - val_loss: 1.6498\n",
      "Epoch 118/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6644 - val_loss: 1.6590\n",
      "Epoch 119/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6602 - val_loss: 1.6568\n",
      "Epoch 120/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6607 - val_loss: 1.6590\n",
      "Epoch 121/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6607 - val_loss: 1.6355\n",
      "Epoch 122/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6583 - val_loss: 1.6504\n",
      "Epoch 123/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6618 - val_loss: 1.6523\n",
      "Epoch 124/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6636 - val_loss: 1.6530\n",
      "Epoch 125/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6601 - val_loss: 1.6503\n",
      "Epoch 126/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6565 - val_loss: 1.6705\n",
      "Epoch 127/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6582 - val_loss: 1.6556\n",
      "Epoch 128/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6630 - val_loss: 1.6555\n",
      "Epoch 129/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6608 - val_loss: 1.6522\n",
      "Epoch 130/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6632 - val_loss: 1.6497\n",
      "Epoch 131/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6610 - val_loss: 1.6516\n",
      "Epoch 132/300\n",
      "7014/7031 [============================>.] - ETA: 0s - loss: 1.6637\n",
      " Reduced learning rate to 0.00131687\n",
      "7031/7031 [==============================] - 8s - loss: 1.6639 - val_loss: 1.6556\n",
      "Epoch 133/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6546 - val_loss: 1.6522\n",
      "Epoch 134/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6554 - val_loss: 1.6405\n",
      "Epoch 135/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6579 - val_loss: 1.6420\n",
      "Epoch 136/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6603\n",
      "Epoch 137/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6594 - val_loss: 1.6570\n",
      "Epoch 138/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6538 - val_loss: 1.6589\n",
      "Epoch 139/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6524 - val_loss: 1.6530\n",
      "Epoch 140/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6572 - val_loss: 1.6483\n",
      "Epoch 141/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6606 - val_loss: 1.6537\n",
      "Epoch 142/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6584 - val_loss: 1.6629\n",
      "Epoch 143/300\n",
      "6997/7031 [============================>.] - ETA: 0s - loss: 1.6613\n",
      " Reduced learning rate to 0.000877915\n",
      "7031/7031 [==============================] - 8s - loss: 1.6615 - val_loss: 1.6472\n",
      "Epoch 144/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6558 - val_loss: 1.6506\n",
      "Epoch 145/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6532 - val_loss: 1.6443\n",
      "Epoch 146/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6550 - val_loss: 1.6543\n",
      "Epoch 147/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6529 - val_loss: 1.6484\n",
      "Epoch 148/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6553 - val_loss: 1.6562\n",
      "Epoch 149/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7031/7031 [==============================] - 8s - loss: 1.6579 - val_loss: 1.6541\n",
      "Epoch 150/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6555 - val_loss: 1.6477\n",
      "Epoch 151/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6557 - val_loss: 1.6447\n",
      "Epoch 152/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6509 - val_loss: 1.6563\n",
      "Epoch 153/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6556 - val_loss: 1.6516\n",
      "Epoch 154/300\n",
      "6989/7031 [============================>.] - ETA: 0s - loss: 1.6535\n",
      " Reduced learning rate to 0.000585277\n",
      "7031/7031 [==============================] - 8s - loss: 1.6538 - val_loss: 1.6477\n",
      "Epoch 155/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6564 - val_loss: 1.6511\n",
      "Epoch 156/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6528 - val_loss: 1.6472\n",
      "Epoch 157/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6512 - val_loss: 1.6510\n",
      "Epoch 158/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6614 - val_loss: 1.6510\n",
      "Epoch 159/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6590 - val_loss: 1.6447\n",
      "Epoch 160/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6525\n",
      "Epoch 161/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6414\n",
      "Epoch 162/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6601 - val_loss: 1.6564\n",
      "Epoch 163/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6466 - val_loss: 1.6425\n",
      "Epoch 164/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6535 - val_loss: 1.6452\n",
      "Epoch 165/300\n",
      "6999/7031 [============================>.] - ETA: 0s - loss: 1.6527\n",
      " Reduced learning rate to 0.000390184\n",
      "7031/7031 [==============================] - 8s - loss: 1.6528 - val_loss: 1.6584\n",
      "Epoch 166/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6528 - val_loss: 1.6447\n",
      "Epoch 167/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6507 - val_loss: 1.6543\n",
      "Epoch 168/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6516 - val_loss: 1.6463\n",
      "Epoch 169/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6523 - val_loss: 1.6564\n",
      "Epoch 170/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6564 - val_loss: 1.6680\n",
      "Epoch 171/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6525 - val_loss: 1.6568\n",
      "Epoch 172/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6633 - val_loss: 1.6445\n",
      "Epoch 173/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6536 - val_loss: 1.6524\n",
      "Epoch 174/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6504 - val_loss: 1.6420\n",
      "Epoch 175/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6573 - val_loss: 1.6439\n",
      "Epoch 176/300\n",
      "6990/7031 [============================>.] - ETA: 0s - loss: 1.6536\n",
      " Reduced learning rate to 0.000260123\n",
      "7031/7031 [==============================] - 8s - loss: 1.6538 - val_loss: 1.6522\n",
      "Epoch 177/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6561 - val_loss: 1.6549\n",
      "Epoch 178/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6447 - val_loss: 1.6463\n",
      "Epoch 179/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6568 - val_loss: 1.6447\n",
      "Epoch 180/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6562 - val_loss: 1.6408\n",
      "Epoch 181/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6490 - val_loss: 1.6439\n",
      "Epoch 182/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6533 - val_loss: 1.6433\n",
      "Epoch 183/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6535\n",
      "Epoch 184/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6537 - val_loss: 1.6511\n",
      "Epoch 185/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6508 - val_loss: 1.6400\n",
      "Epoch 186/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6497 - val_loss: 1.6420\n",
      "Epoch 187/300\n",
      "7021/7031 [============================>.] - ETA: 0s - loss: 1.6567\n",
      " Reduced learning rate to 0.000173415\n",
      "7031/7031 [==============================] - 8s - loss: 1.6567 - val_loss: 1.6447\n",
      "Epoch 188/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6534 - val_loss: 1.6463\n",
      "Epoch 189/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6517 - val_loss: 1.6523\n",
      "Epoch 190/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6551 - val_loss: 1.6555\n",
      "Epoch 191/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6553 - val_loss: 1.6418\n",
      "Epoch 192/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6509 - val_loss: 1.6486\n",
      "Epoch 193/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6509 - val_loss: 1.6537\n",
      "Epoch 194/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6598 - val_loss: 1.6490\n",
      "Epoch 195/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6574 - val_loss: 1.6492\n",
      "Epoch 196/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6494 - val_loss: 1.6445\n",
      "Epoch 197/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6518 - val_loss: 1.6580\n",
      "Epoch 198/300\n",
      "7019/7031 [============================>.] - ETA: 0s - loss: 1.6508\n",
      " Reduced learning rate to 0.00011561\n",
      "7031/7031 [==============================] - 8s - loss: 1.6509 - val_loss: 1.6491\n",
      "Epoch 199/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6510 - val_loss: 1.6472\n",
      "Epoch 200/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6499 - val_loss: 1.6496\n",
      "Epoch 201/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6499 - val_loss: 1.6463\n",
      "Epoch 202/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6547 - val_loss: 1.6457\n",
      "Epoch 203/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6523 - val_loss: 1.6466\n",
      "Epoch 204/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6495 - val_loss: 1.6484\n",
      "Epoch 205/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6528 - val_loss: 1.6451\n",
      "Epoch 206/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6558 - val_loss: 1.6603\n",
      "Epoch 207/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6506 - val_loss: 1.6427\n",
      "Epoch 208/300\n",
      "7031/7031 [==============================] - 8s - loss: 1.6603 - val_loss: 1.6511\n",
      "Epoch 209/300\n",
      "7001/7031 [============================>.] - ETA: 0s - loss: 1.6529\n",
      " Reduced learning rate to 7.70735e-05\n",
      "7031/7031 [==============================] - 8s - loss: 1.6529 - val_loss: 1.6516\n",
      "Epoch 1/300\n",
      "14062/14062 [==============================] - 19s - loss: 2.9620 - val_loss: 1.9376\n",
      "Epoch 2/300\n",
      "14062/14062 [==============================] - 17s - loss: 2.0316 - val_loss: 1.7695\n",
      "Epoch 3/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.9026 - val_loss: 2.1292\n",
      "Epoch 4/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8572 - val_loss: 1.8153\n",
      "Epoch 5/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8383 - val_loss: 1.7266\n",
      "Epoch 6/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8223 - val_loss: 1.7497\n",
      "Epoch 7/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7989 - val_loss: 1.7293\n",
      "Epoch 8/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7936 - val_loss: 1.7551\n",
      "Epoch 9/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7963 - val_loss: 1.8362\n",
      "Epoch 10/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7851 - val_loss: 2.0224\n",
      "Epoch 11/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7786 - val_loss: 2.2530\n",
      "Epoch 12/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7815 - val_loss: 1.7184\n",
      "Epoch 13/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7800 - val_loss: 1.6941\n",
      "Epoch 14/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7709 - val_loss: 1.7893\n",
      "Epoch 15/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7700 - val_loss: 1.7500\n",
      "Epoch 16/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7665 - val_loss: 1.7043\n",
      "Epoch 17/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7626 - val_loss: 1.7614\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.7623 - val_loss: 1.7254\n",
      "Epoch 19/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7610 - val_loss: 1.7294\n",
      "Epoch 20/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7564 - val_loss: 1.7032\n",
      "Epoch 21/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7591 - val_loss: 1.7489\n",
      "Epoch 22/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7603 - val_loss: 1.9307\n",
      "Epoch 23/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7550 - val_loss: 1.7773\n",
      "Epoch 24/300\n",
      "14035/14062 [============================>.] - ETA: 0s - loss: 1.7546\n",
      " Reduced learning rate to 0.01\n",
      "14062/14062 [==============================] - 18s - loss: 1.7546 - val_loss: 1.7407\n",
      "Epoch 25/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7127 - val_loss: 1.7097\n",
      "Epoch 26/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7045 - val_loss: 1.6968\n",
      "Epoch 27/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7074 - val_loss: 1.6965\n",
      "Epoch 28/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7032 - val_loss: 1.7642\n",
      "Epoch 29/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7037 - val_loss: 1.6889\n",
      "Epoch 30/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7069 - val_loss: 1.7071\n",
      "Epoch 31/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7058 - val_loss: 1.6964\n",
      "Epoch 32/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7070 - val_loss: 1.7146\n",
      "Epoch 33/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7045 - val_loss: 1.6730\n",
      "Epoch 34/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7055 - val_loss: 1.6746\n",
      "Epoch 35/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7002 - val_loss: 1.6743\n",
      "Epoch 36/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7048 - val_loss: 1.6770\n",
      "Epoch 37/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7044 - val_loss: 1.6863\n",
      "Epoch 38/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7033 - val_loss: 1.7656\n",
      "Epoch 39/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7074 - val_loss: 1.6719\n",
      "Epoch 40/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7013 - val_loss: 1.7629\n",
      "Epoch 41/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7020 - val_loss: 1.6957\n",
      "Epoch 42/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7019 - val_loss: 1.6939\n",
      "Epoch 43/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7048 - val_loss: 1.6863\n",
      "Epoch 44/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7037 - val_loss: 1.6719\n",
      "Epoch 45/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7045 - val_loss: 1.6759\n",
      "Epoch 46/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7043 - val_loss: 1.6761\n",
      "Epoch 47/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7043 - val_loss: 1.6903\n",
      "Epoch 48/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7018 - val_loss: 1.7123\n",
      "Epoch 49/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7051 - val_loss: 1.6734\n",
      "Epoch 50/300\n",
      "14054/14062 [============================>.] - ETA: 0s - loss: 1.6999\n",
      " Reduced learning rate to 0.00666667\n",
      "14062/14062 [==============================] - 17s - loss: 1.6999 - val_loss: 1.7148\n",
      "Epoch 51/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6819 - val_loss: 1.7397\n",
      "Epoch 52/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6871 - val_loss: 1.6743\n",
      "Epoch 53/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6795 - val_loss: 1.6716\n",
      "Epoch 54/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6794 - val_loss: 1.6644\n",
      "Epoch 55/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6818 - val_loss: 1.6954\n",
      "Epoch 56/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6767 - val_loss: 1.6755\n",
      "Epoch 57/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6803 - val_loss: 1.6903\n",
      "Epoch 58/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6837 - val_loss: 1.6942\n",
      "Epoch 59/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6815 - val_loss: 1.6759\n",
      "Epoch 60/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6842 - val_loss: 1.6667\n",
      "Epoch 61/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6815 - val_loss: 1.6769\n",
      "Epoch 62/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6765 - val_loss: 1.6629\n",
      "Epoch 63/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6814 - val_loss: 1.6691\n",
      "Epoch 64/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6850 - val_loss: 1.6707\n",
      "Epoch 65/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6794 - val_loss: 1.6832\n",
      "Epoch 66/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6798 - val_loss: 1.7278\n",
      "Epoch 67/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6830 - val_loss: 1.6722\n",
      "Epoch 68/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6853 - val_loss: 1.6704\n",
      "Epoch 69/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6780 - val_loss: 1.6638\n",
      "Epoch 70/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6789 - val_loss: 1.6641\n",
      "Epoch 71/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6807 - val_loss: 1.6910\n",
      "Epoch 72/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6770 - val_loss: 1.6793\n",
      "Epoch 73/300\n",
      "14061/14062 [============================>.] - ETA: 0s - loss: 1.6847\n",
      " Reduced learning rate to 0.00444444\n",
      "14062/14062 [==============================] - 17s - loss: 1.6848 - val_loss: 1.7277\n",
      "Epoch 74/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6745 - val_loss: 1.6800\n",
      "Epoch 75/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6733 - val_loss: 1.6496\n",
      "Epoch 76/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6705 - val_loss: 1.6746\n",
      "Epoch 77/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6710 - val_loss: 1.6719\n",
      "Epoch 78/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6739 - val_loss: 1.6652\n",
      "Epoch 79/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6720 - val_loss: 1.6840\n",
      "Epoch 80/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6705 - val_loss: 1.6770\n",
      "Epoch 81/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6711 - val_loss: 1.6743\n",
      "Epoch 82/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6717 - val_loss: 1.6667\n",
      "Epoch 83/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6691 - val_loss: 1.6628\n",
      "Epoch 84/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6711 - val_loss: 1.6812\n",
      "Epoch 85/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6730 - val_loss: 1.7017\n",
      "Epoch 86/300\n",
      "14023/14062 [============================>.] - ETA: 0s - loss: 1.6729\n",
      " Reduced learning rate to 0.00296296\n",
      "14062/14062 [==============================] - 17s - loss: 1.6731 - val_loss: 1.6840\n",
      "Epoch 87/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6626 - val_loss: 1.6605\n",
      "Epoch 88/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6659 - val_loss: 1.6652\n",
      "Epoch 89/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6601 - val_loss: 1.6603\n",
      "Epoch 90/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6630 - val_loss: 1.6642\n",
      "Epoch 91/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6620 - val_loss: 1.6605\n",
      "Epoch 92/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6620 - val_loss: 1.6743\n",
      "Epoch 93/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6627 - val_loss: 1.6508\n",
      "Epoch 94/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6638 - val_loss: 1.6601\n",
      "Epoch 95/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6591 - val_loss: 1.6496\n",
      "Epoch 96/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6633 - val_loss: 1.6617\n",
      "Epoch 97/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14061/14062 [============================>.] - ETA: 0s - loss: 1.6665\n",
      " Reduced learning rate to 0.00197531\n",
      "14062/14062 [==============================] - 17s - loss: 1.6665 - val_loss: 1.6681\n",
      "Epoch 98/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6602 - val_loss: 1.6617\n",
      "Epoch 99/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6524\n",
      "Epoch 100/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6593 - val_loss: 1.6601\n",
      "Epoch 101/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6626 - val_loss: 1.6680\n",
      "Epoch 102/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6609 - val_loss: 1.6691\n",
      "Epoch 103/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6627 - val_loss: 1.6551\n",
      "Epoch 104/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6579 - val_loss: 1.6484\n",
      "Epoch 105/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6613\n",
      "Epoch 106/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6606 - val_loss: 1.6628\n",
      "Epoch 107/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6616 - val_loss: 1.6562\n",
      "Epoch 108/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6607 - val_loss: 1.6535\n",
      "Epoch 109/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6553 - val_loss: 1.6641\n",
      "Epoch 110/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6676 - val_loss: 1.6628\n",
      "Epoch 111/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6601 - val_loss: 1.6602\n",
      "Epoch 112/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6595 - val_loss: 1.6614\n",
      "Epoch 113/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6602 - val_loss: 1.6644\n",
      "Epoch 114/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6614 - val_loss: 1.6562\n",
      "Epoch 115/300\n",
      "14042/14062 [============================>.] - ETA: 0s - loss: 1.6612\n",
      " Reduced learning rate to 0.00131687\n",
      "14062/14062 [==============================] - 17s - loss: 1.6612 - val_loss: 1.6551\n",
      "Epoch 116/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6615 - val_loss: 1.6523\n",
      "Epoch 117/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6569 - val_loss: 1.6520\n",
      "Epoch 118/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6580 - val_loss: 1.6563\n",
      "Epoch 119/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6624 - val_loss: 1.6586\n",
      "Epoch 120/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6606 - val_loss: 1.6598\n",
      "Epoch 121/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6568 - val_loss: 1.6577\n",
      "Epoch 122/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6587 - val_loss: 1.6761\n",
      "Epoch 123/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6603 - val_loss: 1.6605\n",
      "Epoch 124/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6544 - val_loss: 1.6536\n",
      "Epoch 125/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6483\n",
      "Epoch 126/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6624 - val_loss: 1.6589\n",
      "Epoch 127/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6614 - val_loss: 1.6563\n",
      "Epoch 128/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6533 - val_loss: 1.6500\n",
      "Epoch 129/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6523\n",
      "Epoch 130/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6548\n",
      "Epoch 131/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6577\n",
      "Epoch 132/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6565 - val_loss: 1.6605\n",
      "Epoch 133/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6567 - val_loss: 1.6499\n",
      "Epoch 134/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6558 - val_loss: 1.6499\n",
      "Epoch 135/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6579 - val_loss: 1.6578\n",
      "Epoch 136/300\n",
      "14058/14062 [============================>.] - ETA: 0s - loss: 1.6602\n",
      " Reduced learning rate to 0.000877915\n",
      "14062/14062 [==============================] - 17s - loss: 1.6602 - val_loss: 1.6589\n",
      "Epoch 137/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6497\n",
      "Epoch 138/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6598 - val_loss: 1.6500\n",
      "Epoch 139/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6556 - val_loss: 1.6481\n",
      "Epoch 140/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6581 - val_loss: 1.6586\n",
      "Epoch 141/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6547\n",
      "Epoch 142/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6507 - val_loss: 1.6496\n",
      "Epoch 143/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6572 - val_loss: 1.6575\n",
      "Epoch 144/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6600 - val_loss: 1.6565\n",
      "Epoch 145/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6497 - val_loss: 1.6497\n",
      "Epoch 146/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6483\n",
      "Epoch 147/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6554 - val_loss: 1.6551\n",
      "Epoch 148/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6517 - val_loss: 1.6523\n",
      "Epoch 149/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6637\n",
      "Epoch 150/300\n",
      "14055/14062 [============================>.] - ETA: 0s - loss: 1.6534\n",
      " Reduced learning rate to 0.000585277\n",
      "14062/14062 [==============================] - 17s - loss: 1.6533 - val_loss: 1.6524\n",
      "Epoch 151/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6511\n",
      "Epoch 152/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6460\n",
      "Epoch 153/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6577\n",
      "Epoch 154/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6537 - val_loss: 1.6488\n",
      "Epoch 155/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6523\n",
      "Epoch 156/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6449\n",
      "Epoch 157/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6600 - val_loss: 1.6589\n",
      "Epoch 158/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6520\n",
      "Epoch 159/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6517 - val_loss: 1.6602\n",
      "Epoch 160/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6569 - val_loss: 1.6548\n",
      "Epoch 161/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6514 - val_loss: 1.6562\n",
      "Epoch 162/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6496 - val_loss: 1.6613\n",
      "Epoch 163/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6574\n",
      "Epoch 164/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6575 - val_loss: 1.6563\n",
      "Epoch 165/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6608 - val_loss: 1.6539\n",
      "Epoch 166/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6526 - val_loss: 1.6535\n",
      "Epoch 167/300\n",
      "14024/14062 [============================>.] - ETA: 0s - loss: 1.6523\n",
      " Reduced learning rate to 0.000390184\n",
      "14062/14062 [==============================] - 17s - loss: 1.6524 - val_loss: 1.6562\n",
      "Epoch 168/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6509 - val_loss: 1.6488\n",
      "Epoch 169/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6567 - val_loss: 1.6538\n",
      "Epoch 170/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6496 - val_loss: 1.6488\n",
      "Epoch 171/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6488\n",
      "Epoch 172/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6517 - val_loss: 1.6551\n",
      "Epoch 173/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6521 - val_loss: 1.6484\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6537 - val_loss: 1.6485\n",
      "Epoch 175/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6559 - val_loss: 1.6511\n",
      "Epoch 176/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6500\n",
      "Epoch 177/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6572 - val_loss: 1.6547\n",
      "Epoch 178/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6548 - val_loss: 1.6433\n",
      "Epoch 179/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6629\n",
      "Epoch 180/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6513 - val_loss: 1.6511\n",
      "Epoch 181/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6504 - val_loss: 1.6565\n",
      "Epoch 182/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6501 - val_loss: 1.6472\n",
      "Epoch 183/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6498 - val_loss: 1.6559\n",
      "Epoch 184/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6551\n",
      "Epoch 185/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6592 - val_loss: 1.6560\n",
      "Epoch 186/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6511 - val_loss: 1.6563\n",
      "Epoch 187/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6509\n",
      "Epoch 188/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6566\n",
      "Epoch 189/300\n",
      "14031/14062 [============================>.] - ETA: 0s - loss: 1.6526\n",
      " Reduced learning rate to 0.000260123\n",
      "14062/14062 [==============================] - 17s - loss: 1.6526 - val_loss: 1.6548\n",
      "Epoch 190/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6573 - val_loss: 1.6520\n",
      "Epoch 191/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6528 - val_loss: 1.6601\n",
      "Epoch 192/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6521 - val_loss: 1.6524\n",
      "Epoch 193/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6497 - val_loss: 1.6445\n",
      "Epoch 194/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6526\n",
      "Epoch 195/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6589\n",
      "Epoch 196/300\n",
      "14062/14062 [==============================] - 18s - loss: 1.6556 - val_loss: 1.6508\n",
      "Epoch 197/300\n",
      "14062/14062 [==============================] - 18s - loss: 1.6519 - val_loss: 1.6444\n",
      "Epoch 198/300\n",
      "14062/14062 [==============================] - 18s - loss: 1.6532 - val_loss: 1.6598\n",
      "Epoch 199/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6520\n",
      "Epoch 200/300\n",
      "14039/14062 [============================>.] - ETA: 0s - loss: 1.6543\n",
      " Reduced learning rate to 0.000173415\n",
      "14062/14062 [==============================] - 17s - loss: 1.6543 - val_loss: 1.6563\n",
      "Epoch 201/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6516 - val_loss: 1.6499\n",
      "Epoch 202/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6510 - val_loss: 1.6551\n",
      "Epoch 203/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6562\n",
      "Epoch 204/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6556 - val_loss: 1.6496\n",
      "Epoch 205/300\n",
      "14062/14062 [==============================] - 18s - loss: 1.6544 - val_loss: 1.6511\n",
      "Epoch 206/300\n",
      "14062/14062 [==============================] - 18s - loss: 1.6491 - val_loss: 1.6539\n",
      "Epoch 207/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6545 - val_loss: 1.6551\n",
      "Epoch 208/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6544 - val_loss: 1.6520\n",
      "Epoch 209/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6529 - val_loss: 1.6449\n",
      "Epoch 210/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6497 - val_loss: 1.6448\n",
      "Epoch 211/300\n",
      "14044/14062 [============================>.] - ETA: 0s - loss: 1.6538\n",
      " Reduced learning rate to 0.00011561\n",
      "14062/14062 [==============================] - 19s - loss: 1.6539 - val_loss: 1.6487\n",
      "Epoch 212/300\n",
      "14062/14062 [==============================] - 19s - loss: 1.6537 - val_loss: 1.6449\n",
      "Epoch 213/300\n",
      "14062/14062 [==============================] - 23s - loss: 1.6596 - val_loss: 1.6539\n",
      "Epoch 214/300\n",
      "14062/14062 [==============================] - 54s - loss: 1.6504 - val_loss: 1.6487\n",
      "Epoch 215/300\n",
      "14062/14062 [==============================] - 54s - loss: 1.6544 - val_loss: 1.6523\n",
      "Epoch 216/300\n",
      "14062/14062 [==============================] - 46s - loss: 1.6550 - val_loss: 1.6539\n",
      "Epoch 217/300\n",
      "14062/14062 [==============================] - 46s - loss: 1.6518 - val_loss: 1.6509\n",
      "Epoch 218/300\n",
      "14062/14062 [==============================] - 47s - loss: 1.6535 - val_loss: 1.6550\n",
      "Epoch 219/300\n",
      "14062/14062 [==============================] - 41s - loss: 1.6518 - val_loss: 1.6433\n",
      "Epoch 220/300\n",
      "14062/14062 [==============================] - 45s - loss: 1.6513 - val_loss: 1.6488\n",
      "Epoch 221/300\n",
      "14062/14062 [==============================] - 46s - loss: 1.6507 - val_loss: 1.6566\n",
      "Epoch 222/300\n",
      "14052/14062 [============================>.] - ETA: 0s - loss: 1.6526\n",
      " Reduced learning rate to 7.70735e-05\n",
      "14062/14062 [==============================] - 49s - loss: 1.6526 - val_loss: 1.6512\n",
      "Epoch 1/300\n",
      "14062/14062 [==============================] - 46s - loss: 3.0455 - val_loss: 2.0860\n",
      "Epoch 2/300\n",
      "14062/14062 [==============================] - 34s - loss: 2.1405 - val_loss: 2.7470\n",
      "Epoch 3/300\n",
      "14062/14062 [==============================] - 34s - loss: 1.9476 - val_loss: 1.8831\n",
      "Epoch 4/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.8780 - val_loss: 2.1094\n",
      "Epoch 5/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.8409 - val_loss: 1.7383\n",
      "Epoch 6/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.8264 - val_loss: 1.7578\n",
      "Epoch 7/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.8092 - val_loss: 1.8620\n",
      "Epoch 8/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7975 - val_loss: 1.8189\n",
      "Epoch 9/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7983 - val_loss: 1.7865\n",
      "Epoch 10/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7830 - val_loss: 1.9909\n",
      "Epoch 11/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7826 - val_loss: 1.7486\n",
      "Epoch 12/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7765 - val_loss: 1.7525\n",
      "Epoch 13/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7739 - val_loss: 1.7696\n",
      "Epoch 14/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.7681 - val_loss: 1.7004\n",
      "Epoch 15/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7684 - val_loss: 1.7027\n",
      "Epoch 16/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.7635 - val_loss: 1.8114\n",
      "Epoch 17/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7667 - val_loss: 1.7058\n",
      "Epoch 18/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7624 - val_loss: 1.6991\n",
      "Epoch 19/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.7612 - val_loss: 1.7382\n",
      "Epoch 20/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7605 - val_loss: 1.7501\n",
      "Epoch 21/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7562 - val_loss: 1.7004\n",
      "Epoch 22/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7592 - val_loss: 1.6872\n",
      "Epoch 23/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7568 - val_loss: 1.7447\n",
      "Epoch 24/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7567 - val_loss: 1.7308\n",
      "Epoch 25/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7543 - val_loss: 1.7187\n",
      "Epoch 26/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7492 - val_loss: 1.8292\n",
      "Epoch 27/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7501 - val_loss: 1.7152\n",
      "Epoch 28/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7432 - val_loss: 1.8387\n",
      "Epoch 29/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7454 - val_loss: 1.7070\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 32s - loss: 1.7434 - val_loss: 1.6942\n",
      "Epoch 31/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7439 - val_loss: 1.9729\n",
      "Epoch 32/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7396 - val_loss: 1.7251\n",
      "Epoch 33/300\n",
      "14039/14062 [============================>.] - ETA: 0s - loss: 1.7472\n",
      " Reduced learning rate to 0.01\n",
      "14062/14062 [==============================] - 32s - loss: 1.7473 - val_loss: 1.7423\n",
      "Epoch 34/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7044 - val_loss: 1.6677\n",
      "Epoch 35/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7025 - val_loss: 1.6911\n",
      "Epoch 36/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7025 - val_loss: 1.7176\n",
      "Epoch 37/300\n",
      "14062/14062 [==============================] - 31s - loss: 1.7041 - val_loss: 1.7525\n",
      "Epoch 38/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7012 - val_loss: 1.6950\n",
      "Epoch 39/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6978 - val_loss: 1.6872\n",
      "Epoch 40/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7003 - val_loss: 1.7121\n",
      "Epoch 41/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7053 - val_loss: 1.6942\n",
      "Epoch 42/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.7001 - val_loss: 1.6718\n",
      "Epoch 43/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.7033 - val_loss: 1.6811\n",
      "Epoch 44/300\n",
      "14062/14062 [==============================] - 34s - loss: 1.6945 - val_loss: 1.6917\n",
      "Epoch 45/300\n",
      "14059/14062 [============================>.] - ETA: 0s - loss: 1.7038\n",
      " Reduced learning rate to 0.00666667\n",
      "14062/14062 [==============================] - 34s - loss: 1.7038 - val_loss: 1.6887\n",
      "Epoch 46/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.6813 - val_loss: 1.6667\n",
      "Epoch 47/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6810 - val_loss: 1.6758\n",
      "Epoch 48/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6800 - val_loss: 1.6840\n",
      "Epoch 49/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6811 - val_loss: 1.6746\n",
      "Epoch 50/300\n",
      "14062/14062 [==============================] - 33s - loss: 1.6810 - val_loss: 1.6758\n",
      "Epoch 51/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6773 - val_loss: 1.6733\n",
      "Epoch 52/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6861 - val_loss: 1.6953\n",
      "Epoch 53/300\n",
      "14062/14062 [==============================] - 32s - loss: 1.6813 - val_loss: 1.6977\n",
      "Epoch 54/300\n",
      "14062/14062 [==============================] - 24s - loss: 1.6833 - val_loss: 1.6734\n",
      "Epoch 55/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6818 - val_loss: 1.6652\n",
      "Epoch 56/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6793 - val_loss: 1.6743\n",
      "Epoch 57/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6816 - val_loss: 1.6900\n",
      "Epoch 58/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6755 - val_loss: 1.6691\n",
      "Epoch 59/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6812 - val_loss: 1.6613\n",
      "Epoch 60/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6799 - val_loss: 1.6773\n",
      "Epoch 61/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6767 - val_loss: 1.6793\n",
      "Epoch 62/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6872 - val_loss: 1.7202\n",
      "Epoch 63/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6815 - val_loss: 1.6629\n",
      "Epoch 64/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6798 - val_loss: 1.6628\n",
      "Epoch 65/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6799 - val_loss: 1.6835\n",
      "Epoch 66/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6832 - val_loss: 1.6863\n",
      "Epoch 67/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6791 - val_loss: 1.6718\n",
      "Epoch 68/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6814 - val_loss: 1.6769\n",
      "Epoch 69/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6795 - val_loss: 1.6769\n",
      "Epoch 70/300\n",
      "14049/14062 [============================>.] - ETA: 0s - loss: 1.6778\n",
      " Reduced learning rate to 0.00444444\n",
      "14062/14062 [==============================] - 17s - loss: 1.6778 - val_loss: 1.6695\n",
      "Epoch 71/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6695 - val_loss: 1.6718\n",
      "Epoch 72/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6659 - val_loss: 1.6642\n",
      "Epoch 73/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6684 - val_loss: 1.6616\n",
      "Epoch 74/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6714 - val_loss: 1.6718\n",
      "Epoch 75/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6690 - val_loss: 1.6613\n",
      "Epoch 76/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6690 - val_loss: 1.7097\n",
      "Epoch 77/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6714 - val_loss: 1.6589\n",
      "Epoch 78/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6708 - val_loss: 1.6628\n",
      "Epoch 79/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6644 - val_loss: 1.6769\n",
      "Epoch 80/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6664 - val_loss: 1.6577\n",
      "Epoch 81/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6685 - val_loss: 1.6811\n",
      "Epoch 82/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6669 - val_loss: 1.6617\n",
      "Epoch 83/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6695 - val_loss: 1.6637\n",
      "Epoch 84/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6682 - val_loss: 1.6599\n",
      "Epoch 85/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6707 - val_loss: 1.7121\n",
      "Epoch 86/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6665 - val_loss: 1.6602\n",
      "Epoch 87/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6675 - val_loss: 1.6704\n",
      "Epoch 88/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6681 - val_loss: 1.6625\n",
      "Epoch 89/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6702 - val_loss: 1.6785\n",
      "Epoch 90/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6693 - val_loss: 1.6616\n",
      "Epoch 91/300\n",
      "14051/14062 [============================>.] - ETA: 0s - loss: 1.6709\n",
      " Reduced learning rate to 0.00296296\n",
      "14062/14062 [==============================] - 17s - loss: 1.6710 - val_loss: 1.6655\n",
      "Epoch 92/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6608 - val_loss: 1.6939\n",
      "Epoch 93/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6606 - val_loss: 1.6641\n",
      "Epoch 94/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6645 - val_loss: 1.6617\n",
      "Epoch 95/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6631 - val_loss: 1.6628\n",
      "Epoch 96/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6623 - val_loss: 1.6497\n",
      "Epoch 97/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6628 - val_loss: 1.6640\n",
      "Epoch 98/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6613 - val_loss: 1.6704\n",
      "Epoch 99/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6619 - val_loss: 1.6762\n",
      "Epoch 100/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6667 - val_loss: 1.6676\n",
      "Epoch 101/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6608 - val_loss: 1.6641\n",
      "Epoch 102/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6640 - val_loss: 1.6677\n",
      "Epoch 103/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6610 - val_loss: 1.6605\n",
      "Epoch 104/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6653 - val_loss: 1.6551\n",
      "Epoch 105/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6653 - val_loss: 1.6586\n",
      "Epoch 106/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6667 - val_loss: 1.6590\n",
      "Epoch 107/300\n",
      "14055/14062 [============================>.] - ETA: 0s - loss: 1.6626\n",
      " Reduced learning rate to 0.00197531\n",
      "14062/14062 [==============================] - 17s - loss: 1.6625 - val_loss: 1.6642\n",
      "Epoch 108/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.6599\n",
      "Epoch 109/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6582 - val_loss: 1.6484\n",
      "Epoch 110/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6621 - val_loss: 1.6574\n",
      "Epoch 111/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6608 - val_loss: 1.6625\n",
      "Epoch 112/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6582 - val_loss: 1.6578\n",
      "Epoch 113/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6614 - val_loss: 1.6548\n",
      "Epoch 114/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6618 - val_loss: 1.6734\n",
      "Epoch 115/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6637 - val_loss: 1.6559\n",
      "Epoch 116/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.6586\n",
      "Epoch 117/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6579 - val_loss: 1.6565\n",
      "Epoch 118/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6592 - val_loss: 1.6524\n",
      "Epoch 119/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.6589\n",
      "Epoch 120/300\n",
      "14047/14062 [============================>.] - ETA: 0s - loss: 1.6631\n",
      " Reduced learning rate to 0.00131687\n",
      "14062/14062 [==============================] - 17s - loss: 1.6631 - val_loss: 1.6598\n",
      "Epoch 121/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6578\n",
      "Epoch 122/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6565 - val_loss: 1.6575\n",
      "Epoch 123/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6562 - val_loss: 1.6551\n",
      "Epoch 124/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6551 - val_loss: 1.6484\n",
      "Epoch 125/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6573 - val_loss: 1.6523\n",
      "Epoch 126/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6581 - val_loss: 1.6538\n",
      "Epoch 127/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6591 - val_loss: 1.6520\n",
      "Epoch 128/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6527\n",
      "Epoch 129/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6585 - val_loss: 1.6472\n",
      "Epoch 130/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6516 - val_loss: 1.6605\n",
      "Epoch 131/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.6566\n",
      "Epoch 132/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6542 - val_loss: 1.6539\n",
      "Epoch 133/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6559\n",
      "Epoch 134/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6520\n",
      "Epoch 135/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6579 - val_loss: 1.6605\n",
      "Epoch 136/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6547 - val_loss: 1.6617\n",
      "Epoch 137/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6559\n",
      "Epoch 138/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6556 - val_loss: 1.6563\n",
      "Epoch 139/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6629\n",
      "Epoch 140/300\n",
      "14031/14062 [============================>.] - ETA: 0s - loss: 1.6569\n",
      " Reduced learning rate to 0.000877915\n",
      "14062/14062 [==============================] - 17s - loss: 1.6569 - val_loss: 1.6500\n",
      "Epoch 141/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6580 - val_loss: 1.6605\n",
      "Epoch 142/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6524 - val_loss: 1.6548\n",
      "Epoch 143/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6594 - val_loss: 1.6616\n",
      "Epoch 144/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6553 - val_loss: 1.6614\n",
      "Epoch 145/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6568 - val_loss: 1.6520\n",
      "Epoch 146/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6524 - val_loss: 1.6559\n",
      "Epoch 147/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6550 - val_loss: 1.6547\n",
      "Epoch 148/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6601 - val_loss: 1.6589\n",
      "Epoch 149/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6461\n",
      "Epoch 150/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6602\n",
      "Epoch 151/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6543 - val_loss: 1.6550\n",
      "Epoch 152/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6612 - val_loss: 1.6548\n",
      "Epoch 153/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6568 - val_loss: 1.6578\n",
      "Epoch 154/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6545 - val_loss: 1.6485\n",
      "Epoch 155/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6569 - val_loss: 1.6524\n",
      "Epoch 156/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6497\n",
      "Epoch 157/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6598\n",
      "Epoch 158/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6547 - val_loss: 1.6559\n",
      "Epoch 159/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6545 - val_loss: 1.6547\n",
      "Epoch 160/300\n",
      "14057/14062 [============================>.] - ETA: 0s - loss: 1.6521\n",
      " Reduced learning rate to 0.000585277\n",
      "14062/14062 [==============================] - 17s - loss: 1.6521 - val_loss: 1.6574\n",
      "Epoch 161/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6485\n",
      "Epoch 162/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6482 - val_loss: 1.6565\n",
      "Epoch 163/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6533 - val_loss: 1.6548\n",
      "Epoch 164/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6535\n",
      "Epoch 165/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6560\n",
      "Epoch 166/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6512 - val_loss: 1.6625\n",
      "Epoch 167/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6484\n",
      "Epoch 168/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6487 - val_loss: 1.6559\n",
      "Epoch 169/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6488\n",
      "Epoch 170/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6521 - val_loss: 1.6536\n",
      "Epoch 171/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6572 - val_loss: 1.6458\n",
      "Epoch 172/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6557 - val_loss: 1.6538\n",
      "Epoch 173/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6500 - val_loss: 1.6472\n",
      "Epoch 174/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6550 - val_loss: 1.6605\n",
      "Epoch 175/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6537 - val_loss: 1.6508\n",
      "Epoch 176/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6542 - val_loss: 1.6578\n",
      "Epoch 177/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6551\n",
      "Epoch 178/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6535\n",
      "Epoch 179/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6591 - val_loss: 1.6614\n",
      "Epoch 180/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6488\n",
      "Epoch 181/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6508 - val_loss: 1.6520\n",
      "Epoch 182/300\n",
      "14044/14062 [============================>.] - ETA: 0s - loss: 1.6543\n",
      " Reduced learning rate to 0.000390184\n",
      "14062/14062 [==============================] - 17s - loss: 1.6542 - val_loss: 1.6566\n",
      "Epoch 183/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6587 - val_loss: 1.6523\n",
      "Epoch 184/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6548 - val_loss: 1.6449\n",
      "Epoch 185/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6528 - val_loss: 1.6511\n",
      "Epoch 186/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6562\n",
      "Epoch 187/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6566 - val_loss: 1.6520\n",
      "Epoch 188/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6529 - val_loss: 1.6508\n",
      "Epoch 189/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6445\n",
      "Epoch 190/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6550\n",
      "Epoch 191/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6495 - val_loss: 1.6526\n",
      "Epoch 192/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6546 - val_loss: 1.6485\n",
      "Epoch 193/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6502 - val_loss: 1.6481\n",
      "Epoch 194/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6484\n",
      "Epoch 195/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6551\n",
      "Epoch 196/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6562\n",
      "Epoch 197/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6515 - val_loss: 1.6480\n",
      "Epoch 198/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6590\n",
      "Epoch 199/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6590\n",
      "Epoch 200/300\n",
      "14060/14062 [============================>.] - ETA: 0s - loss: 1.6559\n",
      " Reduced learning rate to 0.000260123\n",
      "14062/14062 [==============================] - 17s - loss: 1.6559 - val_loss: 1.6508\n",
      "Epoch 201/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6481\n",
      "Epoch 202/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6525 - val_loss: 1.6523\n",
      "Epoch 203/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6559\n",
      "Epoch 204/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6483\n",
      "Epoch 205/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6546 - val_loss: 1.6499\n",
      "Epoch 206/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6515 - val_loss: 1.6485\n",
      "Epoch 207/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6479 - val_loss: 1.6562\n",
      "Epoch 208/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6485 - val_loss: 1.6559\n",
      "Epoch 209/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6526 - val_loss: 1.6526\n",
      "Epoch 210/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6538\n",
      "Epoch 211/300\n",
      "14038/14062 [============================>.] - ETA: 0s - loss: 1.6536\n",
      " Reduced learning rate to 0.000173415\n",
      "14062/14062 [==============================] - 17s - loss: 1.6536 - val_loss: 1.6566\n",
      "Epoch 212/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6554 - val_loss: 1.6538\n",
      "Epoch 213/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6562\n",
      "Epoch 214/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6481\n",
      "Epoch 215/300\n",
      "14062/14062 [==============================] - 16s - loss: 1.6524 - val_loss: 1.6574\n",
      "Epoch 216/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6520\n",
      "Epoch 217/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6512\n",
      "Epoch 218/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6528 - val_loss: 1.6550\n",
      "Epoch 219/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6483 - val_loss: 1.6550\n",
      "Epoch 220/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6514 - val_loss: 1.6578\n",
      "Epoch 221/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6568 - val_loss: 1.6547\n",
      "Epoch 222/300\n",
      "14046/14062 [============================>.] - ETA: 0s - loss: 1.6521\n",
      " Reduced learning rate to 0.00011561\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6488\n",
      "Epoch 223/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6508 - val_loss: 1.6577\n",
      "Epoch 224/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6523\n",
      "Epoch 225/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6493 - val_loss: 1.6521\n",
      "Epoch 226/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6493 - val_loss: 1.6472\n",
      "Epoch 227/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6487\n",
      "Epoch 228/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6509\n",
      "Epoch 229/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6504 - val_loss: 1.6562\n",
      "Epoch 230/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6503 - val_loss: 1.6449\n",
      "Epoch 231/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6605\n",
      "Epoch 232/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6487 - val_loss: 1.6539\n",
      "Epoch 233/300\n",
      "14033/14062 [============================>.] - ETA: 0s - loss: 1.6542\n",
      " Reduced learning rate to 7.70735e-05\n",
      "14062/14062 [==============================] - 17s - loss: 1.6542 - val_loss: 1.6523\n",
      "Epoch 1/300\n",
      "14062/14062 [==============================] - 18s - loss: 2.9796 - val_loss: 2.1668\n",
      "Epoch 2/300\n",
      "14062/14062 [==============================] - 17s - loss: 2.0583 - val_loss: 1.7823\n",
      "Epoch 3/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.9262 - val_loss: 1.7919\n",
      "Epoch 4/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8642 - val_loss: 1.7450\n",
      "Epoch 5/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8460 - val_loss: 1.7645\n",
      "Epoch 6/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8166 - val_loss: 1.8722\n",
      "Epoch 7/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8092 - val_loss: 1.7347\n",
      "Epoch 8/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7975 - val_loss: 1.7436\n",
      "Epoch 9/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7948 - val_loss: 1.7185\n",
      "Epoch 10/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7913 - val_loss: 1.7199\n",
      "Epoch 11/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7790 - val_loss: 1.7542\n",
      "Epoch 12/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7747 - val_loss: 1.7034\n",
      "Epoch 13/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7731 - val_loss: 1.7200\n",
      "Epoch 14/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7751 - val_loss: 1.7004\n",
      "Epoch 15/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7660 - val_loss: 1.7043\n",
      "Epoch 16/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7704 - val_loss: 2.1562\n",
      "Epoch 17/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7618 - val_loss: 1.7148\n",
      "Epoch 18/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7584 - val_loss: 1.7653\n",
      "Epoch 19/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7600 - val_loss: 1.8568\n",
      "Epoch 20/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7576 - val_loss: 1.7226\n",
      "Epoch 21/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7635 - val_loss: 1.7536\n",
      "Epoch 22/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7551 - val_loss: 1.7957\n",
      "Epoch 23/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7533 - val_loss: 1.7254\n",
      "Epoch 24/300\n",
      "14062/14062 [==============================] - 16s - loss: 1.7516 - val_loss: 1.6839\n",
      "Epoch 25/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7479 - val_loss: 1.7017\n",
      "Epoch 26/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7502 - val_loss: 1.6914\n",
      "Epoch 27/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7470 - val_loss: 1.7539\n",
      "Epoch 28/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7505 - val_loss: 1.7162\n",
      "Epoch 29/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7458 - val_loss: 1.7043\n",
      "Epoch 30/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7453 - val_loss: 1.6952\n",
      "Epoch 31/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.7464 - val_loss: 1.8072\n",
      "Epoch 32/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7437 - val_loss: 1.6743\n",
      "Epoch 33/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7422 - val_loss: 1.7566\n",
      "Epoch 34/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7479 - val_loss: 1.7372\n",
      "Epoch 35/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7429 - val_loss: 1.6981\n",
      "Epoch 36/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7423 - val_loss: 1.8636\n",
      "Epoch 37/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7395 - val_loss: 1.7891\n",
      "Epoch 38/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7427 - val_loss: 1.7280\n",
      "Epoch 39/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7417 - val_loss: 1.7199\n",
      "Epoch 40/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7384 - val_loss: 1.7148\n",
      "Epoch 41/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7403 - val_loss: 1.6821\n",
      "Epoch 42/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7359 - val_loss: 1.7070\n",
      "Epoch 43/300\n",
      "14037/14062 [============================>.] - ETA: 0s - loss: 1.7374\n",
      " Reduced learning rate to 0.01\n",
      "14062/14062 [==============================] - 17s - loss: 1.7374 - val_loss: 1.7418\n",
      "Epoch 44/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6981 - val_loss: 1.6821\n",
      "Epoch 45/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7021 - val_loss: 1.7551\n",
      "Epoch 46/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6997 - val_loss: 1.6993\n",
      "Epoch 47/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6973 - val_loss: 1.7152\n",
      "Epoch 48/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6967 - val_loss: 1.6836\n",
      "Epoch 49/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6993 - val_loss: 1.6918\n",
      "Epoch 50/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6987 - val_loss: 1.6917\n",
      "Epoch 51/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6999 - val_loss: 1.6683\n",
      "Epoch 52/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6969 - val_loss: 1.6833\n",
      "Epoch 53/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7001 - val_loss: 1.7151\n",
      "Epoch 54/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7017 - val_loss: 1.6707\n",
      "Epoch 55/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6974 - val_loss: 1.7016\n",
      "Epoch 56/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6929 - val_loss: 1.6793\n",
      "Epoch 57/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7001 - val_loss: 1.6875\n",
      "Epoch 58/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6962 - val_loss: 1.7457\n",
      "Epoch 59/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6988 - val_loss: 1.6695\n",
      "Epoch 60/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6981 - val_loss: 1.6718\n",
      "Epoch 61/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6981 - val_loss: 1.7645\n",
      "Epoch 62/300\n",
      "14027/14062 [============================>.] - ETA: 0s - loss: 1.6957\n",
      " Reduced learning rate to 0.00666667\n",
      "14062/14062 [==============================] - 17s - loss: 1.6957 - val_loss: 1.6770\n",
      "Epoch 63/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6833 - val_loss: 1.6872\n",
      "Epoch 64/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6776 - val_loss: 1.6734\n",
      "Epoch 65/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6782 - val_loss: 1.6746\n",
      "Epoch 66/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6849 - val_loss: 1.6900\n",
      "Epoch 67/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6768 - val_loss: 1.6808\n",
      "Epoch 68/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6780 - val_loss: 1.6683\n",
      "Epoch 69/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6784 - val_loss: 1.6851\n",
      "Epoch 70/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6814 - val_loss: 1.6704\n",
      "Epoch 71/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6758 - val_loss: 1.6692\n",
      "Epoch 72/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6767 - val_loss: 1.6746\n",
      "Epoch 73/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6809 - val_loss: 1.6653\n",
      "Epoch 74/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6807 - val_loss: 1.6758\n",
      "Epoch 75/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6752 - val_loss: 1.6605\n",
      "Epoch 76/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6791 - val_loss: 1.6890\n",
      "Epoch 77/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6728 - val_loss: 1.6602\n",
      "Epoch 78/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6786 - val_loss: 1.7031\n",
      "Epoch 79/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6818 - val_loss: 1.6915\n",
      "Epoch 80/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6818 - val_loss: 1.6692\n",
      "Epoch 81/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6817 - val_loss: 1.6720\n",
      "Epoch 82/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6823 - val_loss: 1.6723\n",
      "Epoch 83/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6757 - val_loss: 1.6665\n",
      "Epoch 84/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6762 - val_loss: 1.6653\n",
      "Epoch 85/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6787 - val_loss: 1.7004\n",
      "Epoch 86/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6803 - val_loss: 1.6642\n",
      "Epoch 87/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6822 - val_loss: 1.6824\n",
      "Epoch 88/300\n",
      "14048/14062 [============================>.] - ETA: 0s - loss: 1.6794\n",
      " Reduced learning rate to 0.00444444\n",
      "14062/14062 [==============================] - 17s - loss: 1.6794 - val_loss: 1.6809\n",
      "Epoch 89/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6642 - val_loss: 1.6563\n",
      "Epoch 90/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6711 - val_loss: 1.6679\n",
      "Epoch 91/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6645 - val_loss: 1.6694\n",
      "Epoch 92/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6673 - val_loss: 1.6589\n",
      "Epoch 93/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6661 - val_loss: 1.6707\n",
      "Epoch 94/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6726 - val_loss: 1.6563\n",
      "Epoch 95/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6692 - val_loss: 1.6723\n",
      "Epoch 96/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6683 - val_loss: 1.6683\n",
      "Epoch 97/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6693 - val_loss: 1.6743\n",
      "Epoch 98/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6655 - val_loss: 1.6644\n",
      "Epoch 99/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6771 - val_loss: 1.6578\n",
      "Epoch 100/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6637 - val_loss: 1.6563\n",
      "Epoch 101/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6679 - val_loss: 1.6628\n",
      "Epoch 102/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6694 - val_loss: 1.6667\n",
      "Epoch 103/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6714 - val_loss: 1.6563\n",
      "Epoch 104/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6659 - val_loss: 1.6801\n",
      "Epoch 105/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6628 - val_loss: 1.6759\n",
      "Epoch 106/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6694 - val_loss: 1.6754\n",
      "Epoch 107/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6649 - val_loss: 1.6668\n",
      "Epoch 108/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6692 - val_loss: 1.6694\n",
      "Epoch 109/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6671 - val_loss: 1.6629\n",
      "Epoch 110/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6692 - val_loss: 1.6604\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6707 - val_loss: 1.6655\n",
      "Epoch 112/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6673 - val_loss: 1.6574\n",
      "Epoch 113/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6664 - val_loss: 1.6629\n",
      "Epoch 114/300\n",
      "14019/14062 [============================>.] - ETA: 0s - loss: 1.6663\n",
      " Reduced learning rate to 0.00296296\n",
      "14062/14062 [==============================] - 17s - loss: 1.6664 - val_loss: 1.6598\n",
      "Epoch 115/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6660 - val_loss: 1.6653\n",
      "Epoch 116/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6625 - val_loss: 1.6641\n",
      "Epoch 117/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6623 - val_loss: 1.6641\n",
      "Epoch 118/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6600 - val_loss: 1.6722\n",
      "Epoch 119/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6612 - val_loss: 1.6601\n",
      "Epoch 120/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6668 - val_loss: 1.6956\n",
      "Epoch 121/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6656 - val_loss: 1.6641\n",
      "Epoch 122/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6640 - val_loss: 1.6563\n",
      "Epoch 123/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6604 - val_loss: 1.6551\n",
      "Epoch 124/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6582 - val_loss: 1.6598\n",
      "Epoch 125/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6601 - val_loss: 1.6602\n",
      "Epoch 126/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6666 - val_loss: 1.6602\n",
      "Epoch 127/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6640 - val_loss: 1.6603\n",
      "Epoch 128/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6682 - val_loss: 1.6441\n",
      "Epoch 129/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6634 - val_loss: 1.6613\n",
      "Epoch 130/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6600 - val_loss: 1.6589\n",
      "Epoch 131/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.7097\n",
      "Epoch 132/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6520\n",
      "Epoch 133/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6588 - val_loss: 1.6563\n",
      "Epoch 134/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6614 - val_loss: 1.6602\n",
      "Epoch 135/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6606 - val_loss: 1.6598\n",
      "Epoch 136/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6669 - val_loss: 1.6449\n",
      "Epoch 137/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6629 - val_loss: 1.6562\n",
      "Epoch 138/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6600 - val_loss: 1.6665\n",
      "Epoch 139/300\n",
      "14033/14062 [============================>.] - ETA: 0s - loss: 1.6605\n",
      " Reduced learning rate to 0.00197531\n",
      "14062/14062 [==============================] - 17s - loss: 1.6606 - val_loss: 1.6626\n",
      "Epoch 140/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6573 - val_loss: 1.6602\n",
      "Epoch 141/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6579 - val_loss: 1.6562\n",
      "Epoch 142/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6611 - val_loss: 1.6512\n",
      "Epoch 143/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6593 - val_loss: 1.6578\n",
      "Epoch 144/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6594 - val_loss: 1.6590\n",
      "Epoch 145/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6595 - val_loss: 1.6565\n",
      "Epoch 146/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6527\n",
      "Epoch 147/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6539\n",
      "Epoch 148/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6590\n",
      "Epoch 149/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6591 - val_loss: 1.6538\n",
      "Epoch 150/300\n",
      "14041/14062 [============================>.] - ETA: 0s - loss: 1.6625\n",
      " Reduced learning rate to 0.00131687\n",
      "14062/14062 [==============================] - 17s - loss: 1.6625 - val_loss: 1.6565\n",
      "Epoch 151/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6551 - val_loss: 1.6488\n",
      "Epoch 152/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6576 - val_loss: 1.6551\n",
      "Epoch 153/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6582 - val_loss: 1.6562\n",
      "Epoch 154/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6522 - val_loss: 1.6613\n",
      "Epoch 155/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6554 - val_loss: 1.6605\n",
      "Epoch 156/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6592 - val_loss: 1.6562\n",
      "Epoch 157/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6580 - val_loss: 1.6472\n",
      "Epoch 158/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6634 - val_loss: 1.6628\n",
      "Epoch 159/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6529 - val_loss: 1.6497\n",
      "Epoch 160/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6563\n",
      "Epoch 161/300\n",
      "14046/14062 [============================>.] - ETA: 0s - loss: 1.6520\n",
      " Reduced learning rate to 0.000877915\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6472\n",
      "Epoch 162/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6565 - val_loss: 1.6527\n",
      "Epoch 163/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6555 - val_loss: 1.6559\n",
      "Epoch 164/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6563\n",
      "Epoch 165/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6524\n",
      "Epoch 166/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6543 - val_loss: 1.6538\n",
      "Epoch 167/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6579 - val_loss: 1.6604\n",
      "Epoch 168/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6517 - val_loss: 1.6523\n",
      "Epoch 169/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6555 - val_loss: 1.6590\n",
      "Epoch 170/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6604 - val_loss: 1.6574\n",
      "Epoch 171/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6583 - val_loss: 1.6481\n",
      "Epoch 172/300\n",
      "14031/14062 [============================>.] - ETA: 0s - loss: 1.6528\n",
      " Reduced learning rate to 0.000585277\n",
      "14062/14062 [==============================] - 17s - loss: 1.6528 - val_loss: 1.6550\n",
      "Epoch 173/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6572 - val_loss: 1.6551\n",
      "Epoch 174/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6499\n",
      "Epoch 175/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6525 - val_loss: 1.6539\n",
      "Epoch 176/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6544 - val_loss: 1.6511\n",
      "Epoch 177/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6548\n",
      "Epoch 178/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6510 - val_loss: 1.6574\n",
      "Epoch 179/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6544 - val_loss: 1.6509\n",
      "Epoch 180/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6460\n",
      "Epoch 181/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6544 - val_loss: 1.6461\n",
      "Epoch 182/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6569 - val_loss: 1.6523\n",
      "Epoch 183/300\n",
      "14054/14062 [============================>.] - ETA: 0s - loss: 1.6563\n",
      " Reduced learning rate to 0.000390184\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6460\n",
      "Epoch 184/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6537 - val_loss: 1.6527\n",
      "Epoch 185/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6473 - val_loss: 1.6578\n",
      "Epoch 186/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6521\n",
      "Epoch 187/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6562\n",
      "Epoch 188/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6505 - val_loss: 1.6512\n",
      "Epoch 189/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6488 - val_loss: 1.6527\n",
      "Epoch 190/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6491 - val_loss: 1.6577\n",
      "Epoch 191/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6514 - val_loss: 1.6496\n",
      "Epoch 192/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6514 - val_loss: 1.6566\n",
      "Epoch 193/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6529 - val_loss: 1.6524\n",
      "Epoch 194/300\n",
      "14021/14062 [============================>.] - ETA: 0s - loss: 1.6526\n",
      " Reduced learning rate to 0.000260123\n",
      "14062/14062 [==============================] - 17s - loss: 1.6526 - val_loss: 1.6562\n",
      "Epoch 195/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6477 - val_loss: 1.6509\n",
      "Epoch 196/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6489 - val_loss: 1.6524\n",
      "Epoch 197/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6544 - val_loss: 1.6524\n",
      "Epoch 198/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6550\n",
      "Epoch 199/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6460\n",
      "Epoch 200/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6563\n",
      "Epoch 201/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6496 - val_loss: 1.6527\n",
      "Epoch 202/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6507 - val_loss: 1.6523\n",
      "Epoch 203/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6512\n",
      "Epoch 204/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6512\n",
      "Epoch 205/300\n",
      "14025/14062 [============================>.] - ETA: 0s - loss: 1.6552\n",
      " Reduced learning rate to 0.000173415\n",
      "14062/14062 [==============================] - 17s - loss: 1.6551 - val_loss: 1.6445\n",
      "Epoch 206/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6520\n",
      "Epoch 207/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6550\n",
      "Epoch 208/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6486 - val_loss: 1.6575\n",
      "Epoch 209/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6581 - val_loss: 1.6535\n",
      "Epoch 210/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6503 - val_loss: 1.6523\n",
      "Epoch 211/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6444\n",
      "Epoch 212/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6551\n",
      "Epoch 213/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6533 - val_loss: 1.6527\n",
      "Epoch 214/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6508 - val_loss: 1.6485\n",
      "Epoch 215/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6506 - val_loss: 1.6559\n",
      "Epoch 216/300\n",
      "14045/14062 [============================>.] - ETA: 0s - loss: 1.6497\n",
      " Reduced learning rate to 0.00011561\n",
      "14062/14062 [==============================] - 17s - loss: 1.6496 - val_loss: 1.6535\n",
      "Epoch 217/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6505 - val_loss: 1.6539\n",
      "Epoch 218/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6527\n",
      "Epoch 219/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6470\n",
      "Epoch 220/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6512 - val_loss: 1.6526\n",
      "Epoch 221/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6523\n",
      "Epoch 222/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6508\n",
      "Epoch 223/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6508\n",
      "Epoch 224/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6504 - val_loss: 1.6483\n",
      "Epoch 225/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6496 - val_loss: 1.6548\n",
      "Epoch 226/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6517 - val_loss: 1.6605\n",
      "Epoch 227/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6514 - val_loss: 1.6433\n",
      "Epoch 228/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6537 - val_loss: 1.6460\n",
      "Epoch 229/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6472\n",
      "Epoch 230/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6469\n",
      "Epoch 231/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6507 - val_loss: 1.6520\n",
      "Epoch 232/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6496\n",
      "Epoch 233/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6503 - val_loss: 1.6419\n",
      "Epoch 234/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6506 - val_loss: 1.6496\n",
      "Epoch 235/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6532 - val_loss: 1.6497\n",
      "Epoch 236/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6493 - val_loss: 1.6551\n",
      "Epoch 237/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6475 - val_loss: 1.6442\n",
      "Epoch 238/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6515 - val_loss: 1.6602\n",
      "Epoch 239/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6460 - val_loss: 1.6460\n",
      "Epoch 240/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6495 - val_loss: 1.6587\n",
      "Epoch 241/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6575\n",
      "Epoch 242/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6551 - val_loss: 1.6563\n",
      "Epoch 243/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6554 - val_loss: 1.6551\n",
      "Epoch 244/300\n",
      "14026/14062 [============================>.] - ETA: 0s - loss: 1.6460\n",
      " Reduced learning rate to 7.70735e-05\n",
      "14062/14062 [==============================] - 17s - loss: 1.6460 - val_loss: 1.6535\n",
      "Epoch 1/300\n",
      "14062/14062 [==============================] - 18s - loss: 2.9609 - val_loss: 1.8128\n",
      "Epoch 2/300\n",
      "14062/14062 [==============================] - 17s - loss: 2.0334 - val_loss: 1.8527\n",
      "Epoch 3/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.9070 - val_loss: 2.0778\n",
      "Epoch 4/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8604 - val_loss: 1.7290\n",
      "Epoch 5/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8315 - val_loss: 1.9248\n",
      "Epoch 6/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8173 - val_loss: 1.7252\n",
      "Epoch 7/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8103 - val_loss: 1.7578\n",
      "Epoch 8/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8030 - val_loss: 2.0937\n",
      "Epoch 9/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7945 - val_loss: 1.7759\n",
      "Epoch 10/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7845 - val_loss: 1.7149\n",
      "Epoch 11/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7809 - val_loss: 1.7407\n",
      "Epoch 12/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7782 - val_loss: 1.7212\n",
      "Epoch 13/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7737 - val_loss: 1.7732\n",
      "Epoch 14/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7777 - val_loss: 1.7316\n",
      "Epoch 15/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7675 - val_loss: 1.7330\n",
      "Epoch 16/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7695 - val_loss: 1.7551\n",
      "Epoch 17/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7677 - val_loss: 1.8085\n",
      "Epoch 18/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7631 - val_loss: 1.8385\n",
      "Epoch 19/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7568 - val_loss: 1.7344\n",
      "Epoch 20/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7612 - val_loss: 1.7628\n",
      "Epoch 21/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14049/14062 [============================>.] - ETA: 0s - loss: 1.7622\n",
      " Reduced learning rate to 0.01\n",
      "14062/14062 [==============================] - 18s - loss: 1.7622 - val_loss: 1.7202\n",
      "Epoch 22/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7113 - val_loss: 1.6917\n",
      "Epoch 23/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7079 - val_loss: 1.6833\n",
      "Epoch 24/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7077 - val_loss: 1.6719\n",
      "Epoch 25/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7047 - val_loss: 1.6917\n",
      "Epoch 26/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7145 - val_loss: 1.6809\n",
      "Epoch 27/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7091 - val_loss: 1.7034\n",
      "Epoch 28/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7054 - val_loss: 1.6835\n",
      "Epoch 29/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7136 - val_loss: 1.6722\n",
      "Epoch 30/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7117 - val_loss: 1.6800\n",
      "Epoch 31/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7094 - val_loss: 1.6782\n",
      "Epoch 32/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7028 - val_loss: 1.7045\n",
      "Epoch 33/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7078 - val_loss: 1.6758\n",
      "Epoch 34/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7088 - val_loss: 1.7305\n",
      "Epoch 35/300\n",
      "14029/14062 [============================>.] - ETA: 0s - loss: 1.7040\n",
      " Reduced learning rate to 0.00666667\n",
      "14062/14062 [==============================] - 17s - loss: 1.7041 - val_loss: 1.7035\n",
      "Epoch 36/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6851 - val_loss: 1.6734\n",
      "Epoch 37/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6918 - val_loss: 1.6770\n",
      "Epoch 38/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6879 - val_loss: 1.6918\n",
      "Epoch 39/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6845 - val_loss: 1.6574\n",
      "Epoch 40/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6872 - val_loss: 1.7524\n",
      "Epoch 41/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6836 - val_loss: 1.7254\n",
      "Epoch 42/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6831 - val_loss: 1.6704\n",
      "Epoch 43/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6871 - val_loss: 1.6773\n",
      "Epoch 44/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6833 - val_loss: 1.6950\n",
      "Epoch 45/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6825 - val_loss: 1.6745\n",
      "Epoch 46/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6844 - val_loss: 1.6840\n",
      "Epoch 47/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6852 - val_loss: 1.6757\n",
      "Epoch 48/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6834 - val_loss: 1.6793\n",
      "Epoch 49/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6826 - val_loss: 1.6644\n",
      "Epoch 50/300\n",
      "14046/14062 [============================>.] - ETA: 0s - loss: 1.6855\n",
      " Reduced learning rate to 0.00444444\n",
      "14062/14062 [==============================] - 17s - loss: 1.6855 - val_loss: 1.7031\n",
      "Epoch 51/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6708 - val_loss: 1.6837\n",
      "Epoch 52/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6816 - val_loss: 1.6602\n",
      "Epoch 53/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6694 - val_loss: 1.6929\n",
      "Epoch 54/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6707 - val_loss: 1.6614\n",
      "Epoch 55/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6750 - val_loss: 1.6874\n",
      "Epoch 56/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6718 - val_loss: 1.6638\n",
      "Epoch 57/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6691 - val_loss: 1.6625\n",
      "Epoch 58/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6741 - val_loss: 1.6863\n",
      "Epoch 59/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6706 - val_loss: 1.6758\n",
      "Epoch 60/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6729 - val_loss: 1.6644\n",
      "Epoch 61/300\n",
      "14021/14062 [============================>.] - ETA: 0s - loss: 1.6703\n",
      " Reduced learning rate to 0.00296296\n",
      "14062/14062 [==============================] - 17s - loss: 1.6704 - val_loss: 1.6755\n",
      "Epoch 62/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6685 - val_loss: 1.6637\n",
      "Epoch 63/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6677 - val_loss: 1.6575\n",
      "Epoch 64/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6586 - val_loss: 1.6625\n",
      "Epoch 65/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6684 - val_loss: 1.6707\n",
      "Epoch 66/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6634 - val_loss: 1.6695\n",
      "Epoch 67/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6671 - val_loss: 1.6638\n",
      "Epoch 68/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6676 - val_loss: 1.6497\n",
      "Epoch 69/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6610 - val_loss: 1.6719\n",
      "Epoch 70/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6673 - val_loss: 1.6758\n",
      "Epoch 71/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6704 - val_loss: 1.6652\n",
      "Epoch 72/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6671 - val_loss: 1.6677\n",
      "Epoch 73/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6657 - val_loss: 1.6644\n",
      "Epoch 74/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6636 - val_loss: 1.6523\n",
      "Epoch 75/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6697 - val_loss: 1.6758\n",
      "Epoch 76/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6621 - val_loss: 1.6587\n",
      "Epoch 77/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6624 - val_loss: 1.6668\n",
      "Epoch 78/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6608 - val_loss: 1.6614\n",
      "Epoch 79/300\n",
      "14029/14062 [============================>.] - ETA: 0s - loss: 1.6662\n",
      " Reduced learning rate to 0.00197531\n",
      "14062/14062 [==============================] - 17s - loss: 1.6662 - val_loss: 1.6523\n",
      "Epoch 80/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6576 - val_loss: 1.6629\n",
      "Epoch 81/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6569 - val_loss: 1.6613\n",
      "Epoch 82/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6587 - val_loss: 1.6641\n",
      "Epoch 83/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6603 - val_loss: 1.6563\n",
      "Epoch 84/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6591 - val_loss: 1.6641\n",
      "Epoch 85/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6614 - val_loss: 1.6604\n",
      "Epoch 86/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6598\n",
      "Epoch 87/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6619 - val_loss: 1.6667\n",
      "Epoch 88/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6606 - val_loss: 1.6605\n",
      "Epoch 89/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6587 - val_loss: 1.6512\n",
      "Epoch 90/300\n",
      "14050/14062 [============================>.] - ETA: 0s - loss: 1.6605\n",
      " Reduced learning rate to 0.00131687\n",
      "14062/14062 [==============================] - 17s - loss: 1.6605 - val_loss: 1.6703\n",
      "Epoch 91/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6613 - val_loss: 1.6578\n",
      "Epoch 92/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.6562\n",
      "Epoch 93/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6551 - val_loss: 1.6590\n",
      "Epoch 94/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6559 - val_loss: 1.6559\n",
      "Epoch 95/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6557 - val_loss: 1.6605\n",
      "Epoch 96/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6545 - val_loss: 1.6614\n",
      "Epoch 97/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6596 - val_loss: 1.6469\n",
      "Epoch 98/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6590 - val_loss: 1.6481\n",
      "Epoch 99/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6614 - val_loss: 1.6523\n",
      "Epoch 100/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6546 - val_loss: 1.6605\n",
      "Epoch 101/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6582 - val_loss: 1.6616\n",
      "Epoch 102/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6567 - val_loss: 1.6574\n",
      "Epoch 103/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6588 - val_loss: 1.6796\n",
      "Epoch 104/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6575\n",
      "Epoch 105/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6584 - val_loss: 1.6587\n",
      "Epoch 106/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6583 - val_loss: 1.6520\n",
      "Epoch 107/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6563 - val_loss: 1.6637\n",
      "Epoch 108/300\n",
      "14044/14062 [============================>.] - ETA: 0s - loss: 1.6573\n",
      " Reduced learning rate to 0.000877915\n",
      "14062/14062 [==============================] - 17s - loss: 1.6574 - val_loss: 1.6538\n",
      "Epoch 109/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6469\n",
      "Epoch 110/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6619 - val_loss: 1.6550\n",
      "Epoch 111/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6533 - val_loss: 1.6574\n",
      "Epoch 112/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6602 - val_loss: 1.6586\n",
      "Epoch 113/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6538 - val_loss: 1.6548\n",
      "Epoch 114/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6601\n",
      "Epoch 115/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6603\n",
      "Epoch 116/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6586\n",
      "Epoch 117/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6592 - val_loss: 1.6539\n",
      "Epoch 118/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6488\n",
      "Epoch 119/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6574 - val_loss: 1.6470\n",
      "Epoch 120/300\n",
      "14021/14062 [============================>.] - ETA: 0s - loss: 1.6529\n",
      " Reduced learning rate to 0.000585277\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6562\n",
      "Epoch 121/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6550\n",
      "Epoch 122/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6559 - val_loss: 1.6550\n",
      "Epoch 123/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6585 - val_loss: 1.6578\n",
      "Epoch 124/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6602\n",
      "Epoch 125/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6600 - val_loss: 1.6562\n",
      "Epoch 126/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6559\n",
      "Epoch 127/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6593 - val_loss: 1.6602\n",
      "Epoch 128/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6563\n",
      "Epoch 129/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6509 - val_loss: 1.6562\n",
      "Epoch 130/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6529 - val_loss: 1.6683\n",
      "Epoch 131/300\n",
      "14036/14062 [============================>.] - ETA: 0s - loss: 1.6547\n",
      " Reduced learning rate to 0.000390184\n",
      "14062/14062 [==============================] - 17s - loss: 1.6545 - val_loss: 1.6586\n",
      "Epoch 132/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6526 - val_loss: 1.6522\n",
      "Epoch 133/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6556 - val_loss: 1.6538\n",
      "Epoch 134/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6551 - val_loss: 1.6472\n",
      "Epoch 135/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6558 - val_loss: 1.6538\n",
      "Epoch 136/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6548\n",
      "Epoch 137/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6590\n",
      "Epoch 138/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6523\n",
      "Epoch 139/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6533 - val_loss: 1.6535\n",
      "Epoch 140/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6523\n",
      "Epoch 141/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6563 - val_loss: 1.6523\n",
      "Epoch 142/300\n",
      "14039/14062 [============================>.] - ETA: 0s - loss: 1.6577\n",
      " Reduced learning rate to 0.000260123\n",
      "14062/14062 [==============================] - 17s - loss: 1.6576 - val_loss: 1.6535\n",
      "Epoch 143/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6513 - val_loss: 1.6527\n",
      "Epoch 144/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6561 - val_loss: 1.6548\n",
      "Epoch 145/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6602\n",
      "Epoch 146/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6575\n",
      "Epoch 147/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6505 - val_loss: 1.6547\n",
      "Epoch 148/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6562\n",
      "Epoch 149/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6536 - val_loss: 1.6547\n",
      "Epoch 150/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6587\n",
      "Epoch 151/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6565\n",
      "Epoch 152/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6545 - val_loss: 1.6562\n",
      "Epoch 153/300\n",
      "14060/14062 [============================>.] - ETA: 0s - loss: 1.6553\n",
      " Reduced learning rate to 0.000173415\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6499\n",
      "Epoch 154/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6473\n",
      "Epoch 155/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6461\n",
      "Epoch 156/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6469\n",
      "Epoch 157/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6524\n",
      "Epoch 158/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6481 - val_loss: 1.6473\n",
      "Epoch 159/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6507 - val_loss: 1.6562\n",
      "Epoch 160/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6497 - val_loss: 1.6614\n",
      "Epoch 161/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6488\n",
      "Epoch 162/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6516 - val_loss: 1.6523\n",
      "Epoch 163/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6558 - val_loss: 1.6524\n",
      "Epoch 164/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6580 - val_loss: 1.6535\n",
      "Epoch 165/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6578 - val_loss: 1.6590\n",
      "Epoch 166/300\n",
      "14026/14062 [============================>.] - ETA: 0s - loss: 1.6552\n",
      " Reduced learning rate to 0.00011561\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6520\n",
      "Epoch 167/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6538\n",
      "Epoch 168/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6566 - val_loss: 1.6508\n",
      "Epoch 169/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6520\n",
      "Epoch 170/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6524\n",
      "Epoch 171/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6498 - val_loss: 1.6485\n",
      "Epoch 172/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6472 - val_loss: 1.6538\n",
      "Epoch 173/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6532 - val_loss: 1.6602\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6524\n",
      "Epoch 175/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6522 - val_loss: 1.6512\n",
      "Epoch 176/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6518 - val_loss: 1.6586\n",
      "Epoch 177/300\n",
      "14045/14062 [============================>.] - ETA: 0s - loss: 1.6566\n",
      " Reduced learning rate to 7.70735e-05\n",
      "14062/14062 [==============================] - 17s - loss: 1.6567 - val_loss: 1.6512\n",
      "Epoch 1/300\n",
      "14062/14062 [==============================] - 19s - loss: 2.9580 - val_loss: 2.2100\n",
      "Epoch 2/300\n",
      "14062/14062 [==============================] - 17s - loss: 2.0246 - val_loss: 1.7812\n",
      "Epoch 3/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.9015 - val_loss: 1.7319\n",
      "Epoch 4/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8507 - val_loss: 1.7280\n",
      "Epoch 5/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8341 - val_loss: 1.7425\n",
      "Epoch 6/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8177 - val_loss: 1.7535\n",
      "Epoch 7/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.8023 - val_loss: 1.7265\n",
      "Epoch 8/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7981 - val_loss: 1.7723\n",
      "Epoch 9/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7899 - val_loss: 1.7614\n",
      "Epoch 10/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7833 - val_loss: 1.7046\n",
      "Epoch 11/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7842 - val_loss: 1.7043\n",
      "Epoch 12/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7770 - val_loss: 1.7254\n",
      "Epoch 13/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7713 - val_loss: 1.7188\n",
      "Epoch 14/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7693 - val_loss: 1.7798\n",
      "Epoch 15/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7718 - val_loss: 1.8753\n",
      "Epoch 16/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7641 - val_loss: 1.7475\n",
      "Epoch 17/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7660 - val_loss: 1.8490\n",
      "Epoch 18/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7628 - val_loss: 1.7188\n",
      "Epoch 19/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7599 - val_loss: 1.7187\n",
      "Epoch 20/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7604 - val_loss: 1.8385\n",
      "Epoch 21/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7586 - val_loss: 1.6824\n",
      "Epoch 22/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7555 - val_loss: 1.7095\n",
      "Epoch 23/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7541 - val_loss: 1.7982\n",
      "Epoch 24/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7527 - val_loss: 1.7460\n",
      "Epoch 25/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7520 - val_loss: 1.6939\n",
      "Epoch 26/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7491 - val_loss: 1.7151\n",
      "Epoch 27/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7556 - val_loss: 1.7525\n",
      "Epoch 28/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7524 - val_loss: 1.7866\n",
      "Epoch 29/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7469 - val_loss: 1.6874\n",
      "Epoch 30/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7441 - val_loss: 1.7554\n",
      "Epoch 31/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7440 - val_loss: 1.6978\n",
      "Epoch 32/300\n",
      "14029/14062 [============================>.] - ETA: 0s - loss: 1.7415\n",
      " Reduced learning rate to 0.01\n",
      "14062/14062 [==============================] - 18s - loss: 1.7415 - val_loss: 1.7574\n",
      "Epoch 33/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7033 - val_loss: 1.7070\n",
      "Epoch 34/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7016 - val_loss: 1.8256\n",
      "Epoch 35/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7009 - val_loss: 1.6668\n",
      "Epoch 36/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7036 - val_loss: 1.6911\n",
      "Epoch 37/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7022 - val_loss: 1.7006\n",
      "Epoch 38/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7040 - val_loss: 1.6770\n",
      "Epoch 39/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7029 - val_loss: 1.6812\n",
      "Epoch 40/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7038 - val_loss: 1.6796\n",
      "Epoch 41/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6974 - val_loss: 1.6957\n",
      "Epoch 42/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6985 - val_loss: 1.7386\n",
      "Epoch 43/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7013 - val_loss: 1.7355\n",
      "Epoch 44/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7041 - val_loss: 1.6915\n",
      "Epoch 45/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.7015 - val_loss: 1.6839\n",
      "Epoch 46/300\n",
      "14030/14062 [============================>.] - ETA: 0s - loss: 1.7036\n",
      " Reduced learning rate to 0.00666667\n",
      "14062/14062 [==============================] - 17s - loss: 1.7035 - val_loss: 1.7056\n",
      "Epoch 47/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6808 - val_loss: 1.7121\n",
      "Epoch 48/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6786 - val_loss: 1.6590\n",
      "Epoch 49/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6819 - val_loss: 1.6629\n",
      "Epoch 50/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6810 - val_loss: 1.6840\n",
      "Epoch 51/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6875 - val_loss: 1.6836\n",
      "Epoch 52/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6805 - val_loss: 1.6757\n",
      "Epoch 53/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6814 - val_loss: 1.6716\n",
      "Epoch 54/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6762 - val_loss: 1.6769\n",
      "Epoch 55/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6798 - val_loss: 1.6822\n",
      "Epoch 56/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6813 - val_loss: 1.6836\n",
      "Epoch 57/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6809 - val_loss: 1.6822\n",
      "Epoch 58/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6817 - val_loss: 1.6762\n",
      "Epoch 59/300\n",
      "14021/14062 [============================>.] - ETA: 0s - loss: 1.6808\n",
      " Reduced learning rate to 0.00444444\n",
      "14062/14062 [==============================] - 17s - loss: 1.6809 - val_loss: 1.6734\n",
      "Epoch 60/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6702 - val_loss: 1.6809\n",
      "Epoch 61/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6724 - val_loss: 1.6602\n",
      "Epoch 62/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6681 - val_loss: 1.6887\n",
      "Epoch 63/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6736 - val_loss: 1.6602\n",
      "Epoch 64/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6739 - val_loss: 1.6601\n",
      "Epoch 65/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6696 - val_loss: 1.6628\n",
      "Epoch 66/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6683 - val_loss: 1.6640\n",
      "Epoch 67/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6692 - val_loss: 1.6746\n",
      "Epoch 68/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6706 - val_loss: 1.6861\n",
      "Epoch 69/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6705 - val_loss: 1.6915\n",
      "Epoch 70/300\n",
      "14037/14062 [============================>.] - ETA: 0s - loss: 1.6701\n",
      " Reduced learning rate to 0.00296296\n",
      "14062/14062 [==============================] - 17s - loss: 1.6700 - val_loss: 1.6640\n",
      "Epoch 71/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6651 - val_loss: 1.6587\n",
      "Epoch 72/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6613 - val_loss: 1.6578\n",
      "Epoch 73/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6642 - val_loss: 1.6586\n",
      "Epoch 74/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6670 - val_loss: 1.6625\n",
      "Epoch 75/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 17s - loss: 1.6635 - val_loss: 1.6655\n",
      "Epoch 76/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6608 - val_loss: 1.6511\n",
      "Epoch 77/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6612 - val_loss: 1.6601\n",
      "Epoch 78/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6604 - val_loss: 1.6638\n",
      "Epoch 79/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6640 - val_loss: 1.6797\n",
      "Epoch 80/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6646 - val_loss: 1.6782\n",
      "Epoch 81/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6616 - val_loss: 1.6602\n",
      "Epoch 82/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6661 - val_loss: 1.6655\n",
      "Epoch 83/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6647 - val_loss: 1.6641\n",
      "Epoch 84/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6623 - val_loss: 1.6577\n",
      "Epoch 85/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6650 - val_loss: 1.6563\n",
      "Epoch 86/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6651 - val_loss: 1.6754\n",
      "Epoch 87/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6654 - val_loss: 1.6497\n",
      "Epoch 88/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6658 - val_loss: 1.6759\n",
      "Epoch 89/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6683 - val_loss: 1.6527\n",
      "Epoch 90/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6595 - val_loss: 1.6655\n",
      "Epoch 91/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6658 - val_loss: 1.6602\n",
      "Epoch 92/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6634 - val_loss: 1.6797\n",
      "Epoch 93/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6636 - val_loss: 1.6638\n",
      "Epoch 94/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6635 - val_loss: 1.6562\n",
      "Epoch 95/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6649 - val_loss: 1.6574\n",
      "Epoch 96/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6641 - val_loss: 1.6679\n",
      "Epoch 97/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6649 - val_loss: 1.6628\n",
      "Epoch 98/300\n",
      "14053/14062 [============================>.] - ETA: 0s - loss: 1.6621\n",
      " Reduced learning rate to 0.00197531\n",
      "14062/14062 [==============================] - 17s - loss: 1.6622 - val_loss: 1.6706\n",
      "Epoch 99/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6571 - val_loss: 1.6512\n",
      "Epoch 100/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6594 - val_loss: 1.6589\n",
      "Epoch 101/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6583 - val_loss: 1.6460\n",
      "Epoch 102/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6551\n",
      "Epoch 103/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6597 - val_loss: 1.6560\n",
      "Epoch 104/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6592 - val_loss: 1.6472\n",
      "Epoch 105/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6576 - val_loss: 1.6616\n",
      "Epoch 106/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6609 - val_loss: 1.6704\n",
      "Epoch 107/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6576 - val_loss: 1.6599\n",
      "Epoch 108/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6603 - val_loss: 1.6520\n",
      "Epoch 109/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6588 - val_loss: 1.6562\n",
      "Epoch 110/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6623 - val_loss: 1.6617\n",
      "Epoch 111/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6580 - val_loss: 1.6500\n",
      "Epoch 112/300\n",
      "14037/14062 [============================>.] - ETA: 0s - loss: 1.6557\n",
      " Reduced learning rate to 0.00131687\n",
      "14062/14062 [==============================] - 17s - loss: 1.6557 - val_loss: 1.6548\n",
      "Epoch 113/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6575 - val_loss: 1.6550\n",
      "Epoch 114/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6563\n",
      "Epoch 115/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6582 - val_loss: 1.6590\n",
      "Epoch 116/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6556 - val_loss: 1.6547\n",
      "Epoch 117/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6562 - val_loss: 1.6587\n",
      "Epoch 118/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6555 - val_loss: 1.6574\n",
      "Epoch 119/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6564 - val_loss: 1.6605\n",
      "Epoch 120/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6565 - val_loss: 1.6508\n",
      "Epoch 121/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6589 - val_loss: 1.6470\n",
      "Epoch 122/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6628 - val_loss: 1.6520\n",
      "Epoch 123/300\n",
      "14023/14062 [============================>.] - ETA: 0s - loss: 1.6575\n",
      " Reduced learning rate to 0.000877915\n",
      "14062/14062 [==============================] - 17s - loss: 1.6574 - val_loss: 1.6563\n",
      "Epoch 124/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6555 - val_loss: 1.6626\n",
      "Epoch 125/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6560\n",
      "Epoch 126/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6580 - val_loss: 1.6679\n",
      "Epoch 127/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6536 - val_loss: 1.6524\n",
      "Epoch 128/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6546 - val_loss: 1.6586\n",
      "Epoch 129/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6553 - val_loss: 1.6469\n",
      "Epoch 130/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6574 - val_loss: 1.6644\n",
      "Epoch 131/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6559\n",
      "Epoch 132/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6520 - val_loss: 1.6599\n",
      "Epoch 133/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6557 - val_loss: 1.6566\n",
      "Epoch 134/300\n",
      "14050/14062 [============================>.] - ETA: 0s - loss: 1.6556\n",
      " Reduced learning rate to 0.000585277\n",
      "14062/14062 [==============================] - 17s - loss: 1.6556 - val_loss: 1.6527\n",
      "Epoch 135/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6519 - val_loss: 1.6562\n",
      "Epoch 136/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6548\n",
      "Epoch 137/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6483 - val_loss: 1.6445\n",
      "Epoch 138/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6548 - val_loss: 1.6575\n",
      "Epoch 139/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6517 - val_loss: 1.6524\n",
      "Epoch 140/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6575\n",
      "Epoch 141/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6587\n",
      "Epoch 142/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6532 - val_loss: 1.6500\n",
      "Epoch 143/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6546 - val_loss: 1.6488\n",
      "Epoch 144/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6554 - val_loss: 1.6598\n",
      "Epoch 145/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6587\n",
      "Epoch 146/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6570 - val_loss: 1.6485\n",
      "Epoch 147/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6553 - val_loss: 1.6485\n",
      "Epoch 148/300\n",
      "14038/14062 [============================>.] - ETA: 0s - loss: 1.6564\n",
      " Reduced learning rate to 0.000390184\n",
      "14062/14062 [==============================] - 17s - loss: 1.6565 - val_loss: 1.6550\n",
      "Epoch 149/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6550 - val_loss: 1.6605\n",
      "Epoch 150/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6511 - val_loss: 1.6512\n",
      "Epoch 151/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6508\n",
      "Epoch 152/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14062/14062 [==============================] - 18s - loss: 1.6548 - val_loss: 1.6520\n",
      "Epoch 153/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6594 - val_loss: 1.6563\n",
      "Epoch 154/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6504 - val_loss: 1.6577\n",
      "Epoch 155/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6523 - val_loss: 1.6562\n",
      "Epoch 156/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6552 - val_loss: 1.6527\n",
      "Epoch 157/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6508 - val_loss: 1.6590\n",
      "Epoch 158/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6562\n",
      "Epoch 159/300\n",
      "14040/14062 [============================>.] - ETA: 0s - loss: 1.6539\n",
      " Reduced learning rate to 0.000260123\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6605\n",
      "Epoch 160/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6527 - val_loss: 1.6512\n",
      "Epoch 161/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6528 - val_loss: 1.6488\n",
      "Epoch 162/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6540 - val_loss: 1.6444\n",
      "Epoch 163/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6555 - val_loss: 1.6524\n",
      "Epoch 164/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6562\n",
      "Epoch 165/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6500 - val_loss: 1.6652\n",
      "Epoch 166/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6566 - val_loss: 1.6508\n",
      "Epoch 167/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6571 - val_loss: 1.6587\n",
      "Epoch 168/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6500\n",
      "Epoch 169/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6503 - val_loss: 1.6488\n",
      "Epoch 170/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6531 - val_loss: 1.6508\n",
      "Epoch 171/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6536\n",
      "Epoch 172/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6509 - val_loss: 1.6520\n",
      "Epoch 173/300\n",
      "14031/14062 [============================>.] - ETA: 0s - loss: 1.6499\n",
      " Reduced learning rate to 0.000173415\n",
      "14062/14062 [==============================] - 17s - loss: 1.6498 - val_loss: 1.6562\n",
      "Epoch 174/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6477 - val_loss: 1.6602\n",
      "Epoch 175/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6578\n",
      "Epoch 176/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6541 - val_loss: 1.6461\n",
      "Epoch 177/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6514 - val_loss: 1.6587\n",
      "Epoch 178/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6539 - val_loss: 1.6551\n",
      "Epoch 179/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6528 - val_loss: 1.6509\n",
      "Epoch 180/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6484 - val_loss: 1.6548\n",
      "Epoch 181/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6530 - val_loss: 1.6469\n",
      "Epoch 182/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6481 - val_loss: 1.6511\n",
      "Epoch 183/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6560 - val_loss: 1.6589\n",
      "Epoch 184/300\n",
      "14060/14062 [============================>.] - ETA: 0s - loss: 1.6566\n",
      " Reduced learning rate to 0.00011561\n",
      "14062/14062 [==============================] - 17s - loss: 1.6566 - val_loss: 1.6590\n",
      "Epoch 185/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6535 - val_loss: 1.6485\n",
      "Epoch 186/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6547 - val_loss: 1.6566\n",
      "Epoch 187/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6549 - val_loss: 1.6473\n",
      "Epoch 188/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6542 - val_loss: 1.6473\n",
      "Epoch 189/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6481\n",
      "Epoch 190/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6503 - val_loss: 1.6629\n",
      "Epoch 191/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6525 - val_loss: 1.6508\n",
      "Epoch 192/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6548 - val_loss: 1.6461\n",
      "Epoch 193/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6555 - val_loss: 1.6535\n",
      "Epoch 194/300\n",
      "14062/14062 [==============================] - 17s - loss: 1.6525 - val_loss: 1.6616\n",
      "Epoch 195/300\n",
      "14043/14062 [============================>.] - ETA: 0s - loss: 1.6535\n",
      " Reduced learning rate to 7.70735e-05\n",
      "14062/14062 [==============================] - 17s - loss: 1.6534 - val_loss: 1.6499\n"
     ]
    }
   ],
   "source": [
    "n_train = [5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "ensemble_size = 5 \n",
    "for n in n_train:\n",
    "    qrnn = QRNN(5, quantiles, 3, 128, ensemble_size = ensemble_size)\n",
    "    qrnn.fit(x_train[:n,:], y_train[:n], 1.0,\n",
    "             initial_learning_rate = 0.01,\n",
    "             learning_rate_decay = 1.5,\n",
    "             convergence_epochs = 10,\n",
    "             batch_size = 64,\n",
    "             maximum_epochs = 300,\n",
    "             learning_rate_minimum = 1e-4)\n",
    "    qrnn.save(\"models/qrnn_\"+ str(ensemble_size) + \"_\" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10  Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qrnn.model.save(\"qrnn_5_1000000_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/x_train_10.npy\")\n",
    "y_train = np.load(\"data/y_train_10.npy\")\n",
    "quantiles = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = [5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "for n in n_train:\n",
    "    qrnn = QRNN(10, quantiles, 3, 256)\n",
    "    qrnn.fit(x_train[:n,:], y_train[:n], 1.0)\n",
    "    qrnn.save(\"qrnn_\"+ str(qrnn.input_dim) + \"_\" + str(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

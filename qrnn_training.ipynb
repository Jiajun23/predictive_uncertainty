{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRNN Training\n",
    "\n",
    "This notebook trains several *quantile regression neural networks* (QRNNs) on differently sized training sets with different numbers of channels (5 and 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n",
      "env: OMP_NUM_THREADS=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "%env OMP_NUM_THREADS=4\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib_settings\n",
    "from typhon.retrieval.qrnn import QRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/x_train_5.npy\")\n",
    "y_train = np.load(\"data/y_train_5.npy\")\n",
    "quantiles = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 2s - loss: 97.3270 - val_loss: 96.4737\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s - loss: 93.4595 - val_loss: 94.7275\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s - loss: 92.3936 - val_loss: 91.9290\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s - loss: 90.5806 - val_loss: 86.9294\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s - loss: 81.5845 - val_loss: 76.8634\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s - loss: 66.9938 - val_loss: 56.5729\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s - loss: 43.3441 - val_loss: 34.1743\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s - loss: 25.6421 - val_loss: 22.6589\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s - loss: 18.3215 - val_loss: 16.8130\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s - loss: 14.5171 - val_loss: 13.1582\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s - loss: 11.5440 - val_loss: 10.9545\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s - loss: 9.2987 - val_loss: 9.4595\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s - loss: 8.0863 - val_loss: 8.3263\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s - loss: 7.3313 - val_loss: 7.7749\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s - loss: 6.9135 - val_loss: 7.1600\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s - loss: 6.3429 - val_loss: 6.7618\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s - loss: 6.7126 - val_loss: 6.5319\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s - loss: 5.6350 - val_loss: 6.2136\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s - loss: 5.4470 - val_loss: 5.9536\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s - loss: 5.5169 - val_loss: 5.8516\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s - loss: 5.0271 - val_loss: 5.4440\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s - loss: 4.7632 - val_loss: 5.4300\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s - loss: 4.5598 - val_loss: 5.3654\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s - loss: 4.9872 - val_loss: 5.0306\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s - loss: 4.2194 - val_loss: 4.9684\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s - loss: 4.1384 - val_loss: 4.7556\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s - loss: 4.4799 - val_loss: 4.8460\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s - loss: 4.1718 - val_loss: 4.7130\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s - loss: 4.2929 - val_loss: 4.5867\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s - loss: 4.0007 - val_loss: 4.5009\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s - loss: 3.8111 - val_loss: 4.3528\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s - loss: 3.8971 - val_loss: 4.1130\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s - loss: 3.6373 - val_loss: 4.1560\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s - loss: 3.6864 - val_loss: 4.2021\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s - loss: 3.9464 - val_loss: 4.1796\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s - loss: 4.1295 - val_loss: 4.0869\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s - loss: 3.6805 - val_loss: 4.2007\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s - loss: 3.6555 - val_loss: 4.1570\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s - loss: 3.7744 - val_loss: 3.9161\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s - loss: 3.6757 - val_loss: 4.0859\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s - loss: 3.7989 - val_loss: 3.8268\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s - loss: 3.4353 - val_loss: 3.8445\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s - loss: 3.9385 - val_loss: 4.2588\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s - loss: 3.6616 - val_loss: 3.7973\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s - loss: 3.4720 - val_loss: 4.0185\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s - loss: 3.4342 - val_loss: 3.8647\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s - loss: 3.5936 - val_loss: 3.9594\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s - loss: 3.5231 - val_loss: 3.7923\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s - loss: 3.4742 - val_loss: 3.9447\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s - loss: 3.7919 - val_loss: 3.7731\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s - loss: 3.6006 - val_loss: 3.8376\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s - loss: 3.6390 - val_loss: 3.8405\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s - loss: 3.6569 - val_loss: 3.5435\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s - loss: 3.9223 - val_loss: 3.5194\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s - loss: 3.4027 - val_loss: 4.0390\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s - loss: 3.6526 - val_loss: 4.0269\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s - loss: 3.5876 - val_loss: 3.8993\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s - loss: 3.4271 - val_loss: 3.5125\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s - loss: 3.2169 - val_loss: 3.6546\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s - loss: 3.4280 - val_loss: 3.8975\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s - loss: 3.6330 - val_loss: 3.7437\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s - loss: 3.4864 - val_loss: 3.5004\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s - loss: 3.4188 - val_loss: 3.6378\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s - loss: 3.8389 - val_loss: 3.7327\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s - loss: 3.3823 - val_loss: 4.1769\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s - loss: 3.9534 - val_loss: 3.8386\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s - loss: 3.2927 - val_loss: 3.6243\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s - loss: 3.3367 - val_loss: 3.4914\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s - loss: 3.3663 - val_loss: 3.8321\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s - loss: 3.2054 - val_loss: 4.0455\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s - loss: 3.7062 - val_loss: 3.7791\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s - loss: 3.3191 - val_loss: 3.5760\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s - loss: 3.5423 - val_loss: 3.6126\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s - loss: 3.8448 - val_loss: 3.8965\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s - loss: 3.7032 - val_loss: 3.1466\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s - loss: 3.5785 - val_loss: 3.7372\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s - loss: 3.6069 - val_loss: 3.8435\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s - loss: 3.5756 - val_loss: 3.4972\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s - loss: 3.5581 - val_loss: 3.8444\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s - loss: 3.3891 - val_loss: 3.5292\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s - loss: 3.9961 - val_loss: 3.2136\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s - loss: 3.5913 - val_loss: 3.2949\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s - loss: 3.6023 - val_loss: 3.3849\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s - loss: 3.5106 - val_loss: 3.8967\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s - loss: 3.6938 - val_loss: 3.7867\n",
      "Epoch 86/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.3534\n",
      " Reduced learning rate to 0.01\n",
      "8/8 [==============================] - 1s - loss: 3.3467 - val_loss: 3.8380\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s - loss: 2.8008 - val_loss: 2.7098\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s - loss: 2.6783 - val_loss: 2.6499\n",
      "Epoch 89/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4099\n",
      " Reduced learning rate to 0.005\n",
      "8/8 [==============================] - 0s - loss: 2.4185 - val_loss: 2.7039\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7188\n",
      " Reduced learning rate to 0.0025\n",
      "8/8 [==============================] - 0s - loss: 2.9558 - val_loss: 2.7941\n",
      "Epoch 91/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7686\n",
      " Reduced learning rate to 0.00125\n",
      "8/8 [==============================] - 0s - loss: 2.5197 - val_loss: 2.7995\n",
      "Epoch 92/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4188\n",
      " Reduced learning rate to 0.000625\n",
      "8/8 [==============================] - 0s - loss: 2.5298 - val_loss: 2.7465\n",
      "Epoch 93/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5962\n",
      " Reduced learning rate to 0.0003125\n",
      "8/8 [==============================] - 0s - loss: 2.3300 - val_loss: 2.7247\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s - loss: 2.7489 - val_loss: 2.6498\n",
      "Epoch 95/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1799\n",
      " Reduced learning rate to 0.00015625\n",
      "8/8 [==============================] - 0s - loss: 2.4536 - val_loss: 2.6849\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s - loss: 2.7575 - val_loss: 2.6342\n",
      "Epoch 97/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.2775\n",
      " Reduced learning rate to 7.8125e-05\n",
      "8/8 [==============================] - 0s - loss: 2.2604 - val_loss: 2.7121\n",
      "Epoch 98/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.1355\n",
      " Reduced learning rate to 3.90625e-05\n",
      "8/8 [==============================] - 0s - loss: 2.4581 - val_loss: 2.8137\n",
      "Epoch 99/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7848\n",
      " Reduced learning rate to 1.95312e-05\n",
      "8/8 [==============================] - 0s - loss: 2.5436 - val_loss: 2.8567\n",
      "Epoch 100/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.4768\n",
      " Reduced learning rate to 9.76562e-06\n",
      "8/8 [==============================] - 0s - loss: 2.5932 - val_loss: 2.8370\n",
      "Epoch 101/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5766\n",
      " Reduced learning rate to 4.88281e-06\n",
      "8/8 [==============================] - 0s - loss: 2.3462 - val_loss: 2.8138\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s - loss: 2.4967 - val_loss: 2.5971\n",
      "Epoch 103/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.4609\n",
      " Reduced learning rate to 2.44141e-06\n",
      "8/8 [==============================] - 0s - loss: 2.6649 - val_loss: 2.7873\n",
      "Epoch 104/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.0614\n",
      " Reduced learning rate to 1.2207e-06\n",
      "8/8 [==============================] - 0s - loss: 2.6977 - val_loss: 2.8005\n",
      "Epoch 105/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3107\n",
      " Reduced learning rate to 6.10352e-07\n",
      "8/8 [==============================] - 0s - loss: 2.6793 - val_loss: 2.7364\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s - loss: 97.1289 - val_loss: 96.3310\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s - loss: 94.7512 - val_loss: 94.2985\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s - loss: 91.7571 - val_loss: 91.0888\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s - loss: 87.8758 - val_loss: 85.3365\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s - loss: 76.1325 - val_loss: 74.5380\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s - loss: 65.8554 - val_loss: 53.3073\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s - loss: 39.6650 - val_loss: 29.0056\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s - loss: 21.7138 - val_loss: 19.0222\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s - loss: 15.4047 - val_loss: 14.4495\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s - loss: 12.3069 - val_loss: 11.6312\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s - loss: 10.1767 - val_loss: 10.1949\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s - loss: 8.7248 - val_loss: 8.8391\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s - loss: 7.7244 - val_loss: 7.8572\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s - loss: 7.2810 - val_loss: 7.3060\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s - loss: 6.0210 - val_loss: 6.8865\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s - loss: 5.7120 - val_loss: 6.6553\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s - loss: 6.1955 - val_loss: 6.2753\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s - loss: 5.4383 - val_loss: 6.0265\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s - loss: 5.9962 - val_loss: 5.7469\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s - loss: 5.3105 - val_loss: 5.6850\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s - loss: 5.0726 - val_loss: 5.5881\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s - loss: 4.7433 - val_loss: 5.1996\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s - loss: 4.8897 - val_loss: 5.3028\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s - loss: 4.6013 - val_loss: 5.0522\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s - loss: 4.0496 - val_loss: 4.8834\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s - loss: 4.4163 - val_loss: 4.5682\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s - loss: 4.0705 - val_loss: 4.6216\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s - loss: 3.8428 - val_loss: 4.5116\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s - loss: 4.4979 - val_loss: 4.5500\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s - loss: 4.0493 - val_loss: 4.4613\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s - loss: 3.9062 - val_loss: 4.2940\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s - loss: 3.9006 - val_loss: 4.3469\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s - loss: 3.7930 - val_loss: 4.3289\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s - loss: 4.4164 - val_loss: 4.3716\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s - loss: 3.5739 - val_loss: 4.0713\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s - loss: 3.1641 - val_loss: 4.1264\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s - loss: 3.9614 - val_loss: 4.1662\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s - loss: 3.8059 - val_loss: 4.0987\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s - loss: 3.5487 - val_loss: 3.9685\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s - loss: 3.4746 - val_loss: 3.7546\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s - loss: 3.5596 - val_loss: 4.0438\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s - loss: 3.5819 - val_loss: 4.0721\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s - loss: 3.7595 - val_loss: 3.8381\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s - loss: 3.5130 - val_loss: 4.1418\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s - loss: 3.3293 - val_loss: 3.8849\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s - loss: 3.7810 - val_loss: 4.0224\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s - loss: 4.1851 - val_loss: 4.0704\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s - loss: 3.4885 - val_loss: 3.5681\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s - loss: 3.4701 - val_loss: 4.0834\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s - loss: 3.8251 - val_loss: 4.1107\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s - loss: 3.5883 - val_loss: 3.6976\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s - loss: 3.5425 - val_loss: 3.8878\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s - loss: 3.4042 - val_loss: 3.8605\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s - loss: 3.3221 - val_loss: 3.6652\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s - loss: 3.6286 - val_loss: 3.8564\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s - loss: 3.5419 - val_loss: 4.0045\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s - loss: 3.9341 - val_loss: 3.7393\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s - loss: 3.5606 - val_loss: 3.6963\n",
      "Epoch 59/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.4229\n",
      " Reduced learning rate to 0.01\n",
      "8/8 [==============================] - 1s - loss: 3.0844 - val_loss: 3.9851\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s - loss: 3.5082 - val_loss: 3.1682\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 [==>...........................] - ETA: 0s - loss: 3.3676\n",
      " Reduced learning rate to 0.005\n",
      "8/8 [==============================] - 0s - loss: 2.8855 - val_loss: 3.2638\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s - loss: 2.9273 - val_loss: 3.0827\n",
      "Epoch 63/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7322\n",
      " Reduced learning rate to 0.0025\n",
      "8/8 [==============================] - 0s - loss: 2.8723 - val_loss: 3.2135\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s - loss: 2.7785 - val_loss: 3.0320\n",
      "Epoch 65/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.3436\n",
      " Reduced learning rate to 0.00125\n",
      "8/8 [==============================] - 0s - loss: 3.0111 - val_loss: 3.0730\n",
      "Epoch 66/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4455\n",
      " Reduced learning rate to 0.000625\n",
      "8/8 [==============================] - 0s - loss: 2.5618 - val_loss: 3.1429\n",
      "Epoch 67/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.2781\n",
      " Reduced learning rate to 0.0003125\n",
      "8/8 [==============================] - 0s - loss: 2.7784 - val_loss: 3.2098\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s - loss: 2.9232 - val_loss: 3.0158\n",
      "Epoch 69/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5806\n",
      " Reduced learning rate to 0.00015625\n",
      "8/8 [==============================] - 0s - loss: 3.0162 - val_loss: 3.1824\n",
      "Epoch 70/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.6253\n",
      " Reduced learning rate to 7.8125e-05\n",
      "8/8 [==============================] - 0s - loss: 2.9847 - val_loss: 3.2210\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s - loss: 3.0172 - val_loss: 2.9681\n",
      "Epoch 72/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.0837\n",
      " Reduced learning rate to 3.90625e-05\n",
      "8/8 [==============================] - 0s - loss: 2.7602 - val_loss: 3.1992\n",
      "Epoch 73/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5586\n",
      " Reduced learning rate to 1.95312e-05\n",
      "8/8 [==============================] - 0s - loss: 2.6846 - val_loss: 3.0951\n",
      "Epoch 74/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.8989\n",
      " Reduced learning rate to 9.76562e-06\n",
      "8/8 [==============================] - 0s - loss: 2.9204 - val_loss: 3.1033\n",
      "Epoch 75/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4283\n",
      " Reduced learning rate to 4.88281e-06\n",
      "8/8 [==============================] - 0s - loss: 2.7530 - val_loss: 3.0933\n",
      "Epoch 76/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.2217\n",
      " Reduced learning rate to 2.44141e-06\n",
      "8/8 [==============================] - 0s - loss: 2.9826 - val_loss: 3.2698\n",
      "Epoch 77/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.9812\n",
      " Reduced learning rate to 1.2207e-06\n",
      "8/8 [==============================] - 0s - loss: 2.6844 - val_loss: 3.1283\n",
      "Epoch 78/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.9437\n",
      " Reduced learning rate to 6.10352e-07\n",
      "8/8 [==============================] - 0s - loss: 2.5982 - val_loss: 3.1583\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s - loss: 93.9404 - val_loss: 96.5010\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s - loss: 92.2222 - val_loss: 94.7477\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s - loss: 91.9367 - val_loss: 92.0120\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s - loss: 86.7858 - val_loss: 87.1891\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s - loss: 83.7078 - val_loss: 77.7748\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s - loss: 66.3118 - val_loss: 57.7630\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s - loss: 42.0630 - val_loss: 29.4873\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s - loss: 21.7431 - val_loss: 18.6506\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s - loss: 16.2015 - val_loss: 14.4867\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s - loss: 12.6678 - val_loss: 11.8750\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s - loss: 10.4974 - val_loss: 10.1295\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s - loss: 9.1258 - val_loss: 9.1501\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s - loss: 8.2843 - val_loss: 8.1666\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s - loss: 6.9457 - val_loss: 7.6982\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s - loss: 6.7812 - val_loss: 7.1307\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s - loss: 6.4992 - val_loss: 6.7638\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s - loss: 5.6889 - val_loss: 6.4283\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s - loss: 5.8586 - val_loss: 6.2101\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s - loss: 5.2565 - val_loss: 6.0370\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s - loss: 4.9991 - val_loss: 5.7784\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s - loss: 5.4396 - val_loss: 5.7087\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s - loss: 5.0251 - val_loss: 5.4610\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s - loss: 5.1066 - val_loss: 5.4285\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s - loss: 4.8647 - val_loss: 5.1406\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s - loss: 5.0071 - val_loss: 5.1596\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s - loss: 4.7166 - val_loss: 4.7678\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s - loss: 4.7223 - val_loss: 4.8626\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s - loss: 4.3582 - val_loss: 4.7249\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s - loss: 4.2737 - val_loss: 4.7387\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s - loss: 4.1655 - val_loss: 4.5559\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s - loss: 3.8813 - val_loss: 4.5873\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s - loss: 3.5527 - val_loss: 4.5828\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s - loss: 4.0142 - val_loss: 4.3702\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s - loss: 3.8329 - val_loss: 4.4687\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s - loss: 4.1352 - val_loss: 4.4503\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s - loss: 4.0169 - val_loss: 4.3598\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s - loss: 4.1829 - val_loss: 4.1659\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s - loss: 3.9591 - val_loss: 4.4707\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s - loss: 3.5612 - val_loss: 4.1578\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s - loss: 3.5734 - val_loss: 4.3356\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s - loss: 3.8412 - val_loss: 4.0752\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s - loss: 3.3772 - val_loss: 4.0755\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s - loss: 3.4936 - val_loss: 4.0295\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s - loss: 3.6606 - val_loss: 4.1612\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s - loss: 3.5098 - val_loss: 4.0016\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s - loss: 3.8417 - val_loss: 3.9710\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s - loss: 3.5726 - val_loss: 3.9152\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s - loss: 3.0423 - val_loss: 4.0992\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s - loss: 3.5300 - val_loss: 3.8264\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s - loss: 4.1178 - val_loss: 3.7560\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s - loss: 3.3409 - val_loss: 3.7252\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s - loss: 3.5174 - val_loss: 3.8351\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s - loss: 3.4086 - val_loss: 3.6013\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s - loss: 3.2076 - val_loss: 3.7683\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s - loss: 3.3485 - val_loss: 3.6708\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s - loss: 3.0241 - val_loss: 3.8255\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s - loss: 3.6674 - val_loss: 3.9451\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s - loss: 3.5735 - val_loss: 3.6483\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s - loss: 3.6726 - val_loss: 3.6592\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s - loss: 3.8529 - val_loss: 3.7041\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s - loss: 3.1612 - val_loss: 3.5832\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s - loss: 4.1687 - val_loss: 3.4485\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s - loss: 3.3735 - val_loss: 4.0826\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s - loss: 3.3054 - val_loss: 3.8513\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s - loss: 3.7811 - val_loss: 3.7729\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s - loss: 3.4039 - val_loss: 3.6157\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s - loss: 3.5054 - val_loss: 3.4329\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s - loss: 3.5228 - val_loss: 3.8143\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s - loss: 4.0499 - val_loss: 3.4461\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s - loss: 3.5827 - val_loss: 3.9049\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s - loss: 3.8144 - val_loss: 4.0642\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s - loss: 3.4021 - val_loss: 3.4998\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s - loss: 3.5135 - val_loss: 3.8051\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s - loss: 3.3611 - val_loss: 3.6284\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s - loss: 3.9456 - val_loss: 3.5678\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s - loss: 3.2806 - val_loss: 3.7686\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s - loss: 3.6733 - val_loss: 3.6451\n",
      "Epoch 78/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.9428\n",
      " Reduced learning rate to 0.01\n",
      "8/8 [==============================] - 1s - loss: 3.3675 - val_loss: 3.6747\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s - loss: 2.6047 - val_loss: 2.8956\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s - loss: 2.6549 - val_loss: 2.8766\n",
      "Epoch 81/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1646\n",
      " Reduced learning rate to 0.005\n",
      "8/8 [==============================] - 0s - loss: 2.6373 - val_loss: 2.9296\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s - loss: 2.6081 - val_loss: 2.7815\n",
      "Epoch 83/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5065\n",
      " Reduced learning rate to 0.0025\n",
      "8/8 [==============================] - 0s - loss: 2.4599 - val_loss: 2.8126\n",
      "Epoch 84/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7654\n",
      " Reduced learning rate to 0.00125\n",
      "8/8 [==============================] - 0s - loss: 2.5797 - val_loss: 2.8726\n",
      "Epoch 85/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.8764\n",
      " Reduced learning rate to 0.000625\n",
      "8/8 [==============================] - 0s - loss: 2.8960 - val_loss: 2.8970\n",
      "Epoch 86/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1250\n",
      " Reduced learning rate to 0.0003125\n",
      "8/8 [==============================] - 0s - loss: 2.4526 - val_loss: 2.8628\n",
      "Epoch 87/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.1706\n",
      " Reduced learning rate to 0.00015625\n",
      "8/8 [==============================] - 0s - loss: 2.8213 - val_loss: 2.8482\n",
      "Epoch 88/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3592\n",
      " Reduced learning rate to 7.8125e-05\n",
      "8/8 [==============================] - 0s - loss: 2.3842 - val_loss: 2.9176\n",
      "Epoch 89/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1553\n",
      " Reduced learning rate to 3.90625e-05\n",
      "8/8 [==============================] - 0s - loss: 2.6775 - val_loss: 2.9415\n",
      "Epoch 90/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7955\n",
      " Reduced learning rate to 1.95312e-05\n",
      "8/8 [==============================] - 0s - loss: 2.7405 - val_loss: 3.0627\n",
      "Epoch 91/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4404\n",
      " Reduced learning rate to 9.76562e-06\n",
      "8/8 [==============================] - 0s - loss: 2.5903 - val_loss: 2.8858\n",
      "Epoch 92/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.9375\n",
      " Reduced learning rate to 4.88281e-06\n",
      "8/8 [==============================] - 0s - loss: 2.9310 - val_loss: 3.0013\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s - loss: 2.7717 - val_loss: 2.7784\n",
      "Epoch 94/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.0654\n",
      " Reduced learning rate to 2.44141e-06\n",
      "8/8 [==============================] - 0s - loss: 2.9338 - val_loss: 2.8694\n",
      "Epoch 95/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.8864\n",
      " Reduced learning rate to 1.2207e-06\n",
      "8/8 [==============================] - 0s - loss: 2.3681 - val_loss: 2.8388\n",
      "Epoch 96/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3028\n",
      " Reduced learning rate to 6.10352e-07\n",
      "8/8 [==============================] - 0s - loss: 2.7018 - val_loss: 2.9504\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 2s - loss: 96.0482 - val_loss: 96.5205\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s - loss: 95.7672 - val_loss: 94.7069\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s - loss: 93.3642 - val_loss: 91.8809\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s - loss: 86.5353 - val_loss: 87.0550\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s - loss: 81.0154 - val_loss: 78.3222\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s - loss: 71.2583 - val_loss: 60.9121\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s - loss: 45.3821 - val_loss: 35.0234\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s - loss: 24.6035 - val_loss: 21.7686\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s - loss: 16.7386 - val_loss: 16.1020\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s - loss: 13.2038 - val_loss: 12.5877\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s - loss: 10.7007 - val_loss: 10.5381\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s - loss: 9.0888 - val_loss: 9.2778\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s - loss: 8.1006 - val_loss: 8.3278\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s - loss: 7.5480 - val_loss: 7.6365\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s - loss: 6.8197 - val_loss: 7.3099\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s - loss: 6.0683 - val_loss: 6.8654\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s - loss: 6.1543 - val_loss: 6.3575\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s - loss: 5.5151 - val_loss: 6.3544\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s - loss: 5.2685 - val_loss: 6.0580\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s - loss: 4.9394 - val_loss: 5.8978\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s - loss: 5.8591 - val_loss: 5.5596\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s - loss: 4.9229 - val_loss: 5.5640\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s - loss: 4.9793 - val_loss: 5.3833\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s - loss: 4.4140 - val_loss: 5.1666\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s - loss: 4.2753 - val_loss: 5.0452\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s - loss: 4.4670 - val_loss: 4.9369\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s - loss: 4.5833 - val_loss: 4.8417\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s - loss: 4.3195 - val_loss: 4.5098\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s - loss: 3.8807 - val_loss: 4.6704\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s - loss: 4.1599 - val_loss: 4.6980\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s - loss: 4.1468 - val_loss: 4.3394\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s - loss: 3.7184 - val_loss: 4.4230\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s - loss: 3.8984 - val_loss: 4.4088\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s - loss: 3.7309 - val_loss: 4.3112\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s - loss: 3.8434 - val_loss: 4.2926\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s - loss: 3.8641 - val_loss: 4.1570\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s - loss: 3.6831 - val_loss: 4.1319\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s - loss: 4.0166 - val_loss: 4.0166\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s - loss: 3.7912 - val_loss: 3.9571\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s - loss: 3.1879 - val_loss: 3.9197\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s - loss: 3.4879 - val_loss: 4.2213\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s - loss: 4.0127 - val_loss: 4.1711\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s - loss: 3.5019 - val_loss: 3.8172\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s - loss: 3.1883 - val_loss: 4.1819\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s - loss: 3.4836 - val_loss: 4.1208\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s - loss: 3.7912 - val_loss: 3.9618\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s - loss: 3.2188 - val_loss: 3.8607\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s - loss: 3.4550 - val_loss: 3.6788\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s - loss: 3.2089 - val_loss: 3.3793\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s - loss: 3.5386 - val_loss: 4.0710\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s - loss: 3.8335 - val_loss: 4.0124\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s - loss: 3.5382 - val_loss: 3.5340\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s - loss: 3.9389 - val_loss: 3.4592\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s - loss: 3.6807 - val_loss: 3.6552\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s - loss: 3.7233 - val_loss: 3.7986\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s - loss: 3.8148 - val_loss: 3.8787\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s - loss: 3.2291 - val_loss: 3.7986\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s - loss: 3.5160 - val_loss: 3.6532\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s - loss: 3.2419 - val_loss: 3.6606\n",
      "Epoch 60/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 5.0805\n",
      " Reduced learning rate to 0.01\n",
      "8/8 [==============================] - 1s - loss: 3.6565 - val_loss: 3.6430\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s - loss: 3.2015 - val_loss: 3.0820\n",
      "Epoch 62/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.6750\n",
      " Reduced learning rate to 0.005\n",
      "8/8 [==============================] - 0s - loss: 3.0786 - val_loss: 3.1833\n",
      "Epoch 63/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5263\n",
      " Reduced learning rate to 0.0025\n",
      "8/8 [==============================] - 0s - loss: 2.6079 - val_loss: 3.3142\n",
      "Epoch 64/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3535\n",
      " Reduced learning rate to 0.00125\n",
      "8/8 [==============================] - 0s - loss: 2.8192 - val_loss: 3.2769\n",
      "Epoch 65/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.2907\n",
      " Reduced learning rate to 0.000625\n",
      "8/8 [==============================] - 0s - loss: 2.8870 - val_loss: 3.1800\n",
      "Epoch 66/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.6478\n",
      " Reduced learning rate to 0.0003125\n",
      "8/8 [==============================] - 0s - loss: 2.8250 - val_loss: 3.1372\n",
      "Epoch 67/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3025\n",
      " Reduced learning rate to 0.00015625\n",
      "8/8 [==============================] - 0s - loss: 2.7290 - val_loss: 3.1050\n",
      "Epoch 68/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.6485\n",
      " Reduced learning rate to 7.8125e-05\n",
      "8/8 [==============================] - 0s - loss: 2.4851 - val_loss: 3.2184\n",
      "Epoch 69/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5762\n",
      " Reduced learning rate to 3.90625e-05\n",
      "8/8 [==============================] - 0s - loss: 2.4489 - val_loss: 3.1549\n",
      "Epoch 70/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.0154\n",
      " Reduced learning rate to 1.95312e-05\n",
      "8/8 [==============================] - 0s - loss: 2.6679 - val_loss: 3.2228\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s - loss: 2.8360 - val_loss: 3.0765\n",
      "Epoch 72/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3830\n",
      " Reduced learning rate to 9.76562e-06\n",
      "8/8 [==============================] - 0s - loss: 2.6367 - val_loss: 3.1062\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s - loss: 3.0179 - val_loss: 3.0462\n",
      "Epoch 74/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3861\n",
      " Reduced learning rate to 4.88281e-06\n",
      "8/8 [==============================] - 0s - loss: 2.4867 - val_loss: 3.1032\n",
      "Epoch 75/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.5920\n",
      " Reduced learning rate to 2.44141e-06\n",
      "8/8 [==============================] - 0s - loss: 2.9788 - val_loss: 3.1563\n",
      "Epoch 76/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4633\n",
      " Reduced learning rate to 1.2207e-06\n",
      "8/8 [==============================] - 0s - loss: 2.9217 - val_loss: 3.1631\n",
      "Epoch 77/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.6406\n",
      " Reduced learning rate to 6.10352e-07\n",
      "8/8 [==============================] - 0s - loss: 2.9721 - val_loss: 3.1296\n",
      "Epoch 1/200\n",
      "8/8 [==============================] - 1s - loss: 94.9536 - val_loss: 96.6104\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s - loss: 93.9831 - val_loss: 94.8574\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s - loss: 92.5689 - val_loss: 92.1552\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s - loss: 87.5749 - val_loss: 87.3818\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s - loss: 83.1112 - val_loss: 78.1862\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s - loss: 68.6957 - val_loss: 60.0096\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s - loss: 45.4406 - val_loss: 35.1064\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s - loss: 25.8865 - val_loss: 21.7421\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s - loss: 17.5716 - val_loss: 15.9619\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s - loss: 13.3102 - val_loss: 12.4621\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s - loss: 10.9864 - val_loss: 10.4239\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s - loss: 8.7520 - val_loss: 9.3131\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s - loss: 8.3014 - val_loss: 8.2070\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s - loss: 7.0083 - val_loss: 7.6967\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s - loss: 6.6910 - val_loss: 7.2185\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s - loss: 6.4402 - val_loss: 6.7757\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s - loss: 5.9540 - val_loss: 6.4306\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s - loss: 5.4094 - val_loss: 6.2674\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s - loss: 5.7993 - val_loss: 5.8364\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s - loss: 5.5547 - val_loss: 5.6623\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s - loss: 5.0628 - val_loss: 5.6681\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s - loss: 5.1925 - val_loss: 5.4063\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s - loss: 4.5523 - val_loss: 5.2669\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s - loss: 4.5687 - val_loss: 5.3067\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s - loss: 4.5298 - val_loss: 4.8962\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s - loss: 4.8139 - val_loss: 4.8131\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s - loss: 4.3375 - val_loss: 4.7787\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s - loss: 3.9175 - val_loss: 4.4687\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s - loss: 4.0700 - val_loss: 4.5441\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s - loss: 3.9560 - val_loss: 4.5093\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s - loss: 3.7604 - val_loss: 4.2261\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s - loss: 3.7828 - val_loss: 4.1752\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s - loss: 4.0837 - val_loss: 4.0754\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s - loss: 3.5470 - val_loss: 4.2262\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s - loss: 3.6821 - val_loss: 4.3113\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s - loss: 3.6363 - val_loss: 4.2041\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s - loss: 3.5057 - val_loss: 4.1519\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s - loss: 3.8157 - val_loss: 4.1786\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s - loss: 3.9901 - val_loss: 3.8251\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s - loss: 3.6773 - val_loss: 4.0955\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s - loss: 3.4516 - val_loss: 4.1117\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s - loss: 3.7476 - val_loss: 3.8260\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s - loss: 3.3634 - val_loss: 4.1278\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s - loss: 3.7007 - val_loss: 3.7860\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s - loss: 3.3510 - val_loss: 3.7405\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s - loss: 3.7657 - val_loss: 3.6921\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s - loss: 3.7654 - val_loss: 3.8574\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s - loss: 3.2755 - val_loss: 3.9571\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s - loss: 3.5530 - val_loss: 3.5585\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s - loss: 3.6051 - val_loss: 3.7422\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s - loss: 3.7753 - val_loss: 3.7176\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s - loss: 3.6568 - val_loss: 3.8012\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s - loss: 3.3802 - val_loss: 4.0185\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s - loss: 3.7075 - val_loss: 3.8024\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s - loss: 3.7799 - val_loss: 3.5830\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s - loss: 3.4748 - val_loss: 3.9601\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s - loss: 3.9824 - val_loss: 4.0753\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s - loss: 3.4839 - val_loss: 3.9267\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s - loss: 3.9154 - val_loss: 3.3601\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s - loss: 3.6524 - val_loss: 3.4795\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s - loss: 3.3956 - val_loss: 3.9956\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s - loss: 3.7854 - val_loss: 3.9207\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s - loss: 4.1938 - val_loss: 3.4449\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s - loss: 3.4876 - val_loss: 3.2706\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s - loss: 3.3623 - val_loss: 3.7182\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s - loss: 3.6862 - val_loss: 3.3157\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s - loss: 4.0565 - val_loss: 3.5574\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s - loss: 3.8182 - val_loss: 3.5518\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s - loss: 3.4133 - val_loss: 3.9293\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s - loss: 3.5760 - val_loss: 3.3785\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s - loss: 3.7669 - val_loss: 3.9662\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s - loss: 3.6197 - val_loss: 4.0071\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s - loss: 3.2406 - val_loss: 3.6556\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s - loss: 3.7807 - val_loss: 4.0404\n",
      "Epoch 75/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.8448\n",
      " Reduced learning rate to 0.01\n",
      "8/8 [==============================] - 1s - loss: 3.5696 - val_loss: 3.8665\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s - loss: 2.8538 - val_loss: 2.8720\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s - loss: 2.7409 - val_loss: 2.8384\n",
      "Epoch 78/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.4127\n",
      " Reduced learning rate to 0.005\n",
      "8/8 [==============================] - 0s - loss: 2.7592 - val_loss: 2.9250\n",
      "Epoch 79/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.7659\n",
      " Reduced learning rate to 0.0025\n",
      "8/8 [==============================] - 0s - loss: 2.6700 - val_loss: 2.8679\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s - loss: 3.1900 - val_loss: 2.7818\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s - loss: 2.5677 - val_loss: 2.7753\n",
      "Epoch 82/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.5153\n",
      " Reduced learning rate to 0.00125\n",
      "8/8 [==============================] - 0s - loss: 2.5419 - val_loss: 2.9833\n",
      "Epoch 83/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.4854\n",
      " Reduced learning rate to 0.000625\n",
      "8/8 [==============================] - 0s - loss: 2.5058 - val_loss: 2.8700\n",
      "Epoch 84/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1603\n",
      " Reduced learning rate to 0.0003125\n",
      "8/8 [==============================] - 0s - loss: 2.6291 - val_loss: 2.9095\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s - loss: 2.6075 - val_loss: 2.7279\n",
      "Epoch 86/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.6395\n",
      " Reduced learning rate to 0.00015625\n",
      "8/8 [==============================] - 0s - loss: 2.8158 - val_loss: 2.8383\n",
      "Epoch 87/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1110\n",
      " Reduced learning rate to 7.8125e-05\n",
      "8/8 [==============================] - 0s - loss: 2.6138 - val_loss: 2.7592\n",
      "Epoch 88/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.9717\n",
      " Reduced learning rate to 3.90625e-05\n",
      "8/8 [==============================] - 0s - loss: 2.5238 - val_loss: 2.7775\n",
      "Epoch 89/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.1013\n",
      " Reduced learning rate to 1.95312e-05\n",
      "8/8 [==============================] - 0s - loss: 2.5940 - val_loss: 2.8978\n",
      "Epoch 90/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1867\n",
      " Reduced learning rate to 9.76562e-06\n",
      "8/8 [==============================] - 0s - loss: 2.5795 - val_loss: 2.8938\n",
      "Epoch 91/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.1950\n",
      " Reduced learning rate to 4.88281e-06\n",
      "8/8 [==============================] - 0s - loss: 2.2353 - val_loss: 2.7737\n",
      "Epoch 92/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3991\n",
      " Reduced learning rate to 2.44141e-06\n",
      "8/8 [==============================] - 0s - loss: 2.4903 - val_loss: 2.7741\n",
      "Epoch 93/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 3.5820\n",
      " Reduced learning rate to 1.2207e-06\n",
      "8/8 [==============================] - 0s - loss: 2.8957 - val_loss: 2.9082\n",
      "Epoch 94/200\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 2.3748\n",
      " Reduced learning rate to 6.10352e-07\n",
      "8/8 [==============================] - 0s - loss: 2.4450 - val_loss: 2.8117\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 2s - loss: 94.0348 - val_loss: 88.8933\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s - loss: 86.5643 - val_loss: 79.8039\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s - loss: 69.8126 - val_loss: 45.8398\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s - loss: 26.6063 - val_loss: 14.5935\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s - loss: 12.2754 - val_loss: 8.5869\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s - loss: 7.9261 - val_loss: 6.2108\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s - loss: 6.2488 - val_loss: 5.2820\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s - loss: 5.3711 - val_loss: 4.7184\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s - loss: 5.1919 - val_loss: 4.4786\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s - loss: 4.5811 - val_loss: 4.1334\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s - loss: 4.7258 - val_loss: 3.8171\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s - loss: 4.7901 - val_loss: 3.6203\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s - loss: 3.9509 - val_loss: 3.4402\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s - loss: 3.8721 - val_loss: 3.4213\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s - loss: 3.8987 - val_loss: 3.3987\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s - loss: 3.9088 - val_loss: 3.4826\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s - loss: 3.5700 - val_loss: 3.0232\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s - loss: 3.3721 - val_loss: 3.4515\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s - loss: 3.7400 - val_loss: 3.2022\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s - loss: 3.4047 - val_loss: 2.9225\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s - loss: 3.3400 - val_loss: 3.3239\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s - loss: 3.5172 - val_loss: 2.9263\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s - loss: 3.1815 - val_loss: 3.2794\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s - loss: 3.4885 - val_loss: 3.1965\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s - loss: 3.7548 - val_loss: 2.9273\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s - loss: 3.5362 - val_loss: 3.0882\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s - loss: 3.4442 - val_loss: 3.1632\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s - loss: 3.4545 - val_loss: 3.2356\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s - loss: 3.6118 - val_loss: 2.9855\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s - loss: 3.6806 - val_loss: 3.1525\n",
      "Epoch 31/200\n",
      "15/17 [=========================>....] - ETA: 0s - loss: 3.4682\n",
      " Reduced learning rate to 0.01\n",
      "17/17 [==============================] - 1s - loss: 3.4670 - val_loss: 3.1637\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s - loss: 2.8779 - val_loss: 2.3786\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s - loss: 2.9308 - val_loss: 2.3173\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s - loss: 2.6991 - val_loss: 2.2717\n",
      "Epoch 35/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.7900\n",
      " Reduced learning rate to 0.005\n",
      "17/17 [==============================] - 0s - loss: 2.7519 - val_loss: 2.3886\n",
      "Epoch 36/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.2540\n",
      " Reduced learning rate to 0.0025\n",
      "17/17 [==============================] - 0s - loss: 2.6536 - val_loss: 2.3204\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s - loss: 2.8096 - val_loss: 2.1967\n",
      "Epoch 38/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.7487\n",
      " Reduced learning rate to 0.00125\n",
      "17/17 [==============================] - 0s - loss: 2.7176 - val_loss: 2.2440\n",
      "Epoch 39/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.9446\n",
      " Reduced learning rate to 0.000625\n",
      "17/17 [==============================] - 0s - loss: 2.7531 - val_loss: 2.3409\n",
      "Epoch 40/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.4819\n",
      " Reduced learning rate to 0.0003125\n",
      "17/17 [==============================] - 0s - loss: 2.4849 - val_loss: 2.2941\n",
      "Epoch 41/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 1.9317\n",
      " Reduced learning rate to 0.00015625\n",
      "17/17 [==============================] - 0s - loss: 2.5753 - val_loss: 2.2799\n",
      "Epoch 42/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.7625\n",
      " Reduced learning rate to 7.8125e-05\n",
      "17/17 [==============================] - 0s - loss: 2.7521 - val_loss: 2.2420\n",
      "Epoch 43/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.0009\n",
      " Reduced learning rate to 3.90625e-05\n",
      "17/17 [==============================] - 0s - loss: 2.3889 - val_loss: 2.2366\n",
      "Epoch 44/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.4542\n",
      " Reduced learning rate to 1.95312e-05\n",
      "17/17 [==============================] - 0s - loss: 2.6728 - val_loss: 2.2543\n",
      "Epoch 45/200\n",
      "15/17 [=========================>....] - ETA: 0s - loss: 2.6433\n",
      " Reduced learning rate to 9.76562e-06\n",
      "17/17 [==============================] - 0s - loss: 2.6327 - val_loss: 2.2939\n",
      "Epoch 46/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.4970\n",
      " Reduced learning rate to 4.88281e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4925 - val_loss: 2.2621\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s - loss: 2.7446 - val_loss: 2.1785\n",
      "Epoch 48/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.7163\n",
      " Reduced learning rate to 2.44141e-06\n",
      "17/17 [==============================] - 0s - loss: 2.7414 - val_loss: 2.1813\n",
      "Epoch 49/200\n",
      "14/17 [=======================>......] - ETA: 0s - loss: 2.4219\n",
      " Reduced learning rate to 1.2207e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4638 - val_loss: 2.4250\n",
      "Epoch 50/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.6906\n",
      " Reduced learning rate to 6.10352e-07\n",
      "17/17 [==============================] - 0s - loss: 2.6712 - val_loss: 2.2980\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 2s - loss: 96.3351 - val_loss: 90.1582\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s - loss: 90.6330 - val_loss: 84.5781\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s - loss: 81.9771 - val_loss: 64.9678\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s - loss: 42.5801 - val_loss: 20.7038\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s - loss: 16.1137 - val_loss: 11.3030\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s - loss: 10.1097 - val_loss: 7.8661\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s - loss: 7.7849 - val_loss: 6.5474\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s - loss: 6.4852 - val_loss: 5.6434\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s - loss: 5.7731 - val_loss: 4.9073\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s - loss: 5.6146 - val_loss: 4.5116\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s - loss: 4.8353 - val_loss: 4.2218\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s - loss: 4.8600 - val_loss: 4.0363\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s - loss: 4.3666 - val_loss: 3.7270\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s - loss: 4.0748 - val_loss: 3.6835\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s - loss: 3.9528 - val_loss: 3.4243\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s - loss: 4.0448 - val_loss: 3.4128\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s - loss: 3.5859 - val_loss: 3.2671\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s - loss: 3.7372 - val_loss: 3.2009\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s - loss: 3.7624 - val_loss: 3.3466\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s - loss: 3.6262 - val_loss: 3.1564\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s - loss: 3.7936 - val_loss: 2.9386\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s - loss: 3.5499 - val_loss: 2.9143\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s - loss: 3.3070 - val_loss: 2.8546\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - ETA: 0s - loss: 2.680 - 0s - loss: 3.4094 - val_loss: 3.1550\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s - loss: 3.3551 - val_loss: 2.8957\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s - loss: 3.5757 - val_loss: 3.0836\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s - loss: 3.2981 - val_loss: 3.0942\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s - loss: 3.4159 - val_loss: 2.7895\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s - loss: 3.7653 - val_loss: 3.2143\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s - loss: 3.3428 - val_loss: 2.6751\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s - loss: 3.3660 - val_loss: 3.1188\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s - loss: 3.4257 - val_loss: 3.0646\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s - loss: 3.5016 - val_loss: 2.9460\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s - loss: 3.3944 - val_loss: 3.0575\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s - loss: 3.4652 - val_loss: 2.8418\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s - loss: 3.3854 - val_loss: 2.9185\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s - loss: 3.5558 - val_loss: 3.3311\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s - loss: 3.5877 - val_loss: 3.6870\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s - loss: 3.4490 - val_loss: 3.1138\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s - loss: 3.6003 - val_loss: 3.2065\n",
      "Epoch 41/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.2811\n",
      " Reduced learning rate to 0.01\n",
      "17/17 [==============================] - 1s - loss: 3.5415 - val_loss: 3.2099\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s - loss: 2.8465 - val_loss: 2.2053\n",
      "Epoch 43/200\n",
      "17/17 [==============================] - 0s - loss: 2.6203 - val_loss: 2.1760\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s - loss: 2.6284 - val_loss: 2.1559\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s - loss: 2.5538 - val_loss: 2.1537\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s - loss: 2.6453 - val_loss: 2.1352\n",
      "Epoch 47/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.216 - ETA: 0s - loss: 2.4656\n",
      " Reduced learning rate to 0.005\n",
      "17/17 [==============================] - 0s - loss: 2.4665 - val_loss: 2.2680\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s - loss: 2.6272 - val_loss: 2.0879\n",
      "Epoch 49/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.6867\n",
      " Reduced learning rate to 0.0025\n",
      "17/17 [==============================] - 0s - loss: 2.6602 - val_loss: 2.1562\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s - loss: 2.4637 - val_loss: 2.0361\n",
      "Epoch 51/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.5831\n",
      " Reduced learning rate to 0.00125\n",
      "17/17 [==============================] - 0s - loss: 2.5541 - val_loss: 2.0881\n",
      "Epoch 52/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2431\n",
      " Reduced learning rate to 0.000625\n",
      "17/17 [==============================] - 0s - loss: 2.4260 - val_loss: 2.1122\n",
      "Epoch 53/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.6300\n",
      " Reduced learning rate to 0.0003125\n",
      "17/17 [==============================] - 0s - loss: 2.2939 - val_loss: 2.1040\n",
      "Epoch 54/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.5599\n",
      " Reduced learning rate to 0.00015625\n",
      "17/17 [==============================] - 0s - loss: 2.5285 - val_loss: 2.0591\n",
      "Epoch 55/200\n",
      "17/17 [==============================] - 0s - loss: 2.4698 - val_loss: 2.0291\n",
      "Epoch 56/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2892\n",
      " Reduced learning rate to 7.8125e-05\n",
      "17/17 [==============================] - 0s - loss: 2.4782 - val_loss: 2.1176\n",
      "Epoch 57/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2619\n",
      " Reduced learning rate to 3.90625e-05\n",
      "17/17 [==============================] - 0s - loss: 2.4344 - val_loss: 2.0302\n",
      "Epoch 58/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2972\n",
      " Reduced learning rate to 1.95312e-05\n",
      "17/17 [==============================] - 0s - loss: 2.3733 - val_loss: 2.0713\n",
      "Epoch 59/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.5236\n",
      " Reduced learning rate to 9.76562e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4402 - val_loss: 2.1358\n",
      "Epoch 60/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.1963\n",
      " Reduced learning rate to 4.88281e-06\n",
      "17/17 [==============================] - 0s - loss: 2.3272 - val_loss: 2.1563\n",
      "Epoch 61/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 1.9637\n",
      " Reduced learning rate to 2.44141e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4343 - val_loss: 2.0746\n",
      "Epoch 62/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2581\n",
      " Reduced learning rate to 1.2207e-06\n",
      "17/17 [==============================] - 0s - loss: 2.6651 - val_loss: 2.0837\n",
      "Epoch 63/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.8735\n",
      " Reduced learning rate to 6.10352e-07\n",
      "17/17 [==============================] - 0s - loss: 2.5641 - val_loss: 2.0590\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 2s - loss: 92.8399 - val_loss: 90.2447\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s - loss: 91.8234 - val_loss: 85.1738\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s - loss: 82.5136 - val_loss: 67.3552\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s - loss: 44.8581 - val_loss: 20.7624\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s - loss: 16.4500 - val_loss: 11.1421\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s - loss: 9.8603 - val_loss: 7.6744\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s - loss: 7.6136 - val_loss: 6.0552\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s - loss: 6.1501 - val_loss: 5.1838\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s - loss: 5.6033 - val_loss: 4.7639\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s - loss: 4.8485 - val_loss: 4.3681\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s - loss: 4.6402 - val_loss: 4.0288\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s - loss: 4.6326 - val_loss: 3.7448\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s - loss: 4.1724 - val_loss: 3.6219\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s - loss: 4.2105 - val_loss: 3.3965\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s - loss: 4.1599 - val_loss: 3.3659\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s - loss: 3.6700 - val_loss: 3.3255\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s - loss: 3.8744 - val_loss: 3.4003\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s - loss: 3.6320 - val_loss: 3.0806\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s - loss: 3.5616 - val_loss: 3.3596\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s - loss: 3.3701 - val_loss: 3.0559\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s - loss: 3.8655 - val_loss: 3.7181\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s - loss: 3.4665 - val_loss: 3.1485\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s - loss: 3.6971 - val_loss: 2.8021\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s - loss: 3.2927 - val_loss: 2.8942\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s - loss: 3.2442 - val_loss: 2.7564\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s - loss: 3.3376 - val_loss: 3.2610\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s - loss: 3.2039 - val_loss: 2.8196\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s - loss: 3.4630 - val_loss: 2.7198\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s - loss: 3.5980 - val_loss: 2.7834\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s - loss: 3.4671 - val_loss: 3.1660\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s - loss: 3.6438 - val_loss: 3.4363\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s - loss: 3.6328 - val_loss: 2.7035\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s - loss: 3.6036 - val_loss: 3.6993\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s - loss: 3.5784 - val_loss: 3.1786\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s - loss: 3.5410 - val_loss: 3.2314\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s - loss: 3.5243 - val_loss: 3.2362\n",
      "Epoch 37/200\n",
      "17/17 [==============================] - 0s - loss: 3.5250 - val_loss: 3.1576\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s - loss: 3.5286 - val_loss: 3.1659\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s - loss: 3.5815 - val_loss: 3.1420\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s - loss: 3.3346 - val_loss: 3.3978\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s - loss: 3.5268 - val_loss: 3.1372\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s - loss: 3.2711 - val_loss: 3.0771\n",
      "Epoch 43/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.2693\n",
      " Reduced learning rate to 0.01\n",
      "17/17 [==============================] - 1s - loss: 3.4349 - val_loss: 3.3801\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s - loss: 2.5113 - val_loss: 2.0305\n",
      "Epoch 45/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.1952\n",
      " Reduced learning rate to 0.005\n",
      "17/17 [==============================] - 0s - loss: 2.3562 - val_loss: 2.1014\n",
      "Epoch 46/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2907\n",
      " Reduced learning rate to 0.0025\n",
      "17/17 [==============================] - 0s - loss: 2.4756 - val_loss: 2.1373\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/17 [>.............................] - ETA: 0s - loss: 2.0859\n",
      " Reduced learning rate to 0.00125\n",
      "17/17 [==============================] - 0s - loss: 2.4133 - val_loss: 2.1669\n",
      "Epoch 48/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.7903\n",
      " Reduced learning rate to 0.000625\n",
      "17/17 [==============================] - 0s - loss: 2.4804 - val_loss: 2.0880\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s - loss: 2.2601 - val_loss: 2.0208\n",
      "Epoch 50/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.1842\n",
      " Reduced learning rate to 0.0003125\n",
      "17/17 [==============================] - 0s - loss: 2.5137 - val_loss: 2.0742\n",
      "Epoch 51/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.2372\n",
      " Reduced learning rate to 0.00015625\n",
      "17/17 [==============================] - 0s - loss: 2.6814 - val_loss: 2.2539\n",
      "Epoch 52/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.1151\n",
      " Reduced learning rate to 7.8125e-05\n",
      "17/17 [==============================] - 0s - loss: 2.7004 - val_loss: 2.0773\n",
      "Epoch 53/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.3638\n",
      " Reduced learning rate to 3.90625e-05\n",
      "17/17 [==============================] - 0s - loss: 2.3920 - val_loss: 2.1243\n",
      "Epoch 54/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.3239\n",
      " Reduced learning rate to 1.95312e-05\n",
      "17/17 [==============================] - 0s - loss: 2.4316 - val_loss: 2.1015\n",
      "Epoch 55/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2097\n",
      " Reduced learning rate to 9.76562e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4304 - val_loss: 2.1022\n",
      "Epoch 56/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2035\n",
      " Reduced learning rate to 4.88281e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4748 - val_loss: 2.0600\n",
      "Epoch 57/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.0786\n",
      " Reduced learning rate to 2.44141e-06\n",
      "17/17 [==============================] - 0s - loss: 2.3336 - val_loss: 2.0802\n",
      "Epoch 58/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.1020\n",
      " Reduced learning rate to 1.2207e-06\n",
      "17/17 [==============================] - 0s - loss: 2.3756 - val_loss: 2.0812\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s - loss: 2.4754 - val_loss: 2.0113\n",
      "Epoch 60/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.7759\n",
      " Reduced learning rate to 6.10352e-07\n",
      "17/17 [==============================] - 0s - loss: 2.3404 - val_loss: 2.0751\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 2s - loss: 93.6311 - val_loss: 89.1639\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s - loss: 88.6535 - val_loss: 80.1810\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s - loss: 66.5560 - val_loss: 40.3145\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s - loss: 25.5134 - val_loss: 14.8973\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s - loss: 12.5815 - val_loss: 9.0220\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s - loss: 8.2985 - val_loss: 6.6615\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s - loss: 6.5599 - val_loss: 5.4752\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s - loss: 5.7231 - val_loss: 4.8215\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s - loss: 5.1354 - val_loss: 4.4489\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s - loss: 4.6178 - val_loss: 4.1369\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s - loss: 4.4672 - val_loss: 3.8431\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s - loss: 4.2960 - val_loss: 3.6001\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s - loss: 4.0727 - val_loss: 3.4175\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s - loss: 3.8124 - val_loss: 3.5005\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s - loss: 3.7746 - val_loss: 3.2157\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s - loss: 3.7756 - val_loss: 3.2193\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s - loss: 3.4755 - val_loss: 2.9259\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s - loss: 3.5523 - val_loss: 3.0761\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s - loss: 3.4850 - val_loss: 3.2079\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s - loss: 3.4097 - val_loss: 2.9172\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s - loss: 3.4255 - val_loss: 2.9802\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s - loss: 3.6407 - val_loss: 3.0135\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s - loss: 3.6030 - val_loss: 2.7726\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s - loss: 3.4772 - val_loss: 3.2568\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s - loss: 3.2350 - val_loss: 3.4850\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s - loss: 3.3546 - val_loss: 2.9734\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s - loss: 3.5034 - val_loss: 3.4740\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s - loss: 3.5739 - val_loss: 3.1870\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s - loss: 3.6075 - val_loss: 3.3414\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s - loss: 3.7076 - val_loss: 3.1096\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s - loss: 3.4190 - val_loss: 3.3168\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s - loss: 3.5342 - val_loss: 3.1068\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s - loss: 3.8474 - val_loss: 2.9873\n",
      "Epoch 34/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.7649\n",
      " Reduced learning rate to 0.01\n",
      "17/17 [==============================] - 1s - loss: 3.4507 - val_loss: 2.8500\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s - loss: 2.7712 - val_loss: 2.2306\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s - loss: 2.7463 - val_loss: 2.2296\n",
      "Epoch 37/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.5775\n",
      " Reduced learning rate to 0.005\n",
      "17/17 [==============================] - 0s - loss: 2.7924 - val_loss: 2.2398\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s - loss: 2.6907 - val_loss: 2.2020\n",
      "Epoch 39/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.3824\n",
      " Reduced learning rate to 0.0025\n",
      "17/17 [==============================] - 0s - loss: 2.6696 - val_loss: 2.2390\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s - loss: 2.4779 - val_loss: 2.1832\n",
      "Epoch 41/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.4138\n",
      " Reduced learning rate to 0.00125\n",
      "17/17 [==============================] - 0s - loss: 2.6057 - val_loss: 2.2271\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s - loss: 2.6421 - val_loss: 2.1470\n",
      "Epoch 43/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.6581\n",
      " Reduced learning rate to 0.000625\n",
      "17/17 [==============================] - 0s - loss: 2.7201 - val_loss: 2.2583\n",
      "Epoch 44/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.5110\n",
      " Reduced learning rate to 0.0003125\n",
      "17/17 [==============================] - 0s - loss: 2.6634 - val_loss: 2.1714\n",
      "Epoch 45/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 4.1589\n",
      " Reduced learning rate to 0.00015625\n",
      "17/17 [==============================] - 0s - loss: 2.5440 - val_loss: 2.2560\n",
      "Epoch 46/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.1834\n",
      " Reduced learning rate to 7.8125e-05\n",
      "17/17 [==============================] - 0s - loss: 2.5377 - val_loss: 2.1585\n",
      "Epoch 47/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.7386\n",
      " Reduced learning rate to 3.90625e-05\n",
      "17/17 [==============================] - 0s - loss: 2.5634 - val_loss: 2.2139\n",
      "Epoch 48/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.0503\n",
      " Reduced learning rate to 1.95312e-05\n",
      "17/17 [==============================] - 0s - loss: 2.6759 - val_loss: 2.2094\n",
      "Epoch 49/200\n",
      "17/17 [==============================] - 0s - loss: 2.5000 - val_loss: 2.0868\n",
      "Epoch 50/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.0211\n",
      " Reduced learning rate to 9.76562e-06\n",
      "17/17 [==============================] - 0s - loss: 2.5004 - val_loss: 2.1692\n",
      "Epoch 51/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.7679\n",
      " Reduced learning rate to 4.88281e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s - loss: 2.4772 - val_loss: 2.1156\n",
      "Epoch 52/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 5.1628\n",
      " Reduced learning rate to 2.44141e-06\n",
      "17/17 [==============================] - 0s - loss: 2.6002 - val_loss: 2.1327\n",
      "Epoch 53/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2848\n",
      " Reduced learning rate to 1.2207e-06\n",
      "17/17 [==============================] - 0s - loss: 2.7358 - val_loss: 2.2579\n",
      "Epoch 54/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.1363\n",
      " Reduced learning rate to 6.10352e-07\n",
      "17/17 [==============================] - 0s - loss: 2.6613 - val_loss: 2.1940\n",
      "Epoch 1/200\n",
      "17/17 [==============================] - 2s - loss: 94.6923 - val_loss: 90.0435\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s - loss: 92.3582 - val_loss: 83.7683\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s - loss: 78.4907 - val_loss: 56.7160\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s - loss: 34.7636 - val_loss: 17.4631\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s - loss: 14.4217 - val_loss: 10.0761\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s - loss: 9.4621 - val_loss: 7.2709\n",
      "Epoch 7/200\n",
      "17/17 [==============================] - 0s - loss: 7.4736 - val_loss: 6.0067\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s - loss: 6.3595 - val_loss: 5.3129\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s - loss: 5.4701 - val_loss: 4.8697\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s - loss: 5.3546 - val_loss: 4.5259\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s - loss: 4.8656 - val_loss: 4.1633\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s - loss: 4.6223 - val_loss: 3.9382\n",
      "Epoch 13/200\n",
      "17/17 [==============================] - 0s - loss: 4.2878 - val_loss: 3.8215\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s - loss: 4.3334 - val_loss: 3.6770\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s - loss: 3.9726 - val_loss: 3.4094\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s - loss: 4.0032 - val_loss: 3.3711\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s - loss: 3.8213 - val_loss: 3.4326\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s - loss: 3.9173 - val_loss: 3.1858\n",
      "Epoch 19/200\n",
      "17/17 [==============================] - 0s - loss: 3.4797 - val_loss: 3.0447\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s - loss: 3.6512 - val_loss: 3.1394\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s - loss: 3.7719 - val_loss: 3.0344\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s - loss: 3.2246 - val_loss: 3.2779\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s - loss: 3.8857 - val_loss: 3.0566\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s - loss: 3.5890 - val_loss: 3.0618\n",
      "Epoch 25/200\n",
      "17/17 [==============================] - 0s - loss: 3.3783 - val_loss: 3.1551\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s - loss: 3.3838 - val_loss: 2.7390\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s - loss: 3.3594 - val_loss: 2.8580\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s - loss: 3.5761 - val_loss: 3.2702\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s - loss: 3.6860 - val_loss: 3.3631\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s - loss: 3.5350 - val_loss: 2.8831\n",
      "Epoch 31/200\n",
      "17/17 [==============================] - 0s - loss: 3.3828 - val_loss: 3.2590\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s - loss: 3.3624 - val_loss: 2.9955\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s - loss: 3.6196 - val_loss: 3.0885\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s - loss: 3.3269 - val_loss: 2.9306\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s - loss: 3.4804 - val_loss: 3.3350\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s - loss: 3.6900 - val_loss: 3.0451\n",
      "Epoch 37/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.2826\n",
      " Reduced learning rate to 0.01\n",
      "17/17 [==============================] - 1s - loss: 3.5916 - val_loss: 3.6126\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s - loss: 2.7794 - val_loss: 2.2512\n",
      "Epoch 39/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.6443\n",
      " Reduced learning rate to 0.005\n",
      "17/17 [==============================] - 0s - loss: 2.6695 - val_loss: 2.2699\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s - loss: 2.5218 - val_loss: 2.1573\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s - loss: 2.8115 - val_loss: 2.1558\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s - loss: 2.6433 - val_loss: 2.1355\n",
      "Epoch 43/200\n",
      "15/17 [=========================>....] - ETA: 0s - loss: 2.4630\n",
      " Reduced learning rate to 0.0025\n",
      "17/17 [==============================] - 0s - loss: 2.4446 - val_loss: 2.1819\n",
      "Epoch 44/200\n",
      "14/17 [=======================>......] - ETA: 0s - loss: 2.5218\n",
      " Reduced learning rate to 0.00125\n",
      "17/17 [==============================] - 0s - loss: 2.6235 - val_loss: 2.2292\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s - loss: 2.6746 - val_loss: 2.1061\n",
      "Epoch 46/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.4160\n",
      " Reduced learning rate to 0.000625\n",
      "17/17 [==============================] - 0s - loss: 2.4389 - val_loss: 2.1649\n",
      "Epoch 47/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.6450\n",
      " Reduced learning rate to 0.0003125\n",
      "17/17 [==============================] - 0s - loss: 2.6012 - val_loss: 2.1827\n",
      "Epoch 48/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.9662\n",
      " Reduced learning rate to 0.00015625\n",
      "17/17 [==============================] - 0s - loss: 2.5741 - val_loss: 2.2040\n",
      "Epoch 49/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2929\n",
      " Reduced learning rate to 7.8125e-05\n",
      "17/17 [==============================] - 0s - loss: 2.4300 - val_loss: 2.1306\n",
      "Epoch 50/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.4601\n",
      " Reduced learning rate to 3.90625e-05\n",
      "17/17 [==============================] - 0s - loss: 2.5851 - val_loss: 2.2622\n",
      "Epoch 51/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.5710\n",
      " Reduced learning rate to 1.95312e-05\n",
      "17/17 [==============================] - 0s - loss: 2.5496 - val_loss: 2.1363\n",
      "Epoch 52/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.2918\n",
      " Reduced learning rate to 9.76562e-06\n",
      "17/17 [==============================] - 0s - loss: 2.5841 - val_loss: 2.1674\n",
      "Epoch 53/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 2.3332\n",
      " Reduced learning rate to 4.88281e-06\n",
      "17/17 [==============================] - 0s - loss: 2.5221 - val_loss: 2.1506\n",
      "Epoch 54/200\n",
      " 1/17 [>.............................] - ETA: 0s - loss: 3.6609\n",
      " Reduced learning rate to 2.44141e-06\n",
      "17/17 [==============================] - 0s - loss: 2.4859 - val_loss: 2.1887\n",
      "Epoch 55/200\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 2.5841\n",
      " Reduced learning rate to 1.2207e-06\n",
      "17/17 [==============================] - 0s - loss: 2.5787 - val_loss: 2.1907\n",
      "Epoch 56/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.6692\n",
      " Reduced learning rate to 6.10352e-07\n",
      "17/17 [==============================] - 0s - loss: 2.6178 - val_loss: 2.1500\n",
      "Epoch 1/200\n",
      "87/87 [==============================] - 2s - loss: 58.2163 - val_loss: 9.7344\n",
      "Epoch 2/200\n",
      "87/87 [==============================] - 0s - loss: 6.3372 - val_loss: 4.2453\n",
      "Epoch 3/200\n",
      "87/87 [==============================] - 0s - loss: 4.1516 - val_loss: 3.2466\n",
      "Epoch 4/200\n",
      "87/87 [==============================] - 0s - loss: 3.5210 - val_loss: 3.0855\n",
      "Epoch 5/200\n",
      "87/87 [==============================] - 0s - loss: 3.3686 - val_loss: 2.7368\n",
      "Epoch 6/200\n",
      "87/87 [==============================] - 0s - loss: 3.3319 - val_loss: 3.3677\n",
      "Epoch 7/200\n",
      "87/87 [==============================] - 0s - loss: 3.3644 - val_loss: 2.5222\n",
      "Epoch 8/200\n",
      "87/87 [==============================] - 0s - loss: 3.3080 - val_loss: 2.6929\n",
      "Epoch 9/200\n",
      "87/87 [==============================] - 0s - loss: 3.3416 - val_loss: 2.6999\n",
      "Epoch 10/200\n",
      "87/87 [==============================] - 0s - loss: 3.2800 - val_loss: 3.5500\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s - loss: 3.2123 - val_loss: 2.8682\n",
      "Epoch 12/200\n",
      "87/87 [==============================] - 0s - loss: 3.3117 - val_loss: 3.4098\n",
      "Epoch 13/200\n",
      "87/87 [==============================] - 0s - loss: 3.3551 - val_loss: 2.9741\n",
      "Epoch 14/200\n",
      "87/87 [==============================] - 0s - loss: 3.2303 - val_loss: 3.0977\n",
      "Epoch 15/200\n",
      "87/87 [==============================] - 0s - loss: 3.2939 - val_loss: 3.3267\n",
      "Epoch 16/200\n",
      "87/87 [==============================] - 0s - loss: 3.1751 - val_loss: 3.4387\n",
      "Epoch 17/200\n",
      "87/87 [==============================] - 0s - loss: 3.1817 - val_loss: 2.8276\n",
      "Epoch 18/200\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 3.1786\n",
      " Reduced learning rate to 0.01\n",
      "87/87 [==============================] - 1s - loss: 3.1603 - val_loss: 3.0020\n",
      "Epoch 19/200\n",
      "87/87 [==============================] - 0s - loss: 2.1131 - val_loss: 1.8653\n",
      "Epoch 20/200\n",
      "74/87 [========================>.....] - ETA: 0s - loss: 2.0488\n",
      " Reduced learning rate to 0.005\n",
      "87/87 [==============================] - 0s - loss: 2.0568 - val_loss: 1.8682\n",
      "Epoch 21/200\n",
      "87/87 [==============================] - 0s - loss: 2.0920 - val_loss: 1.8642\n",
      "Epoch 22/200\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 2.0284\n",
      " Reduced learning rate to 0.0025\n",
      "87/87 [==============================] - 0s - loss: 2.0273 - val_loss: 1.8723\n",
      "Epoch 23/200\n",
      "87/87 [==============================] - 0s - loss: 2.0530 - val_loss: 1.8303\n",
      "Epoch 24/200\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 1.9782\n",
      " Reduced learning rate to 0.00125\n",
      "87/87 [==============================] - 0s - loss: 1.9877 - val_loss: 1.8588\n",
      "Epoch 25/200\n",
      "73/87 [========================>.....] - ETA: 0s - loss: 2.0717\n",
      " Reduced learning rate to 0.000625\n",
      "87/87 [==============================] - 0s - loss: 2.0533 - val_loss: 1.8398\n",
      "Epoch 26/200\n",
      "87/87 [==============================] - 0s - loss: 1.9650 - val_loss: 1.7935\n",
      "Epoch 27/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 2.0598\n",
      " Reduced learning rate to 0.0003125\n",
      "87/87 [==============================] - 0s - loss: 2.0606 - val_loss: 1.8447\n",
      "Epoch 28/200\n",
      "85/87 [============================>.] - ETA: 0s - loss: 1.9828\n",
      " Reduced learning rate to 0.00015625\n",
      "87/87 [==============================] - 0s - loss: 1.9793 - val_loss: 1.8363\n",
      "Epoch 29/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 2.0958\n",
      " Reduced learning rate to 7.8125e-05\n",
      "87/87 [==============================] - 0s - loss: 2.0621 - val_loss: 1.8347\n",
      "Epoch 30/200\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 2.0652\n",
      " Reduced learning rate to 3.90625e-05\n",
      "87/87 [==============================] - 0s - loss: 2.0629 - val_loss: 1.8596\n",
      "Epoch 31/200\n",
      "74/87 [========================>.....] - ETA: 0s - loss: 2.0192\n",
      " Reduced learning rate to 1.95312e-05\n",
      "87/87 [==============================] - 0s - loss: 2.0087 - val_loss: 1.8139\n",
      "Epoch 32/200\n",
      "76/87 [=========================>....] - ETA: 0s - loss: 2.0114\n",
      " Reduced learning rate to 9.76562e-06\n",
      "87/87 [==============================] - 0s - loss: 2.0159 - val_loss: 1.8279\n",
      "Epoch 33/200\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 1.9638\n",
      " Reduced learning rate to 4.88281e-06\n",
      "87/87 [==============================] - 0s - loss: 1.9744 - val_loss: 1.8578\n",
      "Epoch 34/200\n",
      "69/87 [======================>.......] - ETA: 0s - loss: 2.0229\n",
      " Reduced learning rate to 2.44141e-06\n",
      "87/87 [==============================] - 0s - loss: 2.0174 - val_loss: 1.8463\n",
      "Epoch 35/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 2.0344\n",
      " Reduced learning rate to 1.2207e-06\n",
      "87/87 [==============================] - 0s - loss: 2.0214 - val_loss: 1.7935\n",
      "Epoch 36/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.9975\n",
      " Reduced learning rate to 6.10352e-07\n",
      "87/87 [==============================] - 0s - loss: 2.0022 - val_loss: 1.8338\n",
      "Epoch 1/200\n",
      "87/87 [==============================] - 2s - loss: 57.5647 - val_loss: 9.1211\n",
      "Epoch 2/200\n",
      "87/87 [==============================] - 0s - loss: 6.2537 - val_loss: 4.1431\n",
      "Epoch 3/200\n",
      "87/87 [==============================] - 0s - loss: 4.1703 - val_loss: 3.3013\n",
      "Epoch 4/200\n",
      "87/87 [==============================] - 0s - loss: 3.7068 - val_loss: 2.9273\n",
      "Epoch 5/200\n",
      "87/87 [==============================] - 0s - loss: 3.4467 - val_loss: 3.0503\n",
      "Epoch 6/200\n",
      "87/87 [==============================] - 0s - loss: 3.4396 - val_loss: 2.8695\n",
      "Epoch 7/200\n",
      "87/87 [==============================] - 0s - loss: 3.3882 - val_loss: 2.9482\n",
      "Epoch 8/200\n",
      "87/87 [==============================] - 0s - loss: 3.3845 - val_loss: 3.0630\n",
      "Epoch 9/200\n",
      "87/87 [==============================] - 0s - loss: 3.3807 - val_loss: 3.0552\n",
      "Epoch 10/200\n",
      "87/87 [==============================] - 0s - loss: 3.4007 - val_loss: 3.0776\n",
      "Epoch 11/200\n",
      "87/87 [==============================] - 0s - loss: 3.3587 - val_loss: 3.2769\n",
      "Epoch 12/200\n",
      "87/87 [==============================] - 0s - loss: 3.3078 - val_loss: 2.8430\n",
      "Epoch 13/200\n",
      "87/87 [==============================] - 0s - loss: 3.3496 - val_loss: 3.2917\n",
      "Epoch 14/200\n",
      "87/87 [==============================] - 0s - loss: 3.3453 - val_loss: 3.8343\n",
      "Epoch 15/200\n",
      "87/87 [==============================] - 0s - loss: 3.1901 - val_loss: 2.9333\n",
      "Epoch 16/200\n",
      "87/87 [==============================] - 0s - loss: 3.2353 - val_loss: 2.7913\n",
      "Epoch 17/200\n",
      "87/87 [==============================] - 0s - loss: 3.1830 - val_loss: 3.0230\n",
      "Epoch 18/200\n",
      "87/87 [==============================] - 0s - loss: 3.1369 - val_loss: 2.8083\n",
      "Epoch 19/200\n",
      "87/87 [==============================] - 0s - loss: 3.1164 - val_loss: 2.6448\n",
      "Epoch 20/200\n",
      "87/87 [==============================] - 0s - loss: 3.1752 - val_loss: 2.8199\n",
      "Epoch 21/200\n",
      "87/87 [==============================] - 0s - loss: 3.0786 - val_loss: 2.5575\n",
      "Epoch 22/200\n",
      "87/87 [==============================] - 0s - loss: 3.1433 - val_loss: 2.7392\n",
      "Epoch 23/200\n",
      "87/87 [==============================] - 0s - loss: 3.1300 - val_loss: 3.4470\n",
      "Epoch 24/200\n",
      "87/87 [==============================] - 0s - loss: 3.0021 - val_loss: 3.2493\n",
      "Epoch 25/200\n",
      "87/87 [==============================] - 0s - loss: 3.0587 - val_loss: 2.5686\n",
      "Epoch 26/200\n",
      "87/87 [==============================] - 0s - loss: 3.0230 - val_loss: 2.7783\n",
      "Epoch 27/200\n",
      "87/87 [==============================] - 0s - loss: 2.9597 - val_loss: 3.3181\n",
      "Epoch 28/200\n",
      "87/87 [==============================] - 0s - loss: 3.0040 - val_loss: 3.3613\n",
      "Epoch 29/200\n",
      "87/87 [==============================] - 0s - loss: 2.9448 - val_loss: 2.6055\n",
      "Epoch 30/200\n",
      "87/87 [==============================] - 0s - loss: 2.9523 - val_loss: 2.4556\n",
      "Epoch 31/200\n",
      "87/87 [==============================] - 0s - loss: 2.9113 - val_loss: 2.9050\n",
      "Epoch 32/200\n",
      "87/87 [==============================] - 0s - loss: 2.9082 - val_loss: 2.7796\n",
      "Epoch 33/200\n",
      "87/87 [==============================] - 0s - loss: 2.9351 - val_loss: 3.1958\n",
      "Epoch 34/200\n",
      "87/87 [==============================] - 0s - loss: 2.9196 - val_loss: 2.2075\n",
      "Epoch 35/200\n",
      "87/87 [==============================] - 0s - loss: 2.9153 - val_loss: 2.6485\n",
      "Epoch 36/200\n",
      "87/87 [==============================] - 0s - loss: 2.8503 - val_loss: 2.9358\n",
      "Epoch 37/200\n",
      "87/87 [==============================] - 0s - loss: 2.8593 - val_loss: 2.9153\n",
      "Epoch 38/200\n",
      "87/87 [==============================] - 0s - loss: 2.9096 - val_loss: 3.4046\n",
      "Epoch 39/200\n",
      "87/87 [==============================] - 0s - loss: 2.9077 - val_loss: 2.6220\n",
      "Epoch 40/200\n",
      "87/87 [==============================] - 0s - loss: 2.8381 - val_loss: 2.6209\n",
      "Epoch 41/200\n",
      "87/87 [==============================] - 0s - loss: 2.7697 - val_loss: 2.2935\n",
      "Epoch 42/200\n",
      "87/87 [==============================] - 0s - loss: 2.8393 - val_loss: 2.7713\n",
      "Epoch 43/200\n",
      "87/87 [==============================] - 0s - loss: 2.8195 - val_loss: 2.5246\n",
      "Epoch 44/200\n",
      "87/87 [==============================] - 0s - loss: 2.8111 - val_loss: 2.7992\n",
      "Epoch 45/200\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 2.8149\n",
      " Reduced learning rate to 0.01\n",
      "87/87 [==============================] - 1s - loss: 2.7959 - val_loss: 2.7578\n",
      "Epoch 46/200\n",
      "87/87 [==============================] - 0s - loss: 1.8643 - val_loss: 1.7048\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/87 [=======================>......] - ETA: 0s - loss: 1.8629\n",
      " Reduced learning rate to 0.005\n",
      "87/87 [==============================] - 0s - loss: 1.8550 - val_loss: 1.7326\n",
      "Epoch 48/200\n",
      "87/87 [==============================] - 0s - loss: 1.8409 - val_loss: 1.6848\n",
      "Epoch 49/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.8205\n",
      " Reduced learning rate to 0.0025\n",
      "87/87 [==============================] - 0s - loss: 1.8140 - val_loss: 1.7109\n",
      "Epoch 50/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.7956\n",
      " Reduced learning rate to 0.00125\n",
      "87/87 [==============================] - 0s - loss: 1.7991 - val_loss: 1.7124\n",
      "Epoch 51/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.8253\n",
      " Reduced learning rate to 0.000625\n",
      "87/87 [==============================] - 0s - loss: 1.8275 - val_loss: 1.7563\n",
      "Epoch 52/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8543\n",
      " Reduced learning rate to 0.0003125\n",
      "87/87 [==============================] - 0s - loss: 1.8422 - val_loss: 1.7217\n",
      "Epoch 53/200\n",
      "73/87 [========================>.....] - ETA: 0s - loss: 1.8337\n",
      " Reduced learning rate to 0.00015625\n",
      "87/87 [==============================] - 0s - loss: 1.8420 - val_loss: 1.7594\n",
      "Epoch 54/200\n",
      "87/87 [==============================] - 0s - loss: 1.8169 - val_loss: 1.6699\n",
      "Epoch 55/200\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 1.8344\n",
      " Reduced learning rate to 7.8125e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8329 - val_loss: 1.7176\n",
      "Epoch 56/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.8502\n",
      " Reduced learning rate to 3.90625e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8491 - val_loss: 1.7221\n",
      "Epoch 57/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.8605\n",
      " Reduced learning rate to 1.95312e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8513 - val_loss: 1.6846\n",
      "Epoch 58/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8483\n",
      " Reduced learning rate to 9.76562e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8356 - val_loss: 1.7092\n",
      "Epoch 59/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8123\n",
      " Reduced learning rate to 4.88281e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8234 - val_loss: 1.6865\n",
      "Epoch 60/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.8497\n",
      " Reduced learning rate to 2.44141e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8373 - val_loss: 1.7053\n",
      "Epoch 61/200\n",
      "77/87 [=========================>....] - ETA: 0s - loss: 1.8395\n",
      " Reduced learning rate to 1.2207e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8291 - val_loss: 1.7133\n",
      "Epoch 62/200\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 1.8522\n",
      " Reduced learning rate to 6.10352e-07\n",
      "87/87 [==============================] - 0s - loss: 1.8424 - val_loss: 1.6986\n",
      "Epoch 1/200\n",
      "87/87 [==============================] - 2s - loss: 56.1248 - val_loss: 9.5964\n",
      "Epoch 2/200\n",
      "87/87 [==============================] - 0s - loss: 6.2104 - val_loss: 4.1397\n",
      "Epoch 3/200\n",
      "87/87 [==============================] - 0s - loss: 4.0527 - val_loss: 3.2078\n",
      "Epoch 4/200\n",
      "87/87 [==============================] - 0s - loss: 3.6124 - val_loss: 2.8820\n",
      "Epoch 5/200\n",
      "87/87 [==============================] - 0s - loss: 3.3617 - val_loss: 2.7933\n",
      "Epoch 6/200\n",
      "87/87 [==============================] - 0s - loss: 3.3690 - val_loss: 2.8808\n",
      "Epoch 7/200\n",
      "87/87 [==============================] - 0s - loss: 3.4126 - val_loss: 3.1533\n",
      "Epoch 8/200\n",
      "87/87 [==============================] - 0s - loss: 3.3526 - val_loss: 3.1328\n",
      "Epoch 9/200\n",
      "87/87 [==============================] - 0s - loss: 3.3233 - val_loss: 3.0344\n",
      "Epoch 10/200\n",
      "87/87 [==============================] - 0s - loss: 3.3271 - val_loss: 3.8907\n",
      "Epoch 11/200\n",
      "87/87 [==============================] - 0s - loss: 3.2838 - val_loss: 2.8181\n",
      "Epoch 12/200\n",
      "87/87 [==============================] - 0s - loss: 3.3486 - val_loss: 2.6304\n",
      "Epoch 13/200\n",
      "87/87 [==============================] - 0s - loss: 3.2473 - val_loss: 3.1218\n",
      "Epoch 14/200\n",
      "87/87 [==============================] - 0s - loss: 3.2389 - val_loss: 3.0972\n",
      "Epoch 15/200\n",
      "87/87 [==============================] - 0s - loss: 3.1730 - val_loss: 3.5156\n",
      "Epoch 16/200\n",
      "87/87 [==============================] - 0s - loss: 3.2182 - val_loss: 2.8608\n",
      "Epoch 17/200\n",
      "87/87 [==============================] - 0s - loss: 3.1458 - val_loss: 2.6926\n",
      "Epoch 18/200\n",
      "87/87 [==============================] - 0s - loss: 3.0875 - val_loss: 2.7917\n",
      "Epoch 19/200\n",
      "87/87 [==============================] - 0s - loss: 3.1033 - val_loss: 3.0340\n",
      "Epoch 20/200\n",
      "87/87 [==============================] - 0s - loss: 3.1307 - val_loss: 2.8203\n",
      "Epoch 21/200\n",
      "87/87 [==============================] - 0s - loss: 3.1561 - val_loss: 2.6875\n",
      "Epoch 22/200\n",
      "87/87 [==============================] - 0s - loss: 3.0714 - val_loss: 2.4991\n",
      "Epoch 23/200\n",
      "87/87 [==============================] - 0s - loss: 2.9918 - val_loss: 2.6096\n",
      "Epoch 24/200\n",
      "87/87 [==============================] - 0s - loss: 3.1529 - val_loss: 3.1726\n",
      "Epoch 25/200\n",
      "87/87 [==============================] - 0s - loss: 2.9308 - val_loss: 2.9260\n",
      "Epoch 26/200\n",
      "87/87 [==============================] - 0s - loss: 3.0003 - val_loss: 3.2151\n",
      "Epoch 27/200\n",
      "87/87 [==============================] - 0s - loss: 3.0060 - val_loss: 2.6547\n",
      "Epoch 28/200\n",
      "87/87 [==============================] - 0s - loss: 2.9747 - val_loss: 2.7842\n",
      "Epoch 29/200\n",
      "87/87 [==============================] - 0s - loss: 2.9128 - val_loss: 2.9403\n",
      "Epoch 30/200\n",
      "87/87 [==============================] - 0s - loss: 2.9227 - val_loss: 2.3806\n",
      "Epoch 31/200\n",
      "87/87 [==============================] - 0s - loss: 2.9903 - val_loss: 2.7861\n",
      "Epoch 32/200\n",
      "87/87 [==============================] - 0s - loss: 2.9139 - val_loss: 2.5179\n",
      "Epoch 33/200\n",
      "87/87 [==============================] - 0s - loss: 2.9434 - val_loss: 2.7412\n",
      "Epoch 34/200\n",
      "87/87 [==============================] - 0s - loss: 2.9186 - val_loss: 2.4673\n",
      "Epoch 35/200\n",
      "87/87 [==============================] - 0s - loss: 2.8450 - val_loss: 2.4199\n",
      "Epoch 36/200\n",
      "87/87 [==============================] - 0s - loss: 2.8525 - val_loss: 2.7537\n",
      "Epoch 37/200\n",
      "87/87 [==============================] - 0s - loss: 2.7546 - val_loss: 2.6153\n",
      "Epoch 38/200\n",
      "87/87 [==============================] - 0s - loss: 2.8376 - val_loss: 2.5563\n",
      "Epoch 39/200\n",
      "87/87 [==============================] - 0s - loss: 2.8582 - val_loss: 2.5703\n",
      "Epoch 40/200\n",
      "87/87 [==============================] - 0s - loss: 2.8618 - val_loss: 2.6289\n",
      "Epoch 41/200\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 2.7991\n",
      " Reduced learning rate to 0.01\n",
      "87/87 [==============================] - 1s - loss: 2.7917 - val_loss: 3.1254\n",
      "Epoch 42/200\n",
      "87/87 [==============================] - 0s - loss: 1.8860 - val_loss: 1.7278\n",
      "Epoch 43/200\n",
      "87/87 [==============================] - 0s - loss: 1.8791 - val_loss: 1.7015\n",
      "Epoch 44/200\n",
      "87/87 [==============================] - 0s - loss: 1.8629 - val_loss: 1.6996\n",
      "Epoch 45/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8008\n",
      " Reduced learning rate to 0.005\n",
      "87/87 [==============================] - 0s - loss: 1.7969 - val_loss: 1.7320\n",
      "Epoch 46/200\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 1.8155\n",
      " Reduced learning rate to 0.0025\n",
      "87/87 [==============================] - 0s - loss: 1.8143 - val_loss: 1.7491\n",
      "Epoch 47/200\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 1.8314\n",
      " Reduced learning rate to 0.00125\n",
      "87/87 [==============================] - 0s - loss: 1.8284 - val_loss: 1.7098\n",
      "Epoch 48/200\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 1.8500\n",
      " Reduced learning rate to 0.000625\n",
      "87/87 [==============================] - 0s - loss: 1.8517 - val_loss: 1.7151\n",
      "Epoch 49/200\n",
      "87/87 [==============================] - 0s - loss: 1.8372 - val_loss: 1.6913\n",
      "Epoch 50/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8483\n",
      " Reduced learning rate to 0.0003125\n",
      "87/87 [==============================] - 0s - loss: 1.8413 - val_loss: 1.7184\n",
      "Epoch 51/200\n",
      "87/87 [==============================] - 0s - loss: 1.7850 - val_loss: 1.6713\n",
      "Epoch 52/200\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 1.8091\n",
      " Reduced learning rate to 0.00015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s - loss: 1.8076 - val_loss: 1.7297\n",
      "Epoch 53/200\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 1.8333- ETA: 0s - loss: 1.\n",
      " Reduced learning rate to 7.8125e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8562 - val_loss: 1.7000\n",
      "Epoch 54/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.8345\n",
      " Reduced learning rate to 3.90625e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8227 - val_loss: 1.7090\n",
      "Epoch 55/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.8059\n",
      " Reduced learning rate to 1.95312e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8593 - val_loss: 1.7275\n",
      "Epoch 56/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.8093\n",
      " Reduced learning rate to 9.76562e-06\n",
      "87/87 [==============================] - 0s - loss: 1.7999 - val_loss: 1.6958\n",
      "Epoch 57/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8759\n",
      " Reduced learning rate to 4.88281e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8639 - val_loss: 1.7028\n",
      "Epoch 58/200\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 1.8573\n",
      " Reduced learning rate to 2.44141e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8558 - val_loss: 1.7091\n",
      "Epoch 59/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.7937\n",
      " Reduced learning rate to 1.2207e-06\n",
      "87/87 [==============================] - 0s - loss: 1.7941 - val_loss: 1.7235\n",
      "Epoch 60/200\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 1.8708\n",
      " Reduced learning rate to 6.10352e-07\n",
      "87/87 [==============================] - 0s - loss: 1.8709 - val_loss: 1.7149\n",
      "Epoch 1/200\n",
      "87/87 [==============================] - 2s - loss: 58.0004 - val_loss: 9.4082\n",
      "Epoch 2/200\n",
      "87/87 [==============================] - 0s - loss: 6.5839 - val_loss: 4.3371\n",
      "Epoch 3/200\n",
      "87/87 [==============================] - 0s - loss: 4.1597 - val_loss: 3.2134\n",
      "Epoch 4/200\n",
      "87/87 [==============================] - 0s - loss: 3.5097 - val_loss: 2.7803\n",
      "Epoch 5/200\n",
      "87/87 [==============================] - 0s - loss: 3.4061 - val_loss: 3.1693\n",
      "Epoch 6/200\n",
      "87/87 [==============================] - 0s - loss: 3.4334 - val_loss: 3.3875\n",
      "Epoch 7/200\n",
      "87/87 [==============================] - 0s - loss: 3.4180 - val_loss: 3.0389\n",
      "Epoch 8/200\n",
      "87/87 [==============================] - 0s - loss: 3.3326 - val_loss: 3.4247\n",
      "Epoch 9/200\n",
      "87/87 [==============================] - 0s - loss: 3.3512 - val_loss: 3.1965\n",
      "Epoch 10/200\n",
      "87/87 [==============================] - 0s - loss: 3.4150 - val_loss: 2.8798\n",
      "Epoch 11/200\n",
      "87/87 [==============================] - 0s - loss: 3.3566 - val_loss: 3.3533\n",
      "Epoch 12/200\n",
      "87/87 [==============================] - 0s - loss: 3.2895 - val_loss: 2.6161\n",
      "Epoch 13/200\n",
      "87/87 [==============================] - 0s - loss: 3.2343 - val_loss: 2.9417\n",
      "Epoch 14/200\n",
      "87/87 [==============================] - 0s - loss: 3.2918 - val_loss: 3.0911\n",
      "Epoch 15/200\n",
      "87/87 [==============================] - 0s - loss: 3.2127 - val_loss: 2.7024\n",
      "Epoch 16/200\n",
      "87/87 [==============================] - 0s - loss: 3.1797 - val_loss: 3.2981\n",
      "Epoch 17/200\n",
      "87/87 [==============================] - 0s - loss: 3.1476 - val_loss: 2.6297\n",
      "Epoch 18/200\n",
      "87/87 [==============================] - 0s - loss: 3.1123 - val_loss: 3.1120\n",
      "Epoch 19/200\n",
      "87/87 [==============================] - 0s - loss: 3.1148 - val_loss: 3.2430\n",
      "Epoch 20/200\n",
      "87/87 [==============================] - 0s - loss: 3.1131 - val_loss: 3.3406\n",
      "Epoch 21/200\n",
      "87/87 [==============================] - 0s - loss: 3.1997 - val_loss: 2.8290\n",
      "Epoch 22/200\n",
      "87/87 [==============================] - 0s - loss: 3.0788 - val_loss: 2.1383\n",
      "Epoch 23/200\n",
      "87/87 [==============================] - 0s - loss: 2.9792 - val_loss: 3.0224\n",
      "Epoch 24/200\n",
      "87/87 [==============================] - 0s - loss: 3.0395 - val_loss: 2.8223\n",
      "Epoch 25/200\n",
      "87/87 [==============================] - 0s - loss: 3.0701 - val_loss: 2.8914\n",
      "Epoch 26/200\n",
      "87/87 [==============================] - 0s - loss: 3.0660 - val_loss: 3.1831\n",
      "Epoch 27/200\n",
      "87/87 [==============================] - 0s - loss: 2.9956 - val_loss: 2.3718\n",
      "Epoch 28/200\n",
      "87/87 [==============================] - 0s - loss: 3.0285 - val_loss: 2.5400\n",
      "Epoch 29/200\n",
      "87/87 [==============================] - 0s - loss: 2.8863 - val_loss: 2.6924\n",
      "Epoch 30/200\n",
      "87/87 [==============================] - 0s - loss: 3.0045 - val_loss: 2.7048\n",
      "Epoch 31/200\n",
      "87/87 [==============================] - 0s - loss: 2.9280 - val_loss: 2.8913\n",
      "Epoch 32/200\n",
      "87/87 [==============================] - 0s - loss: 2.9283 - val_loss: 2.3384\n",
      "Epoch 33/200\n",
      "85/87 [============================>.] - ETA: 0s - loss: 2.9550\n",
      " Reduced learning rate to 0.01\n",
      "87/87 [==============================] - 1s - loss: 2.9481 - val_loss: 2.8906\n",
      "Epoch 34/200\n",
      "87/87 [==============================] - 0s - loss: 1.9180 - val_loss: 1.7668\n",
      "Epoch 35/200\n",
      "87/87 [==============================] - 0s - loss: 1.9075 - val_loss: 1.7632\n",
      "Epoch 36/200\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 1.8602\n",
      " Reduced learning rate to 0.005\n",
      "87/87 [==============================] - 0s - loss: 1.8594 - val_loss: 1.7750\n",
      "Epoch 37/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8942\n",
      " Reduced learning rate to 0.0025\n",
      "87/87 [==============================] - 0s - loss: 1.8902 - val_loss: 1.7936\n",
      "Epoch 38/200\n",
      "87/87 [==============================] - 0s - loss: 1.8525 - val_loss: 1.7299\n",
      "Epoch 39/200\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 1.8447\n",
      " Reduced learning rate to 0.00125\n",
      "87/87 [==============================] - 0s - loss: 1.8367 - val_loss: 1.7691\n",
      "Epoch 40/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.9397\n",
      " Reduced learning rate to 0.000625\n",
      "87/87 [==============================] - 0s - loss: 1.9380 - val_loss: 1.7580\n",
      "Epoch 41/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.8927\n",
      " Reduced learning rate to 0.0003125\n",
      "87/87 [==============================] - 0s - loss: 1.8884 - val_loss: 1.7548\n",
      "Epoch 42/200\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 1.9486\n",
      " Reduced learning rate to 0.00015625\n",
      "87/87 [==============================] - 0s - loss: 1.9468 - val_loss: 1.7395\n",
      "Epoch 43/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.8841\n",
      " Reduced learning rate to 7.8125e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8840 - val_loss: 1.7427\n",
      "Epoch 44/200\n",
      "87/87 [==============================] - 0s - loss: 1.8889 - val_loss: 1.7273\n",
      "Epoch 45/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.9009\n",
      " Reduced learning rate to 3.90625e-05\n",
      "87/87 [==============================] - 0s - loss: 1.8987 - val_loss: 1.7517\n",
      "Epoch 46/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.9353\n",
      " Reduced learning rate to 1.95312e-05\n",
      "87/87 [==============================] - 0s - loss: 1.9128 - val_loss: 1.7625\n",
      "Epoch 47/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.8739\n",
      " Reduced learning rate to 9.76562e-06\n",
      "87/87 [==============================] - 0s - loss: 1.9069 - val_loss: 1.7313\n",
      "Epoch 48/200\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 1.8296\n",
      " Reduced learning rate to 4.88281e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8315 - val_loss: 1.7312\n",
      "Epoch 49/200\n",
      "87/87 [==============================] - 0s - loss: 1.9238 - val_loss: 1.7229\n",
      "Epoch 50/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.8339\n",
      " Reduced learning rate to 2.44141e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8344 - val_loss: 1.7588\n",
      "Epoch 51/200\n",
      "87/87 [==============================] - 0s - loss: 1.8876 - val_loss: 1.7169\n",
      "Epoch 52/200\n",
      "87/87 [==============================] - 0s - loss: 1.8932 - val_loss: 1.7044\n",
      "Epoch 53/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.8579\n",
      " Reduced learning rate to 1.2207e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8596 - val_loss: 1.7488\n",
      "Epoch 54/200\n",
      "87/87 [==============================] - 0s - loss: 1.8778 - val_loss: 1.6876\n",
      "Epoch 55/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.9223\n",
      " Reduced learning rate to 6.10352e-07\n",
      "87/87 [==============================] - 0s - loss: 1.9266 - val_loss: 1.7440\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s - loss: 56.4123 - val_loss: 8.5665\n",
      "Epoch 2/200\n",
      "87/87 [==============================] - 0s - loss: 6.1947 - val_loss: 4.1014\n",
      "Epoch 3/200\n",
      "87/87 [==============================] - 0s - loss: 4.0848 - val_loss: 3.2363\n",
      "Epoch 4/200\n",
      "87/87 [==============================] - 0s - loss: 3.5116 - val_loss: 2.7738\n",
      "Epoch 5/200\n",
      "87/87 [==============================] - 0s - loss: 3.2412 - val_loss: 3.2110\n",
      "Epoch 6/200\n",
      "87/87 [==============================] - 0s - loss: 3.3105 - val_loss: 3.0291\n",
      "Epoch 7/200\n",
      "87/87 [==============================] - 0s - loss: 3.3820 - val_loss: 2.8770\n",
      "Epoch 8/200\n",
      "87/87 [==============================] - 0s - loss: 3.3896 - val_loss: 3.3960\n",
      "Epoch 9/200\n",
      "87/87 [==============================] - 0s - loss: 3.3336 - val_loss: 3.1633\n",
      "Epoch 10/200\n",
      "87/87 [==============================] - 0s - loss: 3.3335 - val_loss: 3.4192\n",
      "Epoch 11/200\n",
      "87/87 [==============================] - 0s - loss: 3.3180 - val_loss: 3.2432\n",
      "Epoch 12/200\n",
      "87/87 [==============================] - 0s - loss: 3.2909 - val_loss: 3.2419\n",
      "Epoch 13/200\n",
      "87/87 [==============================] - 0s - loss: 3.2679 - val_loss: 2.9885\n",
      "Epoch 14/200\n",
      "87/87 [==============================] - 0s - loss: 3.3141 - val_loss: 2.6572\n",
      "Epoch 15/200\n",
      "87/87 [==============================] - 0s - loss: 3.1568 - val_loss: 3.0374\n",
      "Epoch 16/200\n",
      "87/87 [==============================] - 0s - loss: 3.2374 - val_loss: 2.9614\n",
      "Epoch 17/200\n",
      "87/87 [==============================] - 0s - loss: 3.1187 - val_loss: 3.1385\n",
      "Epoch 18/200\n",
      "87/87 [==============================] - 0s - loss: 3.2080 - val_loss: 2.8132\n",
      "Epoch 19/200\n",
      "87/87 [==============================] - 0s - loss: 3.0719 - val_loss: 3.2070\n",
      "Epoch 20/200\n",
      "87/87 [==============================] - 0s - loss: 3.1234 - val_loss: 2.9302\n",
      "Epoch 21/200\n",
      "87/87 [==============================] - 0s - loss: 3.0919 - val_loss: 3.2531\n",
      "Epoch 22/200\n",
      "87/87 [==============================] - 0s - loss: 3.0582 - val_loss: 3.4886\n",
      "Epoch 23/200\n",
      "87/87 [==============================] - 0s - loss: 3.1155 - val_loss: 3.1946\n",
      "Epoch 24/200\n",
      "87/87 [==============================] - 0s - loss: 3.0979 - val_loss: 2.5104\n",
      "Epoch 25/200\n",
      "87/87 [==============================] - 0s - loss: 3.0705 - val_loss: 2.6821\n",
      "Epoch 26/200\n",
      "87/87 [==============================] - 0s - loss: 2.9914 - val_loss: 3.2815\n",
      "Epoch 27/200\n",
      "87/87 [==============================] - 0s - loss: 3.0178 - val_loss: 3.5359\n",
      "Epoch 28/200\n",
      "87/87 [==============================] - 0s - loss: 2.9945 - val_loss: 3.4651\n",
      "Epoch 29/200\n",
      "87/87 [==============================] - 0s - loss: 3.0069 - val_loss: 3.1577\n",
      "Epoch 30/200\n",
      "87/87 [==============================] - 0s - loss: 2.9162 - val_loss: 2.7727\n",
      "Epoch 31/200\n",
      "87/87 [==============================] - 0s - loss: 2.9636 - val_loss: 2.6784\n",
      "Epoch 32/200\n",
      "87/87 [==============================] - 0s - loss: 2.9080 - val_loss: 2.4189\n",
      "Epoch 33/200\n",
      "87/87 [==============================] - 0s - loss: 2.9346 - val_loss: 3.0987\n",
      "Epoch 34/200\n",
      "87/87 [==============================] - 0s - loss: 2.8704 - val_loss: 2.5838\n",
      "Epoch 35/200\n",
      "87/87 [==============================] - 0s - loss: 2.9571 - val_loss: 2.8796\n",
      "Epoch 36/200\n",
      "87/87 [==============================] - 0s - loss: 2.9816 - val_loss: 3.3161\n",
      "Epoch 37/200\n",
      "87/87 [==============================] - 0s - loss: 2.8680 - val_loss: 2.8772\n",
      "Epoch 38/200\n",
      "87/87 [==============================] - 0s - loss: 2.9043 - val_loss: 3.2010\n",
      "Epoch 39/200\n",
      "87/87 [==============================] - 0s - loss: 2.8791 - val_loss: 2.3467\n",
      "Epoch 40/200\n",
      "87/87 [==============================] - 0s - loss: 2.8250 - val_loss: 2.5627\n",
      "Epoch 41/200\n",
      "87/87 [==============================] - 0s - loss: 2.8457 - val_loss: 2.7966\n",
      "Epoch 42/200\n",
      "87/87 [==============================] - 0s - loss: 2.7633 - val_loss: 2.3813\n",
      "Epoch 43/200\n",
      "87/87 [==============================] - 0s - loss: 2.7859 - val_loss: 2.5775\n",
      "Epoch 44/200\n",
      "87/87 [==============================] - 0s - loss: 2.8021 - val_loss: 2.8118\n",
      "Epoch 45/200\n",
      "87/87 [==============================] - 0s - loss: 2.7985 - val_loss: 2.8123\n",
      "Epoch 46/200\n",
      "87/87 [==============================] - 0s - loss: 2.7390 - val_loss: 2.6599\n",
      "Epoch 47/200\n",
      "87/87 [==============================] - 0s - loss: 2.7865 - val_loss: 2.8437\n",
      "Epoch 48/200\n",
      "87/87 [==============================] - 0s - loss: 2.7750 - val_loss: 2.1363\n",
      "Epoch 49/200\n",
      "87/87 [==============================] - 0s - loss: 2.6978 - val_loss: 3.1206\n",
      "Epoch 50/200\n",
      "87/87 [==============================] - 0s - loss: 2.6902 - val_loss: 2.4968\n",
      "Epoch 51/200\n",
      "87/87 [==============================] - 0s - loss: 2.6704 - val_loss: 2.3773\n",
      "Epoch 52/200\n",
      "87/87 [==============================] - 0s - loss: 2.6747 - val_loss: 2.5083\n",
      "Epoch 53/200\n",
      "87/87 [==============================] - 0s - loss: 2.6443 - val_loss: 3.3996\n",
      "Epoch 54/200\n",
      "87/87 [==============================] - 0s - loss: 2.6505 - val_loss: 2.4391\n",
      "Epoch 55/200\n",
      "87/87 [==============================] - 0s - loss: 2.7111 - val_loss: 2.6396\n",
      "Epoch 56/200\n",
      "87/87 [==============================] - 0s - loss: 2.7144 - val_loss: 2.9172\n",
      "Epoch 57/200\n",
      "87/87 [==============================] - 0s - loss: 2.6725 - val_loss: 2.7093\n",
      "Epoch 58/200\n",
      "87/87 [==============================] - 0s - loss: 2.6458 - val_loss: 2.3306\n",
      "Epoch 59/200\n",
      "87/87 [==============================] - 0s - loss: 2.6534 - val_loss: 2.0121\n",
      "Epoch 60/200\n",
      "87/87 [==============================] - 0s - loss: 2.7144 - val_loss: 2.4705\n",
      "Epoch 61/200\n",
      "87/87 [==============================] - 0s - loss: 2.6009 - val_loss: 2.4859\n",
      "Epoch 62/200\n",
      "87/87 [==============================] - 0s - loss: 2.6105 - val_loss: 2.6275\n",
      "Epoch 63/200\n",
      "87/87 [==============================] - 0s - loss: 2.5546 - val_loss: 2.4204\n",
      "Epoch 64/200\n",
      "87/87 [==============================] - 0s - loss: 2.6186 - val_loss: 2.4262\n",
      "Epoch 65/200\n",
      "87/87 [==============================] - 0s - loss: 2.6105 - val_loss: 2.5312\n",
      "Epoch 66/200\n",
      "87/87 [==============================] - 0s - loss: 2.5920 - val_loss: 2.2609\n",
      "Epoch 67/200\n",
      "87/87 [==============================] - 0s - loss: 2.5477 - val_loss: 2.5540\n",
      "Epoch 68/200\n",
      "87/87 [==============================] - 0s - loss: 2.5991 - val_loss: 2.0979\n",
      "Epoch 69/200\n",
      "87/87 [==============================] - 0s - loss: 2.6080 - val_loss: 2.7185\n",
      "Epoch 70/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 2.5321\n",
      " Reduced learning rate to 0.01\n",
      "87/87 [==============================] - 1s - loss: 2.5468 - val_loss: 2.3922\n",
      "Epoch 71/200\n",
      "87/87 [==============================] - 0s - loss: 1.8115 - val_loss: 1.6883\n",
      "Epoch 72/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.7722\n",
      " Reduced learning rate to 0.005\n",
      "87/87 [==============================] - 0s - loss: 1.7787 - val_loss: 1.7213\n",
      "Epoch 73/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.7871\n",
      " Reduced learning rate to 0.0025\n",
      "87/87 [==============================] - 0s - loss: 1.7911 - val_loss: 1.6922\n",
      "Epoch 74/200\n",
      "87/87 [==============================] - 0s - loss: 1.7670 - val_loss: 1.6597\n",
      "Epoch 75/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.7847\n",
      " Reduced learning rate to 0.00125\n",
      "87/87 [==============================] - 0s - loss: 1.7863 - val_loss: 1.7193\n",
      "Epoch 76/200\n",
      "85/87 [============================>.] - ETA: 0s - loss: 1.7937\n",
      " Reduced learning rate to 0.000625\n",
      "87/87 [==============================] - 0s - loss: 1.7888 - val_loss: 1.6721\n",
      "Epoch 77/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.7896\n",
      " Reduced learning rate to 0.0003125\n",
      "87/87 [==============================] - 0s - loss: 1.7797 - val_loss: 1.6941\n",
      "Epoch 78/200\n",
      "87/87 [==============================] - 0s - loss: 1.7642 - val_loss: 1.6563\n",
      "Epoch 79/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.7889\n",
      " Reduced learning rate to 0.00015625\n",
      "87/87 [==============================] - 0s - loss: 1.7752 - val_loss: 1.6615\n",
      "Epoch 80/200\n",
      "71/87 [=======================>......] - ETA: 0s - loss: 1.8115\n",
      " Reduced learning rate to 7.8125e-05\n",
      "87/87 [==============================] - 0s - loss: 1.7964 - val_loss: 1.6760\n",
      "Epoch 81/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.7466\n",
      " Reduced learning rate to 3.90625e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s - loss: 1.7552 - val_loss: 1.6706\n",
      "Epoch 82/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.7703\n",
      " Reduced learning rate to 1.95312e-05\n",
      "87/87 [==============================] - 0s - loss: 1.7650 - val_loss: 1.7091\n",
      "Epoch 83/200\n",
      "72/87 [=======================>......] - ETA: 0s - loss: 1.8068\n",
      " Reduced learning rate to 9.76562e-06\n",
      "87/87 [==============================] - 0s - loss: 1.8196 - val_loss: 1.6698\n",
      "Epoch 84/200\n",
      "85/87 [============================>.] - ETA: 0s - loss: 1.7504\n",
      " Reduced learning rate to 4.88281e-06\n",
      "87/87 [==============================] - 0s - loss: 1.7512 - val_loss: 1.6757\n",
      "Epoch 85/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.7845\n",
      " Reduced learning rate to 2.44141e-06\n",
      "87/87 [==============================] - 0s - loss: 1.7850 - val_loss: 1.6912\n",
      "Epoch 86/200\n",
      "86/87 [============================>.] - ETA: 0s - loss: 1.7809\n",
      " Reduced learning rate to 1.2207e-06\n",
      "87/87 [==============================] - 0s - loss: 1.7817 - val_loss: 1.6947\n",
      "Epoch 87/200\n",
      "70/87 [=======================>......] - ETA: 0s - loss: 1.8356\n",
      " Reduced learning rate to 6.10352e-07\n",
      "87/87 [==============================] - 0s - loss: 1.8350 - val_loss: 1.6777\n",
      "Epoch 1/200\n",
      "175/175 [==============================] - 2s - loss: 32.7186 - val_loss: 4.6544\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 0s - loss: 3.9102 - val_loss: 3.2544\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 0s - loss: 3.3419 - val_loss: 3.6221\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 0s - loss: 3.3777 - val_loss: 3.6645\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 0s - loss: 3.3817 - val_loss: 3.4019\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 0s - loss: 3.3070 - val_loss: 2.9189\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 0s - loss: 3.2870 - val_loss: 3.0078\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 0s - loss: 3.2441 - val_loss: 2.8619\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 0s - loss: 3.1808 - val_loss: 2.7397\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 0s - loss: 3.1412 - val_loss: 3.1006\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 0s - loss: 3.0706 - val_loss: 2.9214\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 0s - loss: 3.0766 - val_loss: 2.8272\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 0s - loss: 3.0462 - val_loss: 2.5879\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 0s - loss: 3.0272 - val_loss: 3.0304\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 0s - loss: 3.0470 - val_loss: 3.0433\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 0s - loss: 2.9640 - val_loss: 2.9595\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 0s - loss: 2.9715 - val_loss: 2.4561\n",
      "Epoch 18/200\n",
      "175/175 [==============================] - 0s - loss: 2.9678 - val_loss: 2.6831\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 0s - loss: 2.8783 - val_loss: 3.5351\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 0s - loss: 2.8676 - val_loss: 2.6754\n",
      "Epoch 21/200\n",
      "175/175 [==============================] - 0s - loss: 2.8421 - val_loss: 2.8549\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 0s - loss: 2.7878 - val_loss: 2.6585\n",
      "Epoch 23/200\n",
      "175/175 [==============================] - 0s - loss: 2.7603 - val_loss: 3.1528\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 0s - loss: 2.8158 - val_loss: 3.2988\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 0s - loss: 2.7240 - val_loss: 2.3429\n",
      "Epoch 26/200\n",
      "175/175 [==============================] - 0s - loss: 2.7233 - val_loss: 2.0791\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 0s - loss: 2.6882 - val_loss: 2.7150\n",
      "Epoch 28/200\n",
      "175/175 [==============================] - 0s - loss: 2.7121 - val_loss: 2.2800\n",
      "Epoch 29/200\n",
      "175/175 [==============================] - 0s - loss: 2.6352 - val_loss: 2.2915\n",
      "Epoch 30/200\n",
      "175/175 [==============================] - 0s - loss: 2.6337 - val_loss: 2.8320\n",
      "Epoch 31/200\n",
      "175/175 [==============================] - 0s - loss: 2.6003 - val_loss: 3.0275\n",
      "Epoch 32/200\n",
      "175/175 [==============================] - 0s - loss: 2.6278 - val_loss: 2.3159\n",
      "Epoch 33/200\n",
      "175/175 [==============================] - 0s - loss: 2.5431 - val_loss: 2.1653\n",
      "Epoch 34/200\n",
      "175/175 [==============================] - 0s - loss: 2.5497 - val_loss: 2.9624\n",
      "Epoch 35/200\n",
      "175/175 [==============================] - 0s - loss: 2.5884 - val_loss: 2.3350\n",
      "Epoch 36/200\n",
      "175/175 [==============================] - 0s - loss: 2.5228 - val_loss: 2.6216\n",
      "Epoch 37/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 2.4951\n",
      " Reduced learning rate to 0.01\n",
      "175/175 [==============================] - 2s - loss: 2.4970 - val_loss: 2.6263\n",
      "Epoch 38/200\n",
      "175/175 [==============================] - 0s - loss: 1.8400 - val_loss: 1.7683\n",
      "Epoch 39/200\n",
      "175/175 [==============================] - 0s - loss: 1.7781 - val_loss: 1.7658\n",
      "Epoch 40/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.7959\n",
      " Reduced learning rate to 0.005\n",
      "175/175 [==============================] - 0s - loss: 1.7936 - val_loss: 1.7683\n",
      "Epoch 41/200\n",
      "175/175 [==============================] - 0s - loss: 1.7817 - val_loss: 1.7459\n",
      "Epoch 42/200\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 1.7801\n",
      " Reduced learning rate to 0.0025\n",
      "175/175 [==============================] - 0s - loss: 1.7768 - val_loss: 1.7463\n",
      "Epoch 43/200\n",
      "175/175 [==============================] - 0s - loss: 1.7806 - val_loss: 1.7324\n",
      "Epoch 44/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 1.7868\n",
      " Reduced learning rate to 0.00125\n",
      "175/175 [==============================] - 0s - loss: 1.7848 - val_loss: 1.7480\n",
      "Epoch 45/200\n",
      "175/175 [==============================] - 0s - loss: 1.7729 - val_loss: 1.7248\n",
      "Epoch 46/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8046\n",
      " Reduced learning rate to 0.000625\n",
      "175/175 [==============================] - 0s - loss: 1.8024 - val_loss: 1.7493\n",
      "Epoch 47/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.7639\n",
      " Reduced learning rate to 0.0003125\n",
      "175/175 [==============================] - 0s - loss: 1.7657 - val_loss: 1.7250\n",
      "Epoch 48/200\n",
      "161/175 [==========================>...] - ETA: 0s - loss: 1.7946\n",
      " Reduced learning rate to 0.00015625\n",
      "175/175 [==============================] - 0s - loss: 1.7962 - val_loss: 1.7344\n",
      "Epoch 49/200\n",
      "163/175 [==========================>...] - ETA: 0s - loss: 1.7802\n",
      " Reduced learning rate to 7.8125e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7767 - val_loss: 1.7352\n",
      "Epoch 50/200\n",
      "175/175 [==============================] - 0s - loss: 1.7444 - val_loss: 1.7121\n",
      "Epoch 51/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.7813\n",
      " Reduced learning rate to 3.90625e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7814 - val_loss: 1.7322\n",
      "Epoch 52/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 1.7569\n",
      " Reduced learning rate to 1.95312e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7568 - val_loss: 1.7342\n",
      "Epoch 53/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.7955\n",
      " Reduced learning rate to 9.76562e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7925 - val_loss: 1.7300\n",
      "Epoch 54/200\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 1.7738\n",
      " Reduced learning rate to 4.88281e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7757 - val_loss: 1.7544\n",
      "Epoch 55/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.7716\n",
      " Reduced learning rate to 2.44141e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7740 - val_loss: 1.7514\n",
      "Epoch 56/200\n",
      "172/175 [============================>.] - ETA: 0s - loss: 1.7620\n",
      " Reduced learning rate to 1.2207e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7623 - val_loss: 1.7432\n",
      "Epoch 57/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 1.8181\n",
      " Reduced learning rate to 6.10352e-07\n",
      "175/175 [==============================] - 0s - loss: 1.8160 - val_loss: 1.7280\n",
      "Epoch 1/200\n",
      "175/175 [==============================] - 2s - loss: 31.0008 - val_loss: 4.3463\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s - loss: 3.8085 - val_loss: 3.5826\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 0s - loss: 3.4109 - val_loss: 3.1605\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 0s - loss: 3.4769 - val_loss: 3.1177\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 0s - loss: 3.3108 - val_loss: 3.2461\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 0s - loss: 3.3680 - val_loss: 3.2648\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 0s - loss: 3.3049 - val_loss: 3.3691\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 0s - loss: 3.2801 - val_loss: 3.0401\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 0s - loss: 3.1810 - val_loss: 3.1416\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 0s - loss: 3.1717 - val_loss: 3.3285\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 0s - loss: 3.1421 - val_loss: 2.4982\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 0s - loss: 3.0890 - val_loss: 3.0273\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 0s - loss: 3.0806 - val_loss: 2.7452\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 0s - loss: 3.0308 - val_loss: 3.0332\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 0s - loss: 2.9469 - val_loss: 2.9649\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 0s - loss: 2.9519 - val_loss: 3.1646\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 0s - loss: 2.9655 - val_loss: 2.7311\n",
      "Epoch 18/200\n",
      "175/175 [==============================] - 0s - loss: 2.8972 - val_loss: 2.6209\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 0s - loss: 2.8902 - val_loss: 2.7808\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 0s - loss: 2.8901 - val_loss: 3.1571\n",
      "Epoch 21/200\n",
      "175/175 [==============================] - 0s - loss: 2.7987 - val_loss: 2.5131\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 0s - loss: 2.7944 - val_loss: 2.2453\n",
      "Epoch 23/200\n",
      "175/175 [==============================] - 0s - loss: 2.7413 - val_loss: 2.6352\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 0s - loss: 2.7864 - val_loss: 2.8727\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 0s - loss: 2.7475 - val_loss: 3.1255\n",
      "Epoch 26/200\n",
      "175/175 [==============================] - 0s - loss: 2.7181 - val_loss: 2.3828\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 0s - loss: 2.6816 - val_loss: 2.5415\n",
      "Epoch 28/200\n",
      "175/175 [==============================] - 0s - loss: 2.7499 - val_loss: 2.6517\n",
      "Epoch 29/200\n",
      "175/175 [==============================] - 0s - loss: 2.6607 - val_loss: 2.5156\n",
      "Epoch 30/200\n",
      "175/175 [==============================] - 0s - loss: 2.6460 - val_loss: 2.8551\n",
      "Epoch 31/200\n",
      "175/175 [==============================] - 0s - loss: 2.6423 - val_loss: 2.8769\n",
      "Epoch 32/200\n",
      "175/175 [==============================] - 0s - loss: 2.5925 - val_loss: 3.0474\n",
      "Epoch 33/200\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 2.6103\n",
      " Reduced learning rate to 0.01\n",
      "175/175 [==============================] - 2s - loss: 2.6085 - val_loss: 2.5936\n",
      "Epoch 34/200\n",
      "175/175 [==============================] - 0s - loss: 1.8146 - val_loss: 1.7717\n",
      "Epoch 35/200\n",
      "167/175 [===========================>..] - ETA: 0s - loss: 1.8124\n",
      " Reduced learning rate to 0.005\n",
      "175/175 [==============================] - 0s - loss: 1.8116 - val_loss: 1.7768\n",
      "Epoch 36/200\n",
      "175/175 [==============================] - 0s - loss: 1.7873 - val_loss: 1.7497\n",
      "Epoch 37/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8089\n",
      " Reduced learning rate to 0.0025\n",
      "175/175 [==============================] - 0s - loss: 1.8072 - val_loss: 1.7598\n",
      "Epoch 38/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.8048\n",
      " Reduced learning rate to 0.00125\n",
      "175/175 [==============================] - 0s - loss: 1.7996 - val_loss: 1.7612\n",
      "Epoch 39/200\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 1.7985\n",
      " Reduced learning rate to 0.000625\n",
      "175/175 [==============================] - 0s - loss: 1.7913 - val_loss: 1.7603\n",
      "Epoch 40/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8176\n",
      " Reduced learning rate to 0.0003125\n",
      "175/175 [==============================] - 0s - loss: 1.8264 - val_loss: 1.7593\n",
      "Epoch 41/200\n",
      "175/175 [==============================] - 0s - loss: 1.7843 - val_loss: 1.7497\n",
      "Epoch 42/200\n",
      "175/175 [==============================] - 0s - loss: 1.7693 - val_loss: 1.7199\n",
      "Epoch 43/200\n",
      "175/175 [==============================] - 0s - loss: 1.7845 - val_loss: 1.7048\n",
      "Epoch 44/200\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 1.7864\n",
      " Reduced learning rate to 0.00015625\n",
      "175/175 [==============================] - 0s - loss: 1.7871 - val_loss: 1.7544\n",
      "Epoch 45/200\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 1.7747\n",
      " Reduced learning rate to 7.8125e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7722 - val_loss: 1.7503\n",
      "Epoch 46/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.7910\n",
      " Reduced learning rate to 3.90625e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7924 - val_loss: 1.7319\n",
      "Epoch 47/200\n",
      "163/175 [==========================>...] - ETA: 0s - loss: 1.8114\n",
      " Reduced learning rate to 1.95312e-05\n",
      "175/175 [==============================] - 0s - loss: 1.8171 - val_loss: 1.7542\n",
      "Epoch 48/200\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 1.7974\n",
      " Reduced learning rate to 9.76562e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7946 - val_loss: 1.7534\n",
      "Epoch 49/200\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 1.7988\n",
      " Reduced learning rate to 4.88281e-06\n",
      "175/175 [==============================] - 0s - loss: 1.8081 - val_loss: 1.7331\n",
      "Epoch 50/200\n",
      "162/175 [==========================>...] - ETA: 0s - loss: 1.7670\n",
      " Reduced learning rate to 2.44141e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7636 - val_loss: 1.7556\n",
      "Epoch 51/200\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 1.7869\n",
      " Reduced learning rate to 1.2207e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7850 - val_loss: 1.7156\n",
      "Epoch 52/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 1.8012\n",
      " Reduced learning rate to 6.10352e-07\n",
      "175/175 [==============================] - 0s - loss: 1.7993 - val_loss: 1.7300\n",
      "Epoch 1/200\n",
      "175/175 [==============================] - 2s - loss: 34.7383 - val_loss: 4.7210\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 0s - loss: 3.9882 - val_loss: 3.2715\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 0s - loss: 3.3712 - val_loss: 3.1851\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 0s - loss: 3.3405 - val_loss: 3.2578\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 0s - loss: 3.3812 - val_loss: 3.3409\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 0s - loss: 3.2833 - val_loss: 2.9633\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 0s - loss: 3.2346 - val_loss: 2.8204\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 0s - loss: 3.1994 - val_loss: 3.3155\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 0s - loss: 3.1661 - val_loss: 3.2232\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 0s - loss: 3.1397 - val_loss: 3.3276\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 0s - loss: 3.0597 - val_loss: 2.6406\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 0s - loss: 3.0166 - val_loss: 3.0864\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 0s - loss: 3.0351 - val_loss: 2.9887\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 0s - loss: 2.9249 - val_loss: 2.3735\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 0s - loss: 2.9443 - val_loss: 3.2617\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 0s - loss: 2.9350 - val_loss: 2.9230\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 0s - loss: 2.9348 - val_loss: 2.6704\n",
      "Epoch 18/200\n",
      "175/175 [==============================] - 0s - loss: 2.8741 - val_loss: 3.2133\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 0s - loss: 2.8331 - val_loss: 2.7061\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 0s - loss: 2.7740 - val_loss: 3.1220\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s - loss: 2.7865 - val_loss: 2.1828\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 0s - loss: 2.7424 - val_loss: 2.3257\n",
      "Epoch 23/200\n",
      "175/175 [==============================] - 0s - loss: 2.7326 - val_loss: 2.7588\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 0s - loss: 2.7330 - val_loss: 2.2108\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 0s - loss: 2.7113 - val_loss: 2.2852\n",
      "Epoch 26/200\n",
      "175/175 [==============================] - 0s - loss: 2.6885 - val_loss: 2.8226\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 0s - loss: 2.6845 - val_loss: 2.8550\n",
      "Epoch 28/200\n",
      "175/175 [==============================] - 0s - loss: 2.6182 - val_loss: 2.7374\n",
      "Epoch 29/200\n",
      "175/175 [==============================] - 0s - loss: 2.6169 - val_loss: 2.0311\n",
      "Epoch 30/200\n",
      "175/175 [==============================] - 0s - loss: 2.6128 - val_loss: 2.4175\n",
      "Epoch 31/200\n",
      "175/175 [==============================] - 0s - loss: 2.5912 - val_loss: 2.7008\n",
      "Epoch 32/200\n",
      "175/175 [==============================] - 0s - loss: 2.5656 - val_loss: 2.3394\n",
      "Epoch 33/200\n",
      "175/175 [==============================] - 0s - loss: 2.5777 - val_loss: 2.4840\n",
      "Epoch 34/200\n",
      "175/175 [==============================] - 0s - loss: 2.5509 - val_loss: 2.5812\n",
      "Epoch 35/200\n",
      "175/175 [==============================] - 0s - loss: 2.5635 - val_loss: 2.0312\n",
      "Epoch 36/200\n",
      "175/175 [==============================] - 0s - loss: 2.5213 - val_loss: 2.3891\n",
      "Epoch 37/200\n",
      "175/175 [==============================] - 0s - loss: 2.5121 - val_loss: 2.3924\n",
      "Epoch 38/200\n",
      "175/175 [==============================] - 0s - loss: 2.5060 - val_loss: 2.5638\n",
      "Epoch 39/200\n",
      "175/175 [==============================] - 0s - loss: 2.4625 - val_loss: 2.3037\n",
      "Epoch 40/200\n",
      "175/175 [==============================] - 0s - loss: 2.4553 - val_loss: 2.0225\n",
      "Epoch 41/200\n",
      "175/175 [==============================] - 0s - loss: 2.4702 - val_loss: 2.2664\n",
      "Epoch 42/200\n",
      "175/175 [==============================] - 0s - loss: 2.4465 - val_loss: 2.2208\n",
      "Epoch 43/200\n",
      "175/175 [==============================] - 0s - loss: 2.4228 - val_loss: 2.4056\n",
      "Epoch 44/200\n",
      "175/175 [==============================] - 0s - loss: 2.4334 - val_loss: 2.1375\n",
      "Epoch 45/200\n",
      "175/175 [==============================] - 0s - loss: 2.3899 - val_loss: 2.4339\n",
      "Epoch 46/200\n",
      "175/175 [==============================] - 0s - loss: 2.3720 - val_loss: 2.3685\n",
      "Epoch 47/200\n",
      "175/175 [==============================] - 0s - loss: 2.3895 - val_loss: 2.9610\n",
      "Epoch 48/200\n",
      "175/175 [==============================] - 0s - loss: 2.3977 - val_loss: 2.3770\n",
      "Epoch 49/200\n",
      "175/175 [==============================] - 0s - loss: 2.3791 - val_loss: 2.7051\n",
      "Epoch 50/200\n",
      "175/175 [==============================] - 0s - loss: 2.3535 - val_loss: 2.2578\n",
      "Epoch 51/200\n",
      "175/175 [==============================] - 0s - loss: 2.3614 - val_loss: 1.9175\n",
      "Epoch 52/200\n",
      "175/175 [==============================] - 0s - loss: 2.3136 - val_loss: 2.0967\n",
      "Epoch 53/200\n",
      "175/175 [==============================] - 0s - loss: 2.3023 - val_loss: 2.6403\n",
      "Epoch 54/200\n",
      "175/175 [==============================] - 0s - loss: 2.2748 - val_loss: 2.3710\n",
      "Epoch 55/200\n",
      "175/175 [==============================] - 0s - loss: 2.2899 - val_loss: 2.2391\n",
      "Epoch 56/200\n",
      "175/175 [==============================] - 0s - loss: 2.2899 - val_loss: 2.0821\n",
      "Epoch 57/200\n",
      "175/175 [==============================] - 0s - loss: 2.2815 - val_loss: 1.9832\n",
      "Epoch 58/200\n",
      "175/175 [==============================] - 0s - loss: 2.2898 - val_loss: 2.1743\n",
      "Epoch 59/200\n",
      "175/175 [==============================] - 0s - loss: 2.2300 - val_loss: 2.3615\n",
      "Epoch 60/200\n",
      "175/175 [==============================] - 0s - loss: 2.2463 - val_loss: 2.2150\n",
      "Epoch 61/200\n",
      "175/175 [==============================] - 0s - loss: 2.2424 - val_loss: 1.9478\n",
      "Epoch 62/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 2.2262\n",
      " Reduced learning rate to 0.01\n",
      "175/175 [==============================] - 2s - loss: 2.2244 - val_loss: 2.1922\n",
      "Epoch 63/200\n",
      "175/175 [==============================] - 0s - loss: 1.7511 - val_loss: 1.7385\n",
      "Epoch 64/200\n",
      "175/175 [==============================] - 0s - loss: 1.7805 - val_loss: 1.7300\n",
      "Epoch 65/200\n",
      "175/175 [==============================] - 0s - loss: 1.7518 - val_loss: 1.7033\n",
      "Epoch 66/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 1.7721\n",
      " Reduced learning rate to 0.005\n",
      "175/175 [==============================] - 0s - loss: 1.7789 - val_loss: 1.7151\n",
      "Epoch 67/200\n",
      "163/175 [==========================>...] - ETA: 0s - loss: 1.7599\n",
      " Reduced learning rate to 0.0025\n",
      "175/175 [==============================] - 0s - loss: 1.7670 - val_loss: 1.7114\n",
      "Epoch 68/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.7200\n",
      " Reduced learning rate to 0.00125\n",
      "175/175 [==============================] - 0s - loss: 1.7191 - val_loss: 1.7037\n",
      "Epoch 69/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.7527\n",
      " Reduced learning rate to 0.000625\n",
      "175/175 [==============================] - 0s - loss: 1.7573 - val_loss: 1.7095\n",
      "Epoch 70/200\n",
      "163/175 [==========================>...] - ETA: 0s - loss: 1.7477\n",
      " Reduced learning rate to 0.0003125\n",
      "175/175 [==============================] - 0s - loss: 1.7507 - val_loss: 1.7167\n",
      "Epoch 71/200\n",
      "162/175 [==========================>...] - ETA: 0s - loss: 1.7387\n",
      " Reduced learning rate to 0.00015625\n",
      "175/175 [==============================] - 0s - loss: 1.7389 - val_loss: 1.7293\n",
      "Epoch 72/200\n",
      "175/175 [==============================] - 0s - loss: 1.7337 - val_loss: 1.6986\n",
      "Epoch 73/200\n",
      "175/175 [==============================] - 0s - loss: 1.7474 - val_loss: 1.6934\n",
      "Epoch 74/200\n",
      "160/175 [==========================>...] - ETA: 0s - loss: 1.7522\n",
      " Reduced learning rate to 7.8125e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7492 - val_loss: 1.7109\n",
      "Epoch 75/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.7377\n",
      " Reduced learning rate to 3.90625e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7412 - val_loss: 1.7110\n",
      "Epoch 76/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.7480\n",
      " Reduced learning rate to 1.95312e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7528 - val_loss: 1.7073\n",
      "Epoch 77/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 1.7603\n",
      " Reduced learning rate to 9.76562e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7598 - val_loss: 1.7107\n",
      "Epoch 78/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.7376\n",
      " Reduced learning rate to 4.88281e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7348 - val_loss: 1.7007\n",
      "Epoch 79/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.7445\n",
      " Reduced learning rate to 2.44141e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7447 - val_loss: 1.7156\n",
      "Epoch 80/200\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 1.7368\n",
      " Reduced learning rate to 1.2207e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7343 - val_loss: 1.7005\n",
      "Epoch 81/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 1.7327\n",
      " Reduced learning rate to 6.10352e-07\n",
      "175/175 [==============================] - 0s - loss: 1.7393 - val_loss: 1.7241\n",
      "Epoch 1/200\n",
      "175/175 [==============================] - 2s - loss: 29.0294 - val_loss: 4.4847\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 0s - loss: 3.7629 - val_loss: 3.1856\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 0s - loss: 3.3758 - val_loss: 3.2964\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 0s - loss: 3.4006 - val_loss: 3.1718\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 0s - loss: 3.3779 - val_loss: 3.2109\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 0s - loss: 3.3249 - val_loss: 3.3476\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 0s - loss: 3.2856 - val_loss: 3.2406\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 0s - loss: 3.1843 - val_loss: 2.5919\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 0s - loss: 3.1342 - val_loss: 3.3534\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 0s - loss: 3.1932 - val_loss: 2.9200\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s - loss: 3.0946 - val_loss: 3.3252\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 0s - loss: 3.0782 - val_loss: 2.7183\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 0s - loss: 3.0101 - val_loss: 3.1368\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 0s - loss: 2.9967 - val_loss: 2.7660\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 0s - loss: 2.9584 - val_loss: 3.6260\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 0s - loss: 2.9254 - val_loss: 3.0482\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 0s - loss: 2.9101 - val_loss: 2.6134\n",
      "Epoch 18/200\n",
      "175/175 [==============================] - 0s - loss: 2.8679 - val_loss: 3.2037\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 0s - loss: 2.9044 - val_loss: 2.5601\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 0s - loss: 2.8517 - val_loss: 2.5396\n",
      "Epoch 21/200\n",
      "175/175 [==============================] - 0s - loss: 2.7942 - val_loss: 2.7067\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 0s - loss: 2.7694 - val_loss: 2.9400\n",
      "Epoch 23/200\n",
      "175/175 [==============================] - 0s - loss: 2.7729 - val_loss: 2.7382\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 0s - loss: 2.7568 - val_loss: 2.3592\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 0s - loss: 2.7161 - val_loss: 2.9152\n",
      "Epoch 26/200\n",
      "175/175 [==============================] - 0s - loss: 2.7448 - val_loss: 2.4756\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 0s - loss: 2.6788 - val_loss: 2.6152\n",
      "Epoch 28/200\n",
      "175/175 [==============================] - 0s - loss: 2.6877 - val_loss: 2.5695\n",
      "Epoch 29/200\n",
      "175/175 [==============================] - 0s - loss: 2.6083 - val_loss: 2.9440\n",
      "Epoch 30/200\n",
      "175/175 [==============================] - 0s - loss: 2.6504 - val_loss: 2.1766\n",
      "Epoch 31/200\n",
      "175/175 [==============================] - 0s - loss: 2.6122 - val_loss: 1.9988\n",
      "Epoch 32/200\n",
      "175/175 [==============================] - 0s - loss: 2.5680 - val_loss: 2.4987\n",
      "Epoch 33/200\n",
      "175/175 [==============================] - 0s - loss: 2.5128 - val_loss: 2.1866\n",
      "Epoch 34/200\n",
      "175/175 [==============================] - 0s - loss: 2.5749 - val_loss: 2.3783\n",
      "Epoch 35/200\n",
      "175/175 [==============================] - 0s - loss: 2.5825 - val_loss: 2.7632\n",
      "Epoch 36/200\n",
      "175/175 [==============================] - 0s - loss: 2.5222 - val_loss: 2.2500\n",
      "Epoch 37/200\n",
      "175/175 [==============================] - 0s - loss: 2.5188 - val_loss: 2.0210\n",
      "Epoch 38/200\n",
      "175/175 [==============================] - 0s - loss: 2.4940 - val_loss: 2.0203\n",
      "Epoch 39/200\n",
      "175/175 [==============================] - 0s - loss: 2.4743 - val_loss: 2.2962\n",
      "Epoch 40/200\n",
      "175/175 [==============================] - 0s - loss: 2.5145 - val_loss: 2.3945\n",
      "Epoch 41/200\n",
      "175/175 [==============================] - 0s - loss: 2.4233 - val_loss: 2.1025\n",
      "Epoch 42/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 2.4552\n",
      " Reduced learning rate to 0.01\n",
      "175/175 [==============================] - 2s - loss: 2.4497 - val_loss: 2.0958\n",
      "Epoch 43/200\n",
      "175/175 [==============================] - 0s - loss: 1.7994 - val_loss: 1.7661\n",
      "Epoch 44/200\n",
      "175/175 [==============================] - 0s - loss: 1.8031 - val_loss: 1.7619\n",
      "Epoch 45/200\n",
      "175/175 [==============================] - 0s - loss: 1.7771 - val_loss: 1.7468\n",
      "Epoch 46/200\n",
      "175/175 [==============================] - 0s - loss: 1.7748 - val_loss: 1.7314\n",
      "Epoch 47/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.7890\n",
      " Reduced learning rate to 0.005\n",
      "175/175 [==============================] - 0s - loss: 1.7899 - val_loss: 1.7503\n",
      "Epoch 48/200\n",
      "175/175 [==============================] - 0s - loss: 1.7716 - val_loss: 1.7308\n",
      "Epoch 49/200\n",
      "175/175 [==============================] - 0s - loss: 1.7642 - val_loss: 1.7114\n",
      "Epoch 50/200\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 1.7668\n",
      " Reduced learning rate to 0.0025\n",
      "175/175 [==============================] - 0s - loss: 1.7686 - val_loss: 1.7337\n",
      "Epoch 51/200\n",
      "164/175 [===========================>..] - ETA: 0s - loss: 1.7704\n",
      " Reduced learning rate to 0.00125\n",
      "175/175 [==============================] - 0s - loss: 1.7730 - val_loss: 1.7318\n",
      "Epoch 52/200\n",
      "175/175 [==============================] - 0s - loss: 1.7399 - val_loss: 1.7048\n",
      "Epoch 53/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.7545\n",
      " Reduced learning rate to 0.000625\n",
      "175/175 [==============================] - 0s - loss: 1.7532 - val_loss: 1.7393\n",
      "Epoch 54/200\n",
      "168/175 [===========================>..] - ETA: 0s - loss: 1.7474\n",
      " Reduced learning rate to 0.0003125\n",
      "175/175 [==============================] - 0s - loss: 1.7488 - val_loss: 1.7073\n",
      "Epoch 55/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.7568\n",
      " Reduced learning rate to 0.00015625\n",
      "175/175 [==============================] - 0s - loss: 1.7566 - val_loss: 1.7100\n",
      "Epoch 56/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 1.7592\n",
      " Reduced learning rate to 7.8125e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7590 - val_loss: 1.7168\n",
      "Epoch 57/200\n",
      "158/175 [==========================>...] - ETA: 0s - loss: 1.7523\n",
      " Reduced learning rate to 3.90625e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7508 - val_loss: 1.7234\n",
      "Epoch 58/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.7623\n",
      " Reduced learning rate to 1.95312e-05\n",
      "175/175 [==============================] - 0s - loss: 1.7660 - val_loss: 1.7190\n",
      "Epoch 59/200\n",
      "172/175 [============================>.] - ETA: 0s - loss: 1.7474\n",
      " Reduced learning rate to 9.76562e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7459 - val_loss: 1.7332\n",
      "Epoch 60/200\n",
      "172/175 [============================>.] - ETA: 0s - loss: 1.7742\n",
      " Reduced learning rate to 4.88281e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7754 - val_loss: 1.7464\n",
      "Epoch 61/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.7636\n",
      " Reduced learning rate to 2.44141e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7618 - val_loss: 1.7371\n",
      "Epoch 62/200\n",
      "175/175 [==============================] - 0s - loss: 1.7663 - val_loss: 1.7006\n",
      "Epoch 63/200\n",
      "165/175 [===========================>..] - ETA: 0s - loss: 1.7661\n",
      " Reduced learning rate to 1.2207e-06\n",
      "175/175 [==============================] - 0s - loss: 1.7654 - val_loss: 1.7344\n",
      "Epoch 64/200\n",
      "172/175 [============================>.] - ETA: 0s - loss: 1.7530\n",
      " Reduced learning rate to 6.10352e-07\n",
      "175/175 [==============================] - 0s - loss: 1.7506 - val_loss: 1.7026\n",
      "Epoch 1/200\n",
      "175/175 [==============================] - 2s - loss: 36.2021 - val_loss: 4.8708\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 0s - loss: 3.9341 - val_loss: 3.5273\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 0s - loss: 3.4579 - val_loss: 3.3457\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 0s - loss: 3.4094 - val_loss: 3.0679\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 0s - loss: 3.2908 - val_loss: 3.1299\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 0s - loss: 3.3257 - val_loss: 3.4126\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 0s - loss: 3.3273 - val_loss: 2.7204\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 0s - loss: 3.1920 - val_loss: 2.9287\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 0s - loss: 3.1455 - val_loss: 2.6020\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 0s - loss: 3.1496 - val_loss: 2.4647\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 0s - loss: 3.1024 - val_loss: 2.9785\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 0s - loss: 3.0803 - val_loss: 3.5030\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 0s - loss: 3.0301 - val_loss: 3.1977\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 0s - loss: 3.0280 - val_loss: 2.6743\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 0s - loss: 2.9508 - val_loss: 2.6515\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 0s - loss: 2.8829 - val_loss: 2.6664\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 0s - loss: 2.9029 - val_loss: 2.6846\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 0s - loss: 2.8972 - val_loss: 2.6861\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 0s - loss: 2.8318 - val_loss: 2.6049\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 0s - loss: 2.8238 - val_loss: 2.5518\n",
      "Epoch 21/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 2.7601\n",
      " Reduced learning rate to 0.01\n",
      "175/175 [==============================] - 2s - loss: 2.7490 - val_loss: 2.6701\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 0s - loss: 1.8782 - val_loss: 1.7983\n",
      "Epoch 23/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8450\n",
      " Reduced learning rate to 0.005\n",
      "175/175 [==============================] - 0s - loss: 1.8430 - val_loss: 1.7993\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 0s - loss: 1.8343 - val_loss: 1.7866\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 0s - loss: 1.8279 - val_loss: 1.7632\n",
      "Epoch 26/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.8208\n",
      " Reduced learning rate to 0.0025\n",
      "175/175 [==============================] - 0s - loss: 1.8251 - val_loss: 1.7753\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 0s - loss: 1.8466 - val_loss: 1.7457\n",
      "Epoch 28/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.8592\n",
      " Reduced learning rate to 0.00125\n",
      "175/175 [==============================] - 0s - loss: 1.8591 - val_loss: 1.7809\n",
      "Epoch 29/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8115\n",
      " Reduced learning rate to 0.000625\n",
      "175/175 [==============================] - 0s - loss: 1.8117 - val_loss: 1.7649\n",
      "Epoch 30/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.7989\n",
      " Reduced learning rate to 0.0003125\n",
      "175/175 [==============================] - 0s - loss: 1.7998 - val_loss: 1.7471\n",
      "Epoch 31/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8293\n",
      " Reduced learning rate to 0.00015625\n",
      "175/175 [==============================] - 0s - loss: 1.8291 - val_loss: 1.7684\n",
      "Epoch 32/200\n",
      "166/175 [===========================>..] - ETA: 0s - loss: 1.8469\n",
      " Reduced learning rate to 7.8125e-05\n",
      "175/175 [==============================] - 0s - loss: 1.8451 - val_loss: 1.7708\n",
      "Epoch 33/200\n",
      "174/175 [============================>.] - ETA: 0s - loss: 1.8542\n",
      " Reduced learning rate to 3.90625e-05\n",
      "175/175 [==============================] - 0s - loss: 1.8563 - val_loss: 1.7637\n",
      "Epoch 34/200\n",
      "174/175 [============================>.] - ETA: 0s - loss: 1.8063\n",
      " Reduced learning rate to 1.95312e-05\n",
      "175/175 [==============================] - 0s - loss: 1.8059 - val_loss: 1.7754\n",
      "Epoch 35/200\n",
      "169/175 [===========================>..] - ETA: 0s - loss: 1.8290\n",
      " Reduced learning rate to 9.76562e-06\n",
      "175/175 [==============================] - 0s - loss: 1.8265 - val_loss: 1.7737\n",
      "Epoch 36/200\n",
      "170/175 [============================>.] - ETA: 0s - loss: 1.8139\n",
      " Reduced learning rate to 4.88281e-06\n",
      "175/175 [==============================] - 0s - loss: 1.8165 - val_loss: 1.7863\n",
      "Epoch 37/200\n",
      "158/175 [==========================>...] - ETA: 0s - loss: 1.8153\n",
      " Reduced learning rate to 2.44141e-06\n",
      "175/175 [==============================] - 0s - loss: 1.8057 - val_loss: 1.7529\n",
      "Epoch 38/200\n",
      "173/175 [============================>.] - ETA: 0s - loss: 1.8390\n",
      " Reduced learning rate to 1.2207e-06\n",
      "175/175 [==============================] - 0s - loss: 1.8384 - val_loss: 1.7910\n",
      "Epoch 39/200\n",
      "171/175 [============================>.] - ETA: 0s - loss: 1.8208\n",
      " Reduced learning rate to 6.10352e-07\n",
      "175/175 [==============================] - 0s - loss: 1.8285 - val_loss: 1.7830\n",
      "Epoch 1/200\n",
      "878/878 [==============================] - 5s - loss: 9.2071 - val_loss: 3.0286\n",
      "Epoch 2/200\n",
      "878/878 [==============================] - 2s - loss: 3.2364 - val_loss: 2.8658\n",
      "Epoch 3/200\n",
      "878/878 [==============================] - 2s - loss: 3.0286 - val_loss: 3.0312\n",
      "Epoch 4/200\n",
      "878/878 [==============================] - 2s - loss: 2.8813 - val_loss: 2.9947\n",
      "Epoch 5/200\n",
      "878/878 [==============================] - 2s - loss: 2.7710 - val_loss: 2.4828\n",
      "Epoch 6/200\n",
      "878/878 [==============================] - 2s - loss: 2.6598 - val_loss: 2.6664\n",
      "Epoch 7/200\n",
      "878/878 [==============================] - 2s - loss: 2.5669 - val_loss: 2.8555\n",
      "Epoch 8/200\n",
      "878/878 [==============================] - 2s - loss: 2.5250 - val_loss: 3.0741\n",
      "Epoch 9/200\n",
      "878/878 [==============================] - 2s - loss: 2.4464 - val_loss: 2.6817\n",
      "Epoch 10/200\n",
      "878/878 [==============================] - 2s - loss: 2.3579 - val_loss: 2.8750\n",
      "Epoch 11/200\n",
      "878/878 [==============================] - 2s - loss: 2.3059 - val_loss: 2.3911\n",
      "Epoch 12/200\n",
      "878/878 [==============================] - 2s - loss: 2.2624 - val_loss: 2.2515\n",
      "Epoch 13/200\n",
      "878/878 [==============================] - 2s - loss: 2.2370 - val_loss: 2.2109\n",
      "Epoch 14/200\n",
      "878/878 [==============================] - 2s - loss: 2.1658 - val_loss: 2.0298\n",
      "Epoch 15/200\n",
      "878/878 [==============================] - 2s - loss: 2.1432 - val_loss: 2.0338\n",
      "Epoch 16/200\n",
      "878/878 [==============================] - 2s - loss: 2.1118 - val_loss: 2.0744\n",
      "Epoch 17/200\n",
      "878/878 [==============================] - 2s - loss: 2.0763 - val_loss: 1.8333\n",
      "Epoch 18/200\n",
      "878/878 [==============================] - 2s - loss: 2.0607 - val_loss: 2.1387\n",
      "Epoch 19/200\n",
      "878/878 [==============================] - 2s - loss: 2.0108 - val_loss: 1.8054\n",
      "Epoch 20/200\n",
      "878/878 [==============================] - 3s - loss: 2.0224 - val_loss: 2.1753\n",
      "Epoch 21/200\n",
      "878/878 [==============================] - 2s - loss: 1.9624 - val_loss: 2.0845\n",
      "Epoch 22/200\n",
      "878/878 [==============================] - 2s - loss: 1.9481 - val_loss: 1.7837\n",
      "Epoch 23/200\n",
      "878/878 [==============================] - 2s - loss: 1.9362 - val_loss: 1.9966\n",
      "Epoch 24/200\n",
      "878/878 [==============================] - 2s - loss: 1.9372 - val_loss: 1.9217\n",
      "Epoch 25/200\n",
      "878/878 [==============================] - 2s - loss: 1.9178 - val_loss: 1.8359\n",
      "Epoch 26/200\n",
      "878/878 [==============================] - 2s - loss: 1.8811 - val_loss: 1.8457\n",
      "Epoch 27/200\n",
      "878/878 [==============================] - 2s - loss: 1.8868 - val_loss: 1.8770\n",
      "Epoch 28/200\n",
      "878/878 [==============================] - 2s - loss: 1.8804 - val_loss: 2.0521\n",
      "Epoch 29/200\n",
      "878/878 [==============================] - 2s - loss: 1.8657 - val_loss: 1.9376\n",
      "Epoch 30/200\n",
      "878/878 [==============================] - 2s - loss: 1.8690 - val_loss: 1.8634\n",
      "Epoch 31/200\n",
      "878/878 [==============================] - 2s - loss: 1.8397 - val_loss: 1.7070\n",
      "Epoch 32/200\n",
      "878/878 [==============================] - 2s - loss: 1.8411 - val_loss: 2.0111\n",
      "Epoch 33/200\n",
      "878/878 [==============================] - 2s - loss: 1.8182 - val_loss: 1.7338\n",
      "Epoch 34/200\n",
      "878/878 [==============================] - 2s - loss: 1.8259 - val_loss: 1.7442\n",
      "Epoch 35/200\n",
      "878/878 [==============================] - 3s - loss: 1.8405 - val_loss: 1.7077\n",
      "Epoch 36/200\n",
      "878/878 [==============================] - 3s - loss: 1.8189 - val_loss: 1.7677\n",
      "Epoch 37/200\n",
      "878/878 [==============================] - 3s - loss: 1.8153 - val_loss: 1.6991\n",
      "Epoch 38/200\n",
      "878/878 [==============================] - 2s - loss: 1.8262 - val_loss: 1.8959\n",
      "Epoch 39/200\n",
      "878/878 [==============================] - 2s - loss: 1.7968 - val_loss: 1.7851\n",
      "Epoch 40/200\n",
      "878/878 [==============================] - 3s - loss: 1.7877 - val_loss: 2.0371\n",
      "Epoch 41/200\n",
      "878/878 [==============================] - 3s - loss: 1.7903 - val_loss: 1.8789\n",
      "Epoch 42/200\n",
      "878/878 [==============================] - 2s - loss: 1.7810 - val_loss: 1.7166\n",
      "Epoch 43/200\n",
      "878/878 [==============================] - 2s - loss: 1.7953 - val_loss: 1.7428\n",
      "Epoch 44/200\n",
      "878/878 [==============================] - 2s - loss: 1.7822 - val_loss: 1.7948\n",
      "Epoch 45/200\n",
      "878/878 [==============================] - 2s - loss: 1.7790 - val_loss: 1.6971\n",
      "Epoch 46/200\n",
      "878/878 [==============================] - 3s - loss: 1.7721 - val_loss: 1.7084\n",
      "Epoch 47/200\n",
      "878/878 [==============================] - 3s - loss: 1.7777 - val_loss: 1.7655\n",
      "Epoch 48/200\n",
      "878/878 [==============================] - 2s - loss: 1.7702 - val_loss: 1.7911\n",
      "Epoch 49/200\n",
      "878/878 [==============================] - 3s - loss: 1.7732 - val_loss: 1.7390\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 3s - loss: 1.7730 - val_loss: 1.8139\n",
      "Epoch 51/200\n",
      "878/878 [==============================] - 2s - loss: 1.7654 - val_loss: 1.8647\n",
      "Epoch 52/200\n",
      "878/878 [==============================] - 2s - loss: 1.7525 - val_loss: 1.8320\n",
      "Epoch 53/200\n",
      "878/878 [==============================] - 2s - loss: 1.7662 - val_loss: 1.7521\n",
      "Epoch 54/200\n",
      "878/878 [==============================] - 2s - loss: 1.7642 - val_loss: 1.7688\n",
      "Epoch 55/200\n",
      "878/878 [==============================] - 2s - loss: 1.7464 - val_loss: 1.7221\n",
      "Epoch 56/200\n",
      "866/878 [============================>.] - ETA: 0s - loss: 1.7697\n",
      " Reduced learning rate to 0.01\n",
      "878/878 [==============================] - 4s - loss: 1.7699 - val_loss: 1.7149\n",
      "Epoch 57/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.6831\n",
      " Reduced learning rate to 0.005\n",
      "878/878 [==============================] - 2s - loss: 1.6834 - val_loss: 1.7043\n",
      "Epoch 58/200\n",
      "870/878 [============================>.] - ETA: 0s - loss: 1.6740\n",
      " Reduced learning rate to 0.0025\n",
      "878/878 [==============================] - 2s - loss: 1.6738 - val_loss: 1.6972\n",
      "Epoch 59/200\n",
      "878/878 [==============================] - 2s - loss: 1.6728 - val_loss: 1.6809\n",
      "Epoch 60/200\n",
      "875/878 [============================>.] - ETA: 0s - loss: 1.6772\n",
      " Reduced learning rate to 0.00125\n",
      "878/878 [==============================] - 3s - loss: 1.6772 - val_loss: 1.6887\n",
      "Epoch 61/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.6823\n",
      " Reduced learning rate to 0.000625\n",
      "878/878 [==============================] - 3s - loss: 1.6826 - val_loss: 1.6914\n",
      "Epoch 62/200\n",
      "870/878 [============================>.] - ETA: 0s - loss: 1.6779\n",
      " Reduced learning rate to 0.0003125\n",
      "878/878 [==============================] - 2s - loss: 1.6778 - val_loss: 1.6863\n",
      "Epoch 63/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.6804\n",
      " Reduced learning rate to 0.00015625\n",
      "878/878 [==============================] - 2s - loss: 1.6804 - val_loss: 1.6843\n",
      "Epoch 64/200\n",
      "874/878 [============================>.] - ETA: 0s - loss: 1.6699\n",
      " Reduced learning rate to 7.8125e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6698 - val_loss: 1.6837\n",
      "Epoch 65/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.6718\n",
      " Reduced learning rate to 3.90625e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6719 - val_loss: 1.6828\n",
      "Epoch 66/200\n",
      "869/878 [============================>.] - ETA: 0s - loss: 1.6758\n",
      " Reduced learning rate to 1.95312e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6758 - val_loss: 1.6895\n",
      "Epoch 67/200\n",
      "862/878 [============================>.] - ETA: 0s - loss: 1.6737\n",
      " Reduced learning rate to 9.76562e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6737 - val_loss: 1.6882\n",
      "Epoch 68/200\n",
      "875/878 [============================>.] - ETA: 0s - loss: 1.6740\n",
      " Reduced learning rate to 4.88281e-06\n",
      "878/878 [==============================] - 2s - loss: 1.6738 - val_loss: 1.6875\n",
      "Epoch 69/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.6771\n",
      " Reduced learning rate to 2.44141e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6774 - val_loss: 1.6935\n",
      "Epoch 70/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.6754\n",
      " Reduced learning rate to 1.2207e-06\n",
      "878/878 [==============================] - 2s - loss: 1.6765 - val_loss: 1.6816\n",
      "Epoch 71/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.6790\n",
      " Reduced learning rate to 6.10352e-07\n",
      "878/878 [==============================] - 2s - loss: 1.6785 - val_loss: 1.6914\n",
      "Epoch 1/200\n",
      "878/878 [==============================] - 5s - loss: 9.4735 - val_loss: 3.4844\n",
      "Epoch 2/200\n",
      "878/878 [==============================] - 2s - loss: 3.2321 - val_loss: 2.7933\n",
      "Epoch 3/200\n",
      "878/878 [==============================] - 3s - loss: 3.0612 - val_loss: 2.5411\n",
      "Epoch 4/200\n",
      "878/878 [==============================] - 2s - loss: 2.8827 - val_loss: 2.6055\n",
      "Epoch 5/200\n",
      "878/878 [==============================] - 3s - loss: 2.7595 - val_loss: 2.9353\n",
      "Epoch 6/200\n",
      "878/878 [==============================] - 2s - loss: 2.6944 - val_loss: 3.0990\n",
      "Epoch 7/200\n",
      "878/878 [==============================] - 3s - loss: 2.5763 - val_loss: 2.3715\n",
      "Epoch 8/200\n",
      "878/878 [==============================] - 3s - loss: 2.5032 - val_loss: 2.1860\n",
      "Epoch 9/200\n",
      "878/878 [==============================] - 3s - loss: 2.4380 - val_loss: 2.4684\n",
      "Epoch 10/200\n",
      "878/878 [==============================] - 3s - loss: 2.3719 - val_loss: 2.1779\n",
      "Epoch 11/200\n",
      "878/878 [==============================] - 2s - loss: 2.3107 - val_loss: 2.7720\n",
      "Epoch 12/200\n",
      "878/878 [==============================] - 3s - loss: 2.2766 - val_loss: 2.4042\n",
      "Epoch 13/200\n",
      "878/878 [==============================] - 3s - loss: 2.2301 - val_loss: 2.4785\n",
      "Epoch 14/200\n",
      "878/878 [==============================] - 3s - loss: 2.1897 - val_loss: 2.0210\n",
      "Epoch 15/200\n",
      "878/878 [==============================] - 3s - loss: 2.1580 - val_loss: 2.3442\n",
      "Epoch 16/200\n",
      "878/878 [==============================] - 3s - loss: 2.1281 - val_loss: 1.8659\n",
      "Epoch 17/200\n",
      "878/878 [==============================] - 3s - loss: 2.0765 - val_loss: 2.2573\n",
      "Epoch 18/200\n",
      "878/878 [==============================] - 3s - loss: 2.0651 - val_loss: 1.7781\n",
      "Epoch 19/200\n",
      "878/878 [==============================] - 3s - loss: 2.0253 - val_loss: 1.9018\n",
      "Epoch 20/200\n",
      "878/878 [==============================] - 3s - loss: 2.0123 - val_loss: 2.0255\n",
      "Epoch 21/200\n",
      "878/878 [==============================] - 3s - loss: 1.9673 - val_loss: 1.8691\n",
      "Epoch 22/200\n",
      "878/878 [==============================] - 3s - loss: 1.9553 - val_loss: 1.9160\n",
      "Epoch 23/200\n",
      "878/878 [==============================] - 3s - loss: 1.9688 - val_loss: 2.0702\n",
      "Epoch 24/200\n",
      "878/878 [==============================] - 3s - loss: 1.9518 - val_loss: 1.7670\n",
      "Epoch 25/200\n",
      "878/878 [==============================] - 3s - loss: 1.9255 - val_loss: 1.9396\n",
      "Epoch 26/200\n",
      "878/878 [==============================] - 3s - loss: 1.9041 - val_loss: 1.9805\n",
      "Epoch 27/200\n",
      "878/878 [==============================] - 3s - loss: 1.8991 - val_loss: 1.9643\n",
      "Epoch 28/200\n",
      "878/878 [==============================] - 3s - loss: 1.9164 - val_loss: 1.8498\n",
      "Epoch 29/200\n",
      "878/878 [==============================] - 3s - loss: 1.8907 - val_loss: 1.8471\n",
      "Epoch 30/200\n",
      "878/878 [==============================] - 3s - loss: 1.8821 - val_loss: 1.8191\n",
      "Epoch 31/200\n",
      "878/878 [==============================] - 3s - loss: 1.8717 - val_loss: 2.1756\n",
      "Epoch 32/200\n",
      "878/878 [==============================] - 3s - loss: 1.8523 - val_loss: 1.8503\n",
      "Epoch 33/200\n",
      "878/878 [==============================] - 3s - loss: 1.8618 - val_loss: 1.7845\n",
      "Epoch 34/200\n",
      "878/878 [==============================] - 3s - loss: 1.8263 - val_loss: 2.2754\n",
      "Epoch 35/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.8217\n",
      " Reduced learning rate to 0.01\n",
      "878/878 [==============================] - 5s - loss: 1.8203 - val_loss: 1.8418\n",
      "Epoch 36/200\n",
      "878/878 [==============================] - 3s - loss: 1.6940 - val_loss: 1.7195\n",
      "Epoch 37/200\n",
      "878/878 [==============================] - 3s - loss: 1.6981 - val_loss: 1.6974\n",
      "Epoch 38/200\n",
      "878/878 [==============================] - 3s - loss: 1.7028 - val_loss: 1.6939\n",
      "Epoch 39/200\n",
      "866/878 [============================>.] - ETA: 0s - loss: 1.6972\n",
      " Reduced learning rate to 0.005\n",
      "878/878 [==============================] - 3s - loss: 1.6976 - val_loss: 1.7088\n",
      "Epoch 40/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6909\n",
      " Reduced learning rate to 0.0025\n",
      "878/878 [==============================] - 3s - loss: 1.6908 - val_loss: 1.6992\n",
      "Epoch 41/200\n",
      "862/878 [============================>.] - ETA: 0s - loss: 1.6887\n",
      " Reduced learning rate to 0.00125\n",
      "878/878 [==============================] - 3s - loss: 1.6891 - val_loss: 1.7050\n",
      "Epoch 42/200\n",
      "868/878 [============================>.] - ETA: 0s - loss: 1.6916\n",
      " Reduced learning rate to 0.000625\n",
      "878/878 [==============================] - 3s - loss: 1.6918 - val_loss: 1.7029\n",
      "Epoch 43/200\n",
      "868/878 [============================>.] - ETA: 0s - loss: 1.6979\n",
      " Reduced learning rate to 0.0003125\n",
      "878/878 [==============================] - 3s - loss: 1.6977 - val_loss: 1.7117\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/878 [============================>.] - ETA: 0s - loss: 1.6776\n",
      " Reduced learning rate to 0.00015625\n",
      "878/878 [==============================] - 3s - loss: 1.6780 - val_loss: 1.7031\n",
      "Epoch 45/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6900\n",
      " Reduced learning rate to 7.8125e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6900 - val_loss: 1.7031\n",
      "Epoch 46/200\n",
      "878/878 [==============================] - 3s - loss: 1.6944 - val_loss: 1.6881\n",
      "Epoch 47/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6876\n",
      " Reduced learning rate to 3.90625e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6877 - val_loss: 1.7043\n",
      "Epoch 48/200\n",
      "875/878 [============================>.] - ETA: 0s - loss: 1.6903\n",
      " Reduced learning rate to 1.95312e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6904 - val_loss: 1.7031\n",
      "Epoch 49/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.6970\n",
      " Reduced learning rate to 9.76562e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6967 - val_loss: 1.6960\n",
      "Epoch 50/200\n",
      "876/878 [============================>.] - ETA: 0s - loss: 1.6933\n",
      " Reduced learning rate to 4.88281e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6930 - val_loss: 1.7083\n",
      "Epoch 51/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.6860\n",
      " Reduced learning rate to 2.44141e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6853 - val_loss: 1.6946\n",
      "Epoch 52/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6859\n",
      " Reduced learning rate to 1.2207e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6858 - val_loss: 1.7005\n",
      "Epoch 53/200\n",
      "876/878 [============================>.] - ETA: 0s - loss: 1.6952\n",
      " Reduced learning rate to 6.10352e-07\n",
      "878/878 [==============================] - 3s - loss: 1.6952 - val_loss: 1.6926\n",
      "Epoch 1/200\n",
      "878/878 [==============================] - 6s - loss: 8.8397 - val_loss: 3.1250\n",
      "Epoch 2/200\n",
      "878/878 [==============================] - 3s - loss: 3.2508 - val_loss: 3.1468\n",
      "Epoch 3/200\n",
      "878/878 [==============================] - 3s - loss: 3.0664 - val_loss: 3.0250\n",
      "Epoch 4/200\n",
      "878/878 [==============================] - 3s - loss: 2.9269 - val_loss: 2.8101\n",
      "Epoch 5/200\n",
      "878/878 [==============================] - 3s - loss: 2.8241 - val_loss: 2.5856\n",
      "Epoch 6/200\n",
      "878/878 [==============================] - 3s - loss: 2.7213 - val_loss: 2.9085\n",
      "Epoch 7/200\n",
      "878/878 [==============================] - 4s - loss: 2.5839 - val_loss: 2.6444\n",
      "Epoch 8/200\n",
      "878/878 [==============================] - 3s - loss: 2.5305 - val_loss: 2.5238\n",
      "Epoch 9/200\n",
      "878/878 [==============================] - 3s - loss: 2.4496 - val_loss: 2.2983\n",
      "Epoch 10/200\n",
      "878/878 [==============================] - 3s - loss: 2.3822 - val_loss: 2.5073\n",
      "Epoch 11/200\n",
      "878/878 [==============================] - 3s - loss: 2.3174 - val_loss: 2.0698\n",
      "Epoch 12/200\n",
      "878/878 [==============================] - 3s - loss: 2.2774 - val_loss: 2.2618\n",
      "Epoch 13/200\n",
      "878/878 [==============================] - 3s - loss: 2.2234 - val_loss: 1.9888\n",
      "Epoch 14/200\n",
      "878/878 [==============================] - 3s - loss: 2.1740 - val_loss: 2.3609\n",
      "Epoch 15/200\n",
      "878/878 [==============================] - 3s - loss: 2.1366 - val_loss: 2.2514\n",
      "Epoch 16/200\n",
      "878/878 [==============================] - 3s - loss: 2.1096 - val_loss: 2.1933\n",
      "Epoch 17/200\n",
      "878/878 [==============================] - 3s - loss: 2.0629 - val_loss: 1.8569\n",
      "Epoch 18/200\n",
      "878/878 [==============================] - 3s - loss: 2.0450 - val_loss: 2.2988\n",
      "Epoch 19/200\n",
      "878/878 [==============================] - 3s - loss: 2.0487 - val_loss: 1.8939\n",
      "Epoch 20/200\n",
      "878/878 [==============================] - 3s - loss: 2.0033 - val_loss: 1.8971\n",
      "Epoch 21/200\n",
      "878/878 [==============================] - 3s - loss: 1.9950 - val_loss: 1.8535\n",
      "Epoch 22/200\n",
      "878/878 [==============================] - 3s - loss: 1.9733 - val_loss: 1.8613\n",
      "Epoch 23/200\n",
      "878/878 [==============================] - 3s - loss: 1.9486 - val_loss: 1.8509\n",
      "Epoch 24/200\n",
      "878/878 [==============================] - 3s - loss: 1.9150 - val_loss: 1.9823\n",
      "Epoch 25/200\n",
      "878/878 [==============================] - 3s - loss: 1.9280 - val_loss: 1.7342\n",
      "Epoch 26/200\n",
      "878/878 [==============================] - 3s - loss: 1.8975 - val_loss: 1.7578\n",
      "Epoch 27/200\n",
      "878/878 [==============================] - 3s - loss: 1.9043 - val_loss: 1.7326\n",
      "Epoch 28/200\n",
      "878/878 [==============================] - 3s - loss: 1.8601 - val_loss: 1.7643\n",
      "Epoch 29/200\n",
      "878/878 [==============================] - 3s - loss: 1.8719 - val_loss: 1.7910\n",
      "Epoch 30/200\n",
      "878/878 [==============================] - 3s - loss: 1.8520 - val_loss: 1.8900\n",
      "Epoch 31/200\n",
      "878/878 [==============================] - 3s - loss: 1.8596 - val_loss: 1.7136\n",
      "Epoch 32/200\n",
      "878/878 [==============================] - 3s - loss: 1.8492 - val_loss: 1.7576\n",
      "Epoch 33/200\n",
      "878/878 [==============================] - 3s - loss: 1.8378 - val_loss: 1.9349\n",
      "Epoch 34/200\n",
      "878/878 [==============================] - 3s - loss: 1.8188 - val_loss: 1.9178\n",
      "Epoch 35/200\n",
      "878/878 [==============================] - 3s - loss: 1.8155 - val_loss: 1.8809\n",
      "Epoch 36/200\n",
      "878/878 [==============================] - 3s - loss: 1.8059 - val_loss: 1.7662\n",
      "Epoch 37/200\n",
      "878/878 [==============================] - 3s - loss: 1.8159 - val_loss: 1.7639\n",
      "Epoch 38/200\n",
      "878/878 [==============================] - 3s - loss: 1.7934 - val_loss: 1.7610\n",
      "Epoch 39/200\n",
      "878/878 [==============================] - 3s - loss: 1.8110 - val_loss: 1.8835\n",
      "Epoch 40/200\n",
      "878/878 [==============================] - 3s - loss: 1.7911 - val_loss: 1.7291\n",
      "Epoch 41/200\n",
      "878/878 [==============================] - 4s - loss: 1.7952 - val_loss: 1.7226\n",
      "Epoch 42/200\n",
      "866/878 [============================>.] - ETA: 0s - loss: 1.7861\n",
      " Reduced learning rate to 0.01\n",
      "878/878 [==============================] - 5s - loss: 1.7857 - val_loss: 1.7292\n",
      "Epoch 43/200\n",
      "878/878 [==============================] - 3s - loss: 1.6977 - val_loss: 1.6991\n",
      "Epoch 44/200\n",
      "878/878 [==============================] - 3s - loss: 1.6949 - val_loss: 1.6887\n",
      "Epoch 45/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6873\n",
      " Reduced learning rate to 0.005\n",
      "878/878 [==============================] - 3s - loss: 1.6872 - val_loss: 1.6926\n",
      "Epoch 46/200\n",
      "878/878 [==============================] - 3s - loss: 1.6923 - val_loss: 1.6873\n",
      "Epoch 47/200\n",
      "869/878 [============================>.] - ETA: 0s - loss: 1.6841\n",
      " Reduced learning rate to 0.0025\n",
      "878/878 [==============================] - 3s - loss: 1.6841 - val_loss: 1.6947\n",
      "Epoch 48/200\n",
      "878/878 [==============================] - 3s - loss: 1.6824 - val_loss: 1.6854\n",
      "Epoch 49/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6865\n",
      " Reduced learning rate to 0.00125\n",
      "878/878 [==============================] - 3s - loss: 1.6863 - val_loss: 1.7043\n",
      "Epoch 50/200\n",
      "876/878 [============================>.] - ETA: 0s - loss: 1.6858\n",
      " Reduced learning rate to 0.000625\n",
      "878/878 [==============================] - 3s - loss: 1.6857 - val_loss: 1.6914\n",
      "Epoch 51/200\n",
      "878/878 [==============================] - 3s - loss: 1.6917 - val_loss: 1.6797\n",
      "Epoch 52/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6868\n",
      " Reduced learning rate to 0.0003125\n",
      "878/878 [==============================] - 3s - loss: 1.6878 - val_loss: 1.6857\n",
      "Epoch 53/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6802\n",
      " Reduced learning rate to 0.00015625\n",
      "878/878 [==============================] - 3s - loss: 1.6805 - val_loss: 1.6921\n",
      "Epoch 54/200\n",
      "870/878 [============================>.] - ETA: 0s - loss: 1.6829\n",
      " Reduced learning rate to 7.8125e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6833 - val_loss: 1.6915\n",
      "Epoch 55/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.6814\n",
      " Reduced learning rate to 3.90625e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6812 - val_loss: 1.6993\n",
      "Epoch 56/200\n",
      "873/878 [============================>.] - ETA: 0s - loss: 1.6826\n",
      " Reduced learning rate to 1.95312e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6830 - val_loss: 1.6934\n",
      "Epoch 57/200\n",
      "869/878 [============================>.] - ETA: 0s - loss: 1.6791\n",
      " Reduced learning rate to 9.76562e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 3s - loss: 1.6796 - val_loss: 1.6875\n",
      "Epoch 58/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.6792\n",
      " Reduced learning rate to 4.88281e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6795 - val_loss: 1.6955\n",
      "Epoch 59/200\n",
      "872/878 [============================>.] - ETA: 0s - loss: 1.6822\n",
      " Reduced learning rate to 2.44141e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6819 - val_loss: 1.6877\n",
      "Epoch 60/200\n",
      "874/878 [============================>.] - ETA: 0s - loss: 1.6814\n",
      " Reduced learning rate to 1.2207e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6818 - val_loss: 1.6874\n",
      "Epoch 61/200\n",
      "868/878 [============================>.] - ETA: 0s - loss: 1.6834\n",
      " Reduced learning rate to 6.10352e-07\n",
      "878/878 [==============================] - 3s - loss: 1.6831 - val_loss: 1.6900\n",
      "Epoch 1/200\n",
      "878/878 [==============================] - 6s - loss: 8.4900 - val_loss: 4.0820\n",
      "Epoch 2/200\n",
      "878/878 [==============================] - 3s - loss: 3.1981 - val_loss: 3.6406\n",
      "Epoch 3/200\n",
      "878/878 [==============================] - 3s - loss: 3.0153 - val_loss: 3.0899\n",
      "Epoch 4/200\n",
      "878/878 [==============================] - 3s - loss: 2.8886 - val_loss: 3.1341\n",
      "Epoch 5/200\n",
      "878/878 [==============================] - 3s - loss: 2.7649 - val_loss: 2.7968\n",
      "Epoch 6/200\n",
      "878/878 [==============================] - 3s - loss: 2.6491 - val_loss: 2.4472\n",
      "Epoch 7/200\n",
      "878/878 [==============================] - 3s - loss: 2.5858 - val_loss: 2.3612\n",
      "Epoch 8/200\n",
      "878/878 [==============================] - 3s - loss: 2.5385 - val_loss: 2.4961\n",
      "Epoch 9/200\n",
      "878/878 [==============================] - 3s - loss: 2.4305 - val_loss: 2.0841\n",
      "Epoch 10/200\n",
      "878/878 [==============================] - 3s - loss: 2.3830 - val_loss: 1.9648\n",
      "Epoch 11/200\n",
      "878/878 [==============================] - 3s - loss: 2.3366 - val_loss: 2.0649\n",
      "Epoch 12/200\n",
      "878/878 [==============================] - 3s - loss: 2.2646 - val_loss: 2.1304\n",
      "Epoch 13/200\n",
      "878/878 [==============================] - 3s - loss: 2.2236 - val_loss: 2.4023\n",
      "Epoch 14/200\n",
      "878/878 [==============================] - ETA: 0s - loss: 2.184 - 3s - loss: 2.1826 - val_loss: 1.8476\n",
      "Epoch 15/200\n",
      "878/878 [==============================] - 4s - loss: 2.1515 - val_loss: 2.0807\n",
      "Epoch 16/200\n",
      "878/878 [==============================] - 3s - loss: 2.1048 - val_loss: 1.7780\n",
      "Epoch 17/200\n",
      "878/878 [==============================] - 3s - loss: 2.0683 - val_loss: 1.8065\n",
      "Epoch 18/200\n",
      "878/878 [==============================] - 3s - loss: 2.0661 - val_loss: 2.2369\n",
      "Epoch 19/200\n",
      "878/878 [==============================] - 3s - loss: 2.0356 - val_loss: 2.3657\n",
      "Epoch 20/200\n",
      "878/878 [==============================] - 3s - loss: 2.0252 - val_loss: 2.1642\n",
      "Epoch 21/200\n",
      "878/878 [==============================] - 3s - loss: 1.9660 - val_loss: 1.8374\n",
      "Epoch 22/200\n",
      "878/878 [==============================] - 3s - loss: 1.9667 - val_loss: 2.1152\n",
      "Epoch 23/200\n",
      "878/878 [==============================] - 3s - loss: 1.9281 - val_loss: 2.0568\n",
      "Epoch 24/200\n",
      "878/878 [==============================] - 3s - loss: 1.9308 - val_loss: 2.3046\n",
      "Epoch 25/200\n",
      "878/878 [==============================] - 3s - loss: 1.9450 - val_loss: 1.8041\n",
      "Epoch 26/200\n",
      "878/878 [==============================] - 3s - loss: 1.8989 - val_loss: 1.7695\n",
      "Epoch 27/200\n",
      "878/878 [==============================] - 3s - loss: 1.9123 - val_loss: 1.8843\n",
      "Epoch 28/200\n",
      "878/878 [==============================] - 3s - loss: 1.8792 - val_loss: 2.0057\n",
      "Epoch 29/200\n",
      "878/878 [==============================] - 3s - loss: 1.8911 - val_loss: 1.8868\n",
      "Epoch 30/200\n",
      "878/878 [==============================] - 3s - loss: 1.8592 - val_loss: 1.9634\n",
      "Epoch 31/200\n",
      "878/878 [==============================] - 3s - loss: 1.8534 - val_loss: 2.1068\n",
      "Epoch 32/200\n",
      "878/878 [==============================] - 3s - loss: 1.8534 - val_loss: 1.8528\n",
      "Epoch 33/200\n",
      "878/878 [==============================] - 3s - loss: 1.8426 - val_loss: 1.8280\n",
      "Epoch 34/200\n",
      "878/878 [==============================] - 3s - loss: 1.8356 - val_loss: 1.8802\n",
      "Epoch 35/200\n",
      "878/878 [==============================] - 3s - loss: 1.8458 - val_loss: 1.9240\n",
      "Epoch 36/200\n",
      "878/878 [==============================] - 3s - loss: 1.8277 - val_loss: 1.9681\n",
      "Epoch 37/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.8123\n",
      " Reduced learning rate to 0.01\n",
      "878/878 [==============================] - 5s - loss: 1.8129 - val_loss: 1.7917\n",
      "Epoch 38/200\n",
      "878/878 [==============================] - 3s - loss: 1.6964 - val_loss: 1.7092\n",
      "Epoch 39/200\n",
      "878/878 [==============================] - 3s - loss: 1.7049 - val_loss: 1.7070\n",
      "Epoch 40/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.6922\n",
      " Reduced learning rate to 0.005\n",
      "878/878 [==============================] - 3s - loss: 1.6919 - val_loss: 1.7264\n",
      "Epoch 41/200\n",
      "878/878 [==============================] - 3s - loss: 1.7004 - val_loss: 1.6908\n",
      "Epoch 42/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.6964\n",
      " Reduced learning rate to 0.0025\n",
      "878/878 [==============================] - 3s - loss: 1.6960 - val_loss: 1.6947\n",
      "Epoch 43/200\n",
      "878/878 [==============================] - 3s - loss: 1.6868 - val_loss: 1.6893\n",
      "Epoch 44/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.6998\n",
      " Reduced learning rate to 0.00125\n",
      "878/878 [==============================] - 3s - loss: 1.7004 - val_loss: 1.7077\n",
      "Epoch 45/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6927\n",
      " Reduced learning rate to 0.000625\n",
      "878/878 [==============================] - 3s - loss: 1.6928 - val_loss: 1.6985\n",
      "Epoch 46/200\n",
      "878/878 [==============================] - 3s - loss: 1.7013 - val_loss: 1.6829\n",
      "Epoch 47/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.6846\n",
      " Reduced learning rate to 0.0003125\n",
      "878/878 [==============================] - 3s - loss: 1.6844 - val_loss: 1.6920\n",
      "Epoch 48/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6814\n",
      " Reduced learning rate to 0.00015625\n",
      "878/878 [==============================] - 3s - loss: 1.6819 - val_loss: 1.6940\n",
      "Epoch 49/200\n",
      "864/878 [============================>.] - ETA: 0s - loss: 1.6908\n",
      " Reduced learning rate to 7.8125e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6914 - val_loss: 1.6959\n",
      "Epoch 50/200\n",
      "874/878 [============================>.] - ETA: 0s - loss: 1.6924\n",
      " Reduced learning rate to 3.90625e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6923 - val_loss: 1.6836\n",
      "Epoch 51/200\n",
      "870/878 [============================>.] - ETA: 0s - loss: 1.6835\n",
      " Reduced learning rate to 1.95312e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6831 - val_loss: 1.6877\n",
      "Epoch 52/200\n",
      "872/878 [============================>.] - ETA: 0s - loss: 1.6880\n",
      " Reduced learning rate to 9.76562e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6876 - val_loss: 1.6849\n",
      "Epoch 53/200\n",
      "873/878 [============================>.] - ETA: 0s - loss: 1.6897\n",
      " Reduced learning rate to 4.88281e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6898 - val_loss: 1.6920\n",
      "Epoch 54/200\n",
      "866/878 [============================>.] - ETA: 0s - loss: 1.6917\n",
      " Reduced learning rate to 2.44141e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6915 - val_loss: 1.6902\n",
      "Epoch 55/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6884\n",
      " Reduced learning rate to 1.2207e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6885 - val_loss: 1.6994\n",
      "Epoch 56/200\n",
      "869/878 [============================>.] - ETA: 0s - loss: 1.6823\n",
      " Reduced learning rate to 6.10352e-07\n",
      "878/878 [==============================] - 4s - loss: 1.6828 - val_loss: 1.6873\n",
      "Epoch 1/200\n",
      "878/878 [==============================] - 6s - loss: 9.0209 - val_loss: 3.4233\n",
      "Epoch 2/200\n",
      "878/878 [==============================] - 3s - loss: 3.2426 - val_loss: 3.0992\n",
      "Epoch 3/200\n",
      "878/878 [==============================] - 3s - loss: 3.0444 - val_loss: 2.8398\n",
      "Epoch 4/200\n",
      "878/878 [==============================] - 3s - loss: 2.9174 - val_loss: 2.4605\n",
      "Epoch 5/200\n",
      "878/878 [==============================] - 3s - loss: 2.7559 - val_loss: 2.5079\n",
      "Epoch 6/200\n",
      "878/878 [==============================] - 3s - loss: 2.6683 - val_loss: 2.6779\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 3s - loss: 2.5676 - val_loss: 2.4496\n",
      "Epoch 8/200\n",
      "878/878 [==============================] - 3s - loss: 2.4752 - val_loss: 2.2951\n",
      "Epoch 9/200\n",
      "878/878 [==============================] - 3s - loss: 2.4069 - val_loss: 2.1020\n",
      "Epoch 10/200\n",
      "878/878 [==============================] - 3s - loss: 2.3592 - val_loss: 2.8345\n",
      "Epoch 11/200\n",
      "878/878 [==============================] - 3s - loss: 2.3230 - val_loss: 2.3065\n",
      "Epoch 12/200\n",
      "878/878 [==============================] - 3s - loss: 2.2674 - val_loss: 2.1050\n",
      "Epoch 13/200\n",
      "878/878 [==============================] - 3s - loss: 2.2134 - val_loss: 2.0548\n",
      "Epoch 14/200\n",
      "878/878 [==============================] - 3s - loss: 2.1583 - val_loss: 2.0825\n",
      "Epoch 15/200\n",
      "878/878 [==============================] - 3s - loss: 2.1371 - val_loss: 2.0078\n",
      "Epoch 16/200\n",
      "878/878 [==============================] - 3s - loss: 2.1059 - val_loss: 1.9974\n",
      "Epoch 17/200\n",
      "878/878 [==============================] - 3s - loss: 2.0844 - val_loss: 2.0111\n",
      "Epoch 18/200\n",
      "878/878 [==============================] - 3s - loss: 2.0449 - val_loss: 2.2670\n",
      "Epoch 19/200\n",
      "878/878 [==============================] - 3s - loss: 2.0229 - val_loss: 2.1049\n",
      "Epoch 20/200\n",
      "878/878 [==============================] - 3s - loss: 2.0209 - val_loss: 1.8249\n",
      "Epoch 21/200\n",
      "878/878 [==============================] - 3s - loss: 1.9945 - val_loss: 2.1879\n",
      "Epoch 22/200\n",
      "878/878 [==============================] - 3s - loss: 1.9709 - val_loss: 2.2267\n",
      "Epoch 23/200\n",
      "878/878 [==============================] - 3s - loss: 1.9584 - val_loss: 2.0445\n",
      "Epoch 24/200\n",
      "878/878 [==============================] - 3s - loss: 1.9184 - val_loss: 2.0060\n",
      "Epoch 25/200\n",
      "878/878 [==============================] - 3s - loss: 1.9230 - val_loss: 2.0508\n",
      "Epoch 26/200\n",
      "878/878 [==============================] - 3s - loss: 1.9189 - val_loss: 1.9004\n",
      "Epoch 27/200\n",
      "878/878 [==============================] - 3s - loss: 1.8969 - val_loss: 2.0874\n",
      "Epoch 28/200\n",
      "878/878 [==============================] - 3s - loss: 1.8832 - val_loss: 1.8326\n",
      "Epoch 29/200\n",
      "878/878 [==============================] - 3s - loss: 1.8732 - val_loss: 1.9205\n",
      "Epoch 30/200\n",
      "878/878 [==============================] - 3s - loss: 1.8597 - val_loss: 1.8299\n",
      "Epoch 31/200\n",
      "866/878 [============================>.] - ETA: 0s - loss: 1.8591\n",
      " Reduced learning rate to 0.01\n",
      "878/878 [==============================] - 5s - loss: 1.8602 - val_loss: 1.8809\n",
      "Epoch 32/200\n",
      "878/878 [==============================] - 3s - loss: 1.7085 - val_loss: 1.7116\n",
      "Epoch 33/200\n",
      "866/878 [============================>.] - ETA: 0s - loss: 1.7042\n",
      " Reduced learning rate to 0.005\n",
      "878/878 [==============================] - 3s - loss: 1.7046 - val_loss: 1.7487\n",
      "Epoch 34/200\n",
      "878/878 [==============================] - 3s - loss: 1.7024 - val_loss: 1.7049\n",
      "Epoch 35/200\n",
      "878/878 [==============================] - 3s - loss: 1.6925 - val_loss: 1.7029\n",
      "Epoch 36/200\n",
      "867/878 [============================>.] - ETA: 0s - loss: 1.7007\n",
      " Reduced learning rate to 0.0025\n",
      "878/878 [==============================] - 3s - loss: 1.6997 - val_loss: 1.7029\n",
      "Epoch 37/200\n",
      "868/878 [============================>.] - ETA: 0s - loss: 1.6957\n",
      " Reduced learning rate to 0.00125\n",
      "878/878 [==============================] - 3s - loss: 1.6952 - val_loss: 1.7127\n",
      "Epoch 38/200\n",
      "878/878 [==============================] - 3s - loss: 1.6897 - val_loss: 1.7005\n",
      "Epoch 39/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6863\n",
      " Reduced learning rate to 0.000625\n",
      "878/878 [==============================] - 3s - loss: 1.6864 - val_loss: 1.7051\n",
      "Epoch 40/200\n",
      "878/878 [==============================] - 3s - loss: 1.7013 - val_loss: 1.6888\n",
      "Epoch 41/200\n",
      "872/878 [============================>.] - ETA: 0s - loss: 1.7025\n",
      " Reduced learning rate to 0.0003125\n",
      "878/878 [==============================] - 3s - loss: 1.7026 - val_loss: 1.7017\n",
      "Epoch 42/200\n",
      "876/878 [============================>.] - ETA: 0s - loss: 1.6959\n",
      " Reduced learning rate to 0.00015625\n",
      "878/878 [==============================] - 3s - loss: 1.6959 - val_loss: 1.6893\n",
      "Epoch 43/200\n",
      "868/878 [============================>.] - ETA: 0s - loss: 1.7006\n",
      " Reduced learning rate to 7.8125e-05\n",
      "878/878 [==============================] - 3s - loss: 1.7001 - val_loss: 1.6889\n",
      "Epoch 44/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.6986\n",
      " Reduced learning rate to 3.90625e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6982 - val_loss: 1.7082\n",
      "Epoch 45/200\n",
      "875/878 [============================>.] - ETA: 0s - loss: 1.6937\n",
      " Reduced learning rate to 1.95312e-05\n",
      "878/878 [==============================] - 3s - loss: 1.6939 - val_loss: 1.6959\n",
      "Epoch 46/200\n",
      "865/878 [============================>.] - ETA: 0s - loss: 1.6861\n",
      " Reduced learning rate to 9.76562e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6864 - val_loss: 1.7011\n",
      "Epoch 47/200\n",
      "869/878 [============================>.] - ETA: 0s - loss: 1.6881\n",
      " Reduced learning rate to 4.88281e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6889 - val_loss: 1.6955\n",
      "Epoch 48/200\n",
      "872/878 [============================>.] - ETA: 0s - loss: 1.6984\n",
      " Reduced learning rate to 2.44141e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6982 - val_loss: 1.6992\n",
      "Epoch 49/200\n",
      "871/878 [============================>.] - ETA: 0s - loss: 1.6922\n",
      " Reduced learning rate to 1.2207e-06\n",
      "878/878 [==============================] - 3s - loss: 1.6926 - val_loss: 1.7063\n",
      "Epoch 50/200\n",
      "877/878 [============================>.] - ETA: 0s - loss: 1.6948\n",
      " Reduced learning rate to 6.10352e-07\n",
      "878/878 [==============================] - 3s - loss: 1.6948 - val_loss: 1.7025\n",
      "Epoch 1/200\n",
      "1757/1757 [==============================] - 10s - loss: 6.1617 - val_loss: 3.1532\n",
      "Epoch 2/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.9826 - val_loss: 2.4406\n",
      "Epoch 3/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.7156 - val_loss: 2.8167\n",
      "Epoch 4/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.5424 - val_loss: 2.4247\n",
      "Epoch 5/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.4042 - val_loss: 2.2695\n",
      "Epoch 6/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.2841 - val_loss: 2.4112\n",
      "Epoch 7/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.1860 - val_loss: 1.7749\n",
      "Epoch 8/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.1283 - val_loss: 1.9600\n",
      "Epoch 9/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.0462 - val_loss: 2.0235\n",
      "Epoch 10/200\n",
      "1757/1757 [==============================] - 7s - loss: 2.0208 - val_loss: 1.8956\n",
      "Epoch 11/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.9674 - val_loss: 2.0742\n",
      "Epoch 12/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.9218 - val_loss: 1.7461\n",
      "Epoch 13/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9123 - val_loss: 1.7344\n",
      "Epoch 14/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8822 - val_loss: 1.9179\n",
      "Epoch 15/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8634 - val_loss: 1.7865\n",
      "Epoch 16/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.8601 - val_loss: 1.7134\n",
      "Epoch 17/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.8361 - val_loss: 1.7854\n",
      "Epoch 18/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.8338 - val_loss: 1.7653\n",
      "Epoch 19/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.8232 - val_loss: 1.8349\n",
      "Epoch 20/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.8074 - val_loss: 1.6875\n",
      "Epoch 21/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7864 - val_loss: 1.7551\n",
      "Epoch 22/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7915 - val_loss: 1.7770\n",
      "Epoch 23/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7906 - val_loss: 1.9378\n",
      "Epoch 24/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7889 - val_loss: 1.6993\n",
      "Epoch 25/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7800 - val_loss: 1.8412\n",
      "Epoch 26/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7706 - val_loss: 1.6864\n",
      "Epoch 27/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7697 - val_loss: 1.6879\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757/1757 [==============================] - 7s - loss: 1.7700 - val_loss: 1.6836\n",
      "Epoch 29/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7585 - val_loss: 1.7035\n",
      "Epoch 30/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7645 - val_loss: 1.6876\n",
      "Epoch 31/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7584 - val_loss: 1.8909\n",
      "Epoch 32/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7502 - val_loss: 1.7994\n",
      "Epoch 33/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7427 - val_loss: 1.7684\n",
      "Epoch 34/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7494 - val_loss: 1.6926\n",
      "Epoch 35/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7456 - val_loss: 1.6832\n",
      "Epoch 36/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7414 - val_loss: 1.9452\n",
      "Epoch 37/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7432 - val_loss: 1.6929\n",
      "Epoch 38/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7375 - val_loss: 1.6953\n",
      "Epoch 39/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7370 - val_loss: 1.6968\n",
      "Epoch 40/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7351 - val_loss: 1.6833\n",
      "Epoch 41/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7377 - val_loss: 1.7082\n",
      "Epoch 42/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7328 - val_loss: 1.7031\n",
      "Epoch 43/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7215 - val_loss: 1.6824\n",
      "Epoch 44/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7364 - val_loss: 1.7893\n",
      "Epoch 45/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7271 - val_loss: 1.7145\n",
      "Epoch 46/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7251 - val_loss: 1.6926\n",
      "Epoch 47/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7189 - val_loss: 1.7028\n",
      "Epoch 48/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7266 - val_loss: 1.7497\n",
      "Epoch 49/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7262 - val_loss: 1.6821\n",
      "Epoch 50/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7227 - val_loss: 1.6863\n",
      "Epoch 51/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7247 - val_loss: 1.7379\n",
      "Epoch 52/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7193 - val_loss: 1.7933\n",
      "Epoch 53/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7164 - val_loss: 1.6875\n",
      "Epoch 54/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7197 - val_loss: 1.6797\n",
      "Epoch 55/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7087 - val_loss: 1.6875\n",
      "Epoch 56/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7193 - val_loss: 1.9138\n",
      "Epoch 57/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7160 - val_loss: 1.6754\n",
      "Epoch 58/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7083 - val_loss: 1.6677\n",
      "Epoch 59/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.6984 - val_loss: 1.7582\n",
      "Epoch 60/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7115 - val_loss: 1.7199\n",
      "Epoch 61/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7066 - val_loss: 1.7031\n",
      "Epoch 62/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7130 - val_loss: 1.6800\n",
      "Epoch 63/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7092 - val_loss: 1.7224\n",
      "Epoch 64/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7108 - val_loss: 1.7305\n",
      "Epoch 65/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7086 - val_loss: 1.6761\n",
      "Epoch 66/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7009 - val_loss: 1.6605\n",
      "Epoch 67/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7086 - val_loss: 1.6917\n",
      "Epoch 68/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7033 - val_loss: 1.7628\n",
      "Epoch 69/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7071 - val_loss: 1.7046\n",
      "Epoch 70/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7054 - val_loss: 1.7151\n",
      "Epoch 71/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7034 - val_loss: 1.7592\n",
      "Epoch 72/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7022 - val_loss: 1.6992\n",
      "Epoch 73/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7032 - val_loss: 1.7160\n",
      "Epoch 74/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.6969 - val_loss: 1.6655\n",
      "Epoch 75/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.7037 - val_loss: 1.6679\n",
      "Epoch 76/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.6978 - val_loss: 1.6679\n",
      "Epoch 77/200\n",
      "1744/1757 [============================>.] - ETA: 0s - loss: 1.7064\n",
      " Reduced learning rate to 0.01\n",
      "1757/1757 [==============================] - 10s - loss: 1.7065 - val_loss: 1.7593\n",
      "Epoch 78/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6710\n",
      " Reduced learning rate to 0.005\n",
      "1757/1757 [==============================] - 8s - loss: 1.6710 - val_loss: 1.6641\n",
      "Epoch 79/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.6629 - val_loss: 1.6598\n",
      "Epoch 80/200\n",
      "1757/1757 [==============================] - 7s - loss: 1.6697 - val_loss: 1.6577\n",
      "Epoch 81/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6680\n",
      " Reduced learning rate to 0.0025\n",
      "1757/1757 [==============================] - 8s - loss: 1.6680 - val_loss: 1.6653\n",
      "Epoch 82/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.6646 - val_loss: 1.6562\n",
      "Epoch 83/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6634\n",
      " Reduced learning rate to 0.00125\n",
      "1757/1757 [==============================] - 7s - loss: 1.6635 - val_loss: 1.6616\n",
      "Epoch 84/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.6612 - val_loss: 1.6511\n",
      "Epoch 85/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6575\n",
      " Reduced learning rate to 0.000625\n",
      "1757/1757 [==============================] - 8s - loss: 1.6575 - val_loss: 1.6590\n",
      "Epoch 86/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6594\n",
      " Reduced learning rate to 0.0003125\n",
      "1757/1757 [==============================] - 8s - loss: 1.6594 - val_loss: 1.6548\n",
      "Epoch 87/200\n",
      "1752/1757 [============================>.] - ETA: 0s - loss: 1.6623\n",
      " Reduced learning rate to 0.00015625\n",
      "1757/1757 [==============================] - 8s - loss: 1.6622 - val_loss: 1.6565\n",
      "Epoch 88/200\n",
      "1747/1757 [============================>.] - ETA: 0s - loss: 1.6617\n",
      " Reduced learning rate to 7.8125e-05\n",
      "1757/1757 [==============================] - 8s - loss: 1.6615 - val_loss: 1.6626\n",
      "Epoch 89/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6627\n",
      " Reduced learning rate to 3.90625e-05\n",
      "1757/1757 [==============================] - 8s - loss: 1.6626 - val_loss: 1.6578\n",
      "Epoch 90/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6624\n",
      " Reduced learning rate to 1.95312e-05\n",
      "1757/1757 [==============================] - 7s - loss: 1.6623 - val_loss: 1.6563\n",
      "Epoch 91/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6590\n",
      " Reduced learning rate to 9.76562e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6590 - val_loss: 1.6560\n",
      "Epoch 92/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.6640 - val_loss: 1.6481\n",
      "Epoch 93/200\n",
      "1745/1757 [============================>.] - ETA: 0s - loss: 1.6588\n",
      " Reduced learning rate to 4.88281e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6586 - val_loss: 1.6550\n",
      "Epoch 94/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6619\n",
      " Reduced learning rate to 2.44141e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6631 - val_loss: 1.6586\n",
      "Epoch 95/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6631\n",
      " Reduced learning rate to 1.2207e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6632 - val_loss: 1.6602\n",
      "Epoch 96/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6649\n",
      " Reduced learning rate to 6.10352e-07\n",
      "1757/1757 [==============================] - 8s - loss: 1.6649 - val_loss: 1.6640\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757/1757 [==============================] - 11s - loss: 6.4707 - val_loss: 3.2084\n",
      "Epoch 2/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.9744 - val_loss: 2.6995\n",
      "Epoch 3/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.7149 - val_loss: 3.0476\n",
      "Epoch 4/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.5451 - val_loss: 2.7821\n",
      "Epoch 5/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.4123 - val_loss: 2.0433\n",
      "Epoch 6/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.2885 - val_loss: 2.2854\n",
      "Epoch 7/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.2069 - val_loss: 2.1260\n",
      "Epoch 8/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.1391 - val_loss: 1.8955\n",
      "Epoch 9/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.0766 - val_loss: 2.0193\n",
      "Epoch 10/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.0287 - val_loss: 1.9333\n",
      "Epoch 11/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.9865 - val_loss: 1.8544\n",
      "Epoch 12/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.9598 - val_loss: 1.7848\n",
      "Epoch 13/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.9485 - val_loss: 2.0069\n",
      "Epoch 14/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.9118 - val_loss: 1.7983\n",
      "Epoch 15/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8861 - val_loss: 2.2334\n",
      "Epoch 16/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8615 - val_loss: 1.9609\n",
      "Epoch 17/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8572 - val_loss: 1.7382\n",
      "Epoch 18/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8435 - val_loss: 1.9177\n",
      "Epoch 19/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8234 - val_loss: 1.7539\n",
      "Epoch 20/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8353 - val_loss: 1.7422\n",
      "Epoch 21/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8072 - val_loss: 1.7434\n",
      "Epoch 22/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8058 - val_loss: 1.8046\n",
      "Epoch 23/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7985 - val_loss: 1.9365\n",
      "Epoch 24/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7960 - val_loss: 1.8018\n",
      "Epoch 25/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7829 - val_loss: 1.7302\n",
      "Epoch 26/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7847 - val_loss: 1.7252\n",
      "Epoch 27/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7696 - val_loss: 1.7238\n",
      "Epoch 28/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7708 - val_loss: 1.8087\n",
      "Epoch 29/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7662 - val_loss: 1.7059\n",
      "Epoch 30/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7639 - val_loss: 1.7538\n",
      "Epoch 31/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7589 - val_loss: 1.9034\n",
      "Epoch 32/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7556 - val_loss: 1.7788\n",
      "Epoch 33/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7545 - val_loss: 1.7134\n",
      "Epoch 34/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7520 - val_loss: 1.7723\n",
      "Epoch 35/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7448 - val_loss: 1.7213\n",
      "Epoch 36/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7504 - val_loss: 1.7851\n",
      "Epoch 37/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7469 - val_loss: 1.7160\n",
      "Epoch 38/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7424 - val_loss: 1.7709\n",
      "Epoch 39/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7427 - val_loss: 1.7112\n",
      "Epoch 40/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7450 - val_loss: 1.6848\n",
      "Epoch 41/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7396 - val_loss: 1.7319\n",
      "Epoch 42/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7392 - val_loss: 1.6840\n",
      "Epoch 43/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7344 - val_loss: 1.7812\n",
      "Epoch 44/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7369 - val_loss: 1.7536\n",
      "Epoch 45/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7289 - val_loss: 1.6848\n",
      "Epoch 46/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7414 - val_loss: 1.6965\n",
      "Epoch 47/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7296 - val_loss: 1.8309\n",
      "Epoch 48/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7270 - val_loss: 1.6808\n",
      "Epoch 49/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7181 - val_loss: 1.6644\n",
      "Epoch 50/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7278 - val_loss: 1.6800\n",
      "Epoch 51/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7238 - val_loss: 1.7134\n",
      "Epoch 52/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7319 - val_loss: 1.6782\n",
      "Epoch 53/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7230 - val_loss: 1.7067\n",
      "Epoch 54/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7230 - val_loss: 1.6876\n",
      "Epoch 55/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7220 - val_loss: 1.7890\n",
      "Epoch 56/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7253 - val_loss: 1.6731\n",
      "Epoch 57/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7164 - val_loss: 1.6733\n",
      "Epoch 58/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7209 - val_loss: 1.6821\n",
      "Epoch 59/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7127 - val_loss: 1.7458\n",
      "Epoch 60/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.7151\n",
      " Reduced learning rate to 0.01\n",
      "1757/1757 [==============================] - 11s - loss: 1.7151 - val_loss: 1.7043\n",
      "Epoch 61/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6698\n",
      " Reduced learning rate to 0.005\n",
      "1757/1757 [==============================] - 8s - loss: 1.6699 - val_loss: 1.6679\n",
      "Epoch 62/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6696\n",
      " Reduced learning rate to 0.0025\n",
      "1757/1757 [==============================] - 8s - loss: 1.6696 - val_loss: 1.6679\n",
      "Epoch 63/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.6606 - val_loss: 1.6587\n",
      "Epoch 64/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6675\n",
      " Reduced learning rate to 0.00125\n",
      "1757/1757 [==============================] - 8s - loss: 1.6675 - val_loss: 1.6605\n",
      "Epoch 65/200\n",
      "1746/1757 [============================>.] - ETA: 0s - loss: 1.6620\n",
      " Reduced learning rate to 0.000625\n",
      "1757/1757 [==============================] - 8s - loss: 1.6620 - val_loss: 1.6681\n",
      "Epoch 66/200\n",
      "1747/1757 [============================>.] - ETA: 0s - loss: 1.6672\n",
      " Reduced learning rate to 0.0003125\n",
      "1757/1757 [==============================] - 8s - loss: 1.6673 - val_loss: 1.6704\n",
      "Epoch 67/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6626\n",
      " Reduced learning rate to 0.00015625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6626 - val_loss: 1.6602\n",
      "Epoch 68/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6624\n",
      " Reduced learning rate to 7.8125e-05\n",
      "1757/1757 [==============================] - 8s - loss: 1.6624 - val_loss: 1.6602\n",
      "Epoch 69/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6627\n",
      " Reduced learning rate to 3.90625e-05\n",
      "1757/1757 [==============================] - 8s - loss: 1.6626 - val_loss: 1.6605\n",
      "Epoch 70/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6669\n",
      " Reduced learning rate to 1.95312e-05\n",
      "1757/1757 [==============================] - 8s - loss: 1.6667 - val_loss: 1.6694\n",
      "Epoch 71/200\n",
      "1747/1757 [============================>.] - ETA: 0s - loss: 1.6653\n",
      " Reduced learning rate to 9.76562e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6652 - val_loss: 1.6604\n",
      "Epoch 72/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6630\n",
      " Reduced learning rate to 4.88281e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6633 - val_loss: 1.6598\n",
      "Epoch 73/200\n",
      "1754/1757 [============================>.] - ETA: 0s - loss: 1.6671\n",
      " Reduced learning rate to 2.44141e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757/1757 [==============================] - 8s - loss: 1.6671 - val_loss: 1.6642\n",
      "Epoch 74/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6592\n",
      " Reduced learning rate to 1.2207e-06\n",
      "1757/1757 [==============================] - 8s - loss: 1.6592 - val_loss: 1.6652\n",
      "Epoch 75/200\n",
      "1754/1757 [============================>.] - ETA: 0s - loss: 1.6628\n",
      " Reduced learning rate to 6.10352e-07\n",
      "1757/1757 [==============================] - 8s - loss: 1.6632 - val_loss: 1.6652\n",
      "Epoch 1/200\n",
      "1757/1757 [==============================] - 12s - loss: 6.2235 - val_loss: 2.6591\n",
      "Epoch 2/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.9380 - val_loss: 2.7665\n",
      "Epoch 3/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.6976 - val_loss: 2.4373\n",
      "Epoch 4/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.5404 - val_loss: 2.2159\n",
      "Epoch 5/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.4133 - val_loss: 2.6532\n",
      "Epoch 6/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.3085 - val_loss: 2.1289\n",
      "Epoch 7/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.2132 - val_loss: 1.8357\n",
      "Epoch 8/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.1353 - val_loss: 2.1911\n",
      "Epoch 9/200\n",
      "1757/1757 [==============================] - 8s - loss: 2.0657 - val_loss: 2.1992\n",
      "Epoch 10/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9993 - val_loss: 1.9052\n",
      "Epoch 11/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.9825 - val_loss: 1.8231\n",
      "Epoch 12/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.9399 - val_loss: 1.9792\n",
      "Epoch 13/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9053 - val_loss: 2.1201\n",
      "Epoch 14/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8902 - val_loss: 1.9247\n",
      "Epoch 15/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8653 - val_loss: 1.7305\n",
      "Epoch 16/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8583 - val_loss: 2.1710\n",
      "Epoch 17/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8445 - val_loss: 1.7032\n",
      "Epoch 18/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8389 - val_loss: 1.8346\n",
      "Epoch 19/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8246 - val_loss: 1.7902\n",
      "Epoch 20/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8086 - val_loss: 1.8867\n",
      "Epoch 21/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7921 - val_loss: 1.7656\n",
      "Epoch 22/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8060 - val_loss: 1.6942\n",
      "Epoch 23/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.8002 - val_loss: 1.7201\n",
      "Epoch 24/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7779 - val_loss: 1.7227\n",
      "Epoch 25/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7734 - val_loss: 1.8295\n",
      "Epoch 26/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7784 - val_loss: 1.7290\n",
      "Epoch 27/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7676 - val_loss: 1.8385\n",
      "Epoch 28/200\n",
      "1757/1757 [==============================] - 8s - loss: 1.7579 - val_loss: 1.7085\n",
      "Epoch 29/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7640 - val_loss: 1.7145\n",
      "Epoch 30/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7615 - val_loss: 1.7035\n",
      "Epoch 31/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7566 - val_loss: 1.8935\n",
      "Epoch 32/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7622 - val_loss: 1.7149\n",
      "Epoch 33/200\n",
      "1752/1757 [============================>.] - ETA: 0s - loss: 1.7537\n",
      " Reduced learning rate to 0.01\n",
      "1757/1757 [==============================] - 11s - loss: 1.7537 - val_loss: 1.8253\n",
      "Epoch 34/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6863 - val_loss: 1.6719\n",
      "Epoch 35/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6836\n",
      " Reduced learning rate to 0.005\n",
      "1757/1757 [==============================] - 9s - loss: 1.6836 - val_loss: 1.6719\n",
      "Epoch 36/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6769\n",
      " Reduced learning rate to 0.0025\n",
      "1757/1757 [==============================] - 9s - loss: 1.6769 - val_loss: 1.6758\n",
      "Epoch 37/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6819 - val_loss: 1.6692\n",
      "Epoch 38/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6752\n",
      " Reduced learning rate to 0.00125\n",
      "1757/1757 [==============================] - 9s - loss: 1.6753 - val_loss: 1.6730\n",
      "Epoch 39/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6743\n",
      " Reduced learning rate to 0.000625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6744 - val_loss: 1.6695\n",
      "Epoch 40/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6783\n",
      " Reduced learning rate to 0.0003125\n",
      "1757/1757 [==============================] - 9s - loss: 1.6781 - val_loss: 1.6719\n",
      "Epoch 41/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6765 - val_loss: 1.6691\n",
      "Epoch 42/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6745\n",
      " Reduced learning rate to 0.00015625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6743 - val_loss: 1.6719\n",
      "Epoch 43/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6802\n",
      " Reduced learning rate to 7.8125e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6799 - val_loss: 1.6812\n",
      "Epoch 44/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6769 - val_loss: 1.6683\n",
      "Epoch 45/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6750\n",
      " Reduced learning rate to 3.90625e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6750 - val_loss: 1.6798\n",
      "Epoch 46/200\n",
      "1747/1757 [============================>.] - ETA: 0s - loss: 1.6754\n",
      " Reduced learning rate to 1.95312e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6755 - val_loss: 1.6808\n",
      "Epoch 47/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6785 - val_loss: 1.6664\n",
      "Epoch 48/200\n",
      "1751/1757 [============================>.] - ETA: 0s - loss: 1.6726\n",
      " Reduced learning rate to 9.76562e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6725 - val_loss: 1.6743\n",
      "Epoch 49/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6783\n",
      " Reduced learning rate to 4.88281e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6784 - val_loss: 1.6720\n",
      "Epoch 50/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6787\n",
      " Reduced learning rate to 2.44141e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6790 - val_loss: 1.6769\n",
      "Epoch 51/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6746 - val_loss: 1.6602\n",
      "Epoch 52/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6747\n",
      " Reduced learning rate to 1.2207e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6747 - val_loss: 1.6733\n",
      "Epoch 53/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6788\n",
      " Reduced learning rate to 6.10352e-07\n",
      "1757/1757 [==============================] - 9s - loss: 1.6789 - val_loss: 1.6871\n",
      "Epoch 1/200\n",
      "1757/1757 [==============================] - 13s - loss: 6.5128 - val_loss: 3.4061\n",
      "Epoch 2/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.9721 - val_loss: 2.4813\n",
      "Epoch 3/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.7301 - val_loss: 2.7341\n",
      "Epoch 4/200\n",
      "1757/1757 [==============================] - 10s - loss: 2.5518 - val_loss: 2.1800\n",
      "Epoch 5/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.4170 - val_loss: 2.3055\n",
      "Epoch 6/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.3149 - val_loss: 2.3838\n",
      "Epoch 7/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.2081 - val_loss: 2.4541\n",
      "Epoch 8/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.1369 - val_loss: 1.9951\n",
      "Epoch 9/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.0623 - val_loss: 2.2158\n",
      "Epoch 10/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.0350 - val_loss: 1.8505\n",
      "Epoch 11/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9849 - val_loss: 1.9347\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757/1757 [==============================] - 9s - loss: 1.9572 - val_loss: 1.8385\n",
      "Epoch 13/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9313 - val_loss: 1.8825\n",
      "Epoch 14/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9033 - val_loss: 1.8740\n",
      "Epoch 15/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8833 - val_loss: 1.9649\n",
      "Epoch 16/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8603 - val_loss: 1.8214\n",
      "Epoch 17/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8353 - val_loss: 1.7575\n",
      "Epoch 18/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8308 - val_loss: 1.9024\n",
      "Epoch 19/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8254 - val_loss: 1.7098\n",
      "Epoch 20/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8056 - val_loss: 1.8200\n",
      "Epoch 21/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8084 - val_loss: 1.8477\n",
      "Epoch 22/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7905 - val_loss: 1.8424\n",
      "Epoch 23/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8002 - val_loss: 1.7277\n",
      "Epoch 24/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7887 - val_loss: 1.7308\n",
      "Epoch 25/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7907 - val_loss: 1.7969\n",
      "Epoch 26/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7833 - val_loss: 1.7538\n",
      "Epoch 27/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7768 - val_loss: 1.6977\n",
      "Epoch 28/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7778 - val_loss: 1.7308\n",
      "Epoch 29/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7638 - val_loss: 1.9646\n",
      "Epoch 30/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7637 - val_loss: 1.7308\n",
      "Epoch 31/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7646 - val_loss: 1.7213\n",
      "Epoch 32/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7562 - val_loss: 1.6879\n",
      "Epoch 33/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7482 - val_loss: 1.7944\n",
      "Epoch 34/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7477 - val_loss: 1.7866\n",
      "Epoch 35/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7425 - val_loss: 1.7512\n",
      "Epoch 36/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7474 - val_loss: 1.7997\n",
      "Epoch 37/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7407 - val_loss: 1.9036\n",
      "Epoch 38/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7388 - val_loss: 1.6770\n",
      "Epoch 39/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7416 - val_loss: 1.6875\n",
      "Epoch 40/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7427 - val_loss: 1.7152\n",
      "Epoch 41/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7327 - val_loss: 1.6796\n",
      "Epoch 42/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7423 - val_loss: 1.6754\n",
      "Epoch 43/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7307 - val_loss: 1.6879\n",
      "Epoch 44/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7259 - val_loss: 1.7344\n",
      "Epoch 45/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7319 - val_loss: 1.6950\n",
      "Epoch 46/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7352 - val_loss: 1.6913\n",
      "Epoch 47/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7230 - val_loss: 1.6832\n",
      "Epoch 48/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7231 - val_loss: 1.7095\n",
      "Epoch 49/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7223 - val_loss: 1.6837\n",
      "Epoch 50/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7212 - val_loss: 1.7386\n",
      "Epoch 51/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7146 - val_loss: 1.6995\n",
      "Epoch 52/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7218 - val_loss: 1.7542\n",
      "Epoch 53/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.7208\n",
      " Reduced learning rate to 0.01\n",
      "1757/1757 [==============================] - 13s - loss: 1.7208 - val_loss: 1.7564\n",
      "Epoch 54/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6733 - val_loss: 1.6641\n",
      "Epoch 55/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6691 - val_loss: 1.6638\n",
      "Epoch 56/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6724\n",
      " Reduced learning rate to 0.005\n",
      "1757/1757 [==============================] - 9s - loss: 1.6724 - val_loss: 1.6691\n",
      "Epoch 57/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6716\n",
      " Reduced learning rate to 0.0025\n",
      "1757/1757 [==============================] - 9s - loss: 1.6715 - val_loss: 1.6644\n",
      "Epoch 58/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6696 - val_loss: 1.6535\n",
      "Epoch 59/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6706\n",
      " Reduced learning rate to 0.00125\n",
      "1757/1757 [==============================] - 9s - loss: 1.6704 - val_loss: 1.6562\n",
      "Epoch 60/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6681\n",
      " Reduced learning rate to 0.000625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6684 - val_loss: 1.6641\n",
      "Epoch 61/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6658\n",
      " Reduced learning rate to 0.0003125\n",
      "1757/1757 [==============================] - 9s - loss: 1.6658 - val_loss: 1.6656\n",
      "Epoch 62/200\n",
      "1747/1757 [============================>.] - ETA: 0s - loss: 1.6637\n",
      " Reduced learning rate to 0.00015625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6635 - val_loss: 1.6605\n",
      "Epoch 63/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6618\n",
      " Reduced learning rate to 7.8125e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6618 - val_loss: 1.6574\n",
      "Epoch 64/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6609\n",
      " Reduced learning rate to 3.90625e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6607 - val_loss: 1.6679\n",
      "Epoch 65/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6629\n",
      " Reduced learning rate to 1.95312e-05\n",
      "1757/1757 [==============================] - 10s - loss: 1.6628 - val_loss: 1.6617\n",
      "Epoch 66/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6632 - val_loss: 1.6520\n",
      "Epoch 67/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6636\n",
      " Reduced learning rate to 9.76562e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6637 - val_loss: 1.6562\n",
      "Epoch 68/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6647\n",
      " Reduced learning rate to 4.88281e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6649 - val_loss: 1.6625\n",
      "Epoch 69/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6651\n",
      " Reduced learning rate to 2.44141e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6650 - val_loss: 1.6720\n",
      "Epoch 70/200\n",
      "1753/1757 [============================>.] - ETA: 0s - loss: 1.6661\n",
      " Reduced learning rate to 1.2207e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6662 - val_loss: 1.6602\n",
      "Epoch 71/200\n",
      "1747/1757 [============================>.] - ETA: 0s - loss: 1.6645\n",
      " Reduced learning rate to 6.10352e-07\n",
      "1757/1757 [==============================] - 9s - loss: 1.6645 - val_loss: 1.6605\n",
      "Epoch 1/200\n",
      "1757/1757 [==============================] - 13s - loss: 6.2447 - val_loss: 2.6721\n",
      "Epoch 2/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.9769 - val_loss: 2.5967\n",
      "Epoch 3/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.7436 - val_loss: 2.8750\n",
      "Epoch 4/200\n",
      "1757/1757 [==============================] - 10s - loss: 2.5478 - val_loss: 2.0222\n",
      "Epoch 5/200\n",
      "1757/1757 [==============================] - 10s - loss: 2.4108 - val_loss: 2.2227\n",
      "Epoch 6/200\n",
      "1757/1757 [==============================] - 10s - loss: 2.2721 - val_loss: 2.1884\n",
      "Epoch 7/200\n",
      "1757/1757 [==============================] - 10s - loss: 2.1953 - val_loss: 2.7415\n",
      "Epoch 8/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.1190 - val_loss: 2.4807\n",
      "Epoch 9/200\n",
      "1757/1757 [==============================] - 9s - loss: 2.0494 - val_loss: 2.0107\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1757/1757 [==============================] - 9s - loss: 1.9991 - val_loss: 2.0420\n",
      "Epoch 11/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.9830 - val_loss: 1.8005\n",
      "Epoch 12/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.9254 - val_loss: 2.2890\n",
      "Epoch 13/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.9146 - val_loss: 2.1604\n",
      "Epoch 14/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.8834 - val_loss: 1.7788\n",
      "Epoch 15/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8482 - val_loss: 1.7085\n",
      "Epoch 16/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8481 - val_loss: 1.7187\n",
      "Epoch 17/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8319 - val_loss: 1.7384\n",
      "Epoch 18/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8076 - val_loss: 1.8904\n",
      "Epoch 19/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8169 - val_loss: 1.7434\n",
      "Epoch 20/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.8106 - val_loss: 1.8424\n",
      "Epoch 21/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7994 - val_loss: 1.8671\n",
      "Epoch 22/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7918 - val_loss: 1.7071\n",
      "Epoch 23/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7819 - val_loss: 1.7617\n",
      "Epoch 24/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7692 - val_loss: 1.6988\n",
      "Epoch 25/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7802 - val_loss: 1.7227\n",
      "Epoch 26/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7724 - val_loss: 1.7202\n",
      "Epoch 27/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7690 - val_loss: 1.6965\n",
      "Epoch 28/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7600 - val_loss: 2.0480\n",
      "Epoch 29/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7583 - val_loss: 1.7291\n",
      "Epoch 30/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7632 - val_loss: 1.7187\n",
      "Epoch 31/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7489 - val_loss: 1.7904\n",
      "Epoch 32/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7459 - val_loss: 1.7589\n",
      "Epoch 33/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7520 - val_loss: 1.6890\n",
      "Epoch 34/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7464 - val_loss: 1.6926\n",
      "Epoch 35/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7376 - val_loss: 1.6733\n",
      "Epoch 36/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7344 - val_loss: 1.8203\n",
      "Epoch 37/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7374 - val_loss: 1.6832\n",
      "Epoch 38/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7344 - val_loss: 1.7621\n",
      "Epoch 39/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7277 - val_loss: 1.6812\n",
      "Epoch 40/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7354 - val_loss: 1.6861\n",
      "Epoch 41/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7202 - val_loss: 1.7345\n",
      "Epoch 42/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7270 - val_loss: 1.7224\n",
      "Epoch 43/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7224 - val_loss: 1.6942\n",
      "Epoch 44/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.7220 - val_loss: 1.6978\n",
      "Epoch 45/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.7251 - val_loss: 1.6733\n",
      "Epoch 46/200\n",
      "1752/1757 [============================>.] - ETA: 0s - loss: 1.7192\n",
      " Reduced learning rate to 0.01\n",
      "1757/1757 [==============================] - 12s - loss: 1.7194 - val_loss: 1.7199\n",
      "Epoch 47/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6733 - val_loss: 1.6641\n",
      "Epoch 48/200\n",
      "1754/1757 [============================>.] - ETA: 0s - loss: 1.6726\n",
      " Reduced learning rate to 0.005\n",
      "1757/1757 [==============================] - 9s - loss: 1.6726 - val_loss: 1.6691\n",
      "Epoch 49/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6686 - val_loss: 1.6626\n",
      "Epoch 50/200\n",
      "1756/1757 [============================>.] - ETA: 0s - loss: 1.6675\n",
      " Reduced learning rate to 0.0025\n",
      "1757/1757 [==============================] - 9s - loss: 1.6675 - val_loss: 1.6665\n",
      "Epoch 51/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6688\n",
      " Reduced learning rate to 0.00125\n",
      "1757/1757 [==============================] - 9s - loss: 1.6688 - val_loss: 1.6641\n",
      "Epoch 52/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6725\n",
      " Reduced learning rate to 0.000625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6724 - val_loss: 1.6655\n",
      "Epoch 53/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6667 - val_loss: 1.6604\n",
      "Epoch 54/200\n",
      "1757/1757 [==============================] - 10s - loss: 1.6629 - val_loss: 1.6578\n",
      "Epoch 55/200\n",
      "1755/1757 [============================>.] - ETA: 0s - loss: 1.6700\n",
      " Reduced learning rate to 0.0003125\n",
      "1757/1757 [==============================] - 9s - loss: 1.6705 - val_loss: 1.6692\n",
      "Epoch 56/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6675 - val_loss: 1.6565\n",
      "Epoch 57/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6673\n",
      " Reduced learning rate to 0.00015625\n",
      "1757/1757 [==============================] - 9s - loss: 1.6673 - val_loss: 1.6566\n",
      "Epoch 58/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6700\n",
      " Reduced learning rate to 7.8125e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6700 - val_loss: 1.6679\n",
      "Epoch 59/200\n",
      "1757/1757 [==============================] - 9s - loss: 1.6661 - val_loss: 1.6550\n",
      "Epoch 60/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6692\n",
      " Reduced learning rate to 3.90625e-05\n",
      "1757/1757 [==============================] - 10s - loss: 1.6691 - val_loss: 1.6676\n",
      "Epoch 61/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6663\n",
      " Reduced learning rate to 1.95312e-05\n",
      "1757/1757 [==============================] - 9s - loss: 1.6663 - val_loss: 1.6562\n",
      "Epoch 62/200\n",
      "1750/1757 [============================>.] - ETA: 0s - loss: 1.6647\n",
      " Reduced learning rate to 9.76562e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6646 - val_loss: 1.6640\n",
      "Epoch 63/200\n",
      "1754/1757 [============================>.] - ETA: 0s - loss: 1.6686\n",
      " Reduced learning rate to 4.88281e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6685 - val_loss: 1.6629\n",
      "Epoch 64/200\n",
      "1749/1757 [============================>.] - ETA: 0s - loss: 1.6612\n",
      " Reduced learning rate to 2.44141e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6612 - val_loss: 1.6641\n",
      "Epoch 65/200\n",
      "1748/1757 [============================>.] - ETA: 0s - loss: 1.6682\n",
      " Reduced learning rate to 1.2207e-06\n",
      "1757/1757 [==============================] - 9s - loss: 1.6680 - val_loss: 1.6676\n",
      "Epoch 66/200\n",
      "1752/1757 [============================>.] - ETA: 0s - loss: 1.6723\n",
      " Reduced learning rate to 6.10352e-07\n",
      "1757/1757 [==============================] - 10s - loss: 1.6724 - val_loss: 1.6641\n"
     ]
    }
   ],
   "source": [
    "n_train = [5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "ensemble_size = 5 \n",
    "for n in n_train:\n",
    "    qrnn = QRNN(5, quantiles, 3, 128, ensemble_size = ensemble_size)\n",
    "    qrnn.fit(x_train[:n,:], y_train[:n], 1.0, initial_learning_rate = 0.01, minimum_learning_rate = 1e-5)\n",
    "    qrnn.save(\"models/qrnn_\"+ str(ensemble_size) + \"_\" + str(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10  Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qrnn.model.save(\"qrnn_5_1000000_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/x_train_10.npy\")\n",
    "y_train = np.load(\"data/y_train_10.npy\")\n",
    "quantiles = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = [5000, 10000, 50000, 100000, 500000, 1000000]\n",
    "for n in n_train:\n",
    "    qrnn = QRNN(10, quantiles, 3, 256)\n",
    "    qrnn.fit(x_train[:n,:], y_train[:n], 1.0)\n",
    "    qrnn.save(\"qrnn_\"+ str(qrnn.input_dim) + \"_\" + str(n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

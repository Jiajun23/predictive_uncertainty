{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib_settings\n",
    "from typhon.retrieval.qrnn import QRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"data/x_train_5.npy\")\n",
    "y_train = np.load(\"data/y_train_5.npy\")\n",
    "x_mean  = x_train.mean(axis=0, keepdims=True)\n",
    "x_sigma = x_train.std(axis=0,  keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "qrnn = QRNN(5, quantiles, 2, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "17/17 [==============================] - 0s - loss: 40.4321 - val_loss: 7.7970\n",
      "Epoch 2/200\n",
      "17/17 [==============================] - 0s - loss: 19.3145 - val_loss: 53.1140\n",
      "Epoch 3/200\n",
      "17/17 [==============================] - 0s - loss: 21.8985 - val_loss: 10.9789\n",
      "Epoch 4/200\n",
      "17/17 [==============================] - 0s - loss: 18.0767 - val_loss: 13.5530\n",
      "Epoch 5/200\n",
      "17/17 [==============================] - 0s - loss: 17.8018 - val_loss: 15.3350\n",
      "Epoch 6/200\n",
      "17/17 [==============================] - 0s - loss: 15.0296 - val_loss: 29.6240\n",
      "Epoch 7/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 15.3429\n",
      " Reduced learning rate to 0.1\n",
      "17/17 [==============================] - 0s - loss: 14.8940 - val_loss: 16.5551\n",
      "Epoch 8/200\n",
      "17/17 [==============================] - 0s - loss: 7.2336 - val_loss: 14.8648\n",
      "Epoch 9/200\n",
      "17/17 [==============================] - 0s - loss: 7.4840 - val_loss: 19.2207\n",
      "Epoch 10/200\n",
      "17/17 [==============================] - 0s - loss: 7.8074 - val_loss: 15.5564\n",
      "Epoch 11/200\n",
      "17/17 [==============================] - 0s - loss: 7.5312 - val_loss: 21.2871\n",
      "Epoch 12/200\n",
      "17/17 [==============================] - 0s - loss: 7.3503 - val_loss: 16.7684\n",
      "Epoch 13/200\n",
      "13/17 [=====================>........] - ETA: 0s - loss: 7.4482\n",
      " Reduced learning rate to 0.05\n",
      "17/17 [==============================] - 0s - loss: 7.5954 - val_loss: 22.8643\n",
      "Epoch 14/200\n",
      "17/17 [==============================] - 0s - loss: 3.7410 - val_loss: 20.1204\n",
      "Epoch 15/200\n",
      "17/17 [==============================] - 0s - loss: 3.9279 - val_loss: 24.1104\n",
      "Epoch 16/200\n",
      "17/17 [==============================] - 0s - loss: 3.9385 - val_loss: 22.3350\n",
      "Epoch 17/200\n",
      "17/17 [==============================] - 0s - loss: 3.9785 - val_loss: 25.9263\n",
      "Epoch 18/200\n",
      "17/17 [==============================] - 0s - loss: 3.8913 - val_loss: 24.1473\n",
      "Epoch 19/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 4.0923\n",
      " Reduced learning rate to 0.025\n",
      "17/17 [==============================] - 0s - loss: 3.8883 - val_loss: 27.3766\n",
      "Epoch 20/200\n",
      "17/17 [==============================] - 0s - loss: 2.5009 - val_loss: 27.8120\n",
      "Epoch 21/200\n",
      "17/17 [==============================] - 0s - loss: 2.3206 - val_loss: 28.4215\n",
      "Epoch 22/200\n",
      "17/17 [==============================] - 0s - loss: 2.3417 - val_loss: 29.4770\n",
      "Epoch 23/200\n",
      "17/17 [==============================] - 0s - loss: 2.3245 - val_loss: 30.6685\n",
      "Epoch 24/200\n",
      "17/17 [==============================] - 0s - loss: 2.3208 - val_loss: 31.7364\n",
      "Epoch 25/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.1767\n",
      " Reduced learning rate to 0.0125\n",
      "17/17 [==============================] - 0s - loss: 2.2520 - val_loss: 32.9877\n",
      "Epoch 26/200\n",
      "17/17 [==============================] - 0s - loss: 2.2138 - val_loss: 33.5723\n",
      "Epoch 27/200\n",
      "17/17 [==============================] - 0s - loss: 2.1982 - val_loss: 35.0573\n",
      "Epoch 28/200\n",
      "17/17 [==============================] - 0s - loss: 2.2102 - val_loss: 35.1847\n",
      "Epoch 29/200\n",
      "17/17 [==============================] - 0s - loss: 2.1591 - val_loss: 35.6640\n",
      "Epoch 30/200\n",
      "17/17 [==============================] - 0s - loss: 2.2026 - val_loss: 36.4991\n",
      "Epoch 31/200\n",
      "10/17 [================>.............] - ETA: 0s - loss: 2.1605\n",
      " Reduced learning rate to 0.00625\n",
      "17/17 [==============================] - 0s - loss: 2.1863 - val_loss: 37.6461\n",
      "Epoch 32/200\n",
      "17/17 [==============================] - 0s - loss: 2.1650 - val_loss: 38.7848\n",
      "Epoch 33/200\n",
      "17/17 [==============================] - 0s - loss: 2.1351 - val_loss: 40.3263\n",
      "Epoch 34/200\n",
      "17/17 [==============================] - 0s - loss: 2.1532 - val_loss: 41.0084\n",
      "Epoch 35/200\n",
      "17/17 [==============================] - 0s - loss: 2.1384 - val_loss: 41.4923\n",
      "Epoch 36/200\n",
      "17/17 [==============================] - 0s - loss: 2.1450 - val_loss: 42.0032\n",
      "Epoch 37/200\n",
      "10/17 [================>.............] - ETA: 0s - loss: 2.2086\n",
      " Reduced learning rate to 0.003125\n",
      "17/17 [==============================] - 0s - loss: 2.1616 - val_loss: 42.6344\n",
      "Epoch 38/200\n",
      "17/17 [==============================] - 0s - loss: 2.1573 - val_loss: 43.4346\n",
      "Epoch 39/200\n",
      "17/17 [==============================] - 0s - loss: 2.0942 - val_loss: 43.8214\n",
      "Epoch 40/200\n",
      "17/17 [==============================] - 0s - loss: 2.1288 - val_loss: 44.8864\n",
      "Epoch 41/200\n",
      "17/17 [==============================] - 0s - loss: 2.1431 - val_loss: 45.8457\n",
      "Epoch 42/200\n",
      "17/17 [==============================] - 0s - loss: 2.1570 - val_loss: 46.8964\n",
      "Epoch 43/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.1301\n",
      " Reduced learning rate to 0.0015625\n",
      "17/17 [==============================] - 0s - loss: 2.1105 - val_loss: 47.5313\n",
      "Epoch 44/200\n",
      "17/17 [==============================] - 0s - loss: 2.1037 - val_loss: 47.9639\n",
      "Epoch 45/200\n",
      "17/17 [==============================] - 0s - loss: 2.1088 - val_loss: 48.2989\n",
      "Epoch 46/200\n",
      "17/17 [==============================] - 0s - loss: 2.1210 - val_loss: 48.8780\n",
      "Epoch 47/200\n",
      "17/17 [==============================] - 0s - loss: 2.1010 - val_loss: 49.4710\n",
      "Epoch 48/200\n",
      "17/17 [==============================] - 0s - loss: 2.0786 - val_loss: 49.8226\n",
      "Epoch 49/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1442\n",
      " Reduced learning rate to 0.00078125\n",
      "17/17 [==============================] - 0s - loss: 2.1076 - val_loss: 50.4717\n",
      "Epoch 50/200\n",
      "17/17 [==============================] - 0s - loss: 2.1278 - val_loss: 50.7859\n",
      "Epoch 51/200\n",
      "17/17 [==============================] - 0s - loss: 2.1122 - val_loss: 51.5203\n",
      "Epoch 52/200\n",
      "17/17 [==============================] - 0s - loss: 2.0923 - val_loss: 51.8620\n",
      "Epoch 53/200\n",
      "17/17 [==============================] - 0s - loss: 2.1073 - val_loss: 53.2688\n",
      "Epoch 54/200\n",
      "17/17 [==============================] - 0s - loss: 2.1061 - val_loss: 53.7226\n",
      "Epoch 55/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.0577\n",
      " Reduced learning rate to 0.000390625\n",
      "17/17 [==============================] - 0s - loss: 2.1212 - val_loss: 54.7298\n",
      "Epoch 56/200\n",
      "17/17 [==============================] - 0s - loss: 2.1232 - val_loss: 55.4512\n",
      "Epoch 57/200\n",
      "17/17 [==============================] - 0s - loss: 2.1304 - val_loss: 55.7461\n",
      "Epoch 58/200\n",
      "17/17 [==============================] - 0s - loss: 2.1087 - val_loss: 55.5537\n",
      "Epoch 59/200\n",
      "17/17 [==============================] - 0s - loss: 2.0978 - val_loss: 56.3809\n",
      "Epoch 60/200\n",
      "17/17 [==============================] - 0s - loss: 2.0858 - val_loss: 57.2021\n",
      "Epoch 61/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.0615\n",
      " Reduced learning rate to 0.000195313\n",
      "17/17 [==============================] - 0s - loss: 2.1117 - val_loss: 57.5100\n",
      "Epoch 62/200\n",
      "17/17 [==============================] - 0s - loss: 2.1045 - val_loss: 57.4792\n",
      "Epoch 63/200\n",
      "17/17 [==============================] - 0s - loss: 2.1100 - val_loss: 58.0207\n",
      "Epoch 64/200\n",
      "17/17 [==============================] - 0s - loss: 2.0729 - val_loss: 58.5852\n",
      "Epoch 65/200\n",
      "17/17 [==============================] - 0s - loss: 2.0961 - val_loss: 58.9900\n",
      "Epoch 66/200\n",
      "17/17 [==============================] - 0s - loss: 2.1164 - val_loss: 59.1531\n",
      "Epoch 67/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1522\n",
      " Reduced learning rate to 9.76563e-05\n",
      "17/17 [==============================] - 0s - loss: 2.1040 - val_loss: 59.2393\n",
      "Epoch 68/200\n",
      "17/17 [==============================] - 0s - loss: 2.1034 - val_loss: 59.3254\n",
      "Epoch 69/200\n",
      "17/17 [==============================] - 0s - loss: 2.0659 - val_loss: 60.3740\n",
      "Epoch 70/200\n",
      "17/17 [==============================] - 0s - loss: 2.0975 - val_loss: 61.4309\n",
      "Epoch 71/200\n",
      "17/17 [==============================] - 0s - loss: 2.0814 - val_loss: 61.6550\n",
      "Epoch 72/200\n",
      "17/17 [==============================] - 0s - loss: 2.1301 - val_loss: 62.1581\n",
      "Epoch 73/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 1.886 - ETA: 0s - loss: 2.1447\n",
      " Reduced learning rate to 4.88281e-05\n",
      "17/17 [==============================] - 0s - loss: 2.1282 - val_loss: 62.4875\n",
      "Epoch 74/200\n",
      "17/17 [==============================] - 0s - loss: 2.1062 - val_loss: 62.5674\n",
      "Epoch 75/200\n",
      "17/17 [==============================] - 0s - loss: 2.1147 - val_loss: 63.2178\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s - loss: 2.1076 - val_loss: 63.9238\n",
      "Epoch 77/200\n",
      "17/17 [==============================] - 0s - loss: 2.0909 - val_loss: 65.1902\n",
      "Epoch 78/200\n",
      "17/17 [==============================] - 0s - loss: 2.1024 - val_loss: 65.6301\n",
      "Epoch 79/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.1386\n",
      " Reduced learning rate to 2.44141e-05\n",
      "17/17 [==============================] - 0s - loss: 2.1015 - val_loss: 66.6027\n",
      "Epoch 80/200\n",
      "17/17 [==============================] - 0s - loss: 2.1009 - val_loss: 66.8938\n",
      "Epoch 81/200\n",
      "17/17 [==============================] - 0s - loss: 2.1285 - val_loss: 67.7206\n",
      "Epoch 82/200\n",
      "17/17 [==============================] - 0s - loss: 2.0908 - val_loss: 68.8498\n",
      "Epoch 83/200\n",
      "17/17 [==============================] - 0s - loss: 2.1327 - val_loss: 69.8440\n",
      "Epoch 84/200\n",
      "17/17 [==============================] - 0s - loss: 2.1335 - val_loss: 70.3484\n",
      "Epoch 85/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1003\n",
      " Reduced learning rate to 1.2207e-05\n",
      "17/17 [==============================] - 0s - loss: 2.1034 - val_loss: 71.2531\n",
      "Epoch 86/200\n",
      "17/17 [==============================] - 0s - loss: 2.1204 - val_loss: 71.8913\n",
      "Epoch 87/200\n",
      "17/17 [==============================] - 0s - loss: 2.1382 - val_loss: 71.9134\n",
      "Epoch 88/200\n",
      "17/17 [==============================] - 0s - loss: 2.1172 - val_loss: 72.7042\n",
      "Epoch 89/200\n",
      "17/17 [==============================] - 0s - loss: 2.1040 - val_loss: 73.1896\n",
      "Epoch 90/200\n",
      "17/17 [==============================] - 0s - loss: 2.0639 - val_loss: 73.7452\n",
      "Epoch 91/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.0262\n",
      " Reduced learning rate to 6.10352e-06\n",
      "17/17 [==============================] - 0s - loss: 2.0945 - val_loss: 73.7031\n",
      "Epoch 92/200\n",
      "17/17 [==============================] - 0s - loss: 2.0823 - val_loss: 74.2118\n",
      "Epoch 93/200\n",
      "17/17 [==============================] - 0s - loss: 2.1224 - val_loss: 74.3377\n",
      "Epoch 94/200\n",
      "17/17 [==============================] - 0s - loss: 2.0663 - val_loss: 74.9961\n",
      "Epoch 95/200\n",
      "17/17 [==============================] - 0s - loss: 2.0954 - val_loss: 76.0311\n",
      "Epoch 96/200\n",
      "17/17 [==============================] - 0s - loss: 2.1049 - val_loss: 76.9863\n",
      "Epoch 97/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1026\n",
      " Reduced learning rate to 3.05176e-06\n",
      "17/17 [==============================] - 0s - loss: 2.0957 - val_loss: 77.6395\n",
      "Epoch 98/200\n",
      "17/17 [==============================] - 0s - loss: 2.1143 - val_loss: 77.3574\n",
      "Epoch 99/200\n",
      "17/17 [==============================] - 0s - loss: 2.1122 - val_loss: 77.0925\n",
      "Epoch 100/200\n",
      "17/17 [==============================] - 0s - loss: 2.1019 - val_loss: 77.2305\n",
      "Epoch 101/200\n",
      "17/17 [==============================] - 0s - loss: 2.1110 - val_loss: 78.2598\n",
      "Epoch 102/200\n",
      "17/17 [==============================] - 0s - loss: 2.1044 - val_loss: 77.9832\n",
      "Epoch 103/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1793\n",
      " Reduced learning rate to 1.52588e-06\n",
      "17/17 [==============================] - 0s - loss: 2.1209 - val_loss: 78.7129\n",
      "Epoch 104/200\n",
      "17/17 [==============================] - 0s - loss: 2.1085 - val_loss: 79.1750\n",
      "Epoch 105/200\n",
      "17/17 [==============================] - 0s - loss: 2.0804 - val_loss: 79.3353\n",
      "Epoch 106/200\n",
      "17/17 [==============================] - 0s - loss: 2.1291 - val_loss: 80.1135\n",
      "Epoch 107/200\n",
      "17/17 [==============================] - 0s - loss: 2.0966 - val_loss: 80.6836\n",
      "Epoch 108/200\n",
      "17/17 [==============================] - 0s - loss: 2.0734 - val_loss: 81.3424\n",
      "Epoch 109/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.1832\n",
      " Reduced learning rate to 7.62939e-07\n",
      "17/17 [==============================] - 0s - loss: 2.1334 - val_loss: 81.6035\n",
      "Epoch 110/200\n",
      "17/17 [==============================] - 0s - loss: 2.1106 - val_loss: 81.7721\n",
      "Epoch 111/200\n",
      "17/17 [==============================] - 0s - loss: 2.1379 - val_loss: 82.7090\n",
      "Epoch 112/200\n",
      "17/17 [==============================] - 0s - loss: 2.0978 - val_loss: 83.2533\n",
      "Epoch 113/200\n",
      "17/17 [==============================] - 0s - loss: 2.1285 - val_loss: 83.3977\n",
      "Epoch 114/200\n",
      "17/17 [==============================] - 0s - loss: 2.1245 - val_loss: 83.6262\n",
      "Epoch 115/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1054\n",
      " Reduced learning rate to 3.8147e-07\n",
      "17/17 [==============================] - 0s - loss: 2.1099 - val_loss: 83.7513\n",
      "Epoch 116/200\n",
      "17/17 [==============================] - 0s - loss: 2.1241 - val_loss: 83.8888\n",
      "Epoch 117/200\n",
      "17/17 [==============================] - 0s - loss: 2.1191 - val_loss: 83.8625\n",
      "Epoch 118/200\n",
      "17/17 [==============================] - 0s - loss: 2.1332 - val_loss: 84.0906\n",
      "Epoch 119/200\n",
      "17/17 [==============================] - 0s - loss: 2.1140 - val_loss: 84.9447\n",
      "Epoch 120/200\n",
      "17/17 [==============================] - 0s - loss: 2.0968 - val_loss: 85.4199\n",
      "Epoch 121/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.0192\n",
      " Reduced learning rate to 1.90735e-07\n",
      "17/17 [==============================] - 0s - loss: 2.0870 - val_loss: 85.9329\n",
      "Epoch 122/200\n",
      "17/17 [==============================] - 0s - loss: 2.1148 - val_loss: 86.3450\n",
      "Epoch 123/200\n",
      "17/17 [==============================] - 0s - loss: 2.1004 - val_loss: 86.7324\n",
      "Epoch 124/200\n",
      "17/17 [==============================] - 0s - loss: 2.1143 - val_loss: 87.5665\n",
      "Epoch 125/200\n",
      "17/17 [==============================] - 0s - loss: 2.0863 - val_loss: 87.7143\n",
      "Epoch 126/200\n",
      "17/17 [==============================] - 0s - loss: 2.1068 - val_loss: 88.1818\n",
      "Epoch 127/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1466\n",
      " Reduced learning rate to 9.53674e-08\n",
      "17/17 [==============================] - 0s - loss: 2.1251 - val_loss: 89.2031\n",
      "Epoch 128/200\n",
      "17/17 [==============================] - 0s - loss: 2.1079 - val_loss: 89.4831\n",
      "Epoch 129/200\n",
      "17/17 [==============================] - 0s - loss: 2.1057 - val_loss: 89.2813\n",
      "Epoch 130/200\n",
      "17/17 [==============================] - 0s - loss: 2.0723 - val_loss: 90.1209\n",
      "Epoch 131/200\n",
      "17/17 [==============================] - 0s - loss: 2.1068 - val_loss: 90.6687\n",
      "Epoch 132/200\n",
      "17/17 [==============================] - 0s - loss: 2.1238 - val_loss: 91.2012\n",
      "Epoch 133/200\n",
      "11/17 [==================>...........] - ETA: 0s - loss: 2.1692\n",
      " Reduced learning rate to 4.76837e-08\n",
      "17/17 [==============================] - 0s - loss: 2.1270 - val_loss: 92.0703\n",
      "Epoch 134/200\n",
      "17/17 [==============================] - 0s - loss: 2.1204 - val_loss: 91.6289\n",
      "Epoch 135/200\n",
      "17/17 [==============================] - 0s - loss: 2.1114 - val_loss: 91.9884\n",
      "Epoch 136/200\n",
      "17/17 [==============================] - 0s - loss: 2.1218 - val_loss: 92.2697\n",
      "Epoch 137/200\n",
      "17/17 [==============================] - 0s - loss: 2.0963 - val_loss: 92.2364\n",
      "Epoch 138/200\n",
      "17/17 [==============================] - 0s - loss: 2.1205 - val_loss: 92.9856\n",
      "Epoch 139/200\n",
      "13/17 [=====================>........] - ETA: 0s - loss: 2.1306\n",
      " Reduced learning rate to 2.38419e-08\n",
      "17/17 [==============================] - 0s - loss: 2.1129 - val_loss: 93.9038\n",
      "Epoch 140/200\n",
      "17/17 [==============================] - 0s - loss: 2.0965 - val_loss: 94.3301s: 2.137\n",
      "Epoch 141/200\n",
      "17/17 [==============================] - 0s - loss: 2.1239 - val_loss: 94.7525\n",
      "Epoch 142/200\n",
      "17/17 [==============================] - 0s - loss: 2.1590 - val_loss: 95.9889\n",
      "Epoch 143/200\n",
      "17/17 [==============================] - 0s - loss: 2.0761 - val_loss: 96.1577\n",
      "Epoch 144/200\n",
      "17/17 [==============================] - 0s - loss: 2.1363 - val_loss: 96.4009\n",
      "Epoch 145/200\n",
      "12/17 [====================>.........] - ETA: 0s - loss: 2.1138\n",
      " Reduced learning rate to 1.19209e-08\n",
      "17/17 [==============================] - 0s - loss: 2.1112 - val_loss: 96.8373\n",
      "Epoch 146/200\n",
      "17/17 [==============================] - 0s - loss: 2.1118 - val_loss: 97.5529\n",
      "Epoch 147/200\n",
      "17/17 [==============================] - 0s - loss: 2.1286 - val_loss: 98.0978\n",
      "Epoch 148/200\n",
      "17/17 [==============================] - 0s - loss: 2.1141 - val_loss: 98.9471\n",
      "Epoch 149/200\n",
      "17/17 [==============================] - 0s - loss: 2.1254 - val_loss: 99.2090\n",
      "Epoch 150/200\n",
      "17/17 [==============================] - 0s - loss: 2.1070 - val_loss: 99.0799s: 2.046\n",
      "Epoch 151/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/17 [====================>.........] - ETA: 0s - loss: 2.0327\n",
      " Reduced learning rate to 5.96046e-09\n",
      "17/17 [==============================] - 0s - loss: 2.0792 - val_loss: 99.5169\n"
     ]
    }
   ],
   "source": [
    "qrnn.fit(x_train, y_train, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 146.50474944,  175.760782  ,  237.33642253,  265.90076508,\n",
       "         260.36461048]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x_train, axis = 0, keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrnn.save(\"qrnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrnn2 = QRNN.load(\"qrnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  19.57834053,   19.84030342,   20.02257347, ...,   20.54763794,\n",
       "          20.69142914,   20.92699623],\n",
       "       [   5.39958239,    5.50286007,    5.63548851, ...,    6.08992863,\n",
       "           6.21165657,    6.46132946],\n",
       "       [  18.81868744,   19.14671898,   19.39114952, ...,   20.0328331 ,\n",
       "          20.06956291,   20.42111206],\n",
       "       ..., \n",
       "       [  12.26674557,   12.62013435,   12.75143719, ...,   13.25910473,\n",
       "          13.46760368,   13.74556065],\n",
       "       [  23.78139305,   24.09221458,   24.34200096, ...,   24.96905899,\n",
       "          25.17671967,   25.54310799],\n",
       "       [ 124.22517395,  126.38543701,  127.82956696, ...,  134.44300842,\n",
       "         136.72247314,  140.0385437 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrnn2.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  20.18334057,    5.83043859,   19.32219261, ...,   13.12114782,\n",
       "         24.40540452,  139.03744003])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
